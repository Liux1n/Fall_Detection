{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.signal import resample\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/liuxinqing/Documents/FallAllD\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# change this to wherever you store the dataset\n",
    "dataset_dir = '/Users/liuxinqing/Documents/FallAllD'\n",
    "os.chdir(dataset_dir)\n",
    "\n",
    "oldDir=os.getcwd()\n",
    "ParentDir=os.getcwd()\n",
    "print(oldDir)\n",
    "FileNamesAll=os.listdir(dataset_dir)\n",
    "FileNames=[]\n",
    "for f_name in FileNamesAll:\n",
    "    if f_name.endswith('_A.dat'):\n",
    "        FileNames.append(f_name)\n",
    "LL=len(FileNames)\n",
    "\n",
    "l_SubjectID=[]\n",
    "l_Device=[]\n",
    "l_ActivityID=[]\n",
    "l_TrialNo=[]\n",
    "l_Acc=[]\n",
    "l_Gyr=[]\n",
    "l_Mag=[]\n",
    "l_Bar=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File  1  out of 6605\n",
      "File  101  out of 6605\n",
      "File  201  out of 6605\n",
      "File  301  out of 6605\n",
      "File  401  out of 6605\n",
      "File  501  out of 6605\n",
      "File  601  out of 6605\n",
      "File  701  out of 6605\n",
      "File  801  out of 6605\n",
      "File  901  out of 6605\n",
      "File  1001  out of 6605\n",
      "File  1101  out of 6605\n",
      "File  1201  out of 6605\n",
      "File  1301  out of 6605\n",
      "File  1401  out of 6605\n",
      "File  1501  out of 6605\n",
      "File  1601  out of 6605\n",
      "File  1701  out of 6605\n",
      "File  1801  out of 6605\n",
      "File  1901  out of 6605\n",
      "File  2001  out of 6605\n",
      "File  2101  out of 6605\n",
      "File  2201  out of 6605\n",
      "File  2301  out of 6605\n",
      "File  2401  out of 6605\n",
      "File  2501  out of 6605\n",
      "File  2601  out of 6605\n",
      "File  2701  out of 6605\n",
      "File  2801  out of 6605\n",
      "File  2901  out of 6605\n",
      "File  3001  out of 6605\n",
      "File  3101  out of 6605\n",
      "File  3201  out of 6605\n",
      "File  3301  out of 6605\n",
      "File  3401  out of 6605\n",
      "File  3501  out of 6605\n",
      "File  3601  out of 6605\n",
      "File  3701  out of 6605\n",
      "File  3801  out of 6605\n",
      "File  3901  out of 6605\n",
      "File  4001  out of 6605\n",
      "File  4101  out of 6605\n",
      "File  4201  out of 6605\n",
      "File  4301  out of 6605\n",
      "File  4401  out of 6605\n",
      "File  4501  out of 6605\n",
      "File  4601  out of 6605\n",
      "File  4701  out of 6605\n",
      "File  4801  out of 6605\n",
      "File  4901  out of 6605\n",
      "File  5001  out of 6605\n",
      "File  5101  out of 6605\n",
      "File  5201  out of 6605\n",
      "File  5301  out of 6605\n",
      "File  5401  out of 6605\n",
      "File  5501  out of 6605\n",
      "File  5601  out of 6605\n",
      "File  5701  out of 6605\n",
      "File  5801  out of 6605\n",
      "File  5901  out of 6605\n",
      "File  6001  out of 6605\n",
      "File  6101  out of 6605\n",
      "File  6201  out of 6605\n",
      "File  6301  out of 6605\n",
      "File  6401  out of 6605\n",
      "File  6501  out of 6605\n",
      "File  6601  out of 6605\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(LL):\n",
    "    f_name=FileNames[i]\n",
    "    SubjectID=int(f_name[1:3])    \n",
    "    l_SubjectID.append(np.uint8(SubjectID))\n",
    "    ActivityID=int(f_name[8:11])    \n",
    "    l_ActivityID.append(np.uint8(ActivityID))\n",
    "    TrialNo=int(f_name[13:15])    \n",
    "    l_TrialNo.append(np.uint8(TrialNo))\n",
    "    Device=''\n",
    "    if(int(f_name[5])==1):\n",
    "        Device='Neck'\n",
    "    else:\n",
    "        if (int(f_name[5])==2):\n",
    "            Device='Wrist'\n",
    "        else:\n",
    "            Device='Waist'    \n",
    "    l_Device.append(Device)\n",
    "    \n",
    "    l_Acc.append(np.int16(genfromtxt(f_name, delimiter=',')))\n",
    "    chArr=list(f_name)\n",
    "    chArr[16]='G'\n",
    "    f_name=\"\".join(chArr)    \n",
    "    l_Gyr.append(np.int16(genfromtxt(f_name, delimiter=',')))\n",
    "    chArr=list(f_name)\n",
    "    chArr[16]='M'\n",
    "    f_name=\"\".join(chArr)    \n",
    "    l_Mag.append(np.int16(genfromtxt(f_name, delimiter=',')))\n",
    "    chArr=list(f_name)\n",
    "    chArr[16]='B'\n",
    "    f_name=\"\".join(chArr)    \n",
    "    l_Bar.append(genfromtxt(f_name, delimiter=','))\n",
    "    if i%100==0:\n",
    "        print(f'File  {i+1}  out of {len(FileNames)}')\n",
    "    #print(f'File  {i+1}  out of {len(FileNames)}')\n",
    "os.chdir(oldDir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6j/7v412jf92t1f972gcdmx7l8w0000gn/T/ipykernel_86256/2004310300.py:6: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->Index(['Device', 'Acc', 'Gyr', 'Mag', 'Bar'], dtype='object')]\n",
      "\n",
      "  FallAllD.to_hdf('FallAllD.h5', key='df', mode='w')\n"
     ]
    }
   ],
   "source": [
    "FallAllD = pd.DataFrame(list(zip(l_SubjectID,l_Device,l_ActivityID,l_TrialNo,l_Acc,l_Gyr,l_Mag,l_Bar)), \n",
    "               columns =['SubjectID', 'Device','ActivityID','TrialNo','Acc','Gyr','Mag','Bar']) \n",
    "\n",
    "# .pkl and .h files are saved in the same directory as the dataset\n",
    "FallAllD.to_pickle('FallAllD.pkl')\n",
    "FallAllD.to_hdf('FallAllD.h5', key='df', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6605\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# change this to wherever you store the dataset\n",
    "dataset_dir = '/Users/liuxinqing/Documents/FallAllD'\n",
    "os.chdir(dataset_dir)\n",
    "\n",
    "# Load the data\n",
    "FallAllD = pd.read_pickle(f\"{dataset_dir}/FallAllD.pkl\")\n",
    "# Print the first few rows of the DataFrame\n",
    "#print(FallAllD.iloc[0])\n",
    "\n",
    "print(len(FallAllD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall files: 1722\n",
      "Not fall files: 4883\n"
     ]
    }
   ],
   "source": [
    "fall_files=[]\n",
    "not_fall_files=[]\n",
    "#TODO: Splitting into Fall and Not Fall based on ActivtyID2Str.m file\n",
    "\n",
    "# Define the range of ActivityIDs for fall and not fall\n",
    "fall_ids = list(range(101, 136))\n",
    "not_fall_ids = list(range(1, 45))\n",
    "\n",
    "for index, row in FallAllD.iterrows():\n",
    "    #print(row)\n",
    "    # Extract ActivityID from row\n",
    "    activity_id = int(row['ActivityID'])\n",
    "    #print(activity_id)\n",
    "    if activity_id in fall_ids:\n",
    "        fall_files.append(row)\n",
    "    elif activity_id in not_fall_ids:\n",
    "        not_fall_files.append(row)\n",
    "\n",
    "\n",
    "print(\"Fall files:\", len(fall_files))\n",
    "print(\"Not fall files:\", len(not_fall_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_files = sorted(fall_files, key=lambda x: x['ActivityID'])\n",
    "not_fall_files = sorted(not_fall_files, key=lambda x: x['ActivityID'])\n",
    "#print(fall_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_combined_data(\n",
    "        input_files, \n",
    "        mode, \n",
    "        sample_rate=None,\n",
    "        output_dir=None,\n",
    "        label=None,\n",
    "        ):\n",
    "    '''\n",
    "    mode: Acc / Acc+Gyr / Acc+Bar / Acc+Mag / Acc+Gyr+Bar\n",
    "    '''\n",
    "\n",
    "    #Acc (4760, 3)\n",
    "    #Gyr (4760, 3)\n",
    "    #Mag (1600, 3)\n",
    "    #Bar (200, 2)\n",
    "\n",
    "\n",
    "    acc_len = input_files[0]['Acc'].shape[0]\n",
    "    duration = int(acc_len / 238)\n",
    "\n",
    "    #print('duration', duration) #duration = 20  # 20 seconds\n",
    "    # Calculate the new number of samples\n",
    "    num_samples = sample_rate * duration # 40 * 20 = 800\n",
    "\n",
    "    # Create a list for the output data\n",
    "    output_data = []\n",
    "\n",
    "    for i in range(len(input_files)):\n",
    "        # Downsample the data for each sensor\n",
    "        input_files[i]['Acc'] = resample(input_files[i]['Acc'], num_samples)\n",
    "        input_files[i]['Gyr'] = resample(input_files[i]['Gyr'], num_samples)\n",
    "        input_files[i]['Mag'] = resample(input_files[i]['Mag'], num_samples)\n",
    "        input_files[i]['Bar'] = resample(input_files[i]['Bar'], num_samples)\n",
    "\n",
    "        # Append the data to the output list based on the mode\n",
    "        if mode == 'Acc':\n",
    "            output_data.append(input_files[i]['Acc'])\n",
    "        elif mode == 'Acc+Gyr':\n",
    "            output_data.append(np.concatenate((input_files[i]['Acc'], input_files[i]['Gyr']), axis=1))\n",
    "        elif mode == 'Acc+Bar':\n",
    "            output_data.append(np.concatenate((input_files[i]['Acc'], input_files[i]['Bar']), axis=1))\n",
    "        elif mode == 'Acc+Mag':\n",
    "            output_data.append(np.concatenate((input_files[i]['Acc'], input_files[i]['Mag']), axis=1))\n",
    "        elif mode == 'Acc+Gyr+Bar':\n",
    "            output_data.append(np.concatenate((input_files[i]['Acc'], input_files[i]['Gyr'], input_files[i]['Bar']), axis=1))\n",
    "\n",
    "\n",
    "    print('Acc', input_files[0]['Acc'].shape)\n",
    "    print('Gyr', input_files[0]['Gyr'].shape)\n",
    "    print('Mag', input_files[0]['Mag'].shape)\n",
    "    print('Bar', input_files[0]['Bar'].shape)\n",
    "\n",
    "    # Convert output_data to a numpy array\n",
    "    output_data = np.array(output_data)\n",
    "    print(output_data.shape) # (1722, 800, 8)\n",
    "\n",
    "\n",
    "    # Save the data under the output_dir\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    if label == 'fall':\n",
    "        np.save(f'{output_dir}/fall.npy', output_data)\n",
    "    elif label == 'not_fall':\n",
    "        np.save(f'{output_dir}/not_fall.npy', output_data)\n",
    "    #np.save(f'{output_dir}.npy', output_data)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc (400, 3)\n",
      "Gyr (400, 3)\n",
      "Mag (400, 3)\n",
      "Bar (400, 2)\n",
      "(1722, 400, 8)\n",
      "Acc (400, 3)\n",
      "Gyr (400, 3)\n",
      "Mag (400, 3)\n",
      "Bar (400, 2)\n",
      "(4883, 400, 8)\n"
     ]
    }
   ],
   "source": [
    "output_dir = '/Users/liuxinqing/Documents/combined_data'\n",
    "mode = 'Acc+Gyr+Bar'\n",
    "sample_rate = 20\n",
    "\n",
    "save_combined_data(fall_files, mode, sample_rate=sample_rate, output_dir=output_dir, label='fall')\n",
    "save_combined_data(not_fall_files, mode, sample_rate=sample_rate, output_dir=output_dir, label='not_fall')\n",
    "\n",
    "# Load the data from the .npy file\n",
    "#loaded_data = np.load(f'{output_dir}/{mode}.npy')\n",
    "\n",
    "#print(loaded_data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fall_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
