{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=16, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding='same')\n",
    "        self.bn2 = nn.BatchNorm1d(16)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=64, kernel_size=1)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.convr = nn.Conv1d(in_channels=in_channels, out_channels=64, kernel_size=1)\n",
    "    def forward(self, input):\n",
    "        residual = self.convr(input)\n",
    "        x = self.conv1(input)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x += residual\n",
    "        x = self.relu3(x)\n",
    "        return x\n",
    "\n",
    "class IdentityBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(IdentityBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=16, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding='same')\n",
    "        self.bn2 = nn.BatchNorm1d(16)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=64, kernel_size=1)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "    def forward(self, input):\n",
    "        residual = input\n",
    "        x = self.conv1(input)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x += residual\n",
    "        x = self.relu3(x)\n",
    "        return x\n",
    "\n",
    "class ResNet24(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet24, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=6, out_channels=64, kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.convblk1 = ConvBlock(64)\n",
    "        self.convblk2 = ConvBlock(64)\n",
    "        self.identityblk1 = IdentityBlock(64)\n",
    "        self.convblk3 = ConvBlock(64)\n",
    "        self.identityblk2 = IdentityBlock(64)\n",
    "        self.convblk4 = ConvBlock(64)\n",
    "        self.identityblk3 = IdentityBlock(64)\n",
    "        \n",
    "        self.pool2 = nn.AvgPool1d(2)\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.Flatten(),\n",
    "                                nn.Linear(in_features=704, out_features=2),\n",
    "                                nn.Softmax())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.convblk1(x)\n",
    "        x = self.convblk2(x)\n",
    "        x = self.identityblk1(x)\n",
    "        x = self.convblk3(x)\n",
    "        x = self.identityblk2(x)\n",
    "        x = self.convblk4(x)\n",
    "        x = self.identityblk3(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: ResNet24(\n",
      "  (conv1): Conv1d(6, 64, kernel_size=(3,), stride=(1,))\n",
      "  (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (convblk1): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (convblk2): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (identityblk1): IdentityBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "  )\n",
      "  (convblk3): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (identityblk2): IdentityBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "  )\n",
      "  (convblk4): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (identityblk3): IdentityBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "  )\n",
      "  (pool2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
      "  (fc): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=704, out_features=2, bias=True)\n",
      "    (2): Softmax(dim=None)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: conv1.weight | Size: torch.Size([64, 6, 3]) | Values : tensor([[[-2.2235e-01, -1.4260e-01,  1.5729e-01],\n",
      "         [-1.9581e-01, -6.3545e-03, -1.3683e-02],\n",
      "         [ 2.1635e-01, -3.4687e-03, -4.0331e-02],\n",
      "         [ 9.0165e-02, -9.3873e-02,  5.7027e-02],\n",
      "         [-8.7458e-02,  4.9456e-02, -1.9332e-01],\n",
      "         [-2.1955e-01,  2.0650e-01, -1.5125e-01]],\n",
      "\n",
      "        [[-4.1564e-02, -2.1007e-01, -1.1433e-01],\n",
      "         [ 8.5389e-02,  1.5519e-01,  2.3325e-01],\n",
      "         [ 1.7667e-01,  5.6613e-02, -2.3158e-01],\n",
      "         [-2.4867e-05, -9.8914e-03,  1.0309e-01],\n",
      "         [ 9.9222e-02,  1.9718e-01,  2.7003e-02],\n",
      "         [-1.8988e-01, -1.5811e-01,  8.8042e-02]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.bias | Size: torch.Size([64]) | Values : tensor([-0.1585, -0.0422], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.weight | Size: torch.Size([64, 64, 3]) | Values : tensor([[[-0.0259, -0.0509,  0.0325],\n",
      "         [-0.0247, -0.0679, -0.0215],\n",
      "         [ 0.0390, -0.0590, -0.0077],\n",
      "         [ 0.0387,  0.0309,  0.0376],\n",
      "         [-0.0104, -0.0123,  0.0302],\n",
      "         [ 0.0705, -0.0704, -0.0323],\n",
      "         [ 0.0588,  0.0585,  0.0495],\n",
      "         [ 0.0611,  0.0504,  0.0657],\n",
      "         [ 0.0648, -0.0110, -0.0583],\n",
      "         [ 0.0422,  0.0094, -0.0337],\n",
      "         [-0.0057,  0.0043, -0.0144],\n",
      "         [ 0.0032, -0.0337, -0.0363],\n",
      "         [ 0.0339,  0.0460, -0.0227],\n",
      "         [-0.0294, -0.0372,  0.0020],\n",
      "         [-0.0606, -0.0565, -0.0096],\n",
      "         [-0.0548,  0.0462,  0.0217],\n",
      "         [-0.0579,  0.0497, -0.0278],\n",
      "         [ 0.0560, -0.0292, -0.0576],\n",
      "         [-0.0608,  0.0363, -0.0511],\n",
      "         [-0.0271, -0.0075, -0.0162],\n",
      "         [ 0.0350,  0.0026, -0.0695],\n",
      "         [ 0.0065, -0.0468,  0.0421],\n",
      "         [-0.0268,  0.0155,  0.0168],\n",
      "         [-0.0536, -0.0185, -0.0330],\n",
      "         [-0.0668,  0.0085, -0.0167],\n",
      "         [ 0.0294,  0.0167, -0.0642],\n",
      "         [-0.0306, -0.0043,  0.0500],\n",
      "         [ 0.0509, -0.0005,  0.0372],\n",
      "         [ 0.0717, -0.0525,  0.0026],\n",
      "         [ 0.0487,  0.0587, -0.0269],\n",
      "         [-0.0700,  0.0270, -0.0589],\n",
      "         [ 0.0082, -0.0274,  0.0100],\n",
      "         [-0.0184,  0.0147,  0.0660],\n",
      "         [ 0.0717,  0.0104, -0.0484],\n",
      "         [ 0.0678, -0.0477,  0.0701],\n",
      "         [ 0.0226,  0.0486,  0.0592],\n",
      "         [-0.0704, -0.0652,  0.0690],\n",
      "         [ 0.0569, -0.0032, -0.0527],\n",
      "         [-0.0705, -0.0500,  0.0447],\n",
      "         [ 0.0374,  0.0651,  0.0576],\n",
      "         [-0.0261,  0.0256, -0.0394],\n",
      "         [-0.0340, -0.0611, -0.0243],\n",
      "         [ 0.0721, -0.0655, -0.0377],\n",
      "         [-0.0335,  0.0259,  0.0340],\n",
      "         [ 0.0558,  0.0247,  0.0434],\n",
      "         [-0.0289, -0.0198, -0.0105],\n",
      "         [-0.0121,  0.0413, -0.0670],\n",
      "         [-0.0067,  0.0538,  0.0094],\n",
      "         [-0.0515,  0.0205,  0.0482],\n",
      "         [-0.0002, -0.0336,  0.0597],\n",
      "         [ 0.0713,  0.0158,  0.0349],\n",
      "         [-0.0005,  0.0292, -0.0375],\n",
      "         [-0.0291, -0.0630, -0.0185],\n",
      "         [-0.0482, -0.0142, -0.0090],\n",
      "         [ 0.0324,  0.0378, -0.0259],\n",
      "         [-0.0328, -0.0594, -0.0404],\n",
      "         [-0.0103, -0.0661, -0.0426],\n",
      "         [ 0.0232,  0.0412, -0.0653],\n",
      "         [ 0.0224,  0.0411,  0.0143],\n",
      "         [ 0.0610,  0.0638,  0.0340],\n",
      "         [ 0.0024,  0.0404,  0.0251],\n",
      "         [-0.0655, -0.0264, -0.0105],\n",
      "         [-0.0692, -0.0066, -0.0351],\n",
      "         [ 0.0627,  0.0437, -0.0493]],\n",
      "\n",
      "        [[-0.0531,  0.0573, -0.0182],\n",
      "         [ 0.0347,  0.0189,  0.0429],\n",
      "         [-0.0120, -0.0451, -0.0481],\n",
      "         [ 0.0069,  0.0533, -0.0327],\n",
      "         [-0.0072, -0.0704, -0.0628],\n",
      "         [ 0.0673, -0.0547, -0.0654],\n",
      "         [ 0.0419,  0.0564, -0.0454],\n",
      "         [-0.0432, -0.0544,  0.0633],\n",
      "         [-0.0405, -0.0168, -0.0605],\n",
      "         [-0.0633, -0.0516,  0.0032],\n",
      "         [-0.0149,  0.0084, -0.0115],\n",
      "         [-0.0338,  0.0697, -0.0251],\n",
      "         [-0.0146,  0.0621,  0.0632],\n",
      "         [-0.0650,  0.0048,  0.0228],\n",
      "         [-0.0514, -0.0462,  0.0623],\n",
      "         [-0.0551, -0.0674,  0.0672],\n",
      "         [-0.0688,  0.0472,  0.0085],\n",
      "         [ 0.0043,  0.0272,  0.0178],\n",
      "         [ 0.0180, -0.0012,  0.0275],\n",
      "         [ 0.0302, -0.0537, -0.0683],\n",
      "         [-0.0347, -0.0143,  0.0677],\n",
      "         [-0.0642, -0.0318,  0.0553],\n",
      "         [ 0.0447,  0.0354,  0.0710],\n",
      "         [ 0.0052,  0.0612,  0.0529],\n",
      "         [ 0.0712, -0.0241, -0.0702],\n",
      "         [ 0.0411,  0.0228, -0.0533],\n",
      "         [-0.0671,  0.0635,  0.0312],\n",
      "         [-0.0374, -0.0531, -0.0209],\n",
      "         [ 0.0638,  0.0547,  0.0663],\n",
      "         [ 0.0216,  0.0307, -0.0277],\n",
      "         [ 0.0568, -0.0282,  0.0160],\n",
      "         [-0.0612, -0.0546,  0.0397],\n",
      "         [ 0.0036,  0.0244,  0.0645],\n",
      "         [ 0.0623,  0.0243,  0.0071],\n",
      "         [ 0.0140,  0.0371, -0.0268],\n",
      "         [-0.0316,  0.0585,  0.0462],\n",
      "         [ 0.0566,  0.0390,  0.0688],\n",
      "         [ 0.0425,  0.0687, -0.0361],\n",
      "         [-0.0027, -0.0074,  0.0313],\n",
      "         [-0.0521,  0.0160,  0.0662],\n",
      "         [-0.0576,  0.0254, -0.0089],\n",
      "         [ 0.0289, -0.0550,  0.0668],\n",
      "         [-0.0488,  0.0302, -0.0096],\n",
      "         [-0.0391, -0.0530,  0.0430],\n",
      "         [-0.0571, -0.0034,  0.0157],\n",
      "         [-0.0334,  0.0609, -0.0407],\n",
      "         [ 0.0363, -0.0593, -0.0282],\n",
      "         [-0.0059, -0.0301, -0.0475],\n",
      "         [-0.0115, -0.0183, -0.0254],\n",
      "         [ 0.0129, -0.0637,  0.0047],\n",
      "         [ 0.0379,  0.0303, -0.0076],\n",
      "         [ 0.0642,  0.0152,  0.0601],\n",
      "         [ 0.0630, -0.0173,  0.0079],\n",
      "         [ 0.0599,  0.0061,  0.0319],\n",
      "         [ 0.0712, -0.0322,  0.0565],\n",
      "         [ 0.0188,  0.0135, -0.0030],\n",
      "         [-0.0614, -0.0297, -0.0466],\n",
      "         [ 0.0145,  0.0206,  0.0465],\n",
      "         [ 0.0284,  0.0407,  0.0561],\n",
      "         [-0.0051,  0.0054,  0.0024],\n",
      "         [ 0.0037,  0.0415, -0.0247],\n",
      "         [ 0.0396, -0.0430, -0.0512],\n",
      "         [ 0.0061, -0.0253,  0.0106],\n",
      "         [-0.0599,  0.0649,  0.0595]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.bias | Size: torch.Size([64]) | Values : tensor([-0.0371, -0.0521], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[ 0.0170],\n",
      "         [ 0.0100],\n",
      "         [ 0.0760],\n",
      "         [ 0.0210],\n",
      "         [-0.0598],\n",
      "         [ 0.0240],\n",
      "         [-0.0770],\n",
      "         [-0.0258],\n",
      "         [ 0.0219],\n",
      "         [ 0.1248],\n",
      "         [ 0.1213],\n",
      "         [ 0.0389],\n",
      "         [-0.0741],\n",
      "         [-0.0980],\n",
      "         [-0.0432],\n",
      "         [ 0.0895],\n",
      "         [-0.1081],\n",
      "         [-0.0267],\n",
      "         [ 0.0712],\n",
      "         [ 0.0774],\n",
      "         [-0.0372],\n",
      "         [ 0.0294],\n",
      "         [-0.0207],\n",
      "         [-0.0377],\n",
      "         [ 0.0835],\n",
      "         [-0.0747],\n",
      "         [ 0.0532],\n",
      "         [-0.1055],\n",
      "         [-0.0940],\n",
      "         [ 0.1063],\n",
      "         [ 0.0234],\n",
      "         [ 0.0740],\n",
      "         [ 0.0419],\n",
      "         [-0.1191],\n",
      "         [-0.0660],\n",
      "         [ 0.0698],\n",
      "         [ 0.1064],\n",
      "         [ 0.0891],\n",
      "         [ 0.0464],\n",
      "         [-0.0940],\n",
      "         [-0.1163],\n",
      "         [ 0.0527],\n",
      "         [-0.0546],\n",
      "         [ 0.1026],\n",
      "         [ 0.0329],\n",
      "         [-0.0849],\n",
      "         [ 0.0846],\n",
      "         [-0.0523],\n",
      "         [-0.1011],\n",
      "         [ 0.0707],\n",
      "         [ 0.0532],\n",
      "         [-0.0236],\n",
      "         [-0.0191],\n",
      "         [-0.0291],\n",
      "         [-0.0950],\n",
      "         [-0.0016],\n",
      "         [-0.0871],\n",
      "         [ 0.0802],\n",
      "         [ 0.0939],\n",
      "         [-0.1146],\n",
      "         [-0.0841],\n",
      "         [ 0.0212],\n",
      "         [-0.0873],\n",
      "         [-0.1209]],\n",
      "\n",
      "        [[-0.1011],\n",
      "         [ 0.0478],\n",
      "         [ 0.0894],\n",
      "         [ 0.0349],\n",
      "         [-0.0861],\n",
      "         [ 0.0600],\n",
      "         [ 0.0484],\n",
      "         [-0.0849],\n",
      "         [ 0.0654],\n",
      "         [-0.0353],\n",
      "         [-0.0826],\n",
      "         [ 0.1150],\n",
      "         [-0.0510],\n",
      "         [ 0.0170],\n",
      "         [-0.1214],\n",
      "         [ 0.1101],\n",
      "         [ 0.1114],\n",
      "         [-0.0733],\n",
      "         [-0.1172],\n",
      "         [ 0.0047],\n",
      "         [-0.0782],\n",
      "         [-0.0414],\n",
      "         [ 0.0183],\n",
      "         [-0.0922],\n",
      "         [ 0.1054],\n",
      "         [-0.1157],\n",
      "         [ 0.0986],\n",
      "         [ 0.0485],\n",
      "         [ 0.0005],\n",
      "         [-0.0909],\n",
      "         [ 0.1200],\n",
      "         [-0.1246],\n",
      "         [-0.1060],\n",
      "         [ 0.0719],\n",
      "         [-0.0552],\n",
      "         [-0.0091],\n",
      "         [ 0.0418],\n",
      "         [-0.0307],\n",
      "         [-0.0972],\n",
      "         [-0.0958],\n",
      "         [ 0.1101],\n",
      "         [-0.0822],\n",
      "         [-0.1107],\n",
      "         [ 0.0388],\n",
      "         [ 0.0407],\n",
      "         [ 0.0193],\n",
      "         [-0.0856],\n",
      "         [ 0.0078],\n",
      "         [-0.0637],\n",
      "         [-0.1079],\n",
      "         [-0.0108],\n",
      "         [ 0.0558],\n",
      "         [ 0.1072],\n",
      "         [ 0.0630],\n",
      "         [ 0.0819],\n",
      "         [ 0.0249],\n",
      "         [-0.0163],\n",
      "         [ 0.0829],\n",
      "         [-0.1022],\n",
      "         [ 0.1192],\n",
      "         [-0.1050],\n",
      "         [-0.0347],\n",
      "         [-0.0013],\n",
      "         [-0.1009]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv1.bias | Size: torch.Size([16]) | Values : tensor([-0.0519,  0.0182], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[-0.0127,  0.1099,  0.1240],\n",
      "         [ 0.0326,  0.0620, -0.0558],\n",
      "         [ 0.0572,  0.0664,  0.1071],\n",
      "         [-0.1080,  0.0365,  0.0746],\n",
      "         [-0.0121,  0.0412,  0.0316],\n",
      "         [ 0.0468,  0.1130,  0.0662],\n",
      "         [-0.0442, -0.0349, -0.0562],\n",
      "         [-0.0359, -0.0498, -0.0129],\n",
      "         [-0.0603, -0.0471,  0.0891],\n",
      "         [ 0.0379,  0.0448, -0.1340],\n",
      "         [ 0.0112,  0.0067,  0.0652],\n",
      "         [-0.0262,  0.0910, -0.1406],\n",
      "         [ 0.0006, -0.0425,  0.0341],\n",
      "         [-0.0723, -0.0490,  0.0594],\n",
      "         [-0.0650, -0.0394,  0.0677],\n",
      "         [-0.1369, -0.0427, -0.1060]],\n",
      "\n",
      "        [[ 0.1114,  0.0487,  0.0536],\n",
      "         [ 0.1160,  0.0282, -0.0100],\n",
      "         [-0.0116,  0.0578, -0.0396],\n",
      "         [-0.0187, -0.0265, -0.0738],\n",
      "         [-0.0746, -0.0970, -0.1211],\n",
      "         [-0.1288, -0.0235,  0.0195],\n",
      "         [ 0.0998, -0.1203, -0.0237],\n",
      "         [-0.1008, -0.0088, -0.1143],\n",
      "         [-0.1116, -0.0615,  0.0245],\n",
      "         [-0.0319,  0.0358, -0.0879],\n",
      "         [-0.1348, -0.0261, -0.0770],\n",
      "         [-0.0820, -0.0579,  0.0655],\n",
      "         [ 0.0519, -0.0837,  0.1100],\n",
      "         [ 0.1285, -0.0179, -0.0345],\n",
      "         [ 0.0343, -0.0910, -0.1075],\n",
      "         [ 0.0544, -0.0804, -0.0922]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv2.bias | Size: torch.Size([16]) | Values : tensor([0.0959, 0.0978], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[ 0.1820],\n",
      "         [ 0.1610],\n",
      "         [ 0.0188],\n",
      "         [ 0.0955],\n",
      "         [ 0.0044],\n",
      "         [-0.1387],\n",
      "         [-0.2383],\n",
      "         [-0.0969],\n",
      "         [-0.0242],\n",
      "         [ 0.2199],\n",
      "         [-0.2287],\n",
      "         [-0.2046],\n",
      "         [-0.0768],\n",
      "         [ 0.1250],\n",
      "         [ 0.0249],\n",
      "         [-0.1437]],\n",
      "\n",
      "        [[-0.0970],\n",
      "         [ 0.1245],\n",
      "         [ 0.0186],\n",
      "         [-0.1680],\n",
      "         [ 0.2433],\n",
      "         [-0.1743],\n",
      "         [-0.2098],\n",
      "         [-0.0662],\n",
      "         [-0.2203],\n",
      "         [-0.2133],\n",
      "         [ 0.1062],\n",
      "         [-0.0205],\n",
      "         [ 0.1916],\n",
      "         [-0.1743],\n",
      "         [ 0.2490],\n",
      "         [ 0.0230]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv3.bias | Size: torch.Size([64]) | Values : tensor([-0.2299,  0.1633], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[ 3.4451e-05],\n",
      "         [ 4.0336e-02],\n",
      "         [-2.9018e-02],\n",
      "         [ 9.4983e-02],\n",
      "         [ 3.9871e-02],\n",
      "         [-8.3220e-03],\n",
      "         [ 3.0984e-02],\n",
      "         [ 9.2228e-02],\n",
      "         [-1.2101e-01],\n",
      "         [-6.7240e-02],\n",
      "         [-4.6954e-02],\n",
      "         [-7.4309e-02],\n",
      "         [ 3.3802e-03],\n",
      "         [ 1.0190e-01],\n",
      "         [ 4.0855e-02],\n",
      "         [ 4.9423e-02],\n",
      "         [-4.5849e-02],\n",
      "         [ 1.1176e-01],\n",
      "         [-2.2602e-02],\n",
      "         [ 1.2034e-01],\n",
      "         [-2.0107e-02],\n",
      "         [-1.0499e-02],\n",
      "         [-5.0264e-02],\n",
      "         [-8.6479e-02],\n",
      "         [ 1.0985e-01],\n",
      "         [ 5.8356e-02],\n",
      "         [-7.6001e-02],\n",
      "         [ 8.7334e-02],\n",
      "         [-1.1090e-01],\n",
      "         [ 4.6155e-02],\n",
      "         [-3.3591e-02],\n",
      "         [ 6.5877e-02],\n",
      "         [ 3.7168e-02],\n",
      "         [-3.7102e-03],\n",
      "         [-1.1238e-01],\n",
      "         [-4.8749e-02],\n",
      "         [ 7.7820e-02],\n",
      "         [-7.2679e-02],\n",
      "         [ 2.5504e-03],\n",
      "         [ 5.3726e-02],\n",
      "         [-1.6787e-02],\n",
      "         [ 4.5075e-02],\n",
      "         [-2.6528e-03],\n",
      "         [-6.3352e-02],\n",
      "         [-2.1816e-02],\n",
      "         [-3.8205e-02],\n",
      "         [ 3.6522e-02],\n",
      "         [ 1.5686e-03],\n",
      "         [ 7.3642e-02],\n",
      "         [-1.1115e-01],\n",
      "         [ 3.9899e-02],\n",
      "         [ 1.1840e-02],\n",
      "         [-8.2323e-02],\n",
      "         [-8.4315e-02],\n",
      "         [-5.9492e-02],\n",
      "         [ 1.2072e-01],\n",
      "         [-4.8369e-02],\n",
      "         [-3.5444e-02],\n",
      "         [-8.9304e-02],\n",
      "         [ 6.7215e-02],\n",
      "         [-7.6991e-02],\n",
      "         [-1.2280e-01],\n",
      "         [ 9.5482e-02],\n",
      "         [-2.7452e-02]],\n",
      "\n",
      "        [[-4.7180e-02],\n",
      "         [-4.6612e-02],\n",
      "         [-7.8125e-02],\n",
      "         [ 2.8206e-02],\n",
      "         [ 1.2233e-01],\n",
      "         [ 1.1831e-01],\n",
      "         [ 9.2497e-02],\n",
      "         [-7.9875e-02],\n",
      "         [-9.0737e-02],\n",
      "         [-1.0053e-01],\n",
      "         [-8.3257e-02],\n",
      "         [-5.1081e-02],\n",
      "         [ 1.1647e-01],\n",
      "         [-1.9898e-03],\n",
      "         [ 8.7590e-02],\n",
      "         [ 1.1282e-01],\n",
      "         [ 1.5795e-02],\n",
      "         [-7.3221e-03],\n",
      "         [-2.6218e-03],\n",
      "         [-8.7607e-02],\n",
      "         [ 1.0050e-01],\n",
      "         [ 1.0505e-01],\n",
      "         [-5.0348e-02],\n",
      "         [-3.5057e-02],\n",
      "         [ 9.1649e-02],\n",
      "         [ 7.2760e-02],\n",
      "         [ 5.0828e-02],\n",
      "         [ 5.6185e-02],\n",
      "         [-4.0231e-02],\n",
      "         [ 1.0989e-02],\n",
      "         [-6.3618e-02],\n",
      "         [ 5.7101e-02],\n",
      "         [ 1.1211e-01],\n",
      "         [-8.7900e-02],\n",
      "         [ 1.1174e-01],\n",
      "         [-1.5326e-03],\n",
      "         [-7.6675e-02],\n",
      "         [ 4.2700e-02],\n",
      "         [ 4.9317e-02],\n",
      "         [-4.6702e-02],\n",
      "         [ 9.5557e-02],\n",
      "         [ 1.7995e-02],\n",
      "         [-1.0379e-01],\n",
      "         [-1.1551e-01],\n",
      "         [-8.0035e-02],\n",
      "         [ 5.1258e-02],\n",
      "         [ 6.3743e-02],\n",
      "         [ 1.0875e-01],\n",
      "         [-8.2294e-02],\n",
      "         [ 9.5379e-02],\n",
      "         [ 1.5073e-02],\n",
      "         [-1.1567e-01],\n",
      "         [-3.5034e-02],\n",
      "         [ 2.7111e-02],\n",
      "         [-6.3752e-02],\n",
      "         [-6.6641e-02],\n",
      "         [-5.4759e-02],\n",
      "         [ 4.5485e-02],\n",
      "         [-5.5895e-02],\n",
      "         [ 2.1419e-02],\n",
      "         [ 8.5317e-02],\n",
      "         [-5.5859e-02],\n",
      "         [ 1.1972e-01],\n",
      "         [-6.2036e-02]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.convr.bias | Size: torch.Size([64]) | Values : tensor([-0.0734, -0.0223], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[ 1.0566e-01],\n",
      "         [-3.0112e-02],\n",
      "         [ 7.6487e-02],\n",
      "         [ 1.1139e-01],\n",
      "         [-3.0260e-02],\n",
      "         [-6.4627e-02],\n",
      "         [ 4.9099e-02],\n",
      "         [ 1.1547e-01],\n",
      "         [ 6.9331e-02],\n",
      "         [-1.2392e-01],\n",
      "         [ 1.0281e-01],\n",
      "         [-1.0284e-01],\n",
      "         [-7.4187e-02],\n",
      "         [-8.2107e-02],\n",
      "         [-4.4431e-02],\n",
      "         [ 5.3811e-02],\n",
      "         [-9.2577e-02],\n",
      "         [ 2.4226e-02],\n",
      "         [ 6.5550e-02],\n",
      "         [-4.2015e-02],\n",
      "         [ 1.7233e-03],\n",
      "         [-7.4932e-02],\n",
      "         [ 7.3233e-02],\n",
      "         [-1.0196e-01],\n",
      "         [-7.1952e-02],\n",
      "         [-1.1492e-01],\n",
      "         [ 4.4697e-02],\n",
      "         [-1.0489e-01],\n",
      "         [-1.6332e-02],\n",
      "         [ 1.1723e-01],\n",
      "         [-4.6872e-02],\n",
      "         [-2.5844e-02],\n",
      "         [-1.2038e-01],\n",
      "         [-6.7841e-02],\n",
      "         [-4.6001e-02],\n",
      "         [-5.1478e-02],\n",
      "         [ 6.5703e-02],\n",
      "         [ 7.2530e-02],\n",
      "         [-4.5873e-02],\n",
      "         [ 2.5700e-02],\n",
      "         [ 1.2376e-01],\n",
      "         [-2.1700e-02],\n",
      "         [ 7.8241e-02],\n",
      "         [-2.2599e-02],\n",
      "         [-5.8281e-02],\n",
      "         [ 1.0850e-01],\n",
      "         [-2.9755e-02],\n",
      "         [-9.0711e-02],\n",
      "         [ 5.5775e-05],\n",
      "         [ 2.0541e-02],\n",
      "         [-7.0545e-02],\n",
      "         [ 7.1516e-02],\n",
      "         [-5.4838e-02],\n",
      "         [ 1.1028e-01],\n",
      "         [ 1.3739e-03],\n",
      "         [-3.4068e-02],\n",
      "         [-7.9353e-02],\n",
      "         [-3.4519e-02],\n",
      "         [ 3.5870e-02],\n",
      "         [ 8.7132e-02],\n",
      "         [ 1.0071e-01],\n",
      "         [-6.5156e-02],\n",
      "         [ 6.2946e-02],\n",
      "         [ 7.7529e-02]],\n",
      "\n",
      "        [[-7.6462e-02],\n",
      "         [-9.7592e-02],\n",
      "         [ 1.9960e-02],\n",
      "         [ 7.4121e-02],\n",
      "         [-5.8961e-02],\n",
      "         [-7.1844e-02],\n",
      "         [ 5.4913e-02],\n",
      "         [ 8.5221e-02],\n",
      "         [-3.4819e-02],\n",
      "         [ 4.5298e-02],\n",
      "         [ 5.9801e-02],\n",
      "         [-1.0711e-01],\n",
      "         [ 7.3702e-02],\n",
      "         [-5.2191e-02],\n",
      "         [-2.8151e-02],\n",
      "         [ 5.3923e-02],\n",
      "         [ 2.6625e-02],\n",
      "         [ 3.6161e-02],\n",
      "         [ 1.4792e-02],\n",
      "         [-7.0350e-02],\n",
      "         [ 1.2313e-01],\n",
      "         [-1.0466e-01],\n",
      "         [ 1.1801e-01],\n",
      "         [ 4.1264e-02],\n",
      "         [ 5.5629e-02],\n",
      "         [-4.1756e-02],\n",
      "         [ 1.0789e-01],\n",
      "         [-5.9099e-02],\n",
      "         [ 9.8292e-02],\n",
      "         [-7.5867e-02],\n",
      "         [-5.7858e-02],\n",
      "         [-9.2236e-02],\n",
      "         [-3.8839e-02],\n",
      "         [-1.0885e-01],\n",
      "         [-2.1127e-02],\n",
      "         [ 9.7803e-03],\n",
      "         [ 8.6092e-02],\n",
      "         [-1.0005e-01],\n",
      "         [ 5.4193e-02],\n",
      "         [-1.0077e-02],\n",
      "         [ 1.1350e-01],\n",
      "         [ 4.0232e-02],\n",
      "         [-1.0049e-01],\n",
      "         [ 2.7576e-02],\n",
      "         [ 9.8990e-02],\n",
      "         [ 4.5849e-02],\n",
      "         [ 1.0160e-01],\n",
      "         [-3.1070e-02],\n",
      "         [-5.4816e-02],\n",
      "         [ 3.3099e-02],\n",
      "         [ 9.8249e-02],\n",
      "         [-4.7363e-02],\n",
      "         [-8.0547e-02],\n",
      "         [ 5.6557e-02],\n",
      "         [-9.6519e-02],\n",
      "         [-1.0680e-01],\n",
      "         [-1.1238e-02],\n",
      "         [-8.0982e-02],\n",
      "         [ 5.7005e-02],\n",
      "         [-4.7227e-02],\n",
      "         [-9.4437e-03],\n",
      "         [ 5.9697e-02],\n",
      "         [ 6.9413e-02],\n",
      "         [ 2.7572e-02]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv1.bias | Size: torch.Size([16]) | Values : tensor([0.0535, 0.1156], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[ 0.1163, -0.0614,  0.0483],\n",
      "         [ 0.0697,  0.0569, -0.0296],\n",
      "         [ 0.1234, -0.0471, -0.0070],\n",
      "         [ 0.0780, -0.0795, -0.0267],\n",
      "         [ 0.0352, -0.0744, -0.0331],\n",
      "         [-0.0562, -0.0323, -0.1233],\n",
      "         [-0.1311, -0.1353,  0.1015],\n",
      "         [ 0.0307,  0.1430,  0.0960],\n",
      "         [ 0.1113, -0.1063,  0.0102],\n",
      "         [-0.1433,  0.0890, -0.0800],\n",
      "         [-0.0723, -0.0574,  0.0262],\n",
      "         [-0.1293,  0.0489,  0.1066],\n",
      "         [-0.0068, -0.1057,  0.0230],\n",
      "         [ 0.0195, -0.0067,  0.1152],\n",
      "         [ 0.0565, -0.1437,  0.0957],\n",
      "         [ 0.0936, -0.0834,  0.0324]],\n",
      "\n",
      "        [[ 0.0614,  0.0111, -0.0802],\n",
      "         [ 0.0746, -0.1015, -0.1386],\n",
      "         [ 0.0226,  0.1262,  0.1310],\n",
      "         [-0.0237, -0.1399, -0.0672],\n",
      "         [ 0.0324,  0.0762, -0.0285],\n",
      "         [-0.0708,  0.0402, -0.1428],\n",
      "         [ 0.0632,  0.1228, -0.1007],\n",
      "         [ 0.1069,  0.0398, -0.0942],\n",
      "         [ 0.1353,  0.0251,  0.0085],\n",
      "         [ 0.1085, -0.1286,  0.0847],\n",
      "         [ 0.0357, -0.1193,  0.0280],\n",
      "         [ 0.0833, -0.0239,  0.0856],\n",
      "         [-0.0585,  0.0922, -0.0970],\n",
      "         [ 0.1441,  0.1003, -0.1186],\n",
      "         [ 0.0631,  0.0493,  0.0303],\n",
      "         [-0.0330,  0.0019, -0.0933]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv2.bias | Size: torch.Size([16]) | Values : tensor([0.0822, 0.0957], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[-0.0834],\n",
      "         [ 0.2385],\n",
      "         [-0.1352],\n",
      "         [-0.1960],\n",
      "         [-0.2213],\n",
      "         [ 0.1010],\n",
      "         [-0.1070],\n",
      "         [-0.0832],\n",
      "         [ 0.1351],\n",
      "         [ 0.2074],\n",
      "         [ 0.0413],\n",
      "         [-0.0324],\n",
      "         [-0.2417],\n",
      "         [-0.0094],\n",
      "         [ 0.2294],\n",
      "         [-0.0043]],\n",
      "\n",
      "        [[-0.1698],\n",
      "         [ 0.2451],\n",
      "         [-0.0034],\n",
      "         [ 0.0801],\n",
      "         [-0.0985],\n",
      "         [-0.1196],\n",
      "         [-0.1604],\n",
      "         [ 0.1092],\n",
      "         [ 0.1377],\n",
      "         [ 0.1591],\n",
      "         [ 0.2088],\n",
      "         [ 0.0116],\n",
      "         [-0.0194],\n",
      "         [ 0.1992],\n",
      "         [-0.1916],\n",
      "         [-0.1862]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv3.bias | Size: torch.Size([64]) | Values : tensor([0.0274, 0.1557], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[ 1.1699e-01],\n",
      "         [ 1.1477e-01],\n",
      "         [ 3.0949e-02],\n",
      "         [ 1.2079e-01],\n",
      "         [ 4.7318e-02],\n",
      "         [-2.3986e-02],\n",
      "         [-3.1054e-05],\n",
      "         [ 1.0378e-02],\n",
      "         [-7.5490e-02],\n",
      "         [-2.9690e-02],\n",
      "         [-1.0077e-01],\n",
      "         [ 1.0432e-01],\n",
      "         [ 1.3167e-02],\n",
      "         [-3.1060e-02],\n",
      "         [-1.2004e-01],\n",
      "         [ 7.2701e-02],\n",
      "         [-3.9809e-02],\n",
      "         [-8.8085e-02],\n",
      "         [ 2.7492e-02],\n",
      "         [-7.8517e-02],\n",
      "         [-3.7171e-02],\n",
      "         [ 7.0631e-03],\n",
      "         [ 1.7014e-02],\n",
      "         [ 1.1275e-02],\n",
      "         [ 1.0971e-01],\n",
      "         [-4.3174e-03],\n",
      "         [-1.0273e-01],\n",
      "         [-1.3410e-02],\n",
      "         [ 1.1152e-01],\n",
      "         [ 1.0983e-01],\n",
      "         [-3.5541e-02],\n",
      "         [-2.1053e-02],\n",
      "         [-3.0042e-02],\n",
      "         [-3.5576e-02],\n",
      "         [ 1.2090e-01],\n",
      "         [ 1.0674e-01],\n",
      "         [ 9.5640e-02],\n",
      "         [ 6.5405e-02],\n",
      "         [ 2.8342e-02],\n",
      "         [-1.1968e-01],\n",
      "         [ 6.1847e-02],\n",
      "         [ 6.4735e-02],\n",
      "         [-7.6729e-02],\n",
      "         [-1.0200e-01],\n",
      "         [ 3.4598e-02],\n",
      "         [ 5.1453e-02],\n",
      "         [ 8.2464e-02],\n",
      "         [ 4.5150e-02],\n",
      "         [ 1.3836e-02],\n",
      "         [ 9.2095e-02],\n",
      "         [ 1.0042e-01],\n",
      "         [ 7.7006e-02],\n",
      "         [ 9.1469e-02],\n",
      "         [ 1.0197e-02],\n",
      "         [-1.6180e-02],\n",
      "         [-9.4644e-02],\n",
      "         [ 3.3868e-02],\n",
      "         [-2.1468e-02],\n",
      "         [-2.0895e-03],\n",
      "         [-6.9029e-02],\n",
      "         [ 9.6716e-02],\n",
      "         [-1.0490e-01],\n",
      "         [ 1.0823e-01],\n",
      "         [ 1.9579e-03]],\n",
      "\n",
      "        [[-9.7506e-02],\n",
      "         [-3.5353e-02],\n",
      "         [-1.2455e-01],\n",
      "         [-1.2385e-01],\n",
      "         [-1.1722e-01],\n",
      "         [ 4.2660e-02],\n",
      "         [-2.8728e-02],\n",
      "         [-1.1607e-01],\n",
      "         [-7.2124e-02],\n",
      "         [-7.7751e-02],\n",
      "         [-5.2746e-02],\n",
      "         [ 5.3056e-02],\n",
      "         [-1.1281e-02],\n",
      "         [-8.9510e-03],\n",
      "         [ 1.0224e-01],\n",
      "         [ 2.5733e-02],\n",
      "         [ 1.0990e-01],\n",
      "         [ 7.4551e-02],\n",
      "         [-8.3974e-02],\n",
      "         [ 7.1386e-02],\n",
      "         [-7.4838e-02],\n",
      "         [ 6.1704e-02],\n",
      "         [ 3.0387e-02],\n",
      "         [-9.8500e-02],\n",
      "         [ 5.9497e-02],\n",
      "         [ 3.6865e-02],\n",
      "         [-4.5872e-02],\n",
      "         [-3.7296e-02],\n",
      "         [-9.2036e-02],\n",
      "         [ 6.4908e-03],\n",
      "         [-9.7234e-02],\n",
      "         [-2.3425e-02],\n",
      "         [-1.4763e-02],\n",
      "         [ 1.1544e-02],\n",
      "         [ 2.8970e-02],\n",
      "         [-4.0271e-02],\n",
      "         [-6.5753e-02],\n",
      "         [ 1.2316e-01],\n",
      "         [-2.0184e-02],\n",
      "         [ 6.7667e-02],\n",
      "         [ 4.4658e-02],\n",
      "         [-3.4755e-03],\n",
      "         [ 5.4754e-02],\n",
      "         [-1.0928e-01],\n",
      "         [ 5.2542e-02],\n",
      "         [ 3.0267e-02],\n",
      "         [-5.3558e-04],\n",
      "         [-9.7608e-02],\n",
      "         [ 5.2143e-03],\n",
      "         [-1.0517e-02],\n",
      "         [-9.5250e-02],\n",
      "         [ 6.0952e-02],\n",
      "         [-1.2096e-01],\n",
      "         [ 2.7933e-02],\n",
      "         [ 1.8236e-02],\n",
      "         [-7.0758e-02],\n",
      "         [ 4.1166e-02],\n",
      "         [-4.2230e-02],\n",
      "         [-8.5106e-02],\n",
      "         [ 7.4801e-02],\n",
      "         [-5.9238e-02],\n",
      "         [-1.2282e-01],\n",
      "         [ 9.7426e-03],\n",
      "         [ 1.6228e-02]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.convr.bias | Size: torch.Size([64]) | Values : tensor([-0.1240, -0.0240], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[ 0.0251],\n",
      "         [ 0.0525],\n",
      "         [ 0.0101],\n",
      "         [ 0.0066],\n",
      "         [ 0.0395],\n",
      "         [-0.1235],\n",
      "         [-0.1045],\n",
      "         [-0.0870],\n",
      "         [-0.1095],\n",
      "         [ 0.1234],\n",
      "         [ 0.1173],\n",
      "         [ 0.0215],\n",
      "         [ 0.0041],\n",
      "         [ 0.0182],\n",
      "         [ 0.0496],\n",
      "         [ 0.0315],\n",
      "         [ 0.1129],\n",
      "         [-0.0883],\n",
      "         [ 0.0813],\n",
      "         [ 0.0761],\n",
      "         [ 0.0607],\n",
      "         [ 0.0409],\n",
      "         [ 0.0787],\n",
      "         [ 0.0333],\n",
      "         [-0.1119],\n",
      "         [-0.0633],\n",
      "         [ 0.0922],\n",
      "         [-0.0211],\n",
      "         [-0.0190],\n",
      "         [-0.0009],\n",
      "         [ 0.0940],\n",
      "         [-0.0003],\n",
      "         [ 0.0904],\n",
      "         [ 0.0066],\n",
      "         [ 0.0017],\n",
      "         [-0.1194],\n",
      "         [ 0.1030],\n",
      "         [-0.0175],\n",
      "         [ 0.0247],\n",
      "         [-0.1159],\n",
      "         [-0.0581],\n",
      "         [ 0.1056],\n",
      "         [-0.1105],\n",
      "         [ 0.0443],\n",
      "         [-0.1133],\n",
      "         [-0.0960],\n",
      "         [-0.0289],\n",
      "         [ 0.0675],\n",
      "         [ 0.0082],\n",
      "         [-0.0590],\n",
      "         [-0.1036],\n",
      "         [ 0.0761],\n",
      "         [-0.1086],\n",
      "         [-0.0738],\n",
      "         [ 0.1027],\n",
      "         [ 0.0106],\n",
      "         [-0.0413],\n",
      "         [-0.1173],\n",
      "         [-0.0713],\n",
      "         [ 0.0667],\n",
      "         [ 0.0429],\n",
      "         [ 0.0599],\n",
      "         [-0.0397],\n",
      "         [ 0.1056]],\n",
      "\n",
      "        [[ 0.1034],\n",
      "         [-0.0272],\n",
      "         [ 0.0858],\n",
      "         [ 0.0744],\n",
      "         [ 0.0790],\n",
      "         [-0.0748],\n",
      "         [-0.0738],\n",
      "         [-0.0456],\n",
      "         [-0.0544],\n",
      "         [-0.0320],\n",
      "         [-0.0893],\n",
      "         [-0.0581],\n",
      "         [-0.1012],\n",
      "         [-0.1203],\n",
      "         [-0.0914],\n",
      "         [ 0.0305],\n",
      "         [ 0.0456],\n",
      "         [ 0.0366],\n",
      "         [-0.1224],\n",
      "         [-0.0593],\n",
      "         [-0.1141],\n",
      "         [-0.1179],\n",
      "         [-0.0905],\n",
      "         [ 0.0352],\n",
      "         [ 0.0414],\n",
      "         [-0.0200],\n",
      "         [ 0.1176],\n",
      "         [ 0.0764],\n",
      "         [-0.0220],\n",
      "         [-0.0091],\n",
      "         [-0.1034],\n",
      "         [-0.0750],\n",
      "         [-0.0620],\n",
      "         [-0.0439],\n",
      "         [ 0.1217],\n",
      "         [ 0.0406],\n",
      "         [-0.1024],\n",
      "         [ 0.1241],\n",
      "         [ 0.0198],\n",
      "         [ 0.0572],\n",
      "         [ 0.1207],\n",
      "         [-0.1053],\n",
      "         [ 0.1103],\n",
      "         [ 0.0781],\n",
      "         [-0.0255],\n",
      "         [-0.0326],\n",
      "         [ 0.0241],\n",
      "         [ 0.0284],\n",
      "         [-0.0547],\n",
      "         [ 0.0938],\n",
      "         [-0.0081],\n",
      "         [-0.0778],\n",
      "         [ 0.1209],\n",
      "         [ 0.1133],\n",
      "         [ 0.0270],\n",
      "         [ 0.0133],\n",
      "         [-0.0400],\n",
      "         [-0.0749],\n",
      "         [-0.1172],\n",
      "         [-0.0318],\n",
      "         [-0.1045],\n",
      "         [ 0.0805],\n",
      "         [-0.1188],\n",
      "         [-0.0096]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.conv1.bias | Size: torch.Size([16]) | Values : tensor([-0.1034, -0.0142], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[ 9.7891e-02, -1.4114e-01,  1.3091e-01],\n",
      "         [ 4.5846e-02, -2.4599e-02,  5.3359e-02],\n",
      "         [-1.3363e-01,  2.6365e-02, -1.4124e-01],\n",
      "         [ 3.4721e-02, -2.7443e-02, -9.1402e-02],\n",
      "         [ 1.4419e-01, -9.6812e-02,  4.9994e-02],\n",
      "         [ 1.2970e-01,  4.5069e-02,  4.4826e-02],\n",
      "         [ 8.1932e-02, -2.2612e-02, -5.0763e-02],\n",
      "         [-1.6355e-02, -1.4038e-01, -7.7852e-02],\n",
      "         [-8.2157e-02, -8.1609e-02,  1.0894e-01],\n",
      "         [ 9.5658e-02,  1.6992e-02,  1.0494e-01],\n",
      "         [ 1.2073e-02,  1.2595e-01, -5.2822e-02],\n",
      "         [-3.3660e-02,  8.9148e-02,  3.9168e-02],\n",
      "         [ 3.5789e-04, -3.8801e-03, -6.5675e-03],\n",
      "         [-1.2412e-01, -1.0151e-01,  8.0046e-02],\n",
      "         [ 8.8216e-02, -1.1449e-01,  1.3832e-01],\n",
      "         [ 5.3699e-02,  8.5586e-02,  1.2846e-01]],\n",
      "\n",
      "        [[-1.0536e-03,  9.1018e-02, -8.2120e-03],\n",
      "         [-7.9289e-03, -1.3573e-01, -1.2881e-01],\n",
      "         [-1.2271e-01,  1.0813e-02, -2.1858e-02],\n",
      "         [ 1.2336e-01, -2.5317e-02, -4.7644e-02],\n",
      "         [-6.3419e-04, -9.6530e-02,  1.2041e-03],\n",
      "         [-1.0313e-01,  8.8004e-02, -3.1521e-02],\n",
      "         [-1.0276e-01, -9.4135e-02,  1.2965e-01],\n",
      "         [ 1.1268e-01,  1.0257e-02,  4.1313e-05],\n",
      "         [ 5.8739e-02, -2.5885e-03, -9.0098e-02],\n",
      "         [ 4.1166e-02, -1.4014e-01, -3.6287e-02],\n",
      "         [ 4.5793e-02,  1.0897e-01, -9.6441e-02],\n",
      "         [ 1.1616e-01,  1.0028e-01,  1.1151e-01],\n",
      "         [ 4.3097e-02, -1.2940e-01, -8.6135e-05],\n",
      "         [ 4.5463e-02,  1.1183e-01,  2.4750e-02],\n",
      "         [-6.2288e-02, -8.4166e-02,  7.0652e-02],\n",
      "         [ 6.6940e-02,  1.3682e-01,  6.0236e-02]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.conv2.bias | Size: torch.Size([16]) | Values : tensor([0.0707, 0.1090], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[-0.0499],\n",
      "         [-0.0779],\n",
      "         [ 0.0663],\n",
      "         [-0.1201],\n",
      "         [ 0.0859],\n",
      "         [-0.0079],\n",
      "         [ 0.0149],\n",
      "         [ 0.0028],\n",
      "         [-0.0754],\n",
      "         [ 0.0340],\n",
      "         [ 0.0948],\n",
      "         [ 0.2187],\n",
      "         [ 0.0776],\n",
      "         [ 0.0151],\n",
      "         [-0.0381],\n",
      "         [ 0.0517]],\n",
      "\n",
      "        [[-0.1621],\n",
      "         [ 0.0739],\n",
      "         [-0.2115],\n",
      "         [-0.0481],\n",
      "         [ 0.1902],\n",
      "         [-0.0089],\n",
      "         [-0.0130],\n",
      "         [-0.0757],\n",
      "         [ 0.0928],\n",
      "         [-0.0023],\n",
      "         [-0.2291],\n",
      "         [ 0.2253],\n",
      "         [-0.0030],\n",
      "         [ 0.0650],\n",
      "         [ 0.1961],\n",
      "         [ 0.2306]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.conv3.bias | Size: torch.Size([64]) | Values : tensor([-0.1374, -0.0644], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[ 1.1215e-01],\n",
      "         [ 7.2114e-03],\n",
      "         [ 2.1317e-02],\n",
      "         [-7.4336e-02],\n",
      "         [ 1.0781e-01],\n",
      "         [ 8.4436e-02],\n",
      "         [-5.7460e-02],\n",
      "         [ 6.9141e-02],\n",
      "         [ 5.8543e-02],\n",
      "         [-8.3791e-02],\n",
      "         [ 2.9381e-02],\n",
      "         [-2.7100e-02],\n",
      "         [ 6.1903e-03],\n",
      "         [ 5.0443e-02],\n",
      "         [-3.0538e-02],\n",
      "         [-3.2789e-02],\n",
      "         [ 9.7972e-02],\n",
      "         [-1.1792e-01],\n",
      "         [ 5.0899e-02],\n",
      "         [-5.1586e-02],\n",
      "         [-1.0461e-01],\n",
      "         [-1.1372e-01],\n",
      "         [-1.1035e-01],\n",
      "         [ 5.0597e-02],\n",
      "         [ 2.1068e-02],\n",
      "         [ 9.1459e-03],\n",
      "         [-9.7783e-02],\n",
      "         [-1.2467e-01],\n",
      "         [-8.0732e-02],\n",
      "         [-6.7624e-02],\n",
      "         [-5.2195e-03],\n",
      "         [-6.1282e-02],\n",
      "         [ 5.9541e-02],\n",
      "         [-1.0748e-01],\n",
      "         [-1.1822e-03],\n",
      "         [ 1.5906e-02],\n",
      "         [ 4.2151e-02],\n",
      "         [-3.4627e-02],\n",
      "         [-2.4367e-02],\n",
      "         [ 4.6406e-02],\n",
      "         [ 3.6448e-02],\n",
      "         [ 1.1249e-01],\n",
      "         [-1.1935e-02],\n",
      "         [ 1.0848e-05],\n",
      "         [-6.0860e-02],\n",
      "         [ 8.5588e-02],\n",
      "         [-7.6943e-02],\n",
      "         [-7.0799e-03],\n",
      "         [ 7.5177e-02],\n",
      "         [-1.2048e-01],\n",
      "         [-8.5466e-02],\n",
      "         [ 5.2888e-02],\n",
      "         [-8.7391e-02],\n",
      "         [-9.6512e-02],\n",
      "         [ 9.0930e-02],\n",
      "         [ 2.0209e-02],\n",
      "         [-8.0529e-02],\n",
      "         [-1.1756e-01],\n",
      "         [-7.5628e-02],\n",
      "         [ 6.6724e-02],\n",
      "         [-1.1496e-01],\n",
      "         [ 4.6343e-02],\n",
      "         [ 2.1814e-02],\n",
      "         [-5.9567e-02]],\n",
      "\n",
      "        [[-2.3813e-02],\n",
      "         [ 6.6097e-03],\n",
      "         [-5.4049e-02],\n",
      "         [ 1.2000e-01],\n",
      "         [-1.5873e-02],\n",
      "         [-5.9826e-02],\n",
      "         [-9.1771e-02],\n",
      "         [ 1.0664e-01],\n",
      "         [-7.7804e-02],\n",
      "         [-1.1774e-01],\n",
      "         [ 1.2005e-01],\n",
      "         [-1.0978e-01],\n",
      "         [ 3.7346e-02],\n",
      "         [ 3.6576e-02],\n",
      "         [-7.6033e-02],\n",
      "         [-3.8006e-03],\n",
      "         [ 5.8575e-02],\n",
      "         [-6.6351e-02],\n",
      "         [-7.5370e-05],\n",
      "         [ 1.1593e-02],\n",
      "         [-8.1568e-02],\n",
      "         [-1.0404e-01],\n",
      "         [ 4.9326e-02],\n",
      "         [-5.3396e-02],\n",
      "         [-1.0991e-01],\n",
      "         [ 4.3955e-02],\n",
      "         [-7.1707e-02],\n",
      "         [ 9.8819e-02],\n",
      "         [-4.9678e-02],\n",
      "         [-4.0728e-02],\n",
      "         [-9.5437e-03],\n",
      "         [-8.7690e-02],\n",
      "         [ 6.1665e-02],\n",
      "         [-5.1547e-02],\n",
      "         [-6.4851e-02],\n",
      "         [-1.1035e-01],\n",
      "         [ 8.8341e-02],\n",
      "         [ 1.0544e-02],\n",
      "         [-1.0108e-01],\n",
      "         [-8.4633e-02],\n",
      "         [ 6.9512e-02],\n",
      "         [-2.4986e-02],\n",
      "         [ 7.8450e-03],\n",
      "         [-7.4374e-02],\n",
      "         [-6.5080e-02],\n",
      "         [-9.2112e-02],\n",
      "         [ 3.7958e-02],\n",
      "         [-4.1542e-02],\n",
      "         [-2.9186e-02],\n",
      "         [-1.6829e-02],\n",
      "         [ 1.2058e-01],\n",
      "         [ 1.2364e-01],\n",
      "         [-7.8080e-02],\n",
      "         [-1.1469e-01],\n",
      "         [ 8.4985e-02],\n",
      "         [-1.1643e-01],\n",
      "         [-1.0557e-01],\n",
      "         [-4.1908e-02],\n",
      "         [ 8.7672e-02],\n",
      "         [ 1.1013e-01],\n",
      "         [ 4.8294e-03],\n",
      "         [-7.3108e-02],\n",
      "         [ 9.2377e-02],\n",
      "         [ 1.5196e-03]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv1.bias | Size: torch.Size([16]) | Values : tensor([0.0935, 0.0229], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[-0.0485, -0.0553, -0.0454],\n",
      "         [ 0.0526,  0.0120, -0.0416],\n",
      "         [-0.0227,  0.1184,  0.1133],\n",
      "         [-0.1242,  0.0924, -0.0369],\n",
      "         [-0.1316, -0.0091,  0.0704],\n",
      "         [ 0.0009, -0.1293, -0.1025],\n",
      "         [ 0.0304, -0.0290,  0.0012],\n",
      "         [ 0.1009, -0.0666, -0.1413],\n",
      "         [-0.0484, -0.0706,  0.0256],\n",
      "         [-0.0562,  0.0785, -0.1014],\n",
      "         [ 0.1427,  0.0858,  0.1094],\n",
      "         [-0.0883, -0.0352,  0.0574],\n",
      "         [-0.0297, -0.1074, -0.0473],\n",
      "         [-0.1354, -0.1354, -0.1130],\n",
      "         [ 0.0078,  0.0951, -0.0506],\n",
      "         [ 0.1275,  0.0300, -0.0996]],\n",
      "\n",
      "        [[-0.0756, -0.0684,  0.0445],\n",
      "         [-0.1060, -0.1438,  0.0746],\n",
      "         [ 0.0398, -0.0030, -0.1226],\n",
      "         [-0.0863, -0.0729, -0.0559],\n",
      "         [-0.1429,  0.1404, -0.1258],\n",
      "         [-0.1304,  0.0298, -0.1187],\n",
      "         [ 0.1300, -0.0136, -0.1215],\n",
      "         [-0.0629, -0.0858, -0.1326],\n",
      "         [-0.0225, -0.0840,  0.0494],\n",
      "         [ 0.1077,  0.0704,  0.0851],\n",
      "         [ 0.0959,  0.0645,  0.0705],\n",
      "         [ 0.0642,  0.0940, -0.1112],\n",
      "         [-0.0425, -0.0826,  0.0951],\n",
      "         [ 0.1160,  0.0486, -0.0970],\n",
      "         [ 0.0144, -0.1149,  0.0496],\n",
      "         [-0.1299,  0.0268,  0.0086]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv2.bias | Size: torch.Size([16]) | Values : tensor([-0.0797,  0.0108], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[-0.0666],\n",
      "         [ 0.1119],\n",
      "         [-0.1685],\n",
      "         [-0.1180],\n",
      "         [-0.2376],\n",
      "         [-0.0448],\n",
      "         [-0.1536],\n",
      "         [ 0.0457],\n",
      "         [-0.0595],\n",
      "         [ 0.1896],\n",
      "         [ 0.0077],\n",
      "         [-0.0700],\n",
      "         [ 0.1073],\n",
      "         [-0.0268],\n",
      "         [-0.0332],\n",
      "         [-0.1411]],\n",
      "\n",
      "        [[ 0.2491],\n",
      "         [-0.1856],\n",
      "         [ 0.0723],\n",
      "         [ 0.0270],\n",
      "         [ 0.0372],\n",
      "         [-0.1520],\n",
      "         [ 0.1910],\n",
      "         [-0.2149],\n",
      "         [-0.1755],\n",
      "         [-0.2328],\n",
      "         [-0.1448],\n",
      "         [ 0.2289],\n",
      "         [ 0.0913],\n",
      "         [-0.0219],\n",
      "         [-0.0025],\n",
      "         [ 0.2332]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv3.bias | Size: torch.Size([64]) | Values : tensor([-0.1199,  0.1222], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[ 0.0752],\n",
      "         [ 0.0682],\n",
      "         [-0.1064],\n",
      "         [ 0.0833],\n",
      "         [ 0.0589],\n",
      "         [-0.0366],\n",
      "         [ 0.0794],\n",
      "         [-0.0634],\n",
      "         [-0.0298],\n",
      "         [-0.1091],\n",
      "         [ 0.1092],\n",
      "         [-0.0836],\n",
      "         [ 0.0249],\n",
      "         [-0.0794],\n",
      "         [-0.0248],\n",
      "         [-0.0767],\n",
      "         [-0.0191],\n",
      "         [ 0.0696],\n",
      "         [-0.0838],\n",
      "         [ 0.1164],\n",
      "         [ 0.1184],\n",
      "         [ 0.0490],\n",
      "         [-0.0152],\n",
      "         [ 0.1220],\n",
      "         [ 0.0347],\n",
      "         [ 0.1159],\n",
      "         [ 0.0619],\n",
      "         [ 0.0316],\n",
      "         [-0.0576],\n",
      "         [ 0.0443],\n",
      "         [-0.0907],\n",
      "         [ 0.0427],\n",
      "         [-0.0619],\n",
      "         [ 0.0258],\n",
      "         [-0.0801],\n",
      "         [-0.0038],\n",
      "         [ 0.1193],\n",
      "         [-0.1123],\n",
      "         [-0.0725],\n",
      "         [-0.0750],\n",
      "         [ 0.0465],\n",
      "         [-0.0452],\n",
      "         [-0.0537],\n",
      "         [-0.1184],\n",
      "         [-0.0232],\n",
      "         [ 0.0292],\n",
      "         [-0.0768],\n",
      "         [-0.0502],\n",
      "         [ 0.0392],\n",
      "         [ 0.0354],\n",
      "         [-0.0641],\n",
      "         [ 0.1033],\n",
      "         [-0.1098],\n",
      "         [ 0.0939],\n",
      "         [-0.0039],\n",
      "         [ 0.0822],\n",
      "         [-0.1234],\n",
      "         [-0.0365],\n",
      "         [ 0.0292],\n",
      "         [-0.0263],\n",
      "         [ 0.0316],\n",
      "         [-0.0208],\n",
      "         [ 0.1138],\n",
      "         [-0.0753]],\n",
      "\n",
      "        [[-0.0518],\n",
      "         [ 0.0259],\n",
      "         [ 0.1188],\n",
      "         [-0.0150],\n",
      "         [ 0.0958],\n",
      "         [-0.1018],\n",
      "         [-0.0342],\n",
      "         [-0.0250],\n",
      "         [-0.0496],\n",
      "         [ 0.0287],\n",
      "         [-0.1169],\n",
      "         [ 0.1079],\n",
      "         [ 0.0500],\n",
      "         [ 0.1184],\n",
      "         [-0.1129],\n",
      "         [-0.0764],\n",
      "         [ 0.0177],\n",
      "         [-0.1065],\n",
      "         [-0.0196],\n",
      "         [ 0.0129],\n",
      "         [-0.0723],\n",
      "         [ 0.0180],\n",
      "         [-0.0428],\n",
      "         [-0.0119],\n",
      "         [-0.0797],\n",
      "         [-0.0491],\n",
      "         [-0.0442],\n",
      "         [-0.1249],\n",
      "         [ 0.0207],\n",
      "         [-0.0324],\n",
      "         [-0.0237],\n",
      "         [ 0.0858],\n",
      "         [-0.0601],\n",
      "         [-0.0650],\n",
      "         [ 0.0820],\n",
      "         [-0.0219],\n",
      "         [ 0.1197],\n",
      "         [ 0.0238],\n",
      "         [-0.0172],\n",
      "         [-0.1233],\n",
      "         [-0.0450],\n",
      "         [-0.0517],\n",
      "         [-0.0287],\n",
      "         [-0.0558],\n",
      "         [ 0.1164],\n",
      "         [ 0.0604],\n",
      "         [-0.1153],\n",
      "         [ 0.0808],\n",
      "         [-0.0327],\n",
      "         [ 0.1047],\n",
      "         [ 0.0148],\n",
      "         [-0.0321],\n",
      "         [-0.0366],\n",
      "         [-0.0733],\n",
      "         [ 0.0355],\n",
      "         [-0.0202],\n",
      "         [-0.0841],\n",
      "         [ 0.0584],\n",
      "         [ 0.1164],\n",
      "         [-0.1162],\n",
      "         [-0.0990],\n",
      "         [-0.0833],\n",
      "         [ 0.0826],\n",
      "         [-0.0811]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.convr.bias | Size: torch.Size([64]) | Values : tensor([ 0.0597, -0.0374], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[-0.0036],\n",
      "         [-0.0326],\n",
      "         [ 0.0612],\n",
      "         [-0.0133],\n",
      "         [-0.1221],\n",
      "         [-0.1248],\n",
      "         [-0.0852],\n",
      "         [-0.0914],\n",
      "         [-0.0787],\n",
      "         [-0.1204],\n",
      "         [-0.0371],\n",
      "         [ 0.1003],\n",
      "         [-0.0815],\n",
      "         [-0.0843],\n",
      "         [-0.0478],\n",
      "         [-0.0764],\n",
      "         [-0.0637],\n",
      "         [-0.0512],\n",
      "         [-0.0803],\n",
      "         [ 0.0849],\n",
      "         [ 0.0065],\n",
      "         [ 0.0864],\n",
      "         [-0.0822],\n",
      "         [-0.0086],\n",
      "         [-0.0623],\n",
      "         [-0.0124],\n",
      "         [-0.0686],\n",
      "         [-0.0699],\n",
      "         [-0.1151],\n",
      "         [-0.0237],\n",
      "         [-0.0194],\n",
      "         [-0.1036],\n",
      "         [ 0.0735],\n",
      "         [ 0.0689],\n",
      "         [-0.0661],\n",
      "         [ 0.0311],\n",
      "         [-0.0391],\n",
      "         [-0.0616],\n",
      "         [-0.0111],\n",
      "         [-0.1098],\n",
      "         [-0.0724],\n",
      "         [-0.0882],\n",
      "         [-0.0040],\n",
      "         [-0.0445],\n",
      "         [-0.0429],\n",
      "         [-0.0341],\n",
      "         [ 0.0048],\n",
      "         [ 0.0219],\n",
      "         [ 0.1195],\n",
      "         [ 0.0195],\n",
      "         [-0.0810],\n",
      "         [ 0.1188],\n",
      "         [-0.0061],\n",
      "         [ 0.1168],\n",
      "         [ 0.0996],\n",
      "         [ 0.0571],\n",
      "         [-0.0230],\n",
      "         [ 0.0474],\n",
      "         [-0.0154],\n",
      "         [ 0.0880],\n",
      "         [ 0.0906],\n",
      "         [ 0.0066],\n",
      "         [ 0.1067],\n",
      "         [-0.0941]],\n",
      "\n",
      "        [[ 0.0491],\n",
      "         [ 0.0282],\n",
      "         [ 0.0051],\n",
      "         [ 0.0495],\n",
      "         [ 0.1202],\n",
      "         [-0.0164],\n",
      "         [ 0.0054],\n",
      "         [-0.1223],\n",
      "         [-0.0789],\n",
      "         [ 0.0158],\n",
      "         [ 0.1195],\n",
      "         [ 0.0472],\n",
      "         [-0.0414],\n",
      "         [-0.0970],\n",
      "         [-0.0860],\n",
      "         [-0.0834],\n",
      "         [ 0.0832],\n",
      "         [-0.1038],\n",
      "         [-0.0133],\n",
      "         [ 0.1221],\n",
      "         [ 0.0881],\n",
      "         [ 0.0482],\n",
      "         [ 0.0643],\n",
      "         [ 0.0975],\n",
      "         [-0.0052],\n",
      "         [-0.0892],\n",
      "         [ 0.1121],\n",
      "         [-0.0641],\n",
      "         [-0.0595],\n",
      "         [ 0.1041],\n",
      "         [-0.0346],\n",
      "         [-0.1161],\n",
      "         [ 0.0903],\n",
      "         [ 0.0386],\n",
      "         [ 0.1050],\n",
      "         [ 0.0378],\n",
      "         [-0.0579],\n",
      "         [-0.0418],\n",
      "         [ 0.0753],\n",
      "         [ 0.0900],\n",
      "         [-0.0954],\n",
      "         [ 0.0043],\n",
      "         [ 0.0007],\n",
      "         [-0.0089],\n",
      "         [-0.0505],\n",
      "         [-0.1013],\n",
      "         [ 0.0491],\n",
      "         [ 0.0762],\n",
      "         [ 0.0411],\n",
      "         [-0.0572],\n",
      "         [ 0.0133],\n",
      "         [-0.0069],\n",
      "         [-0.0137],\n",
      "         [-0.0162],\n",
      "         [ 0.0243],\n",
      "         [-0.0667],\n",
      "         [-0.0831],\n",
      "         [ 0.0911],\n",
      "         [-0.0222],\n",
      "         [-0.1180],\n",
      "         [-0.0181],\n",
      "         [-0.0404],\n",
      "         [-0.0573],\n",
      "         [ 0.0535]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.conv1.bias | Size: torch.Size([16]) | Values : tensor([-0.0673,  0.0150], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[-0.0211, -0.1269,  0.0740],\n",
      "         [-0.0615,  0.1129,  0.0364],\n",
      "         [-0.1244, -0.0044, -0.0514],\n",
      "         [-0.0129, -0.0128, -0.0102],\n",
      "         [ 0.1026, -0.1396, -0.0014],\n",
      "         [ 0.0498,  0.0432, -0.0102],\n",
      "         [ 0.0683, -0.0233, -0.1243],\n",
      "         [-0.0587,  0.0993, -0.1359],\n",
      "         [-0.1064, -0.1016,  0.0143],\n",
      "         [ 0.0042,  0.1389, -0.0721],\n",
      "         [ 0.1107,  0.0527, -0.0399],\n",
      "         [ 0.1411, -0.1021, -0.0241],\n",
      "         [ 0.0781,  0.0158,  0.0194],\n",
      "         [-0.0760, -0.0177, -0.0664],\n",
      "         [-0.1352, -0.0369,  0.0319],\n",
      "         [-0.1216,  0.0478,  0.0093]],\n",
      "\n",
      "        [[ 0.0920, -0.0643, -0.0941],\n",
      "         [ 0.0638, -0.0681, -0.0864],\n",
      "         [ 0.0037, -0.0913, -0.0241],\n",
      "         [-0.0589,  0.1123, -0.1041],\n",
      "         [-0.1409,  0.0378,  0.1371],\n",
      "         [-0.0226,  0.0643, -0.0994],\n",
      "         [ 0.0063,  0.0913, -0.0840],\n",
      "         [ 0.0112, -0.1132,  0.0267],\n",
      "         [-0.1106,  0.0784,  0.0855],\n",
      "         [ 0.0605,  0.0770, -0.0620],\n",
      "         [ 0.1366, -0.0903, -0.1174],\n",
      "         [ 0.1367, -0.0625,  0.1064],\n",
      "         [ 0.1365,  0.1182, -0.0271],\n",
      "         [ 0.1213,  0.0032, -0.0177],\n",
      "         [ 0.0683,  0.0443,  0.0967],\n",
      "         [ 0.1298,  0.0958, -0.0848]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.conv2.bias | Size: torch.Size([16]) | Values : tensor([ 0.0532, -0.1409], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[ 0.1986],\n",
      "         [ 0.0077],\n",
      "         [ 0.0732],\n",
      "         [ 0.0381],\n",
      "         [-0.0094],\n",
      "         [-0.2164],\n",
      "         [ 0.1426],\n",
      "         [ 0.1597],\n",
      "         [-0.1664],\n",
      "         [ 0.1959],\n",
      "         [ 0.0168],\n",
      "         [-0.1671],\n",
      "         [-0.1449],\n",
      "         [-0.1267],\n",
      "         [ 0.1067],\n",
      "         [-0.1565]],\n",
      "\n",
      "        [[-0.1525],\n",
      "         [ 0.0064],\n",
      "         [ 0.2161],\n",
      "         [-0.1470],\n",
      "         [ 0.1552],\n",
      "         [-0.0039],\n",
      "         [-0.0158],\n",
      "         [ 0.0909],\n",
      "         [ 0.1542],\n",
      "         [-0.1553],\n",
      "         [ 0.1777],\n",
      "         [ 0.2466],\n",
      "         [ 0.1513],\n",
      "         [ 0.1854],\n",
      "         [-0.0274],\n",
      "         [ 0.2098]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.conv3.bias | Size: torch.Size([64]) | Values : tensor([-0.0078, -0.0282], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[-0.0188],\n",
      "         [ 0.0937],\n",
      "         [ 0.0484],\n",
      "         [-0.0099],\n",
      "         [-0.0906],\n",
      "         [ 0.1183],\n",
      "         [-0.0002],\n",
      "         [ 0.0898],\n",
      "         [ 0.0256],\n",
      "         [ 0.1038],\n",
      "         [-0.1196],\n",
      "         [-0.1047],\n",
      "         [ 0.0621],\n",
      "         [ 0.0654],\n",
      "         [-0.0106],\n",
      "         [ 0.0751],\n",
      "         [-0.0788],\n",
      "         [-0.0181],\n",
      "         [ 0.0039],\n",
      "         [ 0.1116],\n",
      "         [ 0.0230],\n",
      "         [ 0.0869],\n",
      "         [ 0.1142],\n",
      "         [ 0.0944],\n",
      "         [-0.1049],\n",
      "         [ 0.0619],\n",
      "         [ 0.0049],\n",
      "         [ 0.0469],\n",
      "         [-0.0121],\n",
      "         [ 0.0523],\n",
      "         [ 0.0336],\n",
      "         [-0.0465],\n",
      "         [ 0.0940],\n",
      "         [-0.0705],\n",
      "         [-0.0403],\n",
      "         [ 0.0951],\n",
      "         [-0.1036],\n",
      "         [ 0.0083],\n",
      "         [-0.0342],\n",
      "         [-0.0992],\n",
      "         [-0.1042],\n",
      "         [-0.0135],\n",
      "         [-0.0114],\n",
      "         [ 0.0028],\n",
      "         [-0.0847],\n",
      "         [-0.0133],\n",
      "         [-0.0255],\n",
      "         [-0.1249],\n",
      "         [ 0.0549],\n",
      "         [-0.0109],\n",
      "         [-0.0721],\n",
      "         [ 0.0192],\n",
      "         [ 0.0449],\n",
      "         [ 0.0494],\n",
      "         [ 0.0620],\n",
      "         [-0.0217],\n",
      "         [-0.0363],\n",
      "         [ 0.0576],\n",
      "         [ 0.0167],\n",
      "         [-0.0696],\n",
      "         [-0.0441],\n",
      "         [ 0.0317],\n",
      "         [ 0.0716],\n",
      "         [-0.0094]],\n",
      "\n",
      "        [[-0.0908],\n",
      "         [ 0.0823],\n",
      "         [ 0.0590],\n",
      "         [-0.0915],\n",
      "         [ 0.0606],\n",
      "         [-0.0640],\n",
      "         [-0.1156],\n",
      "         [-0.0912],\n",
      "         [ 0.1004],\n",
      "         [-0.0988],\n",
      "         [-0.1226],\n",
      "         [ 0.0800],\n",
      "         [-0.1101],\n",
      "         [ 0.1085],\n",
      "         [-0.0197],\n",
      "         [-0.0153],\n",
      "         [-0.0728],\n",
      "         [ 0.0903],\n",
      "         [-0.0445],\n",
      "         [-0.0964],\n",
      "         [ 0.0355],\n",
      "         [ 0.0324],\n",
      "         [-0.0213],\n",
      "         [-0.0821],\n",
      "         [ 0.1125],\n",
      "         [ 0.0335],\n",
      "         [-0.0350],\n",
      "         [ 0.0515],\n",
      "         [ 0.0374],\n",
      "         [ 0.0763],\n",
      "         [ 0.0474],\n",
      "         [-0.0388],\n",
      "         [-0.0450],\n",
      "         [ 0.0611],\n",
      "         [ 0.0478],\n",
      "         [ 0.1095],\n",
      "         [ 0.0943],\n",
      "         [ 0.1209],\n",
      "         [ 0.1127],\n",
      "         [-0.0774],\n",
      "         [ 0.0676],\n",
      "         [-0.0120],\n",
      "         [ 0.1028],\n",
      "         [ 0.0459],\n",
      "         [-0.0310],\n",
      "         [-0.0720],\n",
      "         [ 0.1159],\n",
      "         [-0.0915],\n",
      "         [-0.1183],\n",
      "         [ 0.0358],\n",
      "         [ 0.0221],\n",
      "         [-0.0590],\n",
      "         [ 0.0829],\n",
      "         [-0.0596],\n",
      "         [-0.1058],\n",
      "         [-0.1076],\n",
      "         [-0.0070],\n",
      "         [-0.0313],\n",
      "         [ 0.1051],\n",
      "         [-0.0622],\n",
      "         [-0.0790],\n",
      "         [-0.0405],\n",
      "         [ 0.0382],\n",
      "         [ 0.1020]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv1.bias | Size: torch.Size([16]) | Values : tensor([-0.0251,  0.1195], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[-0.1145, -0.1391,  0.0821],\n",
      "         [ 0.0487,  0.0249,  0.0660],\n",
      "         [-0.0595, -0.0485,  0.1274],\n",
      "         [-0.1323,  0.0384,  0.0669],\n",
      "         [-0.0693,  0.1017,  0.0814],\n",
      "         [-0.0981, -0.0850,  0.0162],\n",
      "         [-0.0774,  0.0827,  0.0204],\n",
      "         [-0.1060, -0.1093,  0.0644],\n",
      "         [ 0.0589,  0.0922,  0.0298],\n",
      "         [-0.0600,  0.0468, -0.0992],\n",
      "         [ 0.1381,  0.0463, -0.0330],\n",
      "         [-0.0913,  0.0367, -0.0490],\n",
      "         [-0.1331,  0.1045,  0.0993],\n",
      "         [ 0.0441, -0.0678, -0.0577],\n",
      "         [ 0.0146, -0.1249,  0.1005],\n",
      "         [ 0.0196,  0.1213, -0.0599]],\n",
      "\n",
      "        [[-0.0892, -0.1154,  0.0849],\n",
      "         [-0.1094,  0.0743, -0.0953],\n",
      "         [ 0.0904,  0.0773,  0.0725],\n",
      "         [ 0.1209, -0.0525, -0.0627],\n",
      "         [-0.1065,  0.0865,  0.0510],\n",
      "         [ 0.1058, -0.0401, -0.0466],\n",
      "         [-0.1429,  0.1146,  0.0609],\n",
      "         [-0.1237,  0.0934, -0.0291],\n",
      "         [ 0.0771, -0.0018,  0.0363],\n",
      "         [-0.0651, -0.0563,  0.0362],\n",
      "         [-0.0954, -0.0010,  0.0108],\n",
      "         [ 0.0258,  0.1289, -0.1121],\n",
      "         [-0.1067,  0.0318, -0.0711],\n",
      "         [ 0.0241,  0.0949,  0.0629],\n",
      "         [-0.0323,  0.0813,  0.0811],\n",
      "         [ 0.1255,  0.0959, -0.0312]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv2.bias | Size: torch.Size([16]) | Values : tensor([ 0.0259, -0.0909], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[ 0.1502],\n",
      "         [ 0.0243],\n",
      "         [-0.1786],\n",
      "         [ 0.1604],\n",
      "         [-0.1225],\n",
      "         [ 0.1436],\n",
      "         [ 0.2483],\n",
      "         [ 0.0112],\n",
      "         [ 0.1474],\n",
      "         [ 0.2161],\n",
      "         [ 0.0901],\n",
      "         [-0.1774],\n",
      "         [ 0.0591],\n",
      "         [ 0.0754],\n",
      "         [ 0.2427],\n",
      "         [-0.2298]],\n",
      "\n",
      "        [[ 0.1318],\n",
      "         [ 0.2344],\n",
      "         [ 0.2164],\n",
      "         [ 0.1250],\n",
      "         [-0.1532],\n",
      "         [ 0.1073],\n",
      "         [-0.1509],\n",
      "         [ 0.0812],\n",
      "         [-0.1788],\n",
      "         [ 0.2380],\n",
      "         [-0.2429],\n",
      "         [ 0.2314],\n",
      "         [-0.2090],\n",
      "         [-0.1227],\n",
      "         [ 0.0828],\n",
      "         [-0.0808]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv3.bias | Size: torch.Size([64]) | Values : tensor([-0.0250, -0.1168], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[ 0.0568],\n",
      "         [ 0.0540],\n",
      "         [-0.1110],\n",
      "         [ 0.0645],\n",
      "         [-0.0144],\n",
      "         [-0.1165],\n",
      "         [ 0.1226],\n",
      "         [ 0.1072],\n",
      "         [-0.0042],\n",
      "         [ 0.0335],\n",
      "         [ 0.0653],\n",
      "         [ 0.0987],\n",
      "         [ 0.0134],\n",
      "         [-0.1072],\n",
      "         [ 0.0073],\n",
      "         [-0.0477],\n",
      "         [-0.0214],\n",
      "         [ 0.0697],\n",
      "         [-0.0767],\n",
      "         [-0.0916],\n",
      "         [ 0.1176],\n",
      "         [ 0.1220],\n",
      "         [-0.1137],\n",
      "         [-0.0902],\n",
      "         [ 0.0788],\n",
      "         [-0.1172],\n",
      "         [ 0.1081],\n",
      "         [-0.0360],\n",
      "         [-0.1216],\n",
      "         [ 0.1004],\n",
      "         [-0.0665],\n",
      "         [-0.0134],\n",
      "         [-0.0240],\n",
      "         [ 0.0440],\n",
      "         [-0.0274],\n",
      "         [ 0.0363],\n",
      "         [-0.1171],\n",
      "         [ 0.0169],\n",
      "         [-0.0275],\n",
      "         [ 0.0448],\n",
      "         [-0.1052],\n",
      "         [ 0.1004],\n",
      "         [-0.0247],\n",
      "         [ 0.0660],\n",
      "         [ 0.0127],\n",
      "         [ 0.0675],\n",
      "         [ 0.0510],\n",
      "         [ 0.1147],\n",
      "         [-0.0948],\n",
      "         [ 0.1131],\n",
      "         [-0.0020],\n",
      "         [ 0.1039],\n",
      "         [ 0.0344],\n",
      "         [ 0.0706],\n",
      "         [ 0.1238],\n",
      "         [ 0.0327],\n",
      "         [-0.1139],\n",
      "         [-0.1043],\n",
      "         [ 0.0715],\n",
      "         [-0.1029],\n",
      "         [-0.0709],\n",
      "         [ 0.0519],\n",
      "         [-0.0382],\n",
      "         [ 0.0942]],\n",
      "\n",
      "        [[-0.0610],\n",
      "         [-0.0068],\n",
      "         [-0.0726],\n",
      "         [-0.0156],\n",
      "         [-0.0700],\n",
      "         [-0.0191],\n",
      "         [-0.0534],\n",
      "         [-0.0821],\n",
      "         [-0.1148],\n",
      "         [-0.1195],\n",
      "         [-0.0534],\n",
      "         [ 0.0694],\n",
      "         [ 0.1086],\n",
      "         [-0.1122],\n",
      "         [ 0.0143],\n",
      "         [-0.0648],\n",
      "         [ 0.0071],\n",
      "         [ 0.1233],\n",
      "         [ 0.0186],\n",
      "         [-0.0599],\n",
      "         [-0.0652],\n",
      "         [ 0.0536],\n",
      "         [ 0.0328],\n",
      "         [ 0.0524],\n",
      "         [ 0.0226],\n",
      "         [-0.0636],\n",
      "         [ 0.1220],\n",
      "         [-0.0658],\n",
      "         [ 0.0649],\n",
      "         [-0.0933],\n",
      "         [-0.0759],\n",
      "         [ 0.0356],\n",
      "         [ 0.0584],\n",
      "         [ 0.0672],\n",
      "         [-0.0240],\n",
      "         [-0.0175],\n",
      "         [ 0.0449],\n",
      "         [ 0.1106],\n",
      "         [-0.0541],\n",
      "         [ 0.0424],\n",
      "         [-0.0356],\n",
      "         [-0.0956],\n",
      "         [ 0.1183],\n",
      "         [-0.0481],\n",
      "         [ 0.1108],\n",
      "         [-0.0161],\n",
      "         [ 0.0244],\n",
      "         [ 0.0476],\n",
      "         [-0.0171],\n",
      "         [-0.0603],\n",
      "         [-0.0959],\n",
      "         [-0.1101],\n",
      "         [ 0.0925],\n",
      "         [ 0.0831],\n",
      "         [ 0.1046],\n",
      "         [ 0.0086],\n",
      "         [-0.0774],\n",
      "         [-0.0777],\n",
      "         [-0.0472],\n",
      "         [ 0.0957],\n",
      "         [ 0.0590],\n",
      "         [-0.0078],\n",
      "         [-0.1036],\n",
      "         [ 0.0713]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.convr.bias | Size: torch.Size([64]) | Values : tensor([-0.0567, -0.1007], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[ 0.0577],\n",
      "         [-0.0891],\n",
      "         [-0.0293],\n",
      "         [-0.0377],\n",
      "         [ 0.0416],\n",
      "         [-0.0745],\n",
      "         [ 0.1047],\n",
      "         [ 0.0923],\n",
      "         [-0.0099],\n",
      "         [ 0.0531],\n",
      "         [-0.0303],\n",
      "         [ 0.0401],\n",
      "         [-0.0662],\n",
      "         [ 0.0448],\n",
      "         [-0.1241],\n",
      "         [ 0.0391],\n",
      "         [-0.0443],\n",
      "         [-0.0296],\n",
      "         [-0.0693],\n",
      "         [-0.0072],\n",
      "         [ 0.0472],\n",
      "         [-0.0212],\n",
      "         [ 0.0935],\n",
      "         [-0.0281],\n",
      "         [ 0.0613],\n",
      "         [-0.0223],\n",
      "         [-0.0387],\n",
      "         [ 0.0812],\n",
      "         [ 0.0492],\n",
      "         [ 0.0677],\n",
      "         [-0.0153],\n",
      "         [ 0.0645],\n",
      "         [ 0.1090],\n",
      "         [ 0.0517],\n",
      "         [ 0.0080],\n",
      "         [ 0.0663],\n",
      "         [-0.1227],\n",
      "         [-0.0339],\n",
      "         [-0.0177],\n",
      "         [-0.0954],\n",
      "         [-0.0098],\n",
      "         [-0.0806],\n",
      "         [-0.0076],\n",
      "         [-0.0337],\n",
      "         [-0.0368],\n",
      "         [-0.0768],\n",
      "         [ 0.0267],\n",
      "         [-0.0781],\n",
      "         [-0.0650],\n",
      "         [-0.1031],\n",
      "         [ 0.0904],\n",
      "         [ 0.0455],\n",
      "         [ 0.0637],\n",
      "         [-0.0807],\n",
      "         [-0.1248],\n",
      "         [ 0.0831],\n",
      "         [-0.0927],\n",
      "         [-0.0742],\n",
      "         [ 0.0152],\n",
      "         [-0.0783],\n",
      "         [ 0.0860],\n",
      "         [ 0.1222],\n",
      "         [ 0.0978],\n",
      "         [-0.0562]],\n",
      "\n",
      "        [[ 0.0368],\n",
      "         [-0.0944],\n",
      "         [-0.0588],\n",
      "         [-0.0566],\n",
      "         [-0.0974],\n",
      "         [-0.0824],\n",
      "         [ 0.0771],\n",
      "         [-0.1122],\n",
      "         [-0.1167],\n",
      "         [-0.1145],\n",
      "         [-0.0797],\n",
      "         [-0.1249],\n",
      "         [-0.0120],\n",
      "         [ 0.0241],\n",
      "         [ 0.0570],\n",
      "         [-0.0515],\n",
      "         [ 0.1163],\n",
      "         [-0.0127],\n",
      "         [-0.0865],\n",
      "         [-0.0342],\n",
      "         [ 0.0306],\n",
      "         [-0.0055],\n",
      "         [-0.0049],\n",
      "         [ 0.1228],\n",
      "         [ 0.1182],\n",
      "         [ 0.0122],\n",
      "         [ 0.0608],\n",
      "         [-0.0107],\n",
      "         [ 0.0431],\n",
      "         [-0.0745],\n",
      "         [ 0.0706],\n",
      "         [-0.1248],\n",
      "         [ 0.0700],\n",
      "         [ 0.0026],\n",
      "         [-0.0709],\n",
      "         [ 0.0811],\n",
      "         [-0.0519],\n",
      "         [-0.0911],\n",
      "         [ 0.1097],\n",
      "         [ 0.0560],\n",
      "         [-0.0010],\n",
      "         [ 0.0428],\n",
      "         [ 0.0330],\n",
      "         [-0.1126],\n",
      "         [-0.0351],\n",
      "         [-0.0739],\n",
      "         [-0.0914],\n",
      "         [ 0.0415],\n",
      "         [-0.0483],\n",
      "         [-0.0460],\n",
      "         [-0.0059],\n",
      "         [-0.0216],\n",
      "         [ 0.1082],\n",
      "         [ 0.0496],\n",
      "         [ 0.0400],\n",
      "         [-0.0006],\n",
      "         [ 0.0121],\n",
      "         [-0.1198],\n",
      "         [-0.0498],\n",
      "         [ 0.0847],\n",
      "         [ 0.1035],\n",
      "         [-0.0436],\n",
      "         [ 0.0841],\n",
      "         [ 0.0888]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.conv1.bias | Size: torch.Size([16]) | Values : tensor([0.1082, 0.0813], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[-0.0994, -0.1405,  0.1407],\n",
      "         [ 0.0185, -0.0589,  0.0939],\n",
      "         [ 0.1284, -0.0264,  0.0989],\n",
      "         [ 0.0389,  0.0940,  0.1390],\n",
      "         [ 0.1323, -0.0350, -0.0129],\n",
      "         [-0.0039, -0.0440,  0.0725],\n",
      "         [-0.1190,  0.0374,  0.0896],\n",
      "         [-0.0644,  0.0751,  0.1062],\n",
      "         [-0.0899,  0.1285,  0.1308],\n",
      "         [ 0.1047, -0.1159,  0.0574],\n",
      "         [-0.1113, -0.0844, -0.0871],\n",
      "         [-0.0761,  0.0805, -0.1016],\n",
      "         [-0.1344,  0.0774,  0.0650],\n",
      "         [ 0.1221, -0.1323,  0.0886],\n",
      "         [-0.1442,  0.0465,  0.0826],\n",
      "         [-0.1390, -0.0992,  0.0903]],\n",
      "\n",
      "        [[-0.0690, -0.1303,  0.0970],\n",
      "         [ 0.0475,  0.0960,  0.1060],\n",
      "         [ 0.0245, -0.0465,  0.0237],\n",
      "         [ 0.0522,  0.0386, -0.0454],\n",
      "         [-0.0654, -0.0006, -0.0664],\n",
      "         [ 0.1131, -0.0863, -0.1338],\n",
      "         [ 0.0329, -0.1433,  0.0916],\n",
      "         [ 0.0334, -0.0002,  0.0023],\n",
      "         [ 0.0717, -0.0948,  0.1301],\n",
      "         [-0.0132, -0.1113,  0.0811],\n",
      "         [ 0.0067, -0.1361,  0.0810],\n",
      "         [-0.1098, -0.0744, -0.1151],\n",
      "         [ 0.0135, -0.0419,  0.0652],\n",
      "         [-0.0938,  0.1329,  0.0862],\n",
      "         [ 0.0659,  0.0038, -0.0632],\n",
      "         [ 0.0899, -0.0866,  0.0435]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.conv2.bias | Size: torch.Size([16]) | Values : tensor([-0.1196,  0.1156], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[ 0.2438],\n",
      "         [-0.0429],\n",
      "         [-0.0289],\n",
      "         [-0.2194],\n",
      "         [-0.1296],\n",
      "         [-0.2337],\n",
      "         [-0.1042],\n",
      "         [-0.0659],\n",
      "         [ 0.1939],\n",
      "         [ 0.1775],\n",
      "         [-0.0746],\n",
      "         [-0.0502],\n",
      "         [ 0.1718],\n",
      "         [-0.1370],\n",
      "         [ 0.1863],\n",
      "         [-0.1613]],\n",
      "\n",
      "        [[ 0.2009],\n",
      "         [ 0.0513],\n",
      "         [ 0.1365],\n",
      "         [-0.0845],\n",
      "         [-0.2220],\n",
      "         [-0.0130],\n",
      "         [ 0.1931],\n",
      "         [-0.0013],\n",
      "         [ 0.0714],\n",
      "         [ 0.0174],\n",
      "         [-0.2208],\n",
      "         [ 0.0609],\n",
      "         [ 0.1865],\n",
      "         [-0.0815],\n",
      "         [ 0.1007],\n",
      "         [ 0.2264]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.conv3.bias | Size: torch.Size([64]) | Values : tensor([-0.1454, -0.0610], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc.1.weight | Size: torch.Size([2, 704]) | Values : tensor([[ 0.0105, -0.0375, -0.0193,  ...,  0.0338, -0.0176,  0.0147],\n",
      "        [ 0.0286, -0.0292, -0.0315,  ..., -0.0292, -0.0254,  0.0163]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc.1.bias | Size: torch.Size([2]) | Values : tensor([ 0.0007, -0.0216], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the model\n",
    "model = ResNet24().to(device)\n",
    "\n",
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 5e-4\n",
    "batch_size = 64\n",
    "epochs = 200\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation\n",
    "current_acc = 0\n",
    "last_acc = 0\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluate the model with torch.no_grad()\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    last_acc = current_acc\n",
    "    current_acc = correct\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triggertimes = 0\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "    # Early Stopping\n",
    "    if current_acc <= last_acc:\n",
    "        triggertimes += 1\n",
    "        if triggertimes >= patience:\n",
    "            print(\"Early Stopping!\")\n",
    "            break\n",
    "    else:\n",
    "        triggertimes = 0\n",
    "print(\"Done!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlonmcu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
