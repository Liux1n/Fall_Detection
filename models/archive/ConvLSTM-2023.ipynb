{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(nn.Conv1d(in_channels=9, out_channels=64, kernel_size=7),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.BatchNorm1d(64),\n",
    "                                   nn.MaxPool1d(2))\n",
    "        self.conv2 = nn.Sequential(nn.Conv1d(in_channels=64, out_channels=64, kernel_size=7),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.BatchNorm1d(64),\n",
    "                                   nn.MaxPool1d(2))\n",
    "        self.conv3 = nn.Sequential(nn.Conv1d(in_channels=64, out_channels=64, kernel_size=7),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.BatchNorm1d(64),\n",
    "                                   nn.MaxPool1d(2))\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size=64, hidden_size=64, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.lstm2 = nn.LSTM(input_size=64, hidden_size=64, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc1 = nn.Sequential(nn.Flatten(),\n",
    "                                 nn.Linear(in_features=64, out_features=32),\n",
    "                                 nn.ReLU())\n",
    "        self.fc2 = nn.Sequential(nn.Linear(in_features=32, out_features=2),\n",
    "                                 nn.ReLU())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = x.select(1, -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: ConvLSTM(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv1d(9, 64, kernel_size=(7,), stride=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv1d(64, 64, kernel_size=(7,), stride=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv1d(64, 64, kernel_size=(7,), stride=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (lstm): Sequential(\n",
      "    (0): LSTM(64, 64)\n",
      "    (1): Dropout(p=0.5, inplace=False)\n",
      "    (2): LSTM(64, 64)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=32, out_features=2, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Softmax(dim=None)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: conv1.0.weight | Size: torch.Size([64, 9, 7]) | Values : tensor([[[ 0.0313,  0.0113, -0.1233,  0.0862,  0.0391, -0.1047, -0.0667],\n",
      "         [-0.0488,  0.0996, -0.0691, -0.0587,  0.0737, -0.0996, -0.0037],\n",
      "         [ 0.0147, -0.1148, -0.0523, -0.0907, -0.0177, -0.1166,  0.0476],\n",
      "         [ 0.0550, -0.0628,  0.0527, -0.1154, -0.0632, -0.0675, -0.1003],\n",
      "         [ 0.0263, -0.0536, -0.1054,  0.0974,  0.0469, -0.0715, -0.0124],\n",
      "         [-0.0156, -0.0518, -0.0555,  0.0464,  0.0373,  0.0879, -0.0363],\n",
      "         [ 0.0135,  0.0448,  0.0648, -0.0525,  0.0585, -0.0273, -0.0922],\n",
      "         [ 0.0830,  0.0707,  0.1205,  0.0059, -0.0965,  0.0333,  0.1207],\n",
      "         [-0.0723,  0.0509, -0.1158, -0.0852,  0.1139,  0.1000,  0.0669]],\n",
      "\n",
      "        [[-0.0118, -0.0365,  0.0937, -0.1221,  0.0084, -0.0672, -0.0833],\n",
      "         [-0.0143,  0.0378,  0.0825,  0.0791,  0.1089,  0.1250, -0.0563],\n",
      "         [-0.0092, -0.0876, -0.0357,  0.0257,  0.0613,  0.0485, -0.0309],\n",
      "         [-0.0468, -0.1246,  0.0840, -0.0319, -0.0982, -0.0957,  0.0622],\n",
      "         [-0.0776, -0.0435,  0.0074, -0.0430,  0.0530, -0.0049,  0.0418],\n",
      "         [-0.0313, -0.0927,  0.0433,  0.1190, -0.0086,  0.0773,  0.1035],\n",
      "         [-0.0143,  0.1217, -0.1232, -0.1133,  0.0462,  0.0215, -0.0167],\n",
      "         [-0.0751,  0.1133, -0.0799, -0.0630,  0.0339, -0.0315, -0.0113],\n",
      "         [ 0.0691,  0.1128, -0.0182,  0.0789,  0.0287, -0.0181, -0.1022]]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.0.bias | Size: torch.Size([64]) | Values : tensor([0.1071, 0.1165], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.2.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.2.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.0.weight | Size: torch.Size([64, 64, 7]) | Values : tensor([[[-8.4006e-03,  3.6186e-02,  1.8752e-02, -3.4460e-02,  3.3919e-02,\n",
      "           2.3411e-02, -3.4456e-02],\n",
      "         [ 3.4582e-02,  4.3171e-03, -3.4735e-02,  3.5106e-02, -1.2474e-02,\n",
      "          -1.3521e-02,  9.6783e-03],\n",
      "         [ 7.5409e-03, -8.8936e-03,  3.1865e-02,  4.4014e-02,  1.3282e-02,\n",
      "          -9.8557e-03, -4.5472e-02],\n",
      "         [-2.3111e-02,  1.1608e-02,  1.9613e-02, -5.9895e-03,  1.4848e-02,\n",
      "           6.6841e-03, -2.1691e-02],\n",
      "         [-2.8943e-02, -1.2261e-02, -4.4353e-02, -3.3983e-02, -5.8838e-03,\n",
      "           8.0560e-03, -4.2741e-02],\n",
      "         [ 5.0113e-03, -3.4891e-02, -2.1579e-03,  9.6194e-04, -4.4592e-02,\n",
      "           1.0290e-02,  2.4224e-02],\n",
      "         [ 4.5649e-02, -3.7848e-02, -4.0416e-02, -3.6396e-02,  2.6349e-02,\n",
      "          -3.5228e-02,  1.7614e-02],\n",
      "         [ 1.4581e-02,  2.0269e-03, -4.6675e-02, -3.9472e-02,  1.4453e-02,\n",
      "          -1.0164e-02, -3.0219e-02],\n",
      "         [-1.0020e-02,  1.4139e-02, -4.1192e-02, -7.6656e-03,  1.3791e-02,\n",
      "          -2.8632e-02,  9.1647e-03],\n",
      "         [ 1.0092e-02, -3.6073e-02, -3.4385e-02,  4.5605e-02, -2.7396e-02,\n",
      "          -2.9501e-02,  2.2045e-02],\n",
      "         [ 2.7611e-02, -1.7251e-03,  3.0700e-02, -2.8657e-02, -4.4993e-02,\n",
      "          -2.2689e-02, -4.4314e-02],\n",
      "         [-3.1140e-02, -1.3672e-02, -1.3149e-02, -3.9940e-02,  3.3259e-02,\n",
      "          -4.3852e-02, -3.8696e-03],\n",
      "         [-2.3221e-02,  3.8826e-02,  4.3614e-02,  5.6544e-03,  2.5691e-02,\n",
      "          -4.4238e-03, -5.6879e-05],\n",
      "         [-4.5582e-02,  1.8048e-02,  3.2975e-02,  6.5654e-03,  4.2918e-02,\n",
      "          -2.8852e-02, -3.4734e-02],\n",
      "         [-3.2280e-02, -4.1790e-02,  3.1456e-02,  8.7780e-03,  1.3201e-02,\n",
      "          -9.6946e-03,  7.7189e-03],\n",
      "         [-1.0175e-02, -2.5042e-02,  4.3598e-02, -3.6581e-02, -1.3663e-02,\n",
      "           4.4651e-02, -4.1773e-02],\n",
      "         [ 4.0684e-02,  8.1214e-03,  3.2892e-02, -3.7656e-02, -4.3682e-02,\n",
      "          -1.1687e-02, -4.4571e-02],\n",
      "         [ 1.1281e-02, -1.2041e-02, -1.2031e-02, -3.0183e-02,  2.2437e-02,\n",
      "          -1.3848e-02, -1.3515e-02],\n",
      "         [ 2.7234e-02, -3.3208e-02,  3.8077e-02,  1.9670e-02, -1.9593e-03,\n",
      "           1.8053e-02, -3.8603e-02],\n",
      "         [-3.6389e-02,  2.2361e-02, -4.4236e-02,  3.5032e-02,  2.9656e-02,\n",
      "          -3.1566e-02,  3.4516e-02],\n",
      "         [ 4.2759e-02,  1.7217e-02,  3.0601e-02,  2.8341e-03, -2.8275e-02,\n",
      "          -1.1905e-02,  6.2056e-03],\n",
      "         [-5.0084e-04,  4.5533e-02, -4.7375e-03, -1.0397e-02, -4.7045e-02,\n",
      "           5.3066e-03,  4.7208e-02],\n",
      "         [-3.2037e-02, -4.4858e-02, -2.7204e-02, -4.2382e-02, -3.5182e-02,\n",
      "           1.3104e-02, -1.2036e-03],\n",
      "         [ 1.9128e-02, -2.1171e-02, -3.3863e-02, -3.3928e-02,  3.0765e-02,\n",
      "          -1.4338e-02, -1.6168e-02],\n",
      "         [ 2.8749e-02, -1.6513e-02,  4.5082e-02, -4.4507e-02,  2.2690e-02,\n",
      "          -1.8942e-02, -6.4481e-03],\n",
      "         [ 4.4411e-02,  3.7663e-02, -2.7552e-02, -5.3125e-03,  3.5005e-03,\n",
      "          -3.5542e-02, -2.9034e-02],\n",
      "         [ 2.2824e-02,  1.1906e-02, -3.5165e-03,  3.5610e-02,  3.6554e-02,\n",
      "           5.5463e-03, -7.9457e-03],\n",
      "         [ 2.6281e-02,  1.9765e-02,  3.6811e-02,  1.3916e-02,  1.6325e-02,\n",
      "          -1.7156e-02,  2.6024e-02],\n",
      "         [ 3.8130e-02, -1.4917e-02,  8.6068e-03,  4.6954e-02,  2.9825e-02,\n",
      "          -1.4479e-02,  3.4903e-02],\n",
      "         [-1.7688e-02,  9.8168e-03, -4.7094e-02, -1.1424e-02,  7.8027e-03,\n",
      "           3.3296e-02,  2.1360e-02],\n",
      "         [ 2.0175e-02,  2.5416e-02,  1.2160e-02, -2.6097e-02,  3.9470e-04,\n",
      "          -1.4872e-02,  1.4789e-02],\n",
      "         [-4.6131e-02,  1.1330e-02, -1.9974e-02, -2.5117e-02, -4.3926e-02,\n",
      "          -1.7293e-02,  3.3081e-02],\n",
      "         [-4.4323e-02, -4.4287e-02,  1.4976e-02, -3.7728e-02,  3.5382e-02,\n",
      "          -4.3031e-02,  3.9583e-02],\n",
      "         [-2.0645e-02,  1.5271e-02, -8.9099e-03,  1.0047e-02, -2.1009e-02,\n",
      "          -3.9843e-02, -3.4639e-02],\n",
      "         [ 4.4851e-02, -3.2364e-02, -3.8165e-02, -2.0509e-03, -1.0416e-02,\n",
      "          -1.7954e-02, -1.1878e-02],\n",
      "         [ 2.3026e-02, -4.3476e-02, -2.7607e-02,  3.5206e-02,  2.2715e-02,\n",
      "           1.1213e-03,  4.7243e-02],\n",
      "         [ 3.3130e-02, -4.2686e-02,  2.3233e-03,  2.2721e-02,  2.6407e-02,\n",
      "           2.8194e-02,  3.4173e-02],\n",
      "         [ 2.6947e-02, -9.0236e-03,  3.1837e-02,  1.3306e-02, -4.5032e-02,\n",
      "          -4.4760e-02, -1.5346e-02],\n",
      "         [ 4.3305e-03,  1.4730e-02,  4.2957e-02,  3.4132e-02,  4.2576e-02,\n",
      "           4.3116e-02,  4.3994e-02],\n",
      "         [-1.3873e-02,  5.5454e-03,  3.8745e-02, -2.5585e-02,  3.2683e-02,\n",
      "           3.3928e-02, -3.2579e-02],\n",
      "         [-3.9858e-02, -2.5867e-02,  1.1084e-02,  2.1913e-02,  3.6241e-02,\n",
      "           6.2841e-03,  1.1278e-02],\n",
      "         [-1.3330e-02,  2.8591e-02, -3.9200e-02, -2.0266e-03,  3.2904e-02,\n",
      "           5.1126e-03, -2.2635e-02],\n",
      "         [-1.3799e-02,  3.1892e-02, -1.5347e-03,  2.5245e-02,  4.4180e-02,\n",
      "          -2.6711e-02,  1.4901e-02],\n",
      "         [-2.5597e-02,  3.2678e-02,  2.6845e-02, -4.5622e-02,  7.6430e-03,\n",
      "           3.6041e-02, -7.1458e-03],\n",
      "         [-2.4481e-02, -1.6320e-03, -1.5621e-02, -2.7987e-02, -3.3241e-02,\n",
      "          -1.8427e-02,  2.7949e-02],\n",
      "         [ 2.9695e-02, -8.5882e-03,  1.1514e-02,  3.0544e-02, -7.9473e-03,\n",
      "          -3.7031e-02, -1.8621e-02],\n",
      "         [-2.0922e-02, -2.8226e-02, -4.8946e-03,  1.7880e-03, -1.0814e-02,\n",
      "          -1.0534e-02, -1.9609e-02],\n",
      "         [-1.3622e-02,  1.1822e-02, -2.1394e-03, -2.6162e-02, -3.8279e-02,\n",
      "           2.9567e-02, -1.5655e-02],\n",
      "         [-1.7709e-02,  4.6404e-02,  3.5721e-02,  1.8480e-02, -1.1012e-02,\n",
      "           4.1538e-02, -2.2512e-02],\n",
      "         [-2.5360e-02, -3.2653e-02,  3.4253e-02,  3.0580e-02,  2.5741e-02,\n",
      "          -2.7489e-02, -3.5923e-02],\n",
      "         [-2.8186e-02, -1.2594e-02, -4.1037e-02, -2.1270e-02,  4.6711e-02,\n",
      "          -3.5477e-02, -1.7194e-02],\n",
      "         [-5.1746e-03,  1.7736e-02, -1.4721e-02,  2.0181e-02, -3.0009e-02,\n",
      "          -3.1725e-02, -2.4962e-02],\n",
      "         [ 3.4351e-02, -2.9806e-02, -1.8270e-02, -2.1502e-02, -2.4935e-03,\n",
      "          -4.2665e-02, -2.8056e-03],\n",
      "         [-3.5031e-02, -4.6431e-02, -4.5049e-02,  2.5125e-02, -1.2199e-02,\n",
      "           1.1211e-02, -2.1456e-02],\n",
      "         [ 1.0368e-02, -4.0705e-02,  2.9834e-02, -9.2585e-03,  4.1885e-02,\n",
      "           2.5481e-02, -1.8341e-02],\n",
      "         [ 3.7935e-02,  4.0459e-02, -1.1555e-02, -3.1833e-02, -9.0604e-03,\n",
      "           2.4682e-02,  1.8693e-02],\n",
      "         [ 1.6455e-02, -2.8714e-02, -4.7196e-02,  4.2706e-02, -1.5245e-02,\n",
      "          -3.6114e-02,  1.8047e-03],\n",
      "         [ 8.1518e-03, -3.9536e-02,  2.9515e-02, -2.0108e-02,  1.8801e-02,\n",
      "          -1.8169e-02, -2.4281e-02],\n",
      "         [ 1.8624e-02, -3.9253e-02,  8.4800e-03,  1.2944e-02,  4.0483e-02,\n",
      "          -4.1797e-02, -4.2107e-02],\n",
      "         [-2.4408e-02,  4.4163e-02,  1.7501e-02, -1.9998e-02,  1.1299e-02,\n",
      "          -3.1619e-02,  3.3384e-02],\n",
      "         [ 4.3922e-02,  4.1183e-02,  1.4771e-02,  4.4823e-02,  1.3848e-02,\n",
      "          -1.3171e-02, -3.6449e-02],\n",
      "         [-4.6469e-02, -1.4996e-02,  3.5178e-02,  1.9386e-03,  2.5091e-02,\n",
      "           4.4808e-02,  2.3927e-02],\n",
      "         [-3.4931e-02,  2.3033e-02, -3.4079e-02,  3.8661e-02, -7.1287e-03,\n",
      "          -7.0241e-03, -4.0075e-02],\n",
      "         [ 2.3896e-02,  2.5997e-02,  1.5221e-02, -3.1895e-02, -1.4789e-02,\n",
      "          -4.6694e-03, -2.6308e-02]],\n",
      "\n",
      "        [[-7.5372e-03, -3.6618e-02,  2.2988e-02, -4.2559e-03, -3.0114e-02,\n",
      "           4.6817e-02, -2.2323e-02],\n",
      "         [-2.0061e-02,  3.9630e-03,  3.3237e-02, -1.9576e-02, -4.2063e-02,\n",
      "          -4.2546e-02, -4.3853e-02],\n",
      "         [ 1.0989e-02,  1.2978e-02, -3.9307e-02, -3.7414e-03, -2.0020e-02,\n",
      "           2.6199e-02,  2.9682e-03],\n",
      "         [-2.2171e-02, -4.3856e-02, -2.8074e-02,  2.1306e-02, -2.9505e-03,\n",
      "           4.5875e-02,  3.8900e-02],\n",
      "         [-3.8474e-02,  2.8390e-02,  2.8090e-02,  2.7587e-02, -2.4065e-02,\n",
      "          -2.1588e-02, -4.7118e-02],\n",
      "         [ 2.6644e-02, -8.8608e-03, -4.2221e-02,  3.0907e-02,  1.9418e-02,\n",
      "           4.2148e-02, -1.8085e-03],\n",
      "         [-4.3189e-02,  1.0292e-02,  2.8402e-02, -2.3251e-02, -1.2094e-02,\n",
      "          -3.5955e-02, -4.1100e-02],\n",
      "         [-9.5881e-03, -8.3396e-03, -9.6298e-03,  2.3945e-02, -6.3692e-03,\n",
      "           9.5840e-03,  3.7684e-02],\n",
      "         [-6.4513e-03, -1.0478e-02,  4.6966e-02, -1.0703e-02,  2.8769e-02,\n",
      "          -2.3937e-02,  2.1438e-02],\n",
      "         [-4.5385e-02, -1.7123e-02, -2.5341e-02,  3.7246e-02,  1.5593e-02,\n",
      "          -3.8797e-02, -1.9202e-02],\n",
      "         [-5.0010e-04,  8.3076e-03, -3.6057e-02,  4.5726e-02, -2.7364e-02,\n",
      "          -2.6112e-02, -7.0195e-03],\n",
      "         [-1.7938e-02,  6.6750e-04, -4.5961e-02, -2.2573e-02,  9.9310e-03,\n",
      "           1.0747e-02,  3.5354e-02],\n",
      "         [-1.8825e-02, -5.5857e-03, -3.1923e-02,  4.1482e-02,  3.6481e-02,\n",
      "          -3.2202e-02,  2.9022e-03],\n",
      "         [-2.6090e-02,  6.0098e-03,  2.4434e-02, -4.9240e-03, -1.5304e-02,\n",
      "           2.0143e-02,  8.3027e-03],\n",
      "         [ 3.6642e-02,  4.4373e-02,  7.3399e-03, -3.1397e-02,  1.6229e-02,\n",
      "          -2.7993e-02, -2.3523e-02],\n",
      "         [-3.2520e-02, -2.5235e-02, -1.7413e-03, -4.4907e-02,  7.3715e-03,\n",
      "          -1.3669e-02,  2.2595e-02],\n",
      "         [ 2.3137e-02,  6.9491e-03,  1.6726e-02, -1.5551e-02, -3.7414e-02,\n",
      "          -1.9462e-02, -2.3956e-02],\n",
      "         [ 5.6962e-03,  1.0847e-05,  4.6454e-02, -4.1514e-02, -7.6253e-03,\n",
      "          -4.6428e-02, -8.3533e-03],\n",
      "         [ 1.5521e-02, -1.6150e-02,  2.0681e-02,  3.2528e-02, -1.0321e-02,\n",
      "           3.1216e-02,  2.0000e-02],\n",
      "         [ 6.7104e-03, -4.4439e-02, -1.4233e-02, -2.4351e-02, -2.2568e-02,\n",
      "           2.8315e-02,  4.6700e-02],\n",
      "         [ 1.8576e-02,  8.3337e-03,  9.4223e-03, -9.3621e-03, -2.7919e-02,\n",
      "           4.2154e-02, -1.1321e-02],\n",
      "         [-1.2756e-02, -1.6557e-02,  2.5106e-02,  2.2956e-02,  1.5566e-02,\n",
      "          -1.6384e-02, -3.8659e-02],\n",
      "         [-6.3633e-03, -1.7948e-02, -2.8712e-02, -2.8501e-02,  3.1559e-02,\n",
      "          -2.3233e-02,  3.9293e-02],\n",
      "         [-2.6161e-02,  2.1886e-02,  3.7894e-02,  2.6912e-02, -2.3413e-02,\n",
      "          -4.5262e-02, -1.0346e-02],\n",
      "         [ 1.2073e-02,  2.2625e-02,  4.3610e-02,  3.3901e-02, -1.9057e-02,\n",
      "           4.2595e-02,  1.5877e-02],\n",
      "         [-4.6167e-02, -2.0275e-02,  4.0729e-02, -1.2288e-02,  8.3210e-03,\n",
      "           3.8805e-02,  3.0355e-02],\n",
      "         [ 3.8406e-02, -3.6474e-02,  1.4133e-02, -4.2496e-02, -1.0884e-02,\n",
      "           5.4726e-03, -3.9861e-02],\n",
      "         [ 2.2544e-02, -4.4972e-02, -1.5445e-02, -3.2590e-02,  1.5553e-03,\n",
      "           4.2041e-02,  4.0065e-02],\n",
      "         [ 3.3623e-02, -2.1530e-03, -2.6181e-02,  3.0776e-02,  1.2553e-02,\n",
      "          -1.1694e-02, -2.2278e-02],\n",
      "         [-3.2250e-02, -2.7355e-03,  1.8611e-02,  1.2748e-02, -4.2942e-02,\n",
      "           4.5858e-02, -2.4028e-02],\n",
      "         [-2.0564e-02,  2.1383e-02,  1.3086e-02, -1.5879e-02,  1.1853e-02,\n",
      "          -9.1449e-04, -1.8004e-02],\n",
      "         [ 2.4556e-02, -4.6901e-02, -3.1150e-02,  1.4558e-03, -3.0383e-02,\n",
      "          -1.4946e-02, -2.3085e-02],\n",
      "         [-3.0948e-02,  7.2745e-03,  4.1760e-02, -4.6208e-03, -2.9146e-02,\n",
      "           6.7491e-03,  2.5764e-02],\n",
      "         [ 4.4425e-02,  2.2431e-02,  4.3249e-02, -4.4665e-02, -4.2398e-02,\n",
      "           2.5604e-02,  3.2080e-03],\n",
      "         [-3.0230e-02, -3.5812e-02,  1.5158e-02,  3.4892e-02, -1.3132e-02,\n",
      "           2.0219e-02,  1.7301e-02],\n",
      "         [ 4.2996e-02,  8.1821e-03,  9.7486e-03, -3.5937e-03,  1.5126e-02,\n",
      "           2.5468e-03,  2.0570e-02],\n",
      "         [ 4.6221e-02, -2.1471e-02,  4.2009e-03,  4.5886e-02,  4.5214e-02,\n",
      "           7.9150e-03,  3.7338e-02],\n",
      "         [-4.6455e-02,  6.1803e-03,  8.3952e-03,  4.1892e-02, -4.6464e-02,\n",
      "           1.6708e-02, -4.4440e-02],\n",
      "         [ 5.3395e-03,  3.3241e-02,  3.6060e-03,  1.2762e-02, -2.6392e-02,\n",
      "           2.3781e-02, -2.5185e-02],\n",
      "         [ 1.5385e-02,  4.2267e-03,  3.8631e-02, -6.3403e-03,  3.3568e-02,\n",
      "          -1.9815e-02, -6.7783e-03],\n",
      "         [-5.1329e-03,  2.6608e-02, -2.9978e-02, -1.3554e-02,  3.1730e-02,\n",
      "           2.5861e-03, -2.5770e-03],\n",
      "         [-3.3004e-02, -4.4568e-02,  4.5136e-03,  2.3774e-02, -4.4539e-02,\n",
      "          -2.4122e-02,  7.4427e-04],\n",
      "         [ 3.5104e-02,  1.0845e-02, -4.1488e-02, -1.4169e-03, -3.7881e-03,\n",
      "          -3.2344e-02,  9.0485e-03],\n",
      "         [ 8.3936e-03, -1.3179e-02,  1.9055e-02, -1.3664e-02,  4.4268e-02,\n",
      "          -2.2953e-02, -4.6658e-02],\n",
      "         [ 1.1031e-02,  4.1523e-02,  4.3301e-02, -1.3969e-02,  3.9318e-02,\n",
      "          -4.1334e-02, -4.0112e-02],\n",
      "         [ 1.2825e-02, -2.1544e-02, -2.2043e-02, -3.5074e-02,  3.5084e-02,\n",
      "          -1.6908e-02, -1.0264e-02],\n",
      "         [-2.3238e-02,  1.7138e-02, -2.2432e-02, -2.0067e-02,  3.5301e-02,\n",
      "          -1.2778e-02,  2.2038e-02],\n",
      "         [ 3.8424e-02,  2.5832e-02, -4.5518e-02,  1.5490e-03,  2.9048e-02,\n",
      "           4.4645e-03, -4.0201e-02],\n",
      "         [ 1.4632e-03,  6.9010e-03,  3.0688e-02, -3.3205e-02,  3.4226e-02,\n",
      "          -4.2879e-02,  4.6883e-02],\n",
      "         [ 4.5595e-02, -1.2533e-02,  2.6608e-02,  3.8434e-02,  1.1839e-02,\n",
      "          -3.0074e-02,  8.3504e-03],\n",
      "         [ 2.9759e-02,  2.5389e-03, -3.2893e-02,  1.1516e-02, -1.9916e-02,\n",
      "           2.0532e-02,  2.1374e-02],\n",
      "         [-1.7464e-02, -3.2338e-02, -2.9210e-02, -7.7491e-03, -2.4043e-03,\n",
      "           3.1023e-02,  2.7766e-02],\n",
      "         [ 2.0665e-02,  3.7389e-02, -4.4377e-02, -4.2229e-02, -1.7554e-02,\n",
      "          -1.9045e-02,  9.5469e-03],\n",
      "         [-6.1917e-04, -3.7396e-02, -2.0357e-02, -3.0107e-02, -1.2528e-02,\n",
      "          -7.2472e-03, -1.2121e-02],\n",
      "         [-5.3490e-03,  6.3979e-03,  2.0174e-02,  1.4172e-02,  8.7501e-03,\n",
      "          -9.6050e-03,  4.6608e-02],\n",
      "         [-1.4478e-02, -7.6614e-03, -2.7878e-02,  9.4325e-03,  3.9045e-02,\n",
      "          -2.3399e-02, -3.1175e-02],\n",
      "         [-1.7397e-02, -8.2259e-03, -3.4852e-02, -1.7475e-02, -7.2156e-03,\n",
      "           1.0936e-02,  1.0235e-02],\n",
      "         [ 3.7653e-02,  9.8312e-04,  8.0912e-03,  4.2569e-02,  1.8338e-02,\n",
      "           3.8085e-02, -3.6024e-02],\n",
      "         [-4.2984e-02,  1.2573e-02, -3.9930e-03, -4.0164e-03,  3.0795e-02,\n",
      "           2.8505e-02, -3.1379e-02],\n",
      "         [ 9.7854e-03,  1.4599e-02,  3.4069e-02,  4.5283e-03, -2.6201e-02,\n",
      "          -2.3932e-02,  8.2792e-03],\n",
      "         [ 1.2378e-02, -4.6724e-02,  2.0370e-02,  3.7420e-02, -4.5968e-02,\n",
      "           2.6201e-02,  1.3576e-02],\n",
      "         [-5.6341e-03,  2.5049e-02, -2.3540e-02, -4.2671e-02, -3.6974e-02,\n",
      "           2.1712e-02,  3.5165e-02],\n",
      "         [ 3.9363e-02, -3.2294e-02, -4.1936e-03,  1.7710e-02, -1.7594e-02,\n",
      "           4.1563e-02,  2.6238e-02],\n",
      "         [ 7.2991e-03, -3.9540e-02,  1.1998e-02, -1.4825e-02, -5.4750e-05,\n",
      "          -2.9700e-02, -2.1666e-02]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.0.bias | Size: torch.Size([64]) | Values : tensor([-0.0235, -0.0210], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.2.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.2.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv3.0.weight | Size: torch.Size([64, 64, 7]) | Values : tensor([[[ 4.1387e-02, -1.4997e-02, -2.5315e-02,  8.9674e-03, -2.7208e-02,\n",
      "           2.9675e-02, -6.2380e-04],\n",
      "         [ 4.5192e-02, -2.8003e-02,  4.6480e-02,  3.0723e-02,  1.8796e-02,\n",
      "           1.7052e-02,  8.5481e-03],\n",
      "         [-1.8190e-02, -4.5490e-02,  2.0398e-02, -2.4363e-02,  1.4855e-02,\n",
      "           3.6752e-02, -5.9844e-03],\n",
      "         [ 3.5253e-02, -2.0200e-03,  2.4424e-02,  4.5326e-02, -2.5987e-02,\n",
      "          -1.4733e-02,  7.3105e-03],\n",
      "         [-2.5440e-02, -8.6302e-03, -4.2798e-02,  8.6419e-03,  4.6896e-02,\n",
      "          -1.1607e-03, -4.1655e-02],\n",
      "         [-1.1441e-02, -2.8309e-02, -1.2217e-02,  3.1228e-02, -3.7956e-02,\n",
      "           1.3756e-02,  2.3727e-02],\n",
      "         [-3.3002e-02,  1.6996e-02, -4.2983e-02,  8.6370e-03, -6.9423e-03,\n",
      "          -1.2024e-02, -1.4833e-02],\n",
      "         [ 2.4743e-02,  7.7245e-03,  4.0036e-02,  1.9739e-02,  5.0793e-03,\n",
      "           4.9914e-03,  4.4914e-02],\n",
      "         [ 4.0486e-02,  1.1652e-02,  1.3626e-02, -7.9056e-03,  1.0190e-02,\n",
      "          -3.5569e-02, -1.9285e-02],\n",
      "         [-1.1214e-02, -2.9075e-02, -2.7782e-03, -2.4499e-02,  3.5857e-02,\n",
      "           4.5702e-02, -9.2961e-03],\n",
      "         [ 3.5334e-02,  7.7783e-03,  4.5114e-03,  8.4932e-03, -3.6082e-02,\n",
      "          -8.3470e-03,  4.1274e-02],\n",
      "         [ 1.3781e-03,  4.1375e-02, -4.1866e-02,  4.3428e-03,  3.7171e-02,\n",
      "          -4.0768e-02, -7.5119e-03],\n",
      "         [ 4.6146e-02, -2.4074e-02, -1.6321e-03,  2.3889e-02,  3.5536e-02,\n",
      "          -4.6080e-02,  3.0664e-02],\n",
      "         [ 2.7733e-02, -2.1638e-02, -2.9578e-02,  9.6185e-03,  2.1314e-02,\n",
      "           1.7611e-02, -4.0347e-02],\n",
      "         [ 4.1287e-02,  1.8854e-02, -6.5309e-03, -4.2442e-02,  1.1787e-02,\n",
      "           1.2937e-02,  3.9117e-02],\n",
      "         [-2.3014e-02, -1.7575e-02, -3.0699e-02, -1.6602e-02, -3.9262e-02,\n",
      "          -4.8986e-03, -4.1794e-02],\n",
      "         [ 2.2484e-03, -1.4041e-02, -3.9464e-02, -2.6567e-03, -1.1574e-02,\n",
      "           3.6902e-02, -8.2539e-03],\n",
      "         [ 3.7645e-02,  3.5666e-02,  3.1663e-02,  4.0901e-02, -2.7315e-02,\n",
      "          -7.4052e-03, -4.3344e-02],\n",
      "         [-1.0851e-02, -4.7190e-02, -4.5272e-02,  3.8432e-02, -2.9229e-02,\n",
      "          -2.1797e-02, -5.7577e-03],\n",
      "         [-3.8812e-02,  2.8415e-02, -3.0280e-02, -4.2933e-02, -1.9398e-02,\n",
      "           8.2326e-03,  6.7666e-03],\n",
      "         [-4.6170e-02,  1.4346e-02, -3.8816e-02,  4.4895e-02, -2.0027e-02,\n",
      "           1.0584e-02,  3.7787e-02],\n",
      "         [-3.3997e-02, -3.0332e-02, -1.4911e-02, -1.4111e-02, -4.4028e-02,\n",
      "          -3.6049e-02,  2.3174e-02],\n",
      "         [-3.8741e-03,  2.0331e-02,  1.0045e-02, -2.3460e-02, -2.9567e-03,\n",
      "           2.4620e-02,  9.7210e-03],\n",
      "         [ 2.1215e-02, -2.0791e-02, -1.4475e-02,  2.5728e-02,  2.7066e-03,\n",
      "          -1.1673e-02,  3.9074e-02],\n",
      "         [ 7.3347e-03, -1.6238e-02,  3.1881e-02,  2.9029e-02, -2.9604e-02,\n",
      "           6.3057e-03,  7.0588e-03],\n",
      "         [-2.9683e-03,  2.0531e-02,  3.5469e-02, -2.0152e-02,  1.3426e-02,\n",
      "           1.4374e-03, -3.5775e-02],\n",
      "         [ 8.2059e-03, -3.8759e-02,  2.1263e-03,  2.0543e-03, -2.0470e-02,\n",
      "           1.6382e-02,  2.4384e-02],\n",
      "         [-2.9050e-02,  2.9186e-05,  2.5725e-02, -1.4233e-02,  4.3981e-02,\n",
      "           2.3270e-02, -2.4843e-02],\n",
      "         [ 1.5220e-02,  1.3844e-02,  1.4177e-02, -3.7028e-02, -2.8748e-02,\n",
      "           2.4820e-02, -2.3116e-03],\n",
      "         [-1.5730e-02, -1.3794e-02,  2.3276e-02,  3.5526e-02, -1.2646e-02,\n",
      "          -2.3612e-02,  2.2059e-02],\n",
      "         [ 3.6370e-02,  2.5502e-03, -1.9676e-02,  1.0804e-02,  4.0851e-02,\n",
      "           2.0343e-02, -1.5722e-02],\n",
      "         [-2.3689e-02, -1.0394e-02,  4.1065e-02,  3.0228e-02, -4.2900e-02,\n",
      "           2.0225e-03, -1.0592e-02],\n",
      "         [-3.6188e-02, -3.3837e-02, -4.0196e-02, -2.9621e-03, -1.6643e-02,\n",
      "          -3.6399e-02, -3.7414e-02],\n",
      "         [ 1.9668e-02, -3.3815e-02, -2.4654e-02,  3.9560e-02, -3.2758e-02,\n",
      "          -4.1150e-03,  3.1048e-02],\n",
      "         [-1.7522e-02, -1.4759e-02, -8.3672e-03,  2.0287e-02, -2.2154e-02,\n",
      "           1.9272e-02,  2.4153e-02],\n",
      "         [-1.6061e-02,  3.1397e-02, -2.6157e-02, -2.6968e-02,  3.7486e-03,\n",
      "           8.1427e-03, -1.6657e-02],\n",
      "         [ 3.9646e-02,  1.7272e-02, -3.7180e-02,  8.6643e-03,  4.8249e-03,\n",
      "          -3.2773e-03,  1.7692e-02],\n",
      "         [-2.1244e-02, -2.4432e-02, -2.3635e-04,  1.4983e-02, -2.0951e-02,\n",
      "           2.1515e-02,  2.4607e-03],\n",
      "         [ 6.4376e-03,  2.2031e-02, -1.7261e-02,  1.3056e-03, -5.7934e-03,\n",
      "           4.1783e-03,  3.0725e-02],\n",
      "         [-1.0877e-02, -2.2481e-02, -8.3190e-03,  5.2349e-03, -1.6842e-03,\n",
      "          -5.6759e-03, -2.2447e-02],\n",
      "         [ 2.9341e-02, -2.3396e-02,  3.4047e-02,  1.9866e-02, -2.5963e-02,\n",
      "           4.1516e-02, -3.6136e-02],\n",
      "         [ 2.1308e-02, -4.6383e-02,  3.1642e-02,  3.0361e-02, -1.4820e-03,\n",
      "          -1.1820e-02, -1.5967e-02],\n",
      "         [-7.8001e-04, -1.8514e-02, -1.8713e-02,  3.9983e-02, -3.7897e-02,\n",
      "           5.3634e-03, -2.2553e-02],\n",
      "         [-2.1762e-02,  3.4253e-02,  1.4600e-02,  4.3296e-02, -1.8965e-02,\n",
      "          -1.6777e-02, -2.4193e-02],\n",
      "         [-5.5380e-03,  2.9574e-02,  2.1241e-02, -3.6424e-02, -2.7290e-02,\n",
      "           1.3725e-02, -2.9369e-02],\n",
      "         [ 7.8134e-03,  2.9170e-02,  8.4170e-03,  2.1203e-02, -4.0102e-02,\n",
      "           4.6588e-02, -3.5451e-03],\n",
      "         [-7.1745e-03, -7.0511e-03,  4.0867e-03,  5.4994e-03,  3.0967e-03,\n",
      "          -4.0280e-02, -4.2500e-02],\n",
      "         [ 1.1775e-02, -6.9778e-03,  2.6543e-02,  3.4819e-02, -6.9166e-03,\n",
      "           2.2930e-02,  9.4774e-04],\n",
      "         [ 7.7072e-03, -2.4979e-02, -1.3515e-02,  4.4945e-02,  1.9945e-02,\n",
      "          -2.6468e-03,  3.7463e-02],\n",
      "         [ 2.1606e-02,  4.2645e-02, -4.6577e-02, -3.3931e-02,  1.9474e-02,\n",
      "           7.1771e-03, -1.0793e-02],\n",
      "         [-4.4988e-02, -9.2832e-03,  4.5433e-02,  4.6757e-02,  4.6780e-03,\n",
      "          -1.9687e-02,  2.9059e-02],\n",
      "         [-3.8341e-02,  1.1691e-02, -1.0230e-02, -4.3003e-02,  1.0470e-02,\n",
      "           4.1804e-02, -4.6344e-03],\n",
      "         [-1.9871e-02,  3.5815e-02,  2.2534e-02,  1.0269e-02, -3.8810e-03,\n",
      "          -2.3567e-02, -1.5834e-02],\n",
      "         [ 2.6213e-02, -4.6412e-02,  3.9092e-02, -4.5330e-02,  6.9601e-03,\n",
      "           3.1797e-02, -1.2591e-02],\n",
      "         [ 4.4312e-02, -3.3110e-02,  2.2020e-02, -3.1268e-02, -1.5260e-02,\n",
      "          -2.4454e-02, -4.2215e-02],\n",
      "         [ 5.0628e-03, -4.4363e-02, -4.3945e-02,  2.1615e-03, -4.6213e-02,\n",
      "           5.6559e-03,  3.5492e-03],\n",
      "         [ 2.5714e-02, -2.2009e-02, -8.3589e-03, -3.4848e-02,  2.2222e-02,\n",
      "           4.2938e-02,  1.0009e-02],\n",
      "         [ 7.6327e-03, -3.4428e-03, -3.7474e-02, -2.6148e-02, -1.2694e-03,\n",
      "           4.1004e-02,  1.0971e-02],\n",
      "         [ 3.8441e-02,  2.6077e-02,  1.8965e-02,  6.4697e-04, -8.7492e-03,\n",
      "           3.6286e-02,  2.0983e-02],\n",
      "         [ 2.5075e-02, -4.4322e-02,  4.0490e-02,  5.4652e-03,  5.5059e-03,\n",
      "          -2.3641e-02,  3.4753e-02],\n",
      "         [-2.2741e-02,  1.1735e-02, -4.2967e-03,  4.5901e-02,  2.2216e-02,\n",
      "          -4.6518e-02, -3.1858e-02],\n",
      "         [-3.7835e-02, -4.1435e-02, -3.0699e-02, -3.9098e-02, -8.6503e-03,\n",
      "           3.0659e-02,  2.1495e-02],\n",
      "         [ 1.8621e-02,  1.6074e-02, -3.8985e-02,  4.3403e-02, -2.8511e-02,\n",
      "           4.4896e-02,  1.3002e-02],\n",
      "         [ 3.8030e-02,  1.0529e-02, -6.9938e-03, -6.0303e-03,  3.9007e-02,\n",
      "          -3.0052e-02, -3.3782e-03]],\n",
      "\n",
      "        [[ 2.7102e-02,  2.0880e-02,  2.1412e-02, -6.1373e-05,  2.2143e-02,\n",
      "           2.9872e-02, -2.9914e-02],\n",
      "         [ 1.1368e-02, -1.2274e-02,  3.7434e-02, -4.1947e-02,  3.0546e-02,\n",
      "           1.1169e-02,  4.2707e-02],\n",
      "         [ 1.2436e-02, -5.6964e-03, -3.5545e-02,  8.7800e-03,  1.3491e-02,\n",
      "          -3.7756e-02, -9.8143e-04],\n",
      "         [ 6.6212e-03,  4.1803e-02,  2.4281e-02, -1.2298e-02,  3.1233e-02,\n",
      "           3.4241e-02,  2.9497e-02],\n",
      "         [ 3.2022e-02, -2.0109e-02,  2.0879e-02, -3.0567e-02, -2.9240e-02,\n",
      "          -2.5464e-02,  3.8013e-03],\n",
      "         [-5.9709e-03,  2.3619e-02,  2.4739e-02, -3.4209e-02,  4.5601e-02,\n",
      "          -4.1052e-02, -1.5515e-02],\n",
      "         [-3.8817e-02, -4.1188e-02, -4.6207e-02, -1.7720e-02,  3.9730e-02,\n",
      "          -1.0483e-02, -1.3406e-02],\n",
      "         [-3.3900e-02,  4.5942e-02, -1.0822e-02, -1.4322e-03, -4.3253e-03,\n",
      "           4.9020e-03,  3.0779e-02],\n",
      "         [ 3.1441e-02,  8.7192e-03,  3.9657e-02,  3.8509e-02, -4.1516e-02,\n",
      "           2.7702e-04,  9.8176e-03],\n",
      "         [-4.2942e-02,  2.4273e-02, -4.6104e-02, -4.4314e-02, -6.9410e-03,\n",
      "           4.2877e-02, -2.0167e-02],\n",
      "         [ 3.7942e-02,  2.4013e-02, -3.4893e-02,  1.3211e-02, -2.9943e-02,\n",
      "           4.1151e-02,  4.5168e-02],\n",
      "         [ 3.9254e-02,  2.9033e-02, -2.0448e-03,  3.4483e-02, -4.6837e-02,\n",
      "           3.0051e-03,  2.1713e-03],\n",
      "         [-4.0491e-02,  6.5536e-03, -3.3912e-02, -1.9584e-02,  1.9376e-02,\n",
      "          -4.4902e-02, -3.7349e-02],\n",
      "         [-6.6928e-03,  1.6223e-02,  2.3230e-02, -3.9077e-02,  1.1554e-02,\n",
      "          -2.8860e-02, -4.0063e-02],\n",
      "         [ 2.1067e-02, -2.1026e-02,  3.3792e-03, -3.6790e-02,  1.8928e-02,\n",
      "          -4.2912e-02,  1.7709e-02],\n",
      "         [ 1.2714e-02,  1.6403e-02, -1.4449e-02, -3.5958e-02, -2.4482e-04,\n",
      "           4.2026e-02, -2.8416e-02],\n",
      "         [-3.8986e-03, -3.9990e-02, -1.5877e-02, -2.0860e-02, -2.6081e-02,\n",
      "          -4.5219e-02, -2.4199e-02],\n",
      "         [ 1.2252e-02,  2.2985e-02,  6.8190e-03,  1.6576e-02, -1.5125e-02,\n",
      "           4.3763e-02, -1.1800e-02],\n",
      "         [-5.3693e-03,  3.3452e-02,  2.1222e-02, -1.8199e-02,  4.1334e-02,\n",
      "          -3.3635e-02,  3.1962e-02],\n",
      "         [ 2.0051e-02, -3.5158e-02, -4.0752e-02,  1.8442e-02,  3.5757e-02,\n",
      "           1.8072e-02,  1.2226e-03],\n",
      "         [ 4.8873e-03, -3.7156e-02, -3.6717e-02,  1.4318e-02, -2.2306e-02,\n",
      "           3.1157e-02,  5.1332e-03],\n",
      "         [ 4.1396e-02, -3.0011e-02, -4.6876e-02, -3.3395e-02,  4.6203e-02,\n",
      "          -4.5376e-02, -4.6111e-02],\n",
      "         [-1.2308e-02, -1.0877e-03, -2.0038e-02, -4.6348e-02,  4.3953e-02,\n",
      "          -8.2893e-03,  1.8246e-02],\n",
      "         [ 1.9224e-03, -1.9003e-02,  8.9758e-03, -1.5754e-02, -4.2265e-02,\n",
      "           3.8946e-02,  1.5823e-03],\n",
      "         [-1.2956e-02,  2.1245e-02, -6.9476e-03,  3.6587e-02,  1.2983e-02,\n",
      "          -9.0733e-03, -3.9525e-02],\n",
      "         [-1.5720e-03, -1.1912e-02, -1.6640e-02,  8.3210e-03, -1.3030e-02,\n",
      "           1.4777e-02,  1.8737e-02],\n",
      "         [-2.5799e-03, -4.4013e-02,  8.3160e-03, -5.9209e-03, -2.2540e-02,\n",
      "          -3.6771e-03,  5.6340e-03],\n",
      "         [-3.3417e-02, -4.4965e-02,  4.9445e-03,  2.8205e-02, -3.3624e-02,\n",
      "          -3.6565e-02, -2.8048e-02],\n",
      "         [ 1.6428e-02, -6.2113e-03, -2.2774e-02, -4.0757e-02,  3.7229e-02,\n",
      "           1.2218e-02,  3.3964e-02],\n",
      "         [ 2.6527e-03,  3.8157e-02,  1.3565e-03, -2.5309e-02,  2.0879e-02,\n",
      "           4.6290e-02, -4.5858e-02],\n",
      "         [ 9.5042e-04,  1.0357e-02, -4.6051e-02, -3.7749e-02,  2.7778e-02,\n",
      "          -1.0270e-02, -1.4043e-02],\n",
      "         [-2.2450e-02,  3.2698e-02, -8.9250e-03, -2.7290e-02, -1.5643e-02,\n",
      "          -2.1074e-02,  9.5615e-03],\n",
      "         [-1.2821e-02, -3.6052e-02,  2.4519e-02,  4.3023e-02,  4.3749e-02,\n",
      "           4.5072e-02,  1.3729e-02],\n",
      "         [-1.1974e-02, -3.4065e-02, -3.1872e-02,  4.0727e-02,  2.8122e-03,\n",
      "           3.3669e-02, -2.6532e-03],\n",
      "         [-7.3890e-03, -3.2018e-02, -5.6703e-03,  4.9731e-03,  6.9801e-03,\n",
      "          -4.2608e-02,  2.2667e-02],\n",
      "         [-3.0636e-02, -1.1739e-02, -1.9744e-02,  6.2271e-03,  4.0309e-02,\n",
      "           1.8219e-02,  2.1517e-02],\n",
      "         [ 1.1385e-02,  3.5098e-02,  8.7809e-03,  8.6889e-03, -3.6305e-02,\n",
      "           1.7048e-02,  2.2233e-02],\n",
      "         [-3.7693e-02, -3.8456e-02,  2.0986e-02, -3.7916e-02, -2.7428e-02,\n",
      "           2.0425e-02, -1.3374e-02],\n",
      "         [ 9.7901e-03, -2.7275e-02, -8.3399e-03,  2.0744e-02,  3.2460e-02,\n",
      "           4.7219e-02,  1.7275e-02],\n",
      "         [ 2.5717e-02,  2.5574e-03, -6.4618e-03, -2.9455e-04, -2.4846e-02,\n",
      "          -9.3265e-03, -6.8208e-03],\n",
      "         [ 2.8749e-02,  1.8505e-02, -2.3356e-02, -4.2577e-02,  4.5293e-02,\n",
      "          -1.8506e-02, -3.7681e-02],\n",
      "         [ 4.0060e-02, -4.2825e-02,  3.2462e-02, -3.5505e-02, -1.0376e-03,\n",
      "          -4.5996e-03, -4.0152e-03],\n",
      "         [ 4.7433e-03, -1.8084e-02,  1.3237e-02, -7.0043e-03,  4.6515e-02,\n",
      "          -2.4197e-02,  3.0709e-02],\n",
      "         [-3.6306e-04, -9.7800e-03, -3.1882e-02,  1.2552e-02, -3.2329e-02,\n",
      "          -4.2200e-02,  2.2423e-02],\n",
      "         [-4.2779e-02, -1.7549e-02, -8.2562e-03, -2.3056e-02, -1.3441e-02,\n",
      "           2.1450e-02,  1.2172e-02],\n",
      "         [ 2.6394e-02,  5.4472e-03, -1.3686e-02, -4.6694e-02,  9.6109e-03,\n",
      "          -2.7862e-02,  3.5618e-02],\n",
      "         [-4.0952e-02, -2.9195e-02, -3.9392e-02,  2.8090e-02, -4.2821e-03,\n",
      "          -4.0785e-02, -1.5933e-02],\n",
      "         [-3.8647e-03, -3.8874e-02, -2.9741e-02, -5.3558e-03, -2.1924e-02,\n",
      "          -3.5072e-02,  1.4696e-02],\n",
      "         [-2.8134e-02,  3.4100e-02,  2.2832e-02, -1.2626e-02, -9.8480e-03,\n",
      "          -3.3352e-02, -3.4625e-02],\n",
      "         [-2.9106e-02, -3.0509e-02, -2.9766e-02, -4.6444e-03,  4.3117e-03,\n",
      "          -1.8360e-02,  4.3040e-02],\n",
      "         [ 1.0490e-02,  3.5533e-02, -2.6764e-02, -2.4355e-02,  2.1271e-02,\n",
      "          -2.1870e-02,  2.3001e-02],\n",
      "         [ 3.1553e-02,  3.1496e-02, -4.3866e-02,  8.4980e-03,  1.3404e-02,\n",
      "           2.7421e-02,  1.7033e-03],\n",
      "         [-3.4105e-02,  6.6754e-03, -4.7119e-02,  9.2621e-03,  7.5703e-03,\n",
      "           1.1804e-02, -6.9219e-03],\n",
      "         [ 4.4618e-02, -3.4342e-02,  3.6450e-02, -4.1372e-02, -4.2662e-03,\n",
      "           1.3101e-03, -3.4140e-02],\n",
      "         [ 2.2319e-02,  5.9479e-03,  6.1405e-03, -6.1338e-03, -2.7865e-02,\n",
      "          -8.4572e-04, -3.8752e-03],\n",
      "         [-1.4185e-02,  1.0741e-02,  1.6315e-02,  2.2157e-02, -1.8797e-02,\n",
      "          -6.3496e-03,  4.0492e-02],\n",
      "         [-2.1662e-02, -6.6551e-03,  1.9083e-02, -1.3120e-03, -4.3251e-02,\n",
      "           1.3865e-02, -1.4917e-02],\n",
      "         [ 2.6728e-02, -2.2233e-02, -2.0439e-02,  2.6639e-02,  4.5821e-02,\n",
      "           8.6343e-03,  1.1700e-02],\n",
      "         [-2.0636e-02,  3.4393e-02, -2.4458e-02,  7.5810e-03,  1.5274e-02,\n",
      "           1.2985e-02, -2.1562e-03],\n",
      "         [ 3.1551e-02,  3.7589e-03,  2.7360e-02,  1.7842e-03,  3.2238e-02,\n",
      "          -2.6829e-02, -4.1203e-02],\n",
      "         [ 4.6392e-02, -3.7983e-02,  8.3413e-03, -4.6247e-03,  3.9295e-02,\n",
      "           4.2615e-02, -3.9230e-02],\n",
      "         [-2.3256e-02,  3.0926e-02, -9.1585e-03,  1.4227e-02, -2.2477e-02,\n",
      "           1.8524e-02,  6.7420e-03],\n",
      "         [ 6.3667e-03,  1.7024e-02,  4.5929e-02,  3.6263e-03, -3.1497e-02,\n",
      "          -3.9738e-02,  2.4224e-02],\n",
      "         [ 7.9316e-03,  1.2216e-02,  1.1080e-02,  1.8388e-02,  2.6159e-03,\n",
      "          -3.0827e-02,  2.5512e-02]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv3.0.bias | Size: torch.Size([64]) | Values : tensor([0.0224, 0.0275], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv3.2.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv3.2.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm.0.weight_ih_l0 | Size: torch.Size([256, 64]) | Values : tensor([[ 0.0965,  0.0037,  0.1235, -0.0951,  0.0385,  0.0721, -0.1054,  0.1111,\n",
      "         -0.0132, -0.0027,  0.1111, -0.0917, -0.1050,  0.1062, -0.0232, -0.0713,\n",
      "         -0.0112,  0.0305, -0.0546,  0.1043,  0.0914,  0.0397,  0.1099,  0.0117,\n",
      "          0.0863, -0.0257, -0.0366, -0.0129, -0.0846, -0.0995,  0.0977, -0.0916,\n",
      "         -0.0189, -0.1027, -0.0852,  0.0052, -0.0733,  0.0892, -0.0255, -0.1155,\n",
      "         -0.0776,  0.0129, -0.0032, -0.1076,  0.0095, -0.1073, -0.0927, -0.0710,\n",
      "         -0.1087, -0.0525, -0.0593,  0.0342, -0.0679,  0.0639,  0.0093, -0.1106,\n",
      "         -0.0525, -0.0952,  0.0604,  0.0356,  0.0718,  0.0793, -0.0909, -0.1034],\n",
      "        [ 0.0844, -0.0664,  0.1026, -0.0717,  0.0012,  0.1161, -0.0931, -0.1184,\n",
      "          0.0099,  0.0717, -0.0289, -0.1030, -0.0593,  0.0015,  0.0517,  0.0899,\n",
      "         -0.0830, -0.0404,  0.0291,  0.0228,  0.1150,  0.0050,  0.1231,  0.0052,\n",
      "         -0.0500, -0.0214, -0.0342, -0.0857,  0.0589, -0.0256, -0.0989,  0.0201,\n",
      "         -0.1163, -0.0908,  0.1226,  0.0457,  0.0108, -0.1069, -0.0853, -0.0342,\n",
      "         -0.0899,  0.0270, -0.0349, -0.0631,  0.0865,  0.0948, -0.0778, -0.0634,\n",
      "         -0.0516,  0.0573,  0.0120, -0.0036, -0.0494,  0.0348,  0.0040,  0.0077,\n",
      "         -0.0556, -0.0554,  0.0783,  0.0371, -0.1157,  0.0686,  0.1174, -0.0582]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm.0.weight_hh_l0 | Size: torch.Size([256, 64]) | Values : tensor([[-0.0684, -0.0159,  0.0537, -0.0012, -0.0721, -0.1109, -0.0027,  0.1169,\n",
      "          0.0713,  0.0997,  0.0142, -0.0920,  0.1115, -0.0702,  0.0670, -0.1060,\n",
      "          0.0567,  0.0480, -0.0049, -0.0695, -0.0668, -0.0230,  0.0136,  0.0344,\n",
      "         -0.0393, -0.0067, -0.0833,  0.0314, -0.0553,  0.0348,  0.1043, -0.0445,\n",
      "          0.0569, -0.0597, -0.0962,  0.0060,  0.0839,  0.0071, -0.0219, -0.0207,\n",
      "         -0.0448,  0.1140,  0.0279, -0.1064,  0.0443,  0.0635, -0.0164,  0.0747,\n",
      "          0.1172,  0.1120,  0.0536, -0.0863,  0.1053, -0.0043, -0.0207,  0.0212,\n",
      "          0.0197, -0.0936,  0.0173, -0.1085,  0.1152, -0.0282,  0.0510, -0.0593],\n",
      "        [-0.0738, -0.1151,  0.1129,  0.0102, -0.0832,  0.0939,  0.0979,  0.0745,\n",
      "          0.1085, -0.1207, -0.1117,  0.0404,  0.0553,  0.0145,  0.0463,  0.0252,\n",
      "         -0.1243,  0.1199,  0.0543,  0.1137, -0.0903,  0.1086, -0.0389,  0.0103,\n",
      "         -0.0520, -0.1087,  0.0628,  0.0649,  0.0103,  0.0108,  0.0481, -0.1152,\n",
      "         -0.1205, -0.1174, -0.0043,  0.1158, -0.0233,  0.0687, -0.1165,  0.0449,\n",
      "          0.0548,  0.0477, -0.0449, -0.0513, -0.0624,  0.0920,  0.0332,  0.0239,\n",
      "         -0.0136,  0.1047, -0.1044,  0.0651,  0.0127, -0.0345,  0.0561,  0.0819,\n",
      "         -0.0188,  0.1130, -0.0212,  0.1216,  0.0432,  0.0525,  0.0961,  0.0830]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm.0.bias_ih_l0 | Size: torch.Size([256]) | Values : tensor([0.0512, 0.1007], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm.0.bias_hh_l0 | Size: torch.Size([256]) | Values : tensor([-0.0455, -0.0459], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm.2.weight_ih_l0 | Size: torch.Size([256, 64]) | Values : tensor([[ 0.0113, -0.0597, -0.1206,  0.1053, -0.0415,  0.0010,  0.0197,  0.0895,\n",
      "         -0.0710,  0.1020,  0.0404,  0.0301,  0.0642, -0.0443, -0.1240, -0.0461,\n",
      "          0.0355,  0.0213, -0.0661,  0.0116,  0.0425, -0.0767,  0.0707,  0.0456,\n",
      "         -0.0894,  0.0280, -0.0745,  0.1034, -0.0329, -0.0248,  0.0136, -0.0211,\n",
      "          0.0995,  0.0442, -0.0772, -0.0200,  0.0821,  0.0560, -0.0079,  0.1160,\n",
      "         -0.0569, -0.0311,  0.0619, -0.0012,  0.0800, -0.0018,  0.1203, -0.0228,\n",
      "         -0.0508,  0.0196, -0.0101,  0.1194,  0.0437,  0.0053, -0.0347,  0.0041,\n",
      "         -0.0513,  0.0557,  0.0497,  0.0098,  0.0789,  0.1220,  0.0762, -0.0454],\n",
      "        [ 0.0697, -0.1068, -0.1065,  0.1076,  0.0123,  0.0377, -0.0459,  0.1067,\n",
      "         -0.1203, -0.0744, -0.0234, -0.0355, -0.0611,  0.0176, -0.1017, -0.1023,\n",
      "         -0.0108,  0.1090, -0.0559,  0.0782, -0.0072, -0.0330, -0.0088,  0.0362,\n",
      "          0.0843,  0.0508,  0.0087,  0.0123, -0.0958,  0.0673, -0.1200, -0.0291,\n",
      "          0.1110,  0.0055, -0.0743,  0.0985,  0.1143,  0.0410, -0.0720, -0.0709,\n",
      "         -0.0816, -0.0896, -0.0136,  0.0187, -0.0221, -0.0080, -0.0968,  0.0353,\n",
      "         -0.0858,  0.1178, -0.0761,  0.0341, -0.1227,  0.0103,  0.0102, -0.0401,\n",
      "          0.0151,  0.0970,  0.0619, -0.0702,  0.0843,  0.1170, -0.0733, -0.0994]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm.2.weight_hh_l0 | Size: torch.Size([256, 64]) | Values : tensor([[-0.0198,  0.0614,  0.0109,  0.1057,  0.0104, -0.0815, -0.1207,  0.0390,\n",
      "          0.0418, -0.0757, -0.0340,  0.0903, -0.0520, -0.1024,  0.0357,  0.0023,\n",
      "         -0.1127,  0.0589,  0.0159,  0.0526,  0.0659,  0.0244, -0.0410,  0.1087,\n",
      "          0.1037, -0.0771, -0.0618, -0.0107, -0.1193, -0.0964,  0.0843, -0.0688,\n",
      "          0.1059,  0.0208,  0.1132,  0.0958,  0.0580,  0.0057,  0.0271, -0.1241,\n",
      "          0.0739,  0.1248,  0.0798,  0.0469,  0.0808,  0.0078, -0.0538,  0.1009,\n",
      "         -0.0404, -0.0958,  0.0404, -0.0204,  0.1178, -0.0215, -0.1169, -0.0460,\n",
      "          0.0782,  0.0137, -0.0977,  0.0136, -0.0288, -0.0757, -0.1248, -0.1005],\n",
      "        [-0.1231,  0.1015, -0.0716, -0.1203, -0.0314, -0.0549, -0.0486,  0.0379,\n",
      "         -0.0073,  0.0369,  0.0247,  0.0791, -0.0788,  0.0171,  0.0352,  0.0575,\n",
      "         -0.0641, -0.0787,  0.0414, -0.0339, -0.0480, -0.1151, -0.0044, -0.0421,\n",
      "          0.0541,  0.0034, -0.0630,  0.0678,  0.0452,  0.0820,  0.0921,  0.0283,\n",
      "          0.0240, -0.0826, -0.1182,  0.0394, -0.0428, -0.0785,  0.0454,  0.0481,\n",
      "         -0.0823,  0.0770, -0.0318, -0.0627,  0.1200, -0.1050, -0.1224, -0.0487,\n",
      "          0.0249, -0.0409, -0.0486,  0.0177, -0.0196, -0.0669,  0.0779, -0.0374,\n",
      "         -0.0220, -0.1235, -0.0542, -0.0020,  0.0946,  0.0355,  0.0786, -0.0978]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm.2.bias_ih_l0 | Size: torch.Size([256]) | Values : tensor([ 0.0322, -0.0484], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm.2.bias_hh_l0 | Size: torch.Size([256]) | Values : tensor([ 0.0002, -0.1176], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc1.1.weight | Size: torch.Size([32, 64]) | Values : tensor([[-0.0366, -0.0264,  0.0503,  0.1006, -0.0045,  0.0179,  0.1040, -0.0953,\n",
      "         -0.0485,  0.0642, -0.0155, -0.0100, -0.0658,  0.0582, -0.0243, -0.0793,\n",
      "         -0.0908, -0.0848, -0.0466,  0.0383,  0.0824, -0.0488,  0.0820, -0.0261,\n",
      "          0.0202, -0.0185, -0.0122, -0.0022, -0.0718, -0.0814, -0.0412, -0.0976,\n",
      "         -0.0184,  0.0438, -0.1109,  0.0700,  0.1222, -0.0292, -0.1117, -0.0624,\n",
      "         -0.1084, -0.0171,  0.0509,  0.1175, -0.1112,  0.0728,  0.0803, -0.0730,\n",
      "         -0.0856,  0.0219, -0.0719, -0.0732,  0.0290, -0.0257,  0.0047,  0.0676,\n",
      "         -0.1036, -0.0138, -0.1128,  0.0467, -0.0363,  0.0210,  0.1242,  0.0441],\n",
      "        [ 0.0957, -0.0132,  0.0359, -0.0868,  0.0998,  0.0058, -0.0647,  0.0327,\n",
      "          0.0033,  0.0918, -0.0598,  0.0202,  0.0507,  0.1025, -0.0995,  0.0430,\n",
      "         -0.0972, -0.1102, -0.0922,  0.0862,  0.0519, -0.0082,  0.0296,  0.1226,\n",
      "          0.0686, -0.1181, -0.0817,  0.0215, -0.0454, -0.0926,  0.0702, -0.0218,\n",
      "         -0.0102, -0.0348, -0.0751,  0.0455,  0.0357,  0.0569, -0.0269,  0.0291,\n",
      "         -0.0100,  0.0335, -0.0564, -0.0351,  0.0648, -0.0776, -0.0481,  0.0089,\n",
      "          0.0070,  0.0847, -0.0720,  0.0899, -0.1238,  0.0540,  0.0767, -0.0952,\n",
      "          0.0069,  0.0522, -0.0370,  0.0801, -0.0916, -0.0234, -0.0912, -0.0987]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc1.1.bias | Size: torch.Size([32]) | Values : tensor([-0.0359, -0.0504], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc2.0.weight | Size: torch.Size([2, 32]) | Values : tensor([[-5.1942e-02, -1.5913e-01,  1.7262e-03, -5.1553e-02, -7.1095e-02,\n",
      "          7.2277e-02, -1.3117e-01,  1.4653e-01, -6.9417e-02, -6.3072e-02,\n",
      "          1.0695e-01, -1.1589e-01,  2.6985e-02,  9.7297e-03, -1.4985e-01,\n",
      "          1.6297e-01,  2.7911e-02, -1.8550e-02,  1.6258e-01, -1.5124e-01,\n",
      "         -1.1307e-01,  1.4286e-01, -4.3491e-02, -1.6065e-01,  9.5709e-02,\n",
      "         -1.9143e-02,  1.4925e-01,  1.3134e-02,  1.7301e-01,  6.2616e-02,\n",
      "          6.7542e-02,  1.2993e-01],\n",
      "        [-1.4326e-01, -1.2302e-01, -1.3940e-04, -1.1023e-01, -5.8476e-02,\n",
      "         -1.2628e-01,  7.0833e-02,  1.6121e-01,  1.6126e-01, -1.3784e-01,\n",
      "          2.1964e-02, -7.1414e-02, -1.4426e-01, -4.4552e-02,  4.5735e-02,\n",
      "         -8.4081e-02, -2.9394e-02, -1.6710e-01,  9.7740e-02,  2.9929e-02,\n",
      "         -5.9953e-02,  8.2880e-02, -6.7701e-02, -5.3485e-02, -4.0538e-02,\n",
      "          8.9857e-02, -7.7065e-02,  1.4337e-01, -4.7902e-02, -3.5202e-03,\n",
      "          5.1285e-03,  1.1996e-01]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc2.0.bias | Size: torch.Size([2]) | Values : tensor([-0.1450, -0.1107], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the model\n",
    "model = ConvLSTM().to(device)\n",
    "\n",
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 5e-4\n",
    "batch_size = 64\n",
    "epochs = 200\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluate the model with torch.no_grad()\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlonmcu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
