{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(nn.Conv1d(in_channels=9, out_channels=64, kernel_size=7),\n",
    "                                   nn.BatchNorm1d(64),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool1d(2))\n",
    "        self.conv2 = nn.Sequential(nn.Conv1d(in_channels=64, out_channels=64, kernel_size=7),\n",
    "                                   nn.BatchNorm1d(64),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool1d(2))\n",
    "        self.conv3 = nn.Sequential(nn.Conv1d(in_channels=64, out_channels=64, kernel_size=7),\n",
    "                                   nn.BatchNorm1d(64),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool1d(2))\n",
    "        \n",
    "        self.lstm = nn.Sequential(nn.LSTM(input_size=64, hidden_size=64),\n",
    "                                  nn.Dropout(0.5),\n",
    "                                  nn.LSTM(input_size=64, hidden_size=64),\n",
    "                                  nn.Dropout(0.5))\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.Linear(in_features=64, out_features=2),\n",
    "                                nn.Softmax())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: ConvLSTM(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv1d(9, 64, kernel_size=(7,), stride=(1,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv1d(64, 64, kernel_size=(7,), stride=(1,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv1d(64, 64, kernel_size=(7,), stride=(1,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (lstm): Sequential(\n",
      "    (0): LSTM(64, 64)\n",
      "    (1): Dropout(p=0.5, inplace=False)\n",
      "    (2): LSTM(64, 64)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    (1): Softmax(dim=None)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: conv1.0.weight | Size: torch.Size([64, 9, 7]) | Values : tensor([[[ 0.1002, -0.0304,  0.0252, -0.0599, -0.1198,  0.0744,  0.0929],\n",
      "         [ 0.1065,  0.0805,  0.1219, -0.0382, -0.0404, -0.0170,  0.0967],\n",
      "         [-0.1080,  0.0172, -0.0133,  0.0173, -0.0812,  0.0103, -0.0382],\n",
      "         [-0.0591,  0.0580, -0.0520, -0.0855, -0.0152,  0.0839,  0.0408],\n",
      "         [-0.0419,  0.0049, -0.0726,  0.0972,  0.1111,  0.0687, -0.0165],\n",
      "         [ 0.1134, -0.0172, -0.0544,  0.0569, -0.1099,  0.0415,  0.1163],\n",
      "         [ 0.0647,  0.0852, -0.1129,  0.0472, -0.0590, -0.0906, -0.0985],\n",
      "         [-0.0457,  0.0584,  0.0225,  0.0653,  0.0192,  0.1058, -0.1148],\n",
      "         [ 0.0411, -0.0487, -0.0920,  0.0803,  0.1158, -0.0050, -0.0224]],\n",
      "\n",
      "        [[ 0.0245, -0.0135, -0.0759,  0.0441,  0.0603, -0.0184, -0.0582],\n",
      "         [ 0.0990, -0.1213, -0.0499, -0.0080, -0.0253, -0.1213, -0.1150],\n",
      "         [-0.0989, -0.0140, -0.0517,  0.0943, -0.1035, -0.0294, -0.0881],\n",
      "         [ 0.0298,  0.0229, -0.0421, -0.0455,  0.0799, -0.1018,  0.0440],\n",
      "         [ 0.0748,  0.0620,  0.1151, -0.0382,  0.0182,  0.0028, -0.1128],\n",
      "         [ 0.0354, -0.0515, -0.0523, -0.0943, -0.0836, -0.0985,  0.0463],\n",
      "         [-0.0135, -0.1192,  0.0363,  0.0991, -0.1119,  0.0268, -0.0947],\n",
      "         [ 0.1018, -0.0589,  0.0153,  0.0094, -0.0864, -0.0415,  0.1142],\n",
      "         [ 0.0023,  0.0617, -0.0061,  0.0831, -0.0410, -0.0798, -0.0549]]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.0.bias | Size: torch.Size([64]) | Values : tensor([-0.1034, -0.1165], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.1.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.1.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.0.weight | Size: torch.Size([64, 64, 7]) | Values : tensor([[[ 1.0229e-02,  3.4130e-02, -3.0793e-02, -1.6371e-02, -4.0857e-02,\n",
      "          -7.5870e-03, -1.7171e-02],\n",
      "         [ 4.4123e-02, -7.6039e-03,  3.8519e-02, -1.8529e-02, -4.0476e-02,\n",
      "          -1.6558e-03, -1.8810e-02],\n",
      "         [-1.0684e-02, -4.6823e-02,  1.3205e-03,  3.2319e-02,  1.1456e-02,\n",
      "           4.1509e-03,  3.9612e-02],\n",
      "         [ 2.5872e-02,  3.6502e-03, -3.5073e-02, -4.4280e-02,  2.9658e-02,\n",
      "           1.8295e-02, -1.4952e-02],\n",
      "         [-4.4102e-02, -4.2057e-02, -3.2122e-02,  3.3788e-02, -2.3593e-02,\n",
      "          -1.2269e-03,  4.4045e-02],\n",
      "         [ 2.2528e-02,  4.6299e-02,  4.5755e-02, -4.2649e-02, -9.1671e-03,\n",
      "          -1.3733e-02, -9.8348e-03],\n",
      "         [ 3.4428e-02,  3.4018e-02, -2.2876e-02, -3.7385e-02,  2.3405e-02,\n",
      "          -3.7313e-02, -2.6405e-02],\n",
      "         [ 7.4587e-03,  2.8050e-02,  1.5846e-02, -4.5461e-02, -4.2140e-02,\n",
      "          -1.7760e-02, -3.7931e-02],\n",
      "         [-1.0613e-02, -2.5511e-02, -1.9963e-02, -1.6155e-04, -4.5678e-02,\n",
      "           4.6309e-02, -4.5136e-02],\n",
      "         [ 3.5557e-02, -9.9378e-03, -2.3301e-02, -1.1492e-02,  3.4626e-02,\n",
      "           2.8156e-02,  2.5039e-03],\n",
      "         [ 3.3663e-02,  1.6396e-02,  2.7899e-02,  4.4700e-02,  6.4913e-03,\n",
      "           2.6398e-03, -3.8083e-03],\n",
      "         [-1.2574e-02, -3.0473e-02, -4.6583e-02, -1.7565e-02, -1.5978e-02,\n",
      "           1.7265e-02, -1.3569e-02],\n",
      "         [ 2.1875e-02, -2.9976e-02, -4.2423e-02, -2.8018e-02, -2.1408e-02,\n",
      "           4.4374e-02, -1.5432e-02],\n",
      "         [ 7.1127e-03,  1.3236e-02,  2.1742e-02, -1.8064e-02, -3.3293e-02,\n",
      "          -2.0430e-02, -3.8996e-02],\n",
      "         [-4.0810e-02,  4.4515e-02,  3.2626e-02,  2.4687e-02,  3.3271e-02,\n",
      "          -4.6005e-02,  3.7704e-02],\n",
      "         [ 2.6390e-02,  4.4715e-02, -1.9368e-02,  5.3963e-03, -7.0778e-03,\n",
      "           1.9543e-02, -5.1970e-03],\n",
      "         [ 1.1678e-02, -9.4713e-03,  1.8161e-02, -3.3260e-02, -2.8201e-03,\n",
      "          -4.0670e-02, -1.8709e-03],\n",
      "         [ 1.3084e-02, -8.9462e-03,  2.1990e-02,  6.8908e-03,  1.5877e-02,\n",
      "           3.1958e-02,  2.5076e-02],\n",
      "         [-3.6212e-02,  2.1214e-02,  4.1819e-02,  1.9869e-02,  9.8080e-03,\n",
      "          -1.2149e-02,  3.5168e-02],\n",
      "         [-8.6500e-03,  1.5749e-02,  2.3513e-02, -2.5789e-02,  1.2111e-02,\n",
      "           3.3149e-02, -2.8186e-02],\n",
      "         [-9.7641e-03, -2.1647e-02, -5.9881e-03,  3.2771e-02,  7.4356e-03,\n",
      "           1.3018e-02, -3.6067e-02],\n",
      "         [ 1.5211e-02,  5.3580e-03,  2.8973e-03,  4.6325e-02, -3.7479e-02,\n",
      "          -3.5106e-02, -3.5925e-02],\n",
      "         [-3.1180e-03, -4.2557e-02, -5.7121e-03, -1.9938e-02,  2.1052e-02,\n",
      "           1.0232e-02,  7.2553e-03],\n",
      "         [-4.6294e-02,  2.1111e-02, -4.0407e-02, -1.4504e-02,  2.8263e-02,\n",
      "           2.3192e-02, -3.4014e-02],\n",
      "         [ 2.9054e-02, -4.5102e-02,  1.8793e-02,  3.5291e-02,  2.6354e-02,\n",
      "          -3.2915e-02,  3.0334e-03],\n",
      "         [-4.5926e-02, -1.0976e-02,  2.7315e-02, -2.6308e-02,  2.0083e-02,\n",
      "           4.6488e-02,  1.5421e-02],\n",
      "         [ 4.4699e-02, -2.3756e-02,  2.6922e-02,  1.4675e-02, -4.0920e-02,\n",
      "           4.2391e-02, -2.2141e-02],\n",
      "         [ 2.0346e-03,  3.7995e-02, -6.8663e-03, -2.5567e-02, -4.5581e-02,\n",
      "           1.0371e-02,  4.5069e-02],\n",
      "         [-4.3505e-02, -8.6959e-03,  2.0095e-02,  3.5069e-02,  3.1050e-02,\n",
      "           4.3408e-02, -4.5894e-03],\n",
      "         [ 3.8015e-02,  1.4998e-03,  2.6679e-02, -4.3620e-02, -1.8423e-02,\n",
      "           2.7327e-02,  3.6229e-02],\n",
      "         [ 2.3810e-02, -3.3315e-02,  3.2276e-03,  4.2668e-02,  4.5750e-02,\n",
      "           2.7465e-02,  2.3030e-02],\n",
      "         [ 1.2779e-02,  9.9974e-03, -5.5434e-03,  2.0452e-03,  4.2393e-02,\n",
      "          -1.1457e-02,  3.9769e-02],\n",
      "         [ 2.6192e-02,  1.7055e-02, -3.7098e-02, -4.1268e-02, -2.0479e-02,\n",
      "           2.9341e-02,  2.7319e-02],\n",
      "         [-2.4192e-03,  4.2236e-02,  8.6541e-04,  1.9341e-02,  3.4862e-02,\n",
      "          -9.0484e-03, -2.6677e-02],\n",
      "         [-7.2279e-03,  1.1050e-02,  4.1445e-02, -3.6150e-02, -3.4891e-02,\n",
      "          -6.5432e-04, -1.4549e-02],\n",
      "         [-2.8579e-02,  3.5106e-02,  4.0178e-02, -3.2697e-02, -4.4605e-02,\n",
      "           3.8940e-02, -4.3864e-02],\n",
      "         [ 2.5823e-02, -3.1147e-02,  3.9675e-02, -2.4326e-03,  2.1004e-02,\n",
      "          -3.2471e-02, -2.0312e-02],\n",
      "         [ 1.4343e-03,  4.4803e-02, -2.6290e-04,  2.7376e-02, -4.1057e-02,\n",
      "           2.8150e-02,  2.6579e-02],\n",
      "         [ 2.5514e-02, -1.1276e-03, -2.1300e-02,  4.7134e-02,  4.0355e-02,\n",
      "          -2.8396e-02,  8.4315e-03],\n",
      "         [-1.0988e-02, -1.2116e-02,  3.6218e-02, -2.0180e-02, -4.4127e-02,\n",
      "           8.4263e-03,  3.9900e-02],\n",
      "         [-3.3557e-02,  2.4118e-03,  2.0143e-02, -1.5020e-02,  1.5496e-02,\n",
      "           4.1102e-02, -4.7633e-03],\n",
      "         [-1.0372e-02,  6.2437e-03, -3.8720e-02, -3.7446e-02,  9.8569e-03,\n",
      "          -2.0504e-02, -9.8388e-03],\n",
      "         [ 2.3701e-02, -2.6186e-02,  1.0126e-02,  3.2170e-02, -4.6457e-02,\n",
      "           1.1562e-02, -4.7134e-02],\n",
      "         [-8.4261e-03,  3.1431e-02, -4.3790e-02, -4.6684e-02,  1.5877e-02,\n",
      "           4.4968e-03, -2.2241e-02],\n",
      "         [-2.5254e-02, -4.3429e-03, -3.4890e-02, -1.3018e-02, -1.9032e-02,\n",
      "          -2.0402e-02,  1.3937e-02],\n",
      "         [ 3.2151e-02,  2.9471e-02,  3.5735e-02, -3.2301e-02, -1.8343e-02,\n",
      "          -6.5414e-03,  1.6676e-02],\n",
      "         [-4.6643e-02, -1.8403e-03,  4.7152e-02, -4.7202e-02, -2.5362e-02,\n",
      "           3.8043e-02, -2.8894e-02],\n",
      "         [ 1.1930e-02, -4.3448e-02,  1.0425e-02,  5.6660e-03,  3.4696e-02,\n",
      "           2.7794e-02, -3.5126e-02],\n",
      "         [ 7.6066e-03,  4.7170e-02, -4.4425e-02,  2.2099e-02, -1.2754e-03,\n",
      "          -3.7534e-02, -1.2871e-03],\n",
      "         [-4.0332e-02, -2.5370e-02,  3.2092e-02,  2.6936e-02,  1.2282e-03,\n",
      "          -2.8605e-02,  2.8510e-02],\n",
      "         [-5.4639e-03,  2.4703e-02, -4.3756e-02,  2.1902e-02,  1.5809e-02,\n",
      "           7.6508e-03, -1.3013e-02],\n",
      "         [-1.0088e-02,  1.2513e-02, -2.6876e-02,  2.0698e-02,  1.4176e-02,\n",
      "           4.1522e-02, -1.9949e-02],\n",
      "         [-2.0665e-02,  4.4431e-02,  3.3228e-02, -1.1384e-02, -4.5479e-02,\n",
      "          -3.7218e-02,  1.0294e-02],\n",
      "         [ 2.8426e-02,  1.8153e-02, -1.3981e-03,  9.2131e-03, -4.1515e-02,\n",
      "          -1.2282e-02, -1.1822e-02],\n",
      "         [-3.8469e-02,  4.2412e-02, -5.3661e-03, -3.6213e-02, -2.9826e-02,\n",
      "          -4.1409e-02,  2.8453e-02],\n",
      "         [-2.3041e-02,  5.3794e-03,  1.9699e-02, -4.6224e-02, -2.4669e-02,\n",
      "           1.3452e-02,  3.4715e-02],\n",
      "         [ 1.7418e-03, -1.7722e-02, -3.0264e-03,  3.3637e-02, -3.9205e-02,\n",
      "           3.6614e-02, -2.4408e-02],\n",
      "         [ 2.0142e-02,  3.6551e-03, -7.8164e-03,  2.7420e-02, -4.0647e-02,\n",
      "           1.4134e-03,  2.5543e-02],\n",
      "         [-8.8008e-03, -3.1811e-02, -2.7015e-02,  3.6121e-02,  3.9608e-02,\n",
      "          -1.4199e-02, -6.7783e-03],\n",
      "         [ 3.2106e-02, -4.0133e-02, -2.5798e-02, -3.4685e-02,  7.4657e-03,\n",
      "           9.6217e-03, -2.8774e-02],\n",
      "         [-2.0375e-02, -3.8147e-02,  4.6036e-02,  2.7355e-02,  4.6199e-02,\n",
      "          -3.6664e-02,  2.5385e-02],\n",
      "         [-1.8918e-02,  6.5787e-03, -3.5483e-02,  3.2532e-03,  2.7832e-02,\n",
      "           4.1519e-02, -1.4599e-02],\n",
      "         [ 3.2064e-02,  1.3474e-02,  2.4154e-02, -9.5918e-03, -3.1604e-02,\n",
      "           2.0222e-02,  4.3731e-02],\n",
      "         [-1.4852e-02,  3.0896e-02,  3.1451e-02,  1.6417e-02, -3.9613e-02,\n",
      "           3.3045e-02, -4.1468e-02]],\n",
      "\n",
      "        [[-2.8885e-02,  9.2688e-03,  3.8167e-02, -3.5628e-02,  1.0803e-02,\n",
      "           5.9106e-03,  1.3299e-02],\n",
      "         [ 2.2061e-02,  1.0224e-02,  5.1442e-03,  5.4105e-03, -2.7950e-02,\n",
      "           4.1903e-02, -3.5331e-02],\n",
      "         [-3.9919e-02, -1.0181e-02,  3.1843e-03,  8.2443e-03,  1.1934e-02,\n",
      "           4.2459e-02, -1.6690e-02],\n",
      "         [-1.4682e-02, -2.6584e-02,  1.4801e-03, -4.7598e-04, -3.5764e-02,\n",
      "          -1.5191e-02,  2.4241e-02],\n",
      "         [ 1.1454e-02, -2.1828e-02,  5.7743e-03, -1.5127e-03, -3.4248e-03,\n",
      "           1.0736e-02,  3.7978e-02],\n",
      "         [ 2.2783e-02, -2.7540e-02, -4.5494e-02, -4.4915e-02, -2.3732e-02,\n",
      "           1.5780e-02, -9.3130e-03],\n",
      "         [ 1.0276e-02, -1.5325e-03,  4.5790e-02,  3.8715e-02, -3.6563e-02,\n",
      "          -4.0395e-02,  1.3923e-02],\n",
      "         [ 4.4175e-02, -1.7429e-02, -3.9752e-03, -2.3279e-03,  2.5184e-02,\n",
      "          -2.3608e-02,  4.6587e-03],\n",
      "         [-1.6531e-02, -1.3007e-02,  3.5728e-02, -1.5914e-02,  3.2207e-02,\n",
      "           2.4217e-02, -4.3999e-02],\n",
      "         [ 1.1831e-02, -7.7031e-03,  2.5606e-02,  3.9473e-02,  4.3921e-02,\n",
      "          -3.8974e-02, -2.7470e-02],\n",
      "         [ 4.4659e-02, -4.0615e-02, -3.3350e-02,  4.2453e-02,  1.3317e-02,\n",
      "           3.9357e-02,  3.6274e-02],\n",
      "         [-4.7025e-02,  8.6102e-04,  2.2689e-02, -2.7466e-02, -1.4214e-02,\n",
      "           2.2740e-03,  9.1787e-05],\n",
      "         [-4.2417e-02,  3.1756e-02, -1.7245e-02, -7.0206e-03, -2.4144e-02,\n",
      "           4.4471e-02,  2.3709e-02],\n",
      "         [ 1.2344e-02, -3.4789e-03,  2.5305e-02,  1.5372e-02,  2.3639e-02,\n",
      "          -3.7441e-03, -2.2250e-02],\n",
      "         [ 1.9298e-02,  2.4087e-02,  4.2884e-02, -4.7579e-03,  2.5027e-02,\n",
      "           9.7450e-03,  2.5831e-02],\n",
      "         [ 1.1692e-02, -1.1058e-02,  3.2795e-02,  2.2485e-03, -2.5977e-02,\n",
      "           4.1149e-02,  3.3966e-02],\n",
      "         [ 1.9258e-02, -4.3917e-02, -2.3027e-03, -2.4496e-02,  3.0418e-02,\n",
      "          -2.7810e-02,  3.1032e-02],\n",
      "         [ 2.8356e-02,  4.6468e-02, -8.4498e-03, -7.6470e-03,  3.7129e-02,\n",
      "          -3.1652e-02,  2.8498e-02],\n",
      "         [ 1.4570e-02,  3.0830e-02, -3.7991e-02,  2.1275e-02, -6.0606e-03,\n",
      "          -4.2286e-02, -6.5066e-03],\n",
      "         [ 4.4739e-02,  2.6467e-02,  1.8562e-02, -6.6928e-03,  1.2400e-02,\n",
      "           1.3520e-02,  3.4310e-02],\n",
      "         [-2.6754e-02,  1.9396e-03, -2.6975e-02,  3.5170e-02, -2.2704e-02,\n",
      "          -7.8191e-03, -3.3409e-02],\n",
      "         [ 3.4492e-02, -3.8705e-02,  2.3648e-03, -1.1349e-03, -3.9332e-02,\n",
      "          -2.8042e-02, -2.6934e-02],\n",
      "         [ 6.6179e-03, -4.3593e-04,  2.0786e-02, -4.2901e-02, -2.3069e-03,\n",
      "          -3.9257e-02, -2.4727e-02],\n",
      "         [ 5.4400e-03,  2.9530e-02, -2.0123e-02, -4.3860e-02,  1.8805e-02,\n",
      "          -3.8107e-02, -1.3319e-02],\n",
      "         [ 4.2904e-02,  4.1719e-02, -4.5235e-02, -1.5253e-02, -4.0269e-02,\n",
      "           3.2577e-02,  4.1028e-03],\n",
      "         [-1.1458e-02,  2.0450e-02,  4.3809e-03,  3.3820e-02, -6.1642e-03,\n",
      "           1.5148e-02,  3.0691e-02],\n",
      "         [-2.5319e-02, -2.4227e-02,  4.4215e-02, -2.5938e-02, -2.9186e-02,\n",
      "          -4.1021e-03,  4.3551e-02],\n",
      "         [ 2.1310e-02,  2.4290e-02, -2.0202e-02, -1.3903e-02, -2.6017e-02,\n",
      "          -4.8045e-03,  4.3845e-02],\n",
      "         [ 3.9126e-02, -2.1126e-02,  1.4995e-03,  4.1112e-02,  1.5776e-03,\n",
      "           3.0258e-02,  3.1037e-02],\n",
      "         [-1.0459e-03,  3.4106e-02, -1.7969e-02,  2.0673e-02,  3.0001e-02,\n",
      "          -1.5357e-02,  2.4140e-02],\n",
      "         [ 4.3241e-03, -2.2194e-02,  4.5934e-02,  9.9451e-03,  4.4425e-02,\n",
      "          -3.8064e-02, -6.2625e-04],\n",
      "         [-4.4942e-02,  3.8637e-02, -1.0927e-02,  4.3791e-02,  4.2897e-02,\n",
      "          -1.3909e-02,  4.5158e-03],\n",
      "         [-2.6422e-02,  2.4304e-02, -3.3824e-02, -4.6225e-02, -1.9179e-02,\n",
      "           1.0742e-02, -3.1597e-02],\n",
      "         [-8.7256e-03, -1.3332e-02, -1.5245e-02, -9.4281e-03,  4.1703e-02,\n",
      "           3.7303e-02,  1.6772e-02],\n",
      "         [ 3.0348e-02, -3.1036e-02,  2.3654e-02,  1.5425e-03,  3.0145e-02,\n",
      "           3.8303e-02,  3.9816e-02],\n",
      "         [ 1.3704e-02, -3.4557e-02,  1.2559e-02, -3.3501e-02, -2.5538e-04,\n",
      "           4.1184e-02,  3.6325e-02],\n",
      "         [ 1.0959e-02,  9.3163e-03,  8.3294e-03, -1.1360e-02,  3.6620e-02,\n",
      "          -3.5927e-02, -2.5085e-02],\n",
      "         [-3.5796e-02, -3.2944e-02,  4.4063e-02, -3.0880e-02,  8.9529e-03,\n",
      "          -2.6735e-02, -3.8393e-02],\n",
      "         [-4.3924e-02,  2.3180e-03,  4.3178e-02,  3.3085e-02, -2.6591e-02,\n",
      "           2.1034e-02, -3.7842e-02],\n",
      "         [ 2.1941e-02, -2.8562e-02, -3.5197e-02, -1.6367e-04, -1.9544e-02,\n",
      "           3.1032e-02,  3.2565e-02],\n",
      "         [-3.2913e-02,  5.2583e-03, -1.6117e-02, -3.1712e-02, -4.5340e-02,\n",
      "           2.6670e-02,  4.3033e-02],\n",
      "         [-1.5962e-02, -1.1046e-02,  3.8180e-02, -2.4217e-02, -3.1050e-02,\n",
      "          -2.3834e-02, -3.0208e-02],\n",
      "         [ 3.8893e-02, -1.1842e-02,  3.2724e-02,  3.8530e-02,  3.3111e-02,\n",
      "           1.8786e-02, -9.9958e-03],\n",
      "         [-3.0335e-02,  1.7018e-02,  4.5330e-02, -2.3707e-02, -2.2498e-02,\n",
      "           2.5042e-03,  1.5855e-02],\n",
      "         [ 2.1988e-03, -3.7827e-02,  1.1723e-02, -3.9756e-02,  8.5328e-03,\n",
      "          -4.0948e-03,  4.0990e-02],\n",
      "         [-8.0737e-03,  1.1779e-02, -2.9369e-02,  8.6428e-03,  9.3562e-04,\n",
      "           4.2081e-02, -2.4098e-02],\n",
      "         [ 3.1911e-02,  3.3566e-02, -1.3721e-02, -3.8768e-02, -2.8175e-02,\n",
      "           1.6569e-02, -7.0223e-03],\n",
      "         [ 6.6148e-03,  3.2914e-02, -9.1590e-03, -3.5250e-02, -4.3065e-02,\n",
      "           2.6430e-03,  2.4171e-02],\n",
      "         [-3.5796e-02, -4.4141e-03,  6.8659e-03,  1.0953e-02, -3.8119e-02,\n",
      "          -2.1893e-02, -2.1932e-02],\n",
      "         [ 8.2580e-03, -2.9437e-03,  3.3819e-02,  1.3359e-02, -1.4420e-02,\n",
      "           1.2633e-02, -2.2880e-02],\n",
      "         [-3.9057e-02, -3.1031e-02, -1.2917e-02, -1.3049e-02,  4.6951e-02,\n",
      "           3.8408e-02, -1.4289e-03],\n",
      "         [-1.1489e-02,  4.4274e-02,  4.7105e-02,  3.5740e-02, -1.0647e-02,\n",
      "          -3.2847e-02, -8.2773e-03],\n",
      "         [-2.3996e-02, -3.2716e-02,  1.0422e-02, -3.4967e-02,  4.5762e-02,\n",
      "           1.2826e-02,  3.5587e-02],\n",
      "         [ 1.5546e-02,  2.8971e-02,  4.4289e-02, -8.2980e-04, -1.5970e-02,\n",
      "           2.5725e-02,  2.5984e-02],\n",
      "         [-2.0960e-02,  3.8850e-02,  1.3470e-02,  2.7574e-02,  1.4111e-02,\n",
      "           5.7427e-03, -3.6353e-02],\n",
      "         [-3.7316e-02, -4.1315e-02,  4.3831e-02,  1.0158e-02,  1.2592e-03,\n",
      "          -4.0511e-02,  3.3064e-03],\n",
      "         [ 4.5476e-02,  4.1807e-02, -1.3053e-02, -4.5850e-03,  6.1418e-03,\n",
      "           3.2447e-02,  1.8443e-02],\n",
      "         [-1.7086e-03,  1.4994e-02,  2.8696e-02, -1.4795e-03,  4.5674e-02,\n",
      "          -2.5322e-02,  3.7285e-02],\n",
      "         [ 4.0475e-02,  3.7690e-02,  5.2862e-03,  3.0617e-02, -1.9394e-02,\n",
      "          -3.0620e-02, -1.9519e-02],\n",
      "         [-3.8541e-03,  1.2019e-02,  2.0518e-02,  7.8630e-03,  7.0779e-03,\n",
      "           4.4376e-02,  1.7627e-03],\n",
      "         [-2.6990e-02,  2.9145e-02,  1.7128e-02,  4.6155e-02, -3.2443e-02,\n",
      "          -3.2959e-02,  9.2743e-04],\n",
      "         [-3.9576e-02, -2.2648e-03,  3.4944e-02,  1.5399e-02,  4.4410e-02,\n",
      "          -3.7551e-02,  4.6801e-02],\n",
      "         [ 1.9070e-02, -1.8219e-02, -1.6088e-02,  2.0295e-02, -3.9706e-02,\n",
      "           2.2978e-02, -4.4465e-02],\n",
      "         [ 2.0933e-02, -4.7120e-03, -2.2713e-02,  3.3407e-02,  3.8281e-02,\n",
      "           4.6144e-02, -2.5060e-02]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.0.bias | Size: torch.Size([64]) | Values : tensor([-0.0044, -0.0006], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.1.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.1.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv3.0.weight | Size: torch.Size([64, 64, 7]) | Values : tensor([[[ 8.4050e-04,  3.5190e-02, -3.1892e-02, -3.1169e-02,  3.8034e-02,\n",
      "          -1.5926e-03, -4.4161e-02],\n",
      "         [-1.7786e-03, -2.7149e-02,  9.2901e-03,  3.8501e-02,  1.7184e-02,\n",
      "          -1.8426e-02,  2.1322e-03],\n",
      "         [ 2.7646e-02, -2.2078e-03, -1.5484e-02,  3.4450e-02, -1.7630e-02,\n",
      "           1.9374e-03,  1.2143e-02],\n",
      "         [ 3.8132e-02,  6.8304e-03,  1.7112e-02,  1.2441e-02,  4.9904e-03,\n",
      "           1.3144e-03,  1.9738e-02],\n",
      "         [ 2.0594e-02,  1.2598e-02, -1.5439e-02, -8.8434e-03,  3.2108e-02,\n",
      "          -4.5848e-02, -4.6829e-02],\n",
      "         [ 4.2643e-02, -2.8773e-02, -4.3160e-02, -4.3344e-02,  3.0038e-02,\n",
      "          -6.9382e-03, -2.5007e-02],\n",
      "         [ 1.3273e-02,  3.4233e-02, -7.6498e-03, -1.9954e-02,  9.0218e-04,\n",
      "           2.0232e-02,  1.7552e-02],\n",
      "         [-2.2219e-02,  1.2993e-02, -4.1284e-02, -1.6340e-02,  4.1197e-02,\n",
      "           2.1223e-02, -1.7716e-02],\n",
      "         [-3.4581e-02,  1.1000e-02,  4.3196e-03, -1.9121e-02, -4.2430e-02,\n",
      "          -3.6949e-02,  3.6724e-02],\n",
      "         [-2.8610e-02, -1.3384e-02, -2.4711e-02,  2.1101e-02,  2.6751e-02,\n",
      "           2.7384e-02,  2.9915e-02],\n",
      "         [ 4.0776e-02, -2.7219e-02,  2.9936e-02,  4.2182e-02, -3.5440e-02,\n",
      "           2.0970e-03, -2.2035e-02],\n",
      "         [ 2.5508e-02,  6.7266e-03,  9.1782e-03, -7.3494e-03, -2.5207e-02,\n",
      "           4.6521e-02,  9.3212e-03],\n",
      "         [ 1.6610e-02, -1.6182e-02, -1.2866e-02,  4.5134e-02,  1.5041e-02,\n",
      "           1.3417e-03,  3.6310e-02],\n",
      "         [ 3.8968e-02, -1.7785e-02, -3.1717e-02,  3.5152e-02,  3.6697e-02,\n",
      "          -1.6685e-02, -1.5183e-02],\n",
      "         [-2.6122e-02, -3.4852e-02,  3.1543e-02, -1.4672e-02, -6.4773e-04,\n",
      "          -1.9336e-02, -1.7675e-02],\n",
      "         [ 1.2420e-02, -6.6764e-03,  1.1981e-02, -3.5065e-02,  4.1189e-02,\n",
      "           6.0167e-05, -4.0821e-02],\n",
      "         [ 1.7559e-02, -1.8489e-02, -9.5933e-03,  2.0438e-03,  3.2232e-02,\n",
      "          -2.3332e-02, -1.1102e-02],\n",
      "         [-1.5206e-03,  5.8445e-03, -1.6073e-02, -1.9296e-02,  2.3660e-02,\n",
      "          -3.6635e-02, -3.6925e-02],\n",
      "         [ 1.4141e-02,  1.9536e-02, -7.8945e-03, -2.7952e-02,  2.8110e-02,\n",
      "           4.6047e-02,  2.4984e-02],\n",
      "         [ 3.6827e-02, -4.2446e-02, -2.4210e-02, -4.5077e-02, -2.9136e-02,\n",
      "          -2.8425e-02, -4.2362e-02],\n",
      "         [-2.3015e-02,  9.4512e-03,  1.6832e-02, -4.6859e-02,  4.0185e-02,\n",
      "          -1.8511e-02,  2.9368e-02],\n",
      "         [-4.2430e-02,  4.5748e-02, -3.8973e-02, -2.3943e-02, -3.8431e-02,\n",
      "           3.5464e-02, -3.4852e-02],\n",
      "         [-4.4288e-02,  1.3088e-02,  1.1027e-02,  1.9278e-02,  3.9970e-02,\n",
      "           1.6069e-02,  3.5706e-02],\n",
      "         [-1.2679e-02, -3.7467e-02,  5.4205e-03, -3.1282e-02,  4.5999e-02,\n",
      "          -1.8535e-02, -2.8812e-02],\n",
      "         [ 4.1072e-02, -4.2420e-02,  2.2680e-03, -2.5480e-02,  3.9888e-02,\n",
      "           3.9078e-04,  4.0056e-02],\n",
      "         [ 3.1570e-02, -6.1689e-03,  1.6300e-02, -3.9531e-02,  2.9616e-02,\n",
      "           4.1500e-02, -2.3045e-02],\n",
      "         [-2.5147e-02, -3.6063e-02,  2.5987e-03, -2.9651e-02, -2.8664e-02,\n",
      "           3.5214e-03, -3.0780e-02],\n",
      "         [-4.0154e-02,  4.6868e-02, -4.4347e-02, -1.1506e-02, -2.3559e-02,\n",
      "          -6.4555e-03, -2.5957e-02],\n",
      "         [ 3.0584e-02,  8.4332e-03,  2.5675e-02, -4.3275e-02, -2.7433e-02,\n",
      "           2.2124e-02, -3.0060e-03],\n",
      "         [ 3.2419e-02, -4.6602e-02,  4.0642e-02, -2.1501e-03, -2.8649e-03,\n",
      "          -4.5994e-02,  1.2563e-02],\n",
      "         [ 1.6453e-02,  1.0070e-02, -7.1732e-03, -3.2929e-02, -8.7112e-03,\n",
      "           2.3884e-02,  4.1460e-02],\n",
      "         [-2.8654e-02,  1.8358e-02, -1.6700e-02, -3.0250e-02, -3.1560e-02,\n",
      "           4.7161e-02,  6.2145e-03],\n",
      "         [-3.3270e-02,  2.7698e-02,  3.9887e-02, -1.6959e-02,  1.6268e-02,\n",
      "          -4.5222e-02, -2.1304e-02],\n",
      "         [-2.5184e-03,  2.8949e-02,  3.4120e-02, -3.3414e-02,  2.4343e-02,\n",
      "          -4.7491e-03,  5.8068e-03],\n",
      "         [ 3.3211e-02, -2.5682e-02, -3.2872e-02,  4.3834e-03, -3.3906e-02,\n",
      "           4.0227e-02,  2.8467e-02],\n",
      "         [ 2.3532e-02,  4.1510e-02,  3.2290e-02, -1.9960e-02, -3.8057e-02,\n",
      "           4.4276e-03, -8.9111e-03],\n",
      "         [-2.0425e-02, -4.2725e-02,  3.4697e-02, -1.5117e-02, -9.7936e-03,\n",
      "           1.6319e-02, -2.9288e-02],\n",
      "         [-2.6512e-02, -3.8126e-02,  1.2937e-02,  4.0405e-02, -9.1319e-03,\n",
      "           3.4791e-02,  2.2050e-02],\n",
      "         [ 4.4298e-02, -1.9127e-02,  3.7374e-02,  1.2911e-02, -3.2060e-02,\n",
      "          -4.3758e-02,  1.6916e-02],\n",
      "         [ 1.8533e-02, -8.6278e-03,  3.3433e-02,  1.3445e-02, -4.2087e-02,\n",
      "          -4.5166e-02, -1.8268e-02],\n",
      "         [ 1.4592e-02, -1.9485e-02,  3.0427e-02,  6.1022e-03,  2.4685e-02,\n",
      "           2.7700e-02, -1.0407e-02],\n",
      "         [ 4.0288e-02, -5.3171e-03,  2.1037e-02,  2.1497e-03,  2.3118e-02,\n",
      "           2.2672e-03,  2.5704e-02],\n",
      "         [-4.0984e-02, -3.3094e-02, -2.5056e-02,  4.0194e-03, -2.0463e-03,\n",
      "           4.6949e-02, -1.7884e-02],\n",
      "         [ 3.4597e-02,  3.9559e-02,  3.9717e-02, -9.6002e-03, -8.3633e-06,\n",
      "          -6.0741e-03, -1.6234e-02],\n",
      "         [ 3.1252e-02, -4.3201e-02, -2.2354e-02,  7.4050e-03,  4.5608e-02,\n",
      "           4.4763e-02, -1.4893e-02],\n",
      "         [-1.8839e-02,  2.5611e-04, -3.4259e-02, -2.8338e-02,  2.6976e-02,\n",
      "          -1.5297e-02, -2.7549e-02],\n",
      "         [-2.1619e-02, -4.2609e-02,  1.7459e-02, -7.3341e-03,  2.9941e-02,\n",
      "           2.9759e-02,  4.6274e-02],\n",
      "         [-2.5779e-02, -2.9741e-02, -9.3507e-03, -1.0811e-02, -4.7083e-02,\n",
      "          -3.2846e-02, -2.6011e-02],\n",
      "         [ 9.1257e-03, -3.5532e-02, -7.0799e-03,  5.7550e-03, -4.0390e-02,\n",
      "          -2.9760e-02,  8.5492e-03],\n",
      "         [-9.1263e-03, -2.5736e-02,  4.0915e-02, -4.0064e-02,  2.8898e-02,\n",
      "          -2.1534e-02, -3.2069e-02],\n",
      "         [-3.4647e-02,  2.0590e-02,  1.1203e-02,  4.2205e-02,  6.4572e-03,\n",
      "           3.8922e-02,  4.4120e-02],\n",
      "         [ 1.7517e-02, -2.5485e-02,  5.3438e-03, -3.6904e-02,  1.9746e-02,\n",
      "          -4.2076e-04,  2.4552e-02],\n",
      "         [ 1.1942e-02,  2.2391e-02,  2.0722e-03,  4.5789e-02,  3.1921e-02,\n",
      "          -1.6592e-02,  2.4571e-02],\n",
      "         [-3.4923e-03,  4.5643e-02, -2.3153e-02, -3.1332e-02,  5.9904e-03,\n",
      "           2.6091e-02,  5.5300e-03],\n",
      "         [ 1.6531e-02,  5.8559e-04, -1.9491e-02,  2.4343e-02, -3.6544e-02,\n",
      "          -4.1847e-02,  3.7010e-02],\n",
      "         [-1.7710e-02,  4.3398e-02,  2.1155e-02, -3.3692e-02,  3.7786e-02,\n",
      "          -1.4272e-02,  3.9104e-02],\n",
      "         [-1.2116e-02,  2.6274e-02, -9.0619e-03, -4.2356e-02,  1.7317e-03,\n",
      "          -1.1213e-02, -3.5688e-02],\n",
      "         [ 5.4027e-03,  4.4993e-02,  3.5433e-02,  2.3755e-02,  3.0560e-02,\n",
      "          -2.9546e-02,  3.7146e-02],\n",
      "         [-3.8411e-02, -2.7296e-02,  1.5776e-02, -1.1928e-02, -1.3421e-02,\n",
      "           5.4447e-03, -3.2070e-02],\n",
      "         [ 2.6938e-02, -4.7164e-02,  2.7051e-02, -4.3147e-02, -4.4986e-03,\n",
      "           2.6722e-02,  4.6103e-02],\n",
      "         [ 4.3435e-02, -1.7245e-03, -3.4608e-02, -1.7385e-03,  1.8885e-02,\n",
      "          -1.7802e-02,  8.0645e-03],\n",
      "         [-1.1831e-03, -3.0971e-02, -8.2874e-04, -4.3107e-02,  7.3294e-03,\n",
      "          -1.9976e-02, -9.4714e-03],\n",
      "         [ 6.0440e-03, -6.3752e-03,  1.8555e-03,  1.5854e-02, -1.2546e-02,\n",
      "          -3.4117e-02, -2.4044e-02],\n",
      "         [ 6.3782e-03,  1.0779e-03, -1.4909e-02,  9.7256e-03, -3.9427e-02,\n",
      "           4.0646e-02, -2.2403e-02]],\n",
      "\n",
      "        [[-2.9893e-02,  3.3486e-02, -7.1650e-03, -1.3731e-02,  4.4758e-03,\n",
      "          -4.5112e-02,  3.5104e-02],\n",
      "         [ 2.4492e-02, -3.1010e-02, -1.9224e-02, -3.0013e-02, -2.3085e-02,\n",
      "           3.6356e-02,  3.7314e-02],\n",
      "         [ 1.1728e-02, -2.0176e-02, -7.6675e-03,  6.5120e-03,  2.6629e-02,\n",
      "           7.5759e-04, -4.3633e-03],\n",
      "         [ 3.2517e-02, -1.0659e-02, -3.1801e-02, -4.3440e-02, -2.4238e-02,\n",
      "           3.5778e-02,  3.1060e-02],\n",
      "         [ 4.6699e-02, -4.0936e-02,  2.1371e-02,  4.0347e-02,  1.3160e-02,\n",
      "           6.9603e-03, -4.0440e-02],\n",
      "         [ 3.7951e-02, -2.5782e-02, -2.0405e-02, -4.1676e-02, -3.2499e-02,\n",
      "           4.4281e-03,  7.0290e-03],\n",
      "         [ 1.9268e-02,  4.6450e-03, -2.7174e-02, -3.6842e-02,  1.9383e-02,\n",
      "           3.9112e-03,  3.1437e-02],\n",
      "         [-1.0897e-02,  3.1077e-02,  2.5710e-02, -4.3414e-02,  4.3801e-02,\n",
      "          -2.1515e-03, -1.9513e-02],\n",
      "         [ 6.8026e-03,  3.9880e-02,  1.6603e-02,  2.2976e-02,  4.4171e-02,\n",
      "           4.1516e-02,  4.2634e-02],\n",
      "         [ 1.8739e-02,  1.6025e-02, -3.2893e-02,  1.8837e-02, -2.8228e-02,\n",
      "           7.9041e-03, -1.6096e-02],\n",
      "         [-2.4900e-02,  1.2405e-02, -1.3880e-02,  2.1914e-02,  4.1767e-02,\n",
      "           1.8031e-02,  3.7836e-02],\n",
      "         [-1.1123e-02, -1.8805e-02, -6.0873e-03,  3.9225e-02, -2.7303e-02,\n",
      "           2.5200e-02, -3.0477e-02],\n",
      "         [-7.0281e-03, -3.1511e-04, -3.7722e-02, -3.0631e-02,  4.4474e-03,\n",
      "           5.8067e-03, -4.0666e-02],\n",
      "         [-2.9162e-02,  9.3281e-03, -4.2967e-02, -4.0132e-02, -3.0924e-02,\n",
      "           3.1745e-02, -2.0403e-02],\n",
      "         [-3.0728e-02,  2.1897e-02,  1.1144e-02, -3.3397e-02,  1.7582e-03,\n",
      "          -1.5993e-04,  3.6973e-02],\n",
      "         [-9.8180e-03, -2.9168e-02,  3.6396e-02, -1.3467e-02,  8.3437e-03,\n",
      "           1.8216e-02, -4.3230e-02],\n",
      "         [-3.1010e-02, -9.5862e-03, -3.1081e-02, -1.6702e-02,  1.9933e-02,\n",
      "          -2.3874e-02,  1.0970e-02],\n",
      "         [-4.7965e-03,  3.9852e-02,  2.5539e-02, -2.0773e-02,  3.7444e-02,\n",
      "           2.8317e-02, -2.4389e-02],\n",
      "         [ 8.1929e-03,  3.0099e-02, -3.4970e-02,  3.3128e-02,  2.9732e-02,\n",
      "          -3.5744e-02, -3.1046e-02],\n",
      "         [ 3.4751e-02, -1.5637e-02,  2.1975e-02,  9.4137e-03,  1.9603e-02,\n",
      "           4.1412e-02, -2.5634e-02],\n",
      "         [ 2.0998e-02, -3.0897e-02, -1.6490e-02,  1.1993e-02,  4.4388e-02,\n",
      "           3.8576e-02,  1.3023e-02],\n",
      "         [-8.9187e-03, -4.1060e-02, -2.3254e-02, -1.4885e-02,  1.4559e-02,\n",
      "          -4.3798e-02, -2.7882e-02],\n",
      "         [ 3.9535e-02, -7.5139e-03,  4.4161e-02,  4.2534e-02, -1.2998e-03,\n",
      "           3.7350e-02,  2.0008e-02],\n",
      "         [-3.6784e-02, -4.6964e-03, -1.0875e-02,  1.3316e-02, -3.9047e-02,\n",
      "          -2.7764e-03, -2.9809e-02],\n",
      "         [ 4.3522e-02,  9.1347e-03,  4.6743e-02, -1.2801e-02, -2.1562e-02,\n",
      "          -4.0019e-02,  1.5347e-02],\n",
      "         [ 3.6989e-02,  2.2689e-02, -7.0040e-03,  3.1844e-02, -3.4007e-02,\n",
      "          -1.3600e-02,  2.5372e-02],\n",
      "         [ 1.2249e-02,  3.4193e-04, -6.9980e-03, -2.3629e-03, -4.7785e-03,\n",
      "          -7.4354e-03, -3.5286e-02],\n",
      "         [ 3.6667e-03, -2.8407e-02, -4.0456e-02, -1.6725e-02, -4.8572e-03,\n",
      "          -2.1918e-03, -2.6729e-02],\n",
      "         [-4.0159e-02,  2.8036e-02,  3.4031e-02, -2.0170e-02,  6.2700e-03,\n",
      "           4.2544e-02,  1.4604e-03],\n",
      "         [-4.2861e-02, -2.7066e-02, -1.9654e-02, -2.9975e-02, -2.5477e-02,\n",
      "           2.4720e-02, -4.3210e-02],\n",
      "         [-3.4020e-02, -3.4488e-02, -8.8572e-04, -2.2960e-02,  7.2693e-03,\n",
      "          -3.3423e-02,  2.5175e-02],\n",
      "         [-2.9777e-02,  2.0024e-02, -4.7331e-04, -3.2003e-02, -1.7597e-02,\n",
      "          -3.6405e-03, -2.5181e-03],\n",
      "         [ 4.6604e-02,  2.1056e-02,  2.4520e-02,  3.0613e-02, -3.4183e-02,\n",
      "           3.7925e-02,  4.4032e-02],\n",
      "         [-7.7676e-03, -3.6691e-02,  3.2993e-02, -5.2717e-04, -1.0784e-02,\n",
      "           2.8331e-03, -1.4064e-02],\n",
      "         [-3.6019e-02,  3.3851e-02,  1.7487e-02, -4.0582e-04,  1.5792e-02,\n",
      "           2.3626e-02,  4.5143e-02],\n",
      "         [-4.2659e-02,  3.8256e-02, -3.0668e-02,  3.8313e-02,  1.1471e-02,\n",
      "          -2.0409e-02,  3.3341e-02],\n",
      "         [ 1.5515e-02,  8.4556e-03, -3.5405e-02, -3.9056e-02,  6.0137e-03,\n",
      "           3.1480e-02,  2.5647e-02],\n",
      "         [-1.7653e-02, -1.4933e-02,  2.6346e-02, -1.3207e-02, -3.6781e-02,\n",
      "           4.7054e-02, -3.0071e-02],\n",
      "         [-2.0856e-02,  4.5118e-02,  2.0164e-02,  1.3663e-02,  1.1678e-02,\n",
      "          -2.6762e-02,  9.7212e-03],\n",
      "         [ 2.4244e-03,  3.6805e-02,  3.9129e-02,  8.3801e-03,  3.9824e-02,\n",
      "           4.6242e-02,  4.5981e-02],\n",
      "         [ 3.4890e-02, -3.8856e-02, -1.2880e-02,  2.9817e-02,  5.8682e-03,\n",
      "           1.8746e-02,  3.9687e-02],\n",
      "         [ 3.9536e-03,  4.3817e-02,  2.4837e-03,  4.6964e-03, -4.5071e-02,\n",
      "           1.2319e-02, -3.1146e-02],\n",
      "         [ 3.4491e-02,  1.6344e-02,  2.8491e-02,  4.3028e-02, -1.2133e-02,\n",
      "          -3.6879e-02, -1.3102e-02],\n",
      "         [ 4.2686e-03,  3.6311e-02,  3.1799e-02,  4.4596e-02, -7.8886e-03,\n",
      "           2.3259e-02, -1.0920e-02],\n",
      "         [ 2.0071e-02,  3.4177e-03,  3.7521e-02,  1.6256e-02, -1.1791e-02,\n",
      "          -6.0398e-03,  2.9783e-02],\n",
      "         [-9.9651e-03,  3.6180e-02,  1.1302e-02,  2.8789e-02,  7.8221e-03,\n",
      "          -4.3296e-02,  1.7807e-02],\n",
      "         [-3.7591e-02,  2.3781e-02,  5.3457e-03,  2.3056e-02, -4.5453e-02,\n",
      "           1.1000e-02,  1.0229e-02],\n",
      "         [-1.4638e-02,  4.5004e-02, -1.6751e-02,  1.1019e-02,  2.5276e-02,\n",
      "          -3.8185e-02,  1.8739e-02],\n",
      "         [ 4.2499e-02,  1.4289e-03, -4.0544e-03,  1.6069e-02,  1.9400e-02,\n",
      "          -2.2651e-02, -8.4842e-03],\n",
      "         [-1.7178e-02, -2.2057e-02, -4.3134e-02, -3.0880e-02, -2.6697e-02,\n",
      "          -3.8400e-02, -1.9991e-02],\n",
      "         [ 1.2154e-02, -2.0705e-02, -5.0871e-03, -4.4376e-02,  4.3759e-02,\n",
      "          -1.5138e-02, -1.1772e-02],\n",
      "         [-4.2243e-02,  1.4309e-02,  2.1377e-02, -4.6972e-02, -3.0523e-02,\n",
      "          -1.3574e-02, -1.5318e-02],\n",
      "         [-3.0965e-02, -1.1014e-02,  8.4904e-03, -4.6532e-02, -2.9727e-02,\n",
      "           4.1775e-02, -3.2325e-02],\n",
      "         [-3.0395e-02, -4.4968e-02,  3.4583e-02,  4.2966e-02,  4.6174e-02,\n",
      "           2.2441e-02,  3.0774e-02],\n",
      "         [-3.0680e-02,  1.9070e-02,  9.4784e-04,  4.3808e-02,  1.9977e-02,\n",
      "           7.0117e-03, -4.3396e-02],\n",
      "         [ 3.1080e-02,  3.0819e-02,  3.1171e-02, -6.3539e-03,  3.3588e-02,\n",
      "          -2.7744e-03, -1.2778e-02],\n",
      "         [ 4.0462e-03,  2.1465e-03, -8.2287e-03,  2.3357e-02, -2.8670e-02,\n",
      "          -1.5976e-02, -2.8929e-02],\n",
      "         [-1.5942e-03,  4.7753e-03, -1.1263e-02, -1.6266e-02,  7.8003e-04,\n",
      "           3.3528e-02, -3.1345e-02],\n",
      "         [ 4.6289e-02, -1.3752e-02, -2.3535e-02, -1.6441e-02,  4.6941e-02,\n",
      "          -5.3582e-03, -1.7016e-02],\n",
      "         [ 3.6089e-02,  4.0813e-02,  1.1641e-02,  7.7718e-03, -8.8550e-03,\n",
      "          -1.2636e-02,  3.5863e-02],\n",
      "         [-3.3726e-02, -4.5078e-02,  1.8192e-02, -2.6575e-02,  1.5106e-02,\n",
      "           1.8007e-03, -2.9000e-02],\n",
      "         [ 3.0570e-02,  2.4282e-02,  4.1911e-02,  2.0761e-03,  4.3384e-03,\n",
      "          -2.1223e-02,  2.3822e-03],\n",
      "         [-2.9307e-02,  1.8810e-03, -3.9501e-02, -1.0255e-03,  3.7746e-02,\n",
      "           1.2050e-02,  2.0825e-02],\n",
      "         [-1.4185e-03, -3.0052e-02,  9.0026e-03, -4.4903e-02, -2.4368e-02,\n",
      "          -2.9113e-02, -3.3928e-02]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv3.0.bias | Size: torch.Size([64]) | Values : tensor([-0.0303,  0.0336], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv3.1.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv3.1.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm.0.weight_ih_l0 | Size: torch.Size([256, 64]) | Values : tensor([[ 0.0246,  0.0957,  0.0059,  0.0213,  0.1210, -0.0286,  0.0741, -0.0189,\n",
      "         -0.1006, -0.1000, -0.0611,  0.1021, -0.0978, -0.1016,  0.0932, -0.0400,\n",
      "         -0.0550,  0.0126,  0.0947, -0.0453, -0.0624, -0.0319,  0.0870,  0.0489,\n",
      "         -0.0622,  0.0522,  0.0689, -0.0805, -0.0512,  0.1235,  0.0332, -0.0071,\n",
      "          0.1218, -0.0429,  0.0995,  0.0805, -0.0262, -0.1189,  0.1141, -0.0765,\n",
      "          0.1005, -0.1224, -0.0749, -0.0366,  0.0403,  0.0015,  0.0241,  0.0847,\n",
      "         -0.1150, -0.0106,  0.0472,  0.0118, -0.0550, -0.0590, -0.1026, -0.0828,\n",
      "          0.0719, -0.0069,  0.0007,  0.0207,  0.0286, -0.0385,  0.0923, -0.0371],\n",
      "        [ 0.1133, -0.0532,  0.0160, -0.0553,  0.0341, -0.0535,  0.0622, -0.0594,\n",
      "         -0.0338,  0.0700,  0.0576, -0.1004, -0.0047, -0.0714,  0.1219,  0.0531,\n",
      "          0.0587,  0.1219,  0.0121, -0.0222,  0.0946,  0.1207, -0.0491,  0.0176,\n",
      "         -0.0446,  0.0310,  0.0571, -0.0009, -0.0254,  0.0481,  0.0432,  0.0828,\n",
      "          0.0858, -0.0478,  0.0101,  0.0500,  0.1095,  0.0726, -0.0264,  0.0061,\n",
      "          0.1132,  0.0068, -0.0552,  0.0408,  0.0236, -0.0724, -0.0385, -0.0682,\n",
      "         -0.0551,  0.0418, -0.0827, -0.0733,  0.0630,  0.1093,  0.1036,  0.0748,\n",
      "          0.1120, -0.1001, -0.0114, -0.0007,  0.0522,  0.1063, -0.0249,  0.0010]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm.0.weight_hh_l0 | Size: torch.Size([256, 64]) | Values : tensor([[ 0.0214,  0.0005,  0.0171, -0.0570, -0.0990,  0.1209,  0.0747,  0.1137,\n",
      "          0.0999,  0.0239, -0.0213,  0.1037, -0.1155, -0.1169,  0.1028, -0.0479,\n",
      "         -0.0685, -0.0804,  0.0973, -0.0065,  0.0493, -0.0549, -0.0841, -0.0595,\n",
      "          0.0814, -0.0039, -0.0613, -0.0149, -0.0489, -0.1050,  0.0992,  0.0369,\n",
      "         -0.0930,  0.0878,  0.0481,  0.0074, -0.0338,  0.0698, -0.0424,  0.0242,\n",
      "         -0.0148, -0.1219,  0.0661,  0.0595, -0.1084, -0.0627,  0.1016, -0.1019,\n",
      "          0.0169, -0.0940,  0.0377, -0.0351, -0.1199,  0.0491, -0.0527, -0.0128,\n",
      "          0.1217, -0.0144, -0.0249,  0.1021, -0.0766, -0.0309, -0.0303, -0.0823],\n",
      "        [-0.0416, -0.1077, -0.0802,  0.1168,  0.0368, -0.0469, -0.0982, -0.0668,\n",
      "          0.0947,  0.1140, -0.0852,  0.0067, -0.0483, -0.0946, -0.0772, -0.0385,\n",
      "          0.0028, -0.1214,  0.0081,  0.1024,  0.0940,  0.1103,  0.0092, -0.0484,\n",
      "          0.1015, -0.0391, -0.0935, -0.0257, -0.0811,  0.0148, -0.1078,  0.1103,\n",
      "         -0.1176, -0.1095,  0.1218,  0.0054, -0.0784, -0.1219,  0.0086,  0.1197,\n",
      "          0.0486,  0.0385,  0.0688,  0.0995,  0.0120,  0.1221,  0.0138,  0.0670,\n",
      "         -0.0028,  0.0082,  0.1121,  0.0018, -0.0679,  0.0841,  0.0770,  0.1024,\n",
      "         -0.0101,  0.0104,  0.0579,  0.0946, -0.0626,  0.1154, -0.1237,  0.0285]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm.0.bias_ih_l0 | Size: torch.Size([256]) | Values : tensor([-0.0441,  0.0214], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm.0.bias_hh_l0 | Size: torch.Size([256]) | Values : tensor([0.1044, 0.0962], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm.2.weight_ih_l0 | Size: torch.Size([256, 64]) | Values : tensor([[-0.0485, -0.0721, -0.0379,  0.0432,  0.0127,  0.0004, -0.0671, -0.0118,\n",
      "         -0.0806,  0.0770, -0.0814,  0.1015,  0.0634, -0.1172, -0.0440, -0.1005,\n",
      "          0.0513,  0.0434, -0.0986,  0.0685,  0.0244, -0.0130,  0.0044,  0.0197,\n",
      "          0.0208, -0.0512, -0.0362,  0.0795, -0.1222,  0.1004,  0.0634, -0.1142,\n",
      "         -0.0486, -0.1243, -0.1209,  0.0561,  0.0964,  0.0102, -0.0554, -0.0996,\n",
      "         -0.0231,  0.1037, -0.1021,  0.1039, -0.0819, -0.0317, -0.0089,  0.0507,\n",
      "         -0.0402, -0.0121, -0.0866, -0.0919,  0.0535,  0.0713,  0.0742,  0.0705,\n",
      "          0.0480,  0.0160,  0.1117,  0.0850, -0.0088, -0.0773, -0.0511,  0.0689],\n",
      "        [-0.0748, -0.1008, -0.0117, -0.0057, -0.1083, -0.0165, -0.0903, -0.0631,\n",
      "         -0.0479,  0.0172, -0.0470, -0.1141,  0.0736,  0.0983, -0.0065,  0.0411,\n",
      "          0.0639,  0.0113,  0.0023, -0.0199,  0.1241, -0.0616, -0.1106, -0.1029,\n",
      "         -0.0737, -0.1218,  0.0185,  0.0242, -0.1024, -0.1192,  0.0342, -0.0177,\n",
      "         -0.1244,  0.1039,  0.1128,  0.1100,  0.0408, -0.0242,  0.1121, -0.0746,\n",
      "          0.0762, -0.0634, -0.0540,  0.0757, -0.0705,  0.1005,  0.0085,  0.1208,\n",
      "          0.1205,  0.0555,  0.1244, -0.1175, -0.0542, -0.1099, -0.0883, -0.0937,\n",
      "         -0.0659,  0.0921, -0.0516,  0.0698, -0.0900,  0.0453,  0.0535, -0.1124]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm.2.weight_hh_l0 | Size: torch.Size([256, 64]) | Values : tensor([[-0.0684,  0.0573,  0.0734, -0.0333, -0.0488, -0.0227, -0.0252, -0.0500,\n",
      "         -0.0526,  0.0079, -0.0996,  0.0672, -0.1088,  0.0091,  0.0049,  0.0767,\n",
      "          0.0853,  0.0981, -0.0979,  0.0713, -0.0126,  0.0141, -0.0351, -0.0449,\n",
      "          0.1177, -0.0153, -0.1163, -0.0390,  0.0878,  0.0202,  0.0925, -0.1088,\n",
      "         -0.0984, -0.0126, -0.0753, -0.0726,  0.0208, -0.1211, -0.0921,  0.0860,\n",
      "         -0.0228, -0.0281,  0.0763,  0.0455, -0.1093,  0.1107, -0.0407, -0.0107,\n",
      "         -0.0424, -0.0132,  0.0075,  0.1018, -0.0190,  0.0543, -0.0656, -0.1052,\n",
      "         -0.0930, -0.0913, -0.0770, -0.0415, -0.1109, -0.0739,  0.0029,  0.0620],\n",
      "        [ 0.0397, -0.0050,  0.0274,  0.0085, -0.0268, -0.0292,  0.0263, -0.0629,\n",
      "          0.0410,  0.0595,  0.0518, -0.0213,  0.0420, -0.1159, -0.1067,  0.0920,\n",
      "         -0.0128, -0.1194, -0.0932,  0.0072, -0.0145, -0.0257, -0.0707,  0.0612,\n",
      "          0.0544,  0.0168,  0.0924, -0.0145, -0.0644, -0.0539,  0.0823,  0.0915,\n",
      "          0.0094,  0.1196,  0.0659,  0.0375, -0.1057, -0.1093, -0.1085, -0.0947,\n",
      "         -0.0892,  0.0089,  0.0396, -0.0971,  0.0659,  0.0345,  0.0968, -0.0408,\n",
      "          0.0134,  0.1062,  0.0739, -0.0833,  0.1041, -0.0273,  0.0811, -0.0800,\n",
      "          0.0659, -0.0264, -0.0752,  0.1036, -0.1166,  0.0334,  0.0555,  0.0177]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm.2.bias_ih_l0 | Size: torch.Size([256]) | Values : tensor([0.1091, 0.0259], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm.2.bias_hh_l0 | Size: torch.Size([256]) | Values : tensor([ 0.1114, -0.0412], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc.0.weight | Size: torch.Size([2, 64]) | Values : tensor([[ 0.1155,  0.0039,  0.1080, -0.0078, -0.1113, -0.0898, -0.0244,  0.0019,\n",
      "         -0.0320, -0.0222,  0.0557,  0.0100, -0.0572, -0.0857,  0.0220, -0.0106,\n",
      "          0.0347,  0.0932, -0.0870, -0.1118, -0.0076, -0.0485, -0.0863, -0.0566,\n",
      "          0.0944,  0.0398, -0.0825, -0.1137, -0.0672, -0.0065, -0.0927,  0.0376,\n",
      "          0.0344,  0.0333, -0.0577,  0.0788,  0.0294, -0.0106,  0.1174, -0.0791,\n",
      "          0.0937,  0.0394, -0.0107, -0.0968, -0.0483, -0.0929, -0.0840,  0.0059,\n",
      "          0.0344, -0.0782, -0.0782,  0.1206,  0.0268, -0.0166,  0.0988,  0.0031,\n",
      "         -0.0509,  0.0556,  0.0890,  0.0641, -0.0323, -0.1208, -0.0659,  0.0340],\n",
      "        [ 0.0818, -0.0305, -0.0318,  0.0782, -0.1104,  0.0733,  0.0556,  0.0048,\n",
      "          0.1219,  0.0771, -0.0541, -0.0836, -0.0034,  0.0436,  0.1154, -0.0714,\n",
      "          0.0165, -0.1149, -0.0110,  0.0183, -0.1212, -0.0041,  0.0256, -0.1011,\n",
      "          0.0744, -0.0807,  0.0262, -0.0695,  0.0609,  0.0113, -0.0888, -0.0303,\n",
      "          0.0468, -0.0080, -0.0721,  0.0192,  0.0373, -0.1215,  0.0168, -0.1208,\n",
      "         -0.0604,  0.0260,  0.1028, -0.0674, -0.0827, -0.0446,  0.0030, -0.0385,\n",
      "          0.0983,  0.0600, -0.0388, -0.0398, -0.0765, -0.0922,  0.0045, -0.0319,\n",
      "          0.0840,  0.1079,  0.1087, -0.1138, -0.0569,  0.0182, -0.0019,  0.0313]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc.0.bias | Size: torch.Size([2]) | Values : tensor([-0.0422, -0.1179], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the model\n",
    "model = ConvLSTM()\n",
    "\n",
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 5e-4\n",
    "batch_size = 64\n",
    "epochs = 200\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluate the model with torch.no_grad()\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlonmcu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
