{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(nn.Conv1d(in_channels=9, out_channels=64, kernel_size=7),\n",
    "                                   nn.BatchNorm1d(64),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool1d(2))\n",
    "        self.conv2 = nn.Sequential(nn.Conv1d(in_channels=64, out_channels=64, kernel_size=7),\n",
    "                                   nn.BatchNorm1d(64),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool1d(2))\n",
    "        self.conv3 = nn.Sequential(nn.Conv1d(in_channels=64, out_channels=64, kernel_size=7),\n",
    "                                   nn.BatchNorm1d(64),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool1d(2))\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size=64, hidden_size=64, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.lstm2 = nn.LSTM(input_size=64, hidden_size=64, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc = nn.Linear(in_features=64, out_features=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = x.select(1, -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: ConvLSTM(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv1d(9, 64, kernel_size=(7,), stride=(1,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv1d(64, 64, kernel_size=(7,), stride=(1,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv1d(64, 64, kernel_size=(7,), stride=(1,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (lstm1): LSTM(64, 64, batch_first=True)\n",
      "  (dropout1): Dropout(p=0.5, inplace=False)\n",
      "  (lstm2): LSTM(64, 64, batch_first=True)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "Layer: conv1.0.weight | Size: torch.Size([64, 9, 7]) | Values : tensor([[[ 0.0258, -0.0063,  0.0846, -0.0929,  0.1194, -0.0372, -0.0333],\n",
      "         [-0.0876,  0.0932,  0.0410, -0.0676, -0.0311,  0.0134, -0.1147],\n",
      "         [-0.0438,  0.0196,  0.0278, -0.0656,  0.0347, -0.0313, -0.0830],\n",
      "         [ 0.0490,  0.1135,  0.0599,  0.0685,  0.0922,  0.1056,  0.0053],\n",
      "         [-0.0331,  0.0771, -0.0757, -0.0333, -0.0712, -0.0665,  0.0764],\n",
      "         [-0.0794,  0.0137,  0.0694,  0.0614,  0.0072,  0.1180,  0.0740],\n",
      "         [-0.1182,  0.0919, -0.1020, -0.0247,  0.1154,  0.0339,  0.0381],\n",
      "         [-0.0185,  0.0143, -0.0714,  0.1247, -0.0679, -0.0704, -0.0989],\n",
      "         [ 0.0502, -0.0379,  0.1196,  0.0932,  0.0474, -0.0952,  0.0567]],\n",
      "\n",
      "        [[ 0.0985, -0.0047, -0.0187,  0.0206,  0.1195,  0.0480,  0.0830],\n",
      "         [-0.0119, -0.1202, -0.0292, -0.0387, -0.0737,  0.0846,  0.0148],\n",
      "         [-0.1078,  0.0558, -0.0236, -0.0778, -0.0417,  0.0747,  0.0064],\n",
      "         [-0.0565, -0.0659,  0.1083, -0.0191, -0.0924,  0.0629,  0.0933],\n",
      "         [ 0.1200,  0.0992, -0.0844,  0.1032,  0.1073, -0.0424, -0.0242],\n",
      "         [-0.0651,  0.0707, -0.1259,  0.0887,  0.0144,  0.0934, -0.0449],\n",
      "         [ 0.1141, -0.1152, -0.0458, -0.0958,  0.0456,  0.0926,  0.0910],\n",
      "         [ 0.0988,  0.0507,  0.0954,  0.1128,  0.0835, -0.0974, -0.0503],\n",
      "         [ 0.0789,  0.0962, -0.0392, -0.0171,  0.0573, -0.0902, -0.0317]]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.0.bias | Size: torch.Size([64]) | Values : tensor([ 0.1044, -0.1245], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.1.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.1.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.0.weight | Size: torch.Size([64, 64, 7]) | Values : tensor([[[ 1.3251e-02,  2.0281e-02,  4.9521e-03,  2.6433e-02, -2.6143e-02,\n",
      "          -2.9005e-02, -4.4492e-02],\n",
      "         [-9.9271e-03,  4.5612e-02,  1.4739e-02,  1.3971e-02, -2.9819e-02,\n",
      "          -1.9335e-02,  7.7834e-03],\n",
      "         [-4.6599e-02, -1.4576e-02,  4.3471e-02, -3.2037e-02,  4.0454e-02,\n",
      "          -1.7347e-02, -2.1934e-02],\n",
      "         [-4.2799e-03,  1.7201e-02, -2.5713e-02, -3.5792e-02,  1.4045e-02,\n",
      "          -4.6790e-02,  1.1890e-02],\n",
      "         [ 1.2174e-02,  1.2263e-02,  2.9801e-02, -1.6189e-03,  4.0733e-02,\n",
      "          -3.4867e-02,  8.7718e-03],\n",
      "         [ 1.8450e-03,  2.8422e-02, -2.0174e-02,  1.3382e-02, -2.4403e-02,\n",
      "           1.4135e-02, -3.6325e-02],\n",
      "         [-2.4684e-02,  3.7459e-02, -4.3249e-02,  2.7305e-02,  2.1892e-02,\n",
      "           4.4824e-02,  4.6037e-02],\n",
      "         [-1.7872e-02, -1.9328e-03,  1.7363e-02,  1.5530e-02, -1.1545e-02,\n",
      "           2.3161e-03,  2.3803e-02],\n",
      "         [-1.8335e-02, -2.5589e-02,  3.3662e-02,  1.4113e-02, -1.6298e-02,\n",
      "          -2.3312e-02,  4.5656e-02],\n",
      "         [-2.7609e-02, -3.4029e-02, -3.1531e-02, -3.9740e-02,  1.6342e-02,\n",
      "           2.4358e-02,  2.9433e-02],\n",
      "         [ 4.3579e-02,  3.5255e-02, -5.8653e-05, -2.8130e-02,  9.0396e-03,\n",
      "          -1.5463e-02, -5.1108e-04],\n",
      "         [-2.7180e-02,  2.5386e-02,  3.4854e-03,  1.3602e-02, -3.6949e-02,\n",
      "          -1.1545e-02,  2.9126e-02],\n",
      "         [ 2.3004e-02,  3.5977e-02,  1.2477e-02, -3.5322e-02,  3.8769e-02,\n",
      "          -3.7724e-02,  1.1208e-02],\n",
      "         [-3.6312e-02, -3.9651e-02, -3.3468e-02,  4.3806e-02, -2.6006e-03,\n",
      "          -4.0571e-02,  1.2594e-02],\n",
      "         [-4.5489e-02,  2.5820e-02, -9.4446e-04, -6.7209e-03, -2.5585e-02,\n",
      "           4.7015e-02,  3.2771e-02],\n",
      "         [ 4.5279e-02, -4.5062e-02,  4.2935e-03,  2.9815e-02,  2.0833e-02,\n",
      "          -3.9104e-02, -2.4197e-02],\n",
      "         [-9.0047e-03,  2.4786e-02, -3.1635e-02, -3.1091e-02, -2.2110e-03,\n",
      "           1.7857e-02, -6.2659e-03],\n",
      "         [ 3.8658e-02, -2.2693e-04, -3.9984e-02, -2.7627e-02, -3.2818e-02,\n",
      "           1.3492e-02, -3.9890e-02],\n",
      "         [ 3.8399e-02,  7.7614e-03,  2.5461e-02, -3.6430e-03, -2.2183e-02,\n",
      "          -4.4656e-03, -2.1017e-03],\n",
      "         [-1.4285e-02, -2.4149e-02, -1.8895e-02,  3.5670e-02,  3.4288e-02,\n",
      "          -4.5246e-02,  1.8138e-02],\n",
      "         [-3.5989e-02, -3.3986e-02, -3.4461e-02,  3.9657e-02, -2.7406e-02,\n",
      "          -2.0167e-02,  1.0631e-02],\n",
      "         [-3.0030e-02, -2.2232e-03, -3.7724e-02, -3.5001e-02,  2.4848e-02,\n",
      "           2.1682e-02,  1.2590e-02],\n",
      "         [ 1.0488e-02, -6.7878e-03,  2.9393e-03,  7.6739e-03,  4.5036e-02,\n",
      "          -2.5050e-02, -1.5517e-02],\n",
      "         [ 8.0344e-03, -2.0211e-02,  4.2374e-02, -2.3723e-02, -1.8581e-02,\n",
      "           4.5236e-03, -2.5816e-02],\n",
      "         [-4.2886e-02, -2.0041e-02,  2.8292e-02, -6.3501e-03,  2.4077e-03,\n",
      "          -2.7814e-02, -8.0828e-03],\n",
      "         [-5.3219e-04, -2.7245e-02,  1.0591e-02, -1.1172e-02,  3.5851e-02,\n",
      "          -3.3676e-02, -4.6192e-02],\n",
      "         [ 4.0467e-02, -2.1931e-02, -3.1541e-02, -5.9759e-03, -3.7267e-02,\n",
      "          -2.7743e-02, -2.9543e-02],\n",
      "         [ 4.4477e-02, -4.6054e-02, -1.2526e-02, -3.5903e-02,  6.8031e-03,\n",
      "          -2.9929e-02,  2.6350e-02],\n",
      "         [-3.5536e-02, -1.5515e-02, -1.3983e-02, -4.4430e-02, -3.8663e-02,\n",
      "           2.5531e-02, -1.6445e-02],\n",
      "         [-3.1145e-02,  2.3329e-02, -2.6606e-02,  1.4949e-02,  4.6672e-02,\n",
      "           2.1542e-04, -1.3185e-02],\n",
      "         [-3.7964e-02,  3.1086e-02,  4.8603e-03,  2.0023e-02,  2.9302e-02,\n",
      "           2.6065e-02, -4.0647e-02],\n",
      "         [-4.1780e-02, -5.2058e-03,  1.1438e-02, -1.2352e-02,  3.3818e-03,\n",
      "           4.3010e-02, -4.7177e-02],\n",
      "         [-4.5751e-02, -3.1937e-02,  4.0306e-03, -2.2042e-02, -3.2037e-03,\n",
      "           3.1882e-02, -3.0871e-02],\n",
      "         [ 4.1078e-04, -3.5869e-02, -2.5524e-03,  3.6106e-02, -4.7733e-03,\n",
      "          -1.6150e-03,  1.4643e-02],\n",
      "         [-2.9452e-02,  3.0152e-02,  5.3920e-03,  5.0838e-03,  5.9518e-04,\n",
      "           3.4214e-02, -1.5124e-02],\n",
      "         [ 4.1030e-02,  3.8232e-02, -2.3952e-02,  7.2601e-03, -2.4410e-03,\n",
      "           2.4772e-02,  1.0080e-02],\n",
      "         [ 2.6124e-02,  3.1147e-02, -2.0343e-02,  1.7866e-02, -3.6662e-02,\n",
      "          -9.6011e-03, -1.1845e-02],\n",
      "         [-4.8723e-03, -1.1850e-02,  3.1836e-02, -3.8437e-03, -6.8541e-03,\n",
      "           3.8751e-02, -2.1865e-03],\n",
      "         [-4.2096e-02, -3.3840e-02,  1.4084e-02,  1.0247e-02, -2.0336e-02,\n",
      "           7.6631e-03,  4.6245e-02],\n",
      "         [ 2.7426e-02,  4.3261e-02,  4.0730e-02, -3.4194e-03, -4.1276e-02,\n",
      "          -3.4775e-03, -4.7053e-02],\n",
      "         [-1.9903e-02, -4.0712e-02, -5.8795e-04, -3.6331e-02,  7.9243e-03,\n",
      "           4.2334e-02, -4.0278e-02],\n",
      "         [-6.7337e-03,  1.6677e-02,  1.8474e-02, -4.0633e-02,  2.5228e-02,\n",
      "          -2.1195e-03,  4.8086e-03],\n",
      "         [ 1.3549e-02, -2.0178e-02,  2.6877e-03, -6.5540e-03,  3.3728e-02,\n",
      "          -3.7070e-02,  3.5774e-03],\n",
      "         [ 2.5207e-02, -1.0703e-02, -3.6848e-02, -1.7297e-02,  2.4040e-02,\n",
      "           7.6018e-03,  1.0397e-02],\n",
      "         [-3.7854e-02,  1.6673e-02, -3.6354e-02, -2.2766e-02, -4.0648e-02,\n",
      "          -1.9340e-02,  8.0908e-03],\n",
      "         [-3.4839e-02,  1.8767e-02, -4.3944e-04,  3.5615e-02, -1.0981e-03,\n",
      "          -3.5589e-02, -1.7244e-02],\n",
      "         [ 4.4626e-02,  4.4787e-02, -2.1857e-02, -2.4048e-02, -1.0457e-02,\n",
      "          -1.4673e-03, -1.7125e-02],\n",
      "         [-2.8197e-03, -2.0090e-02, -2.8691e-02,  1.2418e-02, -3.6715e-02,\n",
      "          -3.8881e-02,  3.9678e-03],\n",
      "         [-1.1819e-02, -1.3988e-02,  1.9305e-02,  1.7140e-02,  4.7098e-02,\n",
      "           3.6643e-02,  3.7073e-02],\n",
      "         [ 6.9788e-03,  3.3047e-02, -3.1442e-02, -1.8054e-02, -1.0275e-02,\n",
      "           1.2678e-02,  2.1613e-02],\n",
      "         [-6.5764e-03, -3.2289e-02, -8.9982e-03, -2.6669e-02, -4.6858e-02,\n",
      "           3.9572e-03,  4.4302e-02],\n",
      "         [-1.0548e-02, -9.3746e-03,  1.2449e-02, -2.1185e-02,  9.4190e-03,\n",
      "           2.3922e-02,  2.3119e-02],\n",
      "         [-4.3377e-02, -2.0224e-03, -1.2181e-02,  9.7621e-03, -2.2474e-02,\n",
      "          -2.1631e-02, -3.3955e-02],\n",
      "         [ 2.4009e-02,  7.3973e-03, -3.6850e-02, -4.7200e-02, -1.1621e-02,\n",
      "           1.5511e-02, -4.9190e-03],\n",
      "         [ 3.4242e-02,  1.1726e-02, -2.4244e-02,  1.2293e-02,  1.1816e-02,\n",
      "          -1.4690e-02, -2.9599e-03],\n",
      "         [-4.4830e-02,  3.5927e-02, -8.3507e-03, -3.2239e-02, -9.9700e-03,\n",
      "           9.4126e-04, -2.8408e-02],\n",
      "         [-5.0003e-03, -8.6555e-03, -4.1013e-02, -3.0763e-02, -7.6268e-03,\n",
      "          -2.5152e-03,  4.5375e-02],\n",
      "         [ 1.4750e-02, -4.3118e-02, -2.4870e-02,  4.4081e-02,  8.2314e-03,\n",
      "           4.4577e-02, -4.6789e-02],\n",
      "         [-4.5579e-02,  1.7503e-02,  5.8701e-03,  4.3220e-02, -8.9324e-04,\n",
      "          -2.5329e-02, -8.6426e-03],\n",
      "         [-1.6418e-02,  1.1131e-03,  3.7966e-02,  1.9863e-02, -4.0151e-02,\n",
      "          -3.8212e-02,  3.3729e-03],\n",
      "         [-5.6631e-03,  4.5249e-02,  2.9031e-02, -4.4151e-02, -6.6428e-03,\n",
      "          -4.2533e-03, -2.8862e-02],\n",
      "         [-6.3632e-03,  1.6443e-02,  3.8107e-02,  2.8563e-02,  1.2206e-02,\n",
      "           4.6731e-02,  3.2158e-02],\n",
      "         [-4.6724e-03,  2.4083e-02, -5.5096e-03, -8.4075e-03, -1.1746e-02,\n",
      "           4.6406e-03,  2.6318e-03],\n",
      "         [-1.7027e-02,  3.8825e-02, -1.0038e-02, -4.3431e-02,  1.3742e-02,\n",
      "          -3.3006e-02, -2.7299e-02]],\n",
      "\n",
      "        [[-4.2337e-02,  2.0575e-02,  2.7753e-03,  3.4843e-02,  1.7417e-02,\n",
      "           4.4356e-02,  4.6929e-03],\n",
      "         [ 1.0781e-02, -1.8908e-02, -3.8707e-02,  3.6658e-02, -3.4257e-02,\n",
      "          -3.6973e-02,  1.6625e-03],\n",
      "         [-7.4768e-03,  2.1744e-02,  2.8895e-02, -2.2356e-02, -1.0327e-02,\n",
      "           2.9611e-02,  3.5929e-03],\n",
      "         [-4.6187e-02, -1.9230e-02, -2.4568e-02, -1.1401e-02,  3.3446e-02,\n",
      "          -1.1236e-02,  4.7230e-02],\n",
      "         [-2.5080e-02, -4.3800e-02, -2.3754e-03,  4.2209e-02, -4.5085e-02,\n",
      "           3.7590e-02,  2.8759e-02],\n",
      "         [ 3.2770e-02,  2.2840e-02, -4.7180e-02, -2.7540e-02, -3.8015e-02,\n",
      "          -3.3592e-02,  7.5695e-03],\n",
      "         [-3.0813e-02, -8.9246e-03, -7.4374e-04,  5.6284e-03, -1.9131e-02,\n",
      "          -1.3700e-02,  1.4967e-02],\n",
      "         [ 3.1601e-02,  3.2355e-02, -4.6919e-02, -2.0642e-02, -1.5312e-02,\n",
      "          -4.2112e-02,  1.7288e-02],\n",
      "         [ 3.4862e-02,  1.8753e-02,  2.4600e-02,  1.8699e-02,  3.2961e-02,\n",
      "           1.3236e-02, -4.6823e-02],\n",
      "         [-3.0061e-02, -5.1902e-03, -3.6781e-02,  1.5043e-02, -6.6826e-04,\n",
      "          -3.9288e-02, -1.6611e-02],\n",
      "         [ 2.5191e-03,  3.4703e-02,  2.3849e-02, -2.5678e-02, -1.5606e-03,\n",
      "           1.0737e-02,  1.0958e-02],\n",
      "         [-3.6172e-02, -3.5199e-02, -5.9835e-04,  4.7132e-02,  1.8279e-03,\n",
      "          -2.5013e-02, -7.0116e-03],\n",
      "         [ 1.6895e-02, -3.1926e-02,  1.8661e-02, -2.0027e-02,  3.1011e-02,\n",
      "          -7.7098e-03,  1.2928e-02],\n",
      "         [ 2.7499e-02,  1.2956e-02, -1.5284e-02,  1.8381e-02,  3.5486e-02,\n",
      "          -2.2086e-02,  2.1207e-02],\n",
      "         [ 6.8633e-03, -1.6286e-02,  3.2257e-02,  1.1231e-02, -3.2550e-02,\n",
      "           2.4499e-02,  4.0450e-02],\n",
      "         [-3.7557e-02,  2.5761e-02,  3.0778e-02, -1.4960e-02, -4.9407e-04,\n",
      "           6.8955e-03, -3.9480e-02],\n",
      "         [-4.4345e-02, -2.1496e-02, -3.6497e-04, -7.1883e-03,  3.3889e-02,\n",
      "           1.0346e-02, -3.8114e-02],\n",
      "         [-5.5412e-03,  2.9343e-02,  4.0838e-02, -8.4166e-03,  1.2148e-02,\n",
      "           1.5211e-02,  4.5975e-02],\n",
      "         [-1.4183e-02,  1.5117e-02, -1.1176e-02, -4.3189e-03,  4.2393e-02,\n",
      "          -7.5328e-04, -2.5552e-02],\n",
      "         [ 4.3043e-03, -7.1181e-04, -4.4961e-02,  3.7206e-02, -2.1824e-02,\n",
      "           1.0494e-02, -5.1587e-04],\n",
      "         [ 7.4466e-03,  7.8001e-03,  4.3181e-02,  2.8102e-02, -1.3994e-02,\n",
      "           7.0354e-03, -1.7316e-02],\n",
      "         [-3.3138e-03,  4.8454e-03, -4.4940e-02, -5.6805e-03, -6.1572e-03,\n",
      "           2.4734e-02,  7.6026e-03],\n",
      "         [ 9.7854e-03,  3.1339e-02, -4.4216e-02, -3.3319e-02,  1.6339e-02,\n",
      "           1.3444e-02,  1.8380e-02],\n",
      "         [-3.9780e-02, -4.0804e-02,  1.6800e-02, -2.8357e-02,  3.9382e-02,\n",
      "          -8.8175e-03,  8.0133e-03],\n",
      "         [ 2.3056e-02, -2.1108e-02, -1.0496e-02, -8.6290e-03,  6.0279e-04,\n",
      "          -1.2422e-02, -1.0422e-02],\n",
      "         [ 1.5832e-02,  2.5141e-02, -1.7529e-02,  1.7393e-02, -2.3270e-02,\n",
      "           1.8799e-02, -7.0313e-03],\n",
      "         [-1.0735e-02,  1.7053e-02, -4.5362e-02, -1.0949e-03, -2.1977e-02,\n",
      "           1.3253e-02, -4.6096e-02],\n",
      "         [-3.0455e-02,  3.2425e-03,  2.9438e-02, -1.4764e-02, -1.4330e-02,\n",
      "           3.1221e-02, -4.6221e-02],\n",
      "         [-4.0736e-02, -4.1204e-02, -2.8703e-02, -6.0733e-03,  2.7374e-02,\n",
      "           3.5385e-02,  3.1940e-02],\n",
      "         [-4.5566e-03,  2.3850e-02,  2.7717e-02, -3.1766e-02, -1.8945e-02,\n",
      "          -2.8525e-02, -1.3327e-02],\n",
      "         [-4.0661e-02,  4.6454e-02,  1.2478e-02, -2.9154e-02,  4.1949e-02,\n",
      "          -5.6227e-03, -2.5653e-02],\n",
      "         [ 3.3934e-02, -3.9648e-02, -6.0370e-03, -4.7024e-02, -2.1879e-02,\n",
      "           2.3581e-02,  1.1232e-02],\n",
      "         [ 1.2145e-02,  5.6512e-03, -3.4838e-02,  2.5395e-02, -1.8646e-03,\n",
      "          -2.7217e-02,  3.0137e-02],\n",
      "         [ 7.1014e-03,  3.3257e-02, -3.9446e-02,  4.2432e-02, -1.0277e-02,\n",
      "          -4.5686e-02,  1.5197e-02],\n",
      "         [ 4.0084e-03,  8.2437e-03,  1.8870e-02, -3.3989e-02, -1.1691e-03,\n",
      "          -3.8288e-03,  3.9817e-02],\n",
      "         [-4.0811e-02, -9.8633e-03, -2.9257e-02,  1.9268e-02,  2.2340e-04,\n",
      "           2.6787e-02,  2.3167e-02],\n",
      "         [-4.1846e-02, -6.4084e-03, -3.7001e-02, -3.4067e-02, -2.2095e-02,\n",
      "           2.4601e-02,  1.5107e-02],\n",
      "         [ 1.3200e-02,  2.7498e-02,  2.8213e-02,  1.7314e-02, -4.5571e-02,\n",
      "           1.9503e-02,  2.4737e-04],\n",
      "         [-1.5301e-02,  1.3399e-02,  4.0840e-02, -4.4429e-02,  3.5342e-02,\n",
      "          -2.2262e-02,  9.4165e-03],\n",
      "         [-2.0544e-02,  3.9239e-02, -2.2263e-02,  2.1595e-03,  3.9782e-02,\n",
      "          -6.4294e-03,  3.1652e-02],\n",
      "         [ 3.0072e-02,  4.0887e-02,  1.5408e-02,  3.4733e-02,  1.8661e-02,\n",
      "           1.8156e-02, -9.8680e-03],\n",
      "         [-1.0982e-02, -2.5748e-02,  4.6422e-02,  4.6703e-02, -2.6798e-02,\n",
      "          -4.0386e-02,  3.7124e-02],\n",
      "         [-3.2637e-02,  2.8724e-02,  1.0539e-02, -3.4184e-02, -1.8428e-02,\n",
      "           4.1046e-02,  2.8189e-02],\n",
      "         [ 1.3957e-02, -3.0427e-03,  2.3168e-02,  2.8294e-02,  3.3132e-02,\n",
      "          -6.8541e-04,  1.8998e-03],\n",
      "         [ 3.8857e-02,  1.2228e-03,  4.5313e-02, -3.7967e-04, -2.5811e-02,\n",
      "           2.0339e-02,  2.1601e-02],\n",
      "         [ 3.3430e-02, -2.9318e-02,  4.4914e-02,  3.0799e-02,  7.3908e-04,\n",
      "          -3.4444e-02,  3.3622e-02],\n",
      "         [-4.0752e-02, -4.5298e-02,  3.0252e-04, -2.8124e-02, -3.3790e-02,\n",
      "          -9.6172e-03, -4.3109e-02],\n",
      "         [-2.3883e-02, -2.0875e-02,  3.3287e-02,  3.7840e-02, -9.5643e-03,\n",
      "          -4.2731e-02, -2.6014e-02],\n",
      "         [-1.2650e-02,  3.9645e-02, -6.0227e-03,  8.9885e-03, -2.4357e-02,\n",
      "          -2.1966e-02, -2.8654e-02],\n",
      "         [-2.0926e-02, -1.1457e-02,  1.3427e-02, -2.0011e-04,  6.1504e-03,\n",
      "          -1.0197e-02, -3.2895e-02],\n",
      "         [ 3.9708e-02, -4.2343e-02,  4.2302e-02, -3.5987e-02,  3.6452e-02,\n",
      "          -3.4334e-02,  2.4968e-02],\n",
      "         [-3.1277e-02, -1.5539e-02,  2.9482e-02, -9.7486e-03,  3.0996e-02,\n",
      "          -2.6869e-02,  2.4241e-02],\n",
      "         [ 3.2215e-02,  5.7952e-03,  3.3435e-02, -3.7534e-02,  4.1534e-02,\n",
      "          -2.3336e-02,  3.8266e-02],\n",
      "         [-6.9107e-03, -3.7597e-02, -4.6868e-02,  1.9382e-02,  1.6591e-02,\n",
      "          -2.2256e-02,  2.2607e-02],\n",
      "         [-1.9548e-02,  3.3613e-02, -4.5228e-02, -4.3265e-02,  2.5209e-02,\n",
      "           4.5084e-02, -4.0500e-02],\n",
      "         [ 4.1421e-02,  3.9845e-02,  1.0124e-02,  1.2008e-03,  1.3972e-02,\n",
      "           4.4349e-02, -3.0547e-02],\n",
      "         [-2.9318e-02,  3.7914e-02,  1.4673e-03,  1.8914e-02, -4.3491e-02,\n",
      "           1.9673e-04, -1.1530e-02],\n",
      "         [-2.2244e-02, -1.7557e-02, -3.0114e-02, -2.8079e-02, -3.5178e-02,\n",
      "          -1.6705e-02,  2.1017e-02],\n",
      "         [ 2.9129e-02,  1.6881e-02,  1.5193e-02, -2.7345e-02, -3.2629e-02,\n",
      "           3.7570e-02,  3.8819e-02],\n",
      "         [ 4.0973e-02,  3.2127e-02,  3.1163e-03, -1.9843e-02, -1.3009e-02,\n",
      "           3.0733e-02, -4.0658e-02],\n",
      "         [-4.7055e-02,  5.8660e-03, -2.7024e-02,  3.2436e-02,  2.2136e-02,\n",
      "          -2.5377e-02,  2.2762e-02],\n",
      "         [-1.4560e-02,  2.7123e-02,  2.4772e-02,  7.2895e-03,  4.0347e-02,\n",
      "           1.4580e-03, -2.8455e-02],\n",
      "         [ 1.7576e-02,  1.6985e-02, -7.3250e-03, -1.2983e-02,  2.0754e-02,\n",
      "          -5.1653e-03,  2.5791e-02],\n",
      "         [-6.1633e-03, -2.0386e-02,  5.8121e-03,  2.2632e-02,  1.9514e-02,\n",
      "           4.4850e-02,  2.6664e-02]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.0.bias | Size: torch.Size([64]) | Values : tensor([-0.0087,  0.0238], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.1.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.1.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv3.0.weight | Size: torch.Size([64, 64, 7]) | Values : tensor([[[ 4.0285e-02,  1.8926e-02,  3.4412e-02,  2.1308e-03,  4.3181e-02,\n",
      "           7.7265e-03, -4.4526e-02],\n",
      "         [-4.5765e-02,  3.8802e-02,  2.6068e-02,  4.6850e-02,  2.6343e-02,\n",
      "          -2.0695e-02, -2.0054e-02],\n",
      "         [ 9.9322e-03,  3.5269e-02, -3.0161e-02,  1.3948e-02,  1.9333e-03,\n",
      "          -1.2791e-02, -4.2260e-02],\n",
      "         [ 6.9412e-03,  1.2769e-02,  1.6548e-02, -1.1997e-02, -2.1253e-02,\n",
      "           6.0131e-03, -3.7916e-02],\n",
      "         [ 4.4753e-03, -1.4111e-02,  4.0959e-02,  2.5667e-02,  1.2455e-02,\n",
      "          -1.8495e-02, -8.4273e-03],\n",
      "         [-4.1708e-02,  1.5666e-02,  5.7353e-03, -1.7238e-02,  1.8378e-02,\n",
      "           1.1785e-02,  2.0210e-02],\n",
      "         [-1.2580e-02,  4.2107e-02, -1.4530e-02, -1.5770e-02, -3.1080e-02,\n",
      "           4.0452e-02,  3.8910e-02],\n",
      "         [ 3.8487e-02,  4.5363e-02,  2.7340e-03, -2.2032e-02,  3.2333e-02,\n",
      "          -3.7183e-02, -1.6120e-02],\n",
      "         [-3.7746e-02,  2.9534e-02, -2.1228e-02, -2.0543e-02, -8.6980e-03,\n",
      "           4.3445e-02, -3.4386e-03],\n",
      "         [-1.0670e-04,  1.4977e-02, -2.3801e-02,  8.4572e-03,  2.7961e-02,\n",
      "          -2.2776e-02,  3.1886e-02],\n",
      "         [-2.1892e-02,  9.8594e-04,  4.3554e-02, -2.6180e-02,  6.9103e-03,\n",
      "          -3.0423e-02,  3.0451e-02],\n",
      "         [-2.5475e-02, -3.8429e-02,  2.5152e-02,  4.0791e-03,  7.0446e-03,\n",
      "           2.3296e-02, -4.1105e-02],\n",
      "         [ 4.3387e-02,  3.3811e-02,  3.8681e-02,  1.0663e-02, -3.0188e-02,\n",
      "          -1.8975e-02, -1.1136e-02],\n",
      "         [ 3.9913e-02, -3.0705e-02, -4.6819e-02,  3.2676e-02, -1.2149e-02,\n",
      "           3.9128e-02, -1.1235e-02],\n",
      "         [-4.4336e-02, -3.3291e-02,  4.4906e-02, -3.8037e-02, -6.4678e-03,\n",
      "          -4.4479e-02,  3.2574e-02],\n",
      "         [-1.1354e-02, -7.5251e-03,  1.8335e-03, -4.2898e-02, -3.8514e-02,\n",
      "           1.2649e-02,  4.0358e-02],\n",
      "         [-2.3894e-02, -1.8974e-02,  4.3739e-02,  3.1079e-02,  9.5311e-03,\n",
      "           9.4797e-03, -7.6531e-04],\n",
      "         [ 2.5901e-02,  2.9570e-02, -3.2854e-02, -1.5166e-02,  4.1299e-02,\n",
      "          -9.7262e-03,  4.5549e-02],\n",
      "         [-2.6890e-02, -3.9306e-03,  2.2327e-02,  4.1559e-03, -2.6896e-02,\n",
      "           2.8383e-02, -1.8029e-02],\n",
      "         [-1.5489e-02, -2.4325e-02, -2.0982e-02, -1.9903e-02, -2.9006e-02,\n",
      "          -3.5751e-02,  2.3593e-03],\n",
      "         [ 2.2684e-02, -2.3905e-02,  3.3443e-03, -2.4104e-02, -4.0708e-02,\n",
      "           2.6452e-02,  6.8014e-03],\n",
      "         [-8.7661e-03,  2.3326e-02,  1.9930e-02, -5.6191e-03, -3.9449e-02,\n",
      "           2.9790e-02,  8.8473e-03],\n",
      "         [-4.1495e-02, -7.4473e-04,  1.2870e-02, -4.0840e-02, -2.0081e-02,\n",
      "           4.2394e-02, -3.3141e-02],\n",
      "         [-1.2098e-05, -4.1761e-02,  3.4598e-02,  1.9870e-02,  5.9385e-04,\n",
      "           2.6500e-02,  3.4605e-02],\n",
      "         [-7.8891e-03, -1.9612e-02,  1.9725e-02, -2.9382e-02,  2.0352e-02,\n",
      "          -8.0322e-03,  3.2473e-02],\n",
      "         [ 3.2358e-02,  4.3708e-02,  3.9933e-02, -2.1254e-02, -4.3248e-02,\n",
      "          -2.3117e-02, -3.3249e-03],\n",
      "         [ 2.5198e-02,  1.4684e-02,  3.3006e-02,  7.7767e-03, -2.2718e-03,\n",
      "           1.9919e-02,  4.5700e-02],\n",
      "         [-4.0969e-02,  3.0715e-02,  2.5374e-02, -3.8003e-02,  1.5395e-02,\n",
      "          -3.2988e-02, -3.0847e-03],\n",
      "         [-1.0392e-02, -7.3118e-03, -4.4066e-03,  4.1931e-02, -1.5885e-02,\n",
      "           2.2414e-02, -3.8909e-02],\n",
      "         [-6.3172e-03, -2.5894e-02,  3.3669e-02,  4.8976e-03,  2.3807e-02,\n",
      "           2.4296e-02,  2.1277e-04],\n",
      "         [ 4.6660e-02,  4.4962e-02,  1.7817e-02, -3.7651e-02,  3.9628e-02,\n",
      "          -1.4345e-02, -6.5989e-04],\n",
      "         [-2.3584e-02,  3.6005e-02, -1.7550e-02, -1.8121e-02,  1.6168e-02,\n",
      "          -1.5892e-02,  1.5021e-02],\n",
      "         [-4.0815e-02,  5.5852e-03,  2.7353e-02, -3.0023e-02, -5.8849e-03,\n",
      "           4.1883e-02, -1.5076e-02],\n",
      "         [ 7.3821e-03, -1.7272e-02, -2.1002e-03, -4.6115e-03, -8.5123e-03,\n",
      "           3.4667e-02, -1.1703e-02],\n",
      "         [ 3.4724e-02, -4.6782e-02,  2.5518e-02, -2.9973e-02, -2.6471e-02,\n",
      "          -4.0452e-02, -4.6453e-02],\n",
      "         [-2.1544e-02,  9.1977e-03,  3.8150e-02, -3.6359e-02,  4.7712e-03,\n",
      "          -4.3155e-02, -4.6444e-02],\n",
      "         [-1.3320e-02, -2.6218e-03, -1.0877e-02, -2.2968e-02,  8.0604e-03,\n",
      "          -7.7718e-03,  2.3956e-02],\n",
      "         [ 4.5350e-02,  1.5733e-02, -2.4292e-02, -4.2729e-02,  3.7056e-02,\n",
      "          -3.9664e-02,  3.7275e-02],\n",
      "         [-2.5715e-02,  1.0065e-02,  9.3323e-03,  2.0746e-02, -2.4534e-02,\n",
      "           4.0455e-02,  3.1710e-03],\n",
      "         [-6.3678e-03, -3.0678e-02,  4.6881e-02, -5.2489e-03,  9.5941e-03,\n",
      "           4.6504e-02, -8.3399e-03],\n",
      "         [ 3.7071e-02, -2.6458e-02,  3.4540e-02, -1.1861e-02,  3.7727e-02,\n",
      "           3.7930e-02,  4.9835e-03],\n",
      "         [ 3.5736e-02, -2.7149e-02,  3.4331e-03,  3.6808e-02, -1.0320e-02,\n",
      "          -3.6918e-02, -4.1364e-02],\n",
      "         [ 4.5829e-02, -2.9144e-02,  4.1070e-02, -2.9667e-03,  1.2861e-02,\n",
      "           2.4844e-02, -4.1084e-02],\n",
      "         [-2.7179e-02,  1.7131e-02,  4.5208e-02,  3.2794e-02,  1.6341e-02,\n",
      "          -4.5841e-02, -3.1851e-02],\n",
      "         [ 3.9186e-02, -1.8106e-02,  1.8510e-02,  4.2755e-02,  3.6813e-02,\n",
      "          -2.8293e-02, -1.3430e-02],\n",
      "         [-3.0910e-02,  1.0981e-02,  2.1223e-02, -1.2964e-02, -3.0767e-02,\n",
      "          -1.5768e-02,  3.3885e-02],\n",
      "         [-1.3904e-02, -2.4062e-02,  3.5199e-02, -2.6397e-02, -2.9636e-02,\n",
      "           3.8332e-02, -1.3903e-02],\n",
      "         [ 3.0297e-02, -4.0205e-02, -4.0199e-02, -5.5492e-03, -2.8376e-02,\n",
      "          -6.7679e-03, -3.4056e-02],\n",
      "         [-2.2461e-03, -8.8810e-03, -4.5151e-02,  3.8644e-02, -1.5838e-02,\n",
      "          -4.3508e-02, -3.0867e-02],\n",
      "         [-2.7605e-02, -3.1383e-02, -3.2908e-02,  2.6532e-02,  2.6967e-02,\n",
      "          -4.3158e-02, -9.7262e-03],\n",
      "         [ 7.3142e-03,  1.2101e-02,  3.7036e-02,  3.9527e-02, -2.9442e-02,\n",
      "          -3.7555e-02, -9.3903e-03],\n",
      "         [-6.7150e-03,  4.4168e-02,  3.3781e-03, -3.6818e-02,  2.4017e-02,\n",
      "           4.5404e-03,  1.0793e-02],\n",
      "         [-2.8221e-02,  2.8076e-02, -1.1772e-02, -4.2408e-02, -2.9410e-02,\n",
      "          -1.2283e-02,  1.5806e-03],\n",
      "         [-1.5997e-02,  2.1135e-02, -2.2053e-02,  3.9415e-02, -2.5869e-02,\n",
      "          -3.8006e-02,  3.4116e-02],\n",
      "         [-2.8537e-02,  1.0623e-02, -3.6435e-02,  4.7682e-03, -2.5948e-02,\n",
      "          -2.0845e-02,  2.1390e-02],\n",
      "         [ 2.9886e-02,  3.0750e-02,  1.2530e-02,  3.4517e-02, -3.7969e-02,\n",
      "           3.3716e-02,  6.6526e-03],\n",
      "         [-2.7112e-04, -1.9336e-02,  1.9484e-03, -2.1628e-02, -1.7926e-02,\n",
      "          -7.8857e-03,  3.2096e-02],\n",
      "         [-3.9367e-02, -4.4850e-02, -1.6762e-02,  2.9702e-02, -2.8939e-02,\n",
      "           1.6941e-03, -6.3979e-03],\n",
      "         [ 1.3234e-02, -2.6934e-02, -4.6353e-02, -2.8083e-02, -1.5094e-02,\n",
      "          -3.6052e-02, -2.5740e-02],\n",
      "         [-2.4133e-03, -1.3786e-02,  2.0214e-03, -3.5057e-02, -6.9793e-03,\n",
      "          -4.3447e-02, -2.2803e-02],\n",
      "         [-3.2662e-02,  1.2657e-02, -3.4725e-02, -9.4750e-03,  4.6568e-02,\n",
      "          -4.6312e-02, -2.3979e-02],\n",
      "         [ 1.1288e-02,  4.4716e-02, -4.4956e-03,  3.8662e-02, -4.0264e-02,\n",
      "          -2.8835e-02,  4.2098e-02],\n",
      "         [-3.0288e-02, -4.5501e-02,  4.2814e-02,  1.4121e-02,  2.3599e-02,\n",
      "           7.7774e-03,  2.2299e-02],\n",
      "         [-1.4845e-02,  2.1645e-02, -2.3382e-02, -3.4473e-02, -2.4640e-02,\n",
      "          -4.2705e-02, -3.9895e-02]],\n",
      "\n",
      "        [[-3.9554e-02,  4.5475e-02,  2.0397e-02, -2.9863e-02, -4.6141e-02,\n",
      "          -3.3118e-02, -3.6864e-02],\n",
      "         [-3.3859e-02,  3.0090e-02,  1.0200e-02,  2.0057e-02,  1.9782e-02,\n",
      "          -5.3135e-03, -2.4395e-02],\n",
      "         [-2.8695e-02,  3.3254e-02,  8.6002e-03, -1.2315e-02,  2.4991e-02,\n",
      "           2.7654e-02,  3.0157e-02],\n",
      "         [-3.8285e-02,  1.2988e-02,  5.6892e-03,  1.8606e-02, -1.4255e-02,\n",
      "          -2.9061e-03, -3.6389e-03],\n",
      "         [-1.7233e-02,  2.0326e-02, -1.3905e-02, -3.7261e-02, -1.4343e-02,\n",
      "           9.1771e-03,  3.1213e-02],\n",
      "         [-2.4205e-03, -4.5135e-02, -1.9131e-02,  2.3195e-02, -2.4832e-02,\n",
      "          -4.5762e-03, -2.1476e-02],\n",
      "         [ 6.3151e-03,  2.2380e-02,  4.4574e-02,  3.4610e-02, -4.0472e-03,\n",
      "           1.0628e-02, -1.3717e-02],\n",
      "         [ 3.6166e-02, -4.2904e-04, -3.6404e-03, -2.1759e-02, -1.5552e-02,\n",
      "          -2.9224e-02,  2.7420e-02],\n",
      "         [-3.8794e-02,  2.5757e-02, -2.1530e-02, -4.2602e-02,  1.7704e-02,\n",
      "          -3.5323e-03,  2.4261e-02],\n",
      "         [-4.7181e-02,  2.1427e-02, -2.7319e-02, -7.8193e-03,  3.4527e-02,\n",
      "           4.6742e-02,  1.9580e-02],\n",
      "         [ 4.4595e-02, -4.1912e-02,  3.4949e-02,  2.2256e-02, -1.9274e-02,\n",
      "          -2.6087e-02,  1.8940e-02],\n",
      "         [-3.6217e-03, -2.1582e-02, -2.3689e-02, -4.3884e-02, -3.7945e-02,\n",
      "          -2.1130e-02,  2.0071e-02],\n",
      "         [-1.2136e-02,  3.5654e-02, -2.4536e-02, -4.4738e-02,  2.5159e-02,\n",
      "          -3.9539e-02,  4.1509e-02],\n",
      "         [-3.5155e-02,  4.4101e-02, -4.4337e-02,  4.6619e-02, -3.6218e-02,\n",
      "          -2.4183e-02, -3.8141e-02],\n",
      "         [-1.6887e-02,  2.6788e-02,  1.5506e-02,  2.3073e-02, -4.5656e-02,\n",
      "          -2.0277e-02, -2.2086e-03],\n",
      "         [ 1.1428e-02, -1.3369e-03, -1.5442e-02,  3.7044e-02, -2.7825e-02,\n",
      "           4.3235e-02,  3.2256e-03],\n",
      "         [ 2.7582e-03,  4.6675e-02,  2.8767e-02,  6.5950e-03,  8.9147e-03,\n",
      "          -4.1216e-02, -1.4791e-02],\n",
      "         [ 4.4405e-02, -3.4704e-02,  1.8678e-02, -6.8002e-03,  2.4878e-02,\n",
      "           3.7188e-03,  4.6085e-02],\n",
      "         [-4.2509e-02, -3.0593e-02,  4.3285e-02,  1.1123e-02, -9.1981e-03,\n",
      "           4.7689e-03, -2.7792e-02],\n",
      "         [-3.6919e-02,  3.9026e-02,  3.9191e-02, -1.5863e-02,  9.4095e-03,\n",
      "          -1.4746e-02, -3.6963e-02],\n",
      "         [-6.8214e-03,  9.1571e-04,  5.8636e-03,  2.6024e-02,  1.3673e-02,\n",
      "           3.9558e-02, -2.0000e-02],\n",
      "         [ 1.6037e-02, -2.9332e-02,  1.8489e-02,  2.8096e-02, -5.9064e-05,\n",
      "          -4.6556e-04,  2.2849e-04],\n",
      "         [-1.8542e-02,  2.2284e-02, -3.6185e-02, -1.5200e-02, -1.4548e-02,\n",
      "           4.5184e-02,  2.2241e-02],\n",
      "         [ 4.1786e-02, -1.0147e-02, -3.0523e-02, -1.4334e-02,  3.8139e-02,\n",
      "           2.2646e-03, -2.2646e-02],\n",
      "         [ 3.2125e-02,  2.8865e-02,  4.3741e-02,  4.6630e-02, -2.3564e-02,\n",
      "          -4.4191e-02, -3.7363e-02],\n",
      "         [-2.0883e-02, -3.1628e-02,  2.5073e-02, -4.2863e-02,  1.9664e-02,\n",
      "           3.7692e-02,  2.2763e-02],\n",
      "         [ 8.7008e-04, -1.5892e-02, -2.8826e-02, -1.1802e-02, -2.8771e-02,\n",
      "           1.6871e-02,  3.6049e-03],\n",
      "         [ 2.8716e-02,  1.2693e-02,  3.4419e-02,  2.8633e-02, -1.5303e-02,\n",
      "           4.5510e-02,  2.4720e-02],\n",
      "         [ 4.3806e-02, -2.3479e-02,  3.4557e-02,  9.4718e-03, -4.5258e-02,\n",
      "          -3.8164e-02,  1.3894e-02],\n",
      "         [-3.8789e-02, -1.4830e-02,  1.5358e-03,  2.7875e-02,  2.2121e-02,\n",
      "          -3.5890e-02, -4.1030e-02],\n",
      "         [-4.1625e-02,  1.8900e-03,  3.4154e-02,  4.3627e-02, -3.7778e-02,\n",
      "           3.4641e-02,  2.8531e-02],\n",
      "         [-2.9736e-02, -3.4221e-02, -3.0542e-02,  1.6429e-02, -2.7514e-03,\n",
      "           1.0274e-02,  4.4987e-02],\n",
      "         [-2.6003e-02,  4.3228e-02,  1.6104e-02,  2.3188e-02,  2.7377e-03,\n",
      "           6.1507e-03, -1.3949e-02],\n",
      "         [-5.7916e-03,  6.5196e-03,  6.6751e-03,  4.4078e-02, -4.1914e-02,\n",
      "           1.7509e-02, -2.9490e-02],\n",
      "         [ 1.9825e-02, -5.7223e-03, -4.4932e-02,  4.0245e-02, -1.8599e-02,\n",
      "          -4.1149e-02,  2.4142e-02],\n",
      "         [ 1.7956e-02,  9.6490e-03, -4.1686e-02,  4.3230e-02,  1.4025e-02,\n",
      "           3.2142e-02,  3.3175e-02],\n",
      "         [ 3.7137e-02, -3.2404e-02, -5.5806e-04,  3.1239e-02,  1.5540e-02,\n",
      "          -1.5718e-02,  6.1670e-03],\n",
      "         [ 2.2618e-02,  2.1553e-02,  4.0764e-02, -4.5073e-02, -3.4990e-03,\n",
      "          -1.6429e-02, -1.2860e-02],\n",
      "         [ 3.7543e-02, -2.8252e-02, -1.9117e-02, -2.4291e-02, -4.6689e-02,\n",
      "          -2.9940e-02,  4.2129e-03],\n",
      "         [-1.8720e-02,  3.1295e-02,  1.4863e-02,  3.0077e-03,  3.7603e-02,\n",
      "          -1.3772e-02,  4.4501e-02],\n",
      "         [-1.9555e-02, -1.9871e-02, -2.6569e-02, -1.9382e-02,  1.7814e-02,\n",
      "          -5.7539e-03, -3.0071e-02],\n",
      "         [ 6.7896e-03,  2.8891e-03, -2.4988e-03,  3.4698e-02, -3.4392e-02,\n",
      "           1.2731e-02, -2.8192e-02],\n",
      "         [ 1.1551e-02,  2.7052e-02,  2.9831e-03,  1.2464e-02, -1.4079e-02,\n",
      "           1.9630e-02, -2.5106e-02],\n",
      "         [ 2.4481e-02,  4.6536e-02,  4.0134e-02, -2.6336e-02, -5.2326e-03,\n",
      "           2.9462e-02, -4.0920e-02],\n",
      "         [-1.1572e-02,  8.0635e-03, -6.2445e-03, -1.2345e-02, -3.3936e-02,\n",
      "           3.9857e-02,  2.1246e-02],\n",
      "         [-4.1807e-02, -3.1717e-02,  3.9376e-02, -2.9754e-02, -9.5137e-03,\n",
      "           2.3334e-03, -1.5285e-02],\n",
      "         [-2.3050e-02,  2.3214e-02, -5.9842e-03, -3.6437e-02,  1.9177e-02,\n",
      "          -1.3585e-02,  3.6540e-02],\n",
      "         [ 2.5554e-02,  4.0129e-02, -2.7192e-02,  1.0261e-02,  3.9214e-02,\n",
      "          -2.6189e-02,  3.2717e-02],\n",
      "         [ 3.6641e-02, -5.0067e-04,  1.8376e-02,  1.5031e-02,  4.0955e-03,\n",
      "           1.9068e-02, -3.1058e-02],\n",
      "         [-3.2679e-02,  2.6881e-02, -2.8425e-02,  2.1670e-02, -1.7870e-02,\n",
      "          -3.0123e-02,  3.2005e-02],\n",
      "         [ 4.0797e-02, -3.3493e-03,  1.0196e-02, -2.2570e-02,  3.2092e-02,\n",
      "           3.0314e-02,  1.3243e-02],\n",
      "         [ 2.6599e-02, -2.2753e-02,  3.8193e-03,  1.0438e-02, -6.7543e-03,\n",
      "           1.3509e-02, -9.5090e-03],\n",
      "         [ 2.1297e-02,  2.8832e-02,  3.7592e-02, -3.4446e-02,  2.4544e-02,\n",
      "          -2.5955e-02, -1.8254e-02],\n",
      "         [ 3.4549e-02, -7.2356e-03,  1.3483e-03,  3.9877e-02,  1.1246e-03,\n",
      "          -1.9212e-02,  2.0487e-02],\n",
      "         [ 4.6169e-02, -9.9368e-03,  3.3172e-03,  1.6784e-02,  4.3227e-02,\n",
      "          -9.4552e-03,  3.1444e-02],\n",
      "         [ 1.8014e-02,  1.0677e-02, -1.1586e-02, -1.2791e-02, -3.2810e-02,\n",
      "          -2.5672e-02,  2.7603e-02],\n",
      "         [ 3.0415e-02, -3.1489e-03, -3.3487e-02,  7.2175e-03, -2.4377e-02,\n",
      "          -4.5811e-02, -5.2982e-04],\n",
      "         [ 3.4791e-02,  6.5405e-03, -3.5993e-02,  7.3398e-03,  2.7211e-02,\n",
      "           6.6225e-03,  3.7988e-03],\n",
      "         [-3.6525e-02, -2.1464e-02,  4.1009e-02, -3.2852e-02, -4.0895e-02,\n",
      "           3.1308e-02,  2.3164e-03],\n",
      "         [ 6.7240e-03, -3.1230e-02,  2.8491e-02,  3.5587e-02,  1.2601e-03,\n",
      "          -3.5044e-02,  8.8945e-03],\n",
      "         [-6.8962e-03,  6.3637e-03,  7.8194e-03,  1.8398e-02,  2.1878e-02,\n",
      "           2.0186e-02,  3.6854e-02],\n",
      "         [ 2.0817e-02, -2.2468e-02,  3.9507e-02,  1.8836e-03,  1.4857e-02,\n",
      "          -4.6911e-02, -3.1166e-02],\n",
      "         [-2.3485e-02,  2.5497e-02, -2.3860e-02,  5.2795e-04,  2.2773e-02,\n",
      "          -4.5191e-03,  4.2080e-02],\n",
      "         [ 1.7253e-02,  3.4778e-02, -3.2043e-02,  2.4680e-02,  4.9529e-03,\n",
      "           4.3959e-02, -3.4812e-02]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv3.0.bias | Size: torch.Size([64]) | Values : tensor([ 0.0124, -0.0253], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv3.1.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv3.1.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm1.weight_ih_l0 | Size: torch.Size([256, 64]) | Values : tensor([[ 0.0552, -0.0293,  0.0315, -0.1146,  0.0606, -0.0851,  0.1056,  0.0525,\n",
      "         -0.0752, -0.0080, -0.0091, -0.0561,  0.0397, -0.0199,  0.0012,  0.0350,\n",
      "         -0.0272, -0.0296,  0.0670, -0.1066, -0.0192, -0.1143,  0.1181,  0.0467,\n",
      "         -0.0851, -0.1114,  0.0935,  0.0496, -0.0199, -0.0757, -0.0928, -0.0029,\n",
      "          0.0131, -0.0823, -0.0712,  0.1227, -0.0485,  0.0342, -0.0128,  0.0839,\n",
      "         -0.1039,  0.0199,  0.1158,  0.0622, -0.0902,  0.0961, -0.0544, -0.0093,\n",
      "          0.0869,  0.1138,  0.0801, -0.0821, -0.0643,  0.0219, -0.0763, -0.0396,\n",
      "          0.1225, -0.0486, -0.0448,  0.0201,  0.0875,  0.0708, -0.0196,  0.0713],\n",
      "        [ 0.0294, -0.0584,  0.1028,  0.0593, -0.1100, -0.0659, -0.0927, -0.0227,\n",
      "         -0.1090, -0.0631, -0.1150,  0.0139, -0.1200,  0.0619, -0.0717, -0.0630,\n",
      "          0.0351,  0.0167,  0.0614,  0.0196, -0.0451, -0.0954, -0.1242, -0.1190,\n",
      "          0.0942,  0.0080, -0.0960, -0.0542,  0.0531, -0.0788,  0.0577,  0.0220,\n",
      "          0.0388, -0.1006,  0.0410,  0.0588, -0.0640,  0.0890, -0.0455,  0.1152,\n",
      "         -0.0571, -0.0514,  0.0705,  0.0844, -0.1225,  0.0705,  0.0135, -0.0106,\n",
      "          0.1116, -0.0960,  0.0903,  0.0301,  0.0734, -0.0626,  0.0276,  0.1162,\n",
      "          0.1094, -0.0759,  0.0230,  0.0802,  0.0202, -0.0768, -0.0759, -0.0694]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm1.weight_hh_l0 | Size: torch.Size([256, 64]) | Values : tensor([[-0.1007,  0.0239, -0.0961, -0.0877, -0.0380, -0.1081, -0.0427, -0.1238,\n",
      "         -0.0305, -0.0857,  0.0904,  0.1035,  0.0277, -0.0396,  0.0716, -0.0273,\n",
      "          0.0149,  0.1059, -0.0311,  0.0459, -0.1072,  0.0989, -0.1112,  0.0326,\n",
      "          0.1153,  0.0577, -0.0536, -0.1104, -0.0636,  0.0609, -0.0871,  0.1231,\n",
      "         -0.0299, -0.0290,  0.0197, -0.0976, -0.0130,  0.0990, -0.0383, -0.0349,\n",
      "          0.0241, -0.0346, -0.1119,  0.0894, -0.0536, -0.0556,  0.0822, -0.1248,\n",
      "          0.0131, -0.0406,  0.0229,  0.0590, -0.0299, -0.0917, -0.1049, -0.0786,\n",
      "         -0.0691, -0.0430, -0.0747,  0.0104,  0.0382,  0.0686,  0.0755,  0.0358],\n",
      "        [-0.0459,  0.1033,  0.0947, -0.0686,  0.0240,  0.0328,  0.1151, -0.0195,\n",
      "         -0.0858, -0.1220, -0.0189,  0.0640, -0.0523,  0.1012, -0.0926, -0.0236,\n",
      "         -0.0868,  0.0116,  0.0847,  0.1232, -0.0594,  0.1043, -0.0025,  0.0668,\n",
      "         -0.0848,  0.1077, -0.0596, -0.1017,  0.0222,  0.1085, -0.1238,  0.0861,\n",
      "          0.0552,  0.0598, -0.0807,  0.0201, -0.0224, -0.0760, -0.0363,  0.1018,\n",
      "          0.0892,  0.0446, -0.0116,  0.1156, -0.0659,  0.0037, -0.0671,  0.0786,\n",
      "         -0.1233,  0.0004,  0.1074, -0.1056, -0.0990, -0.1155,  0.1059,  0.0599,\n",
      "         -0.1070, -0.1068, -0.0562, -0.1140, -0.0136,  0.0921,  0.0925, -0.0781]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm1.bias_ih_l0 | Size: torch.Size([256]) | Values : tensor([ 0.0595, -0.0491], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm1.bias_hh_l0 | Size: torch.Size([256]) | Values : tensor([0.0827, 0.0611], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm2.weight_ih_l0 | Size: torch.Size([256, 64]) | Values : tensor([[ 0.0149,  0.1090, -0.0480, -0.0131, -0.0083, -0.0756,  0.0564, -0.0452,\n",
      "          0.0225, -0.1215,  0.0735, -0.1056, -0.0798,  0.0907,  0.0441, -0.0086,\n",
      "         -0.1248, -0.0931, -0.0387,  0.1059, -0.0204,  0.0156,  0.1125,  0.0288,\n",
      "          0.0916,  0.0258,  0.0203,  0.0546, -0.0815, -0.0473,  0.1122,  0.1128,\n",
      "          0.0149,  0.0789,  0.0792,  0.0398,  0.1163, -0.0656,  0.0386,  0.0494,\n",
      "          0.0930, -0.0010,  0.0311, -0.1006, -0.0279,  0.0984,  0.0960,  0.0344,\n",
      "         -0.0744, -0.0037,  0.0503,  0.1241,  0.0197,  0.0557,  0.0652, -0.0807,\n",
      "          0.0021, -0.0982,  0.0439,  0.0591,  0.0583, -0.0873, -0.0399,  0.0516],\n",
      "        [ 0.0023, -0.0752,  0.0298, -0.0752,  0.0648,  0.1173,  0.1226,  0.0547,\n",
      "          0.0089,  0.0142, -0.1219,  0.0564, -0.1043, -0.1129, -0.1191,  0.0103,\n",
      "          0.0790, -0.0132,  0.0788,  0.0508, -0.1199, -0.1074,  0.1028,  0.1051,\n",
      "         -0.0951, -0.0271, -0.0446, -0.0091,  0.1212,  0.0880, -0.0989,  0.1097,\n",
      "          0.0168,  0.0687,  0.1031, -0.0379, -0.1071, -0.0569, -0.0537,  0.0299,\n",
      "          0.1241, -0.0756,  0.0801, -0.0881, -0.0142, -0.0029,  0.0278,  0.1093,\n",
      "         -0.0889,  0.0732, -0.0769, -0.1199, -0.0656,  0.0231, -0.0670, -0.0357,\n",
      "         -0.0543,  0.0246,  0.0532, -0.0815,  0.0264, -0.0056, -0.1160, -0.0229]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm2.weight_hh_l0 | Size: torch.Size([256, 64]) | Values : tensor([[-0.0683, -0.0858, -0.0214,  0.0240, -0.0417,  0.0166,  0.1110, -0.0016,\n",
      "         -0.0118,  0.0500, -0.1183,  0.0060,  0.0186,  0.0556, -0.0458, -0.0332,\n",
      "         -0.0934, -0.0952, -0.0032, -0.1086,  0.0215, -0.0661,  0.0139, -0.0893,\n",
      "         -0.0787, -0.1223, -0.0738, -0.0041,  0.0171, -0.1109, -0.0729,  0.0216,\n",
      "          0.0923,  0.0024, -0.1208, -0.0316,  0.1002, -0.0436,  0.1173,  0.0434,\n",
      "          0.0302,  0.0874,  0.1049, -0.0264,  0.0393,  0.0815,  0.0900, -0.1229,\n",
      "         -0.0097,  0.0584,  0.1175, -0.0385,  0.0111, -0.0216,  0.0844,  0.0703,\n",
      "          0.0736, -0.0702,  0.0239,  0.0006,  0.0925, -0.0205, -0.0715,  0.0462],\n",
      "        [-0.0279,  0.0951,  0.0399,  0.0734,  0.0727,  0.1076,  0.1071,  0.0853,\n",
      "         -0.0819,  0.0668,  0.1096, -0.1140, -0.1107,  0.1154,  0.0959,  0.1240,\n",
      "          0.0475,  0.0685,  0.0965, -0.0410,  0.0839,  0.0125,  0.0017, -0.1068,\n",
      "          0.0370, -0.0649, -0.0574,  0.0081, -0.0023, -0.0512, -0.0094, -0.0780,\n",
      "         -0.1204,  0.1069, -0.1178,  0.0153, -0.0185, -0.0586,  0.0366, -0.0436,\n",
      "         -0.0075, -0.1134, -0.1130,  0.0013, -0.0676,  0.1154,  0.0265,  0.0722,\n",
      "          0.0281, -0.0288, -0.0512, -0.0577,  0.0223,  0.0030,  0.0169, -0.0275,\n",
      "          0.0956, -0.0854,  0.1184,  0.0495,  0.0144,  0.1013,  0.1002,  0.0866]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm2.bias_ih_l0 | Size: torch.Size([256]) | Values : tensor([-0.1002,  0.0588], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm2.bias_hh_l0 | Size: torch.Size([256]) | Values : tensor([0.0660, 0.0235], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc.weight | Size: torch.Size([2, 64]) | Values : tensor([[-0.0715,  0.0281,  0.0090, -0.0399, -0.0885,  0.1051, -0.1162, -0.0040,\n",
      "          0.0942, -0.1109, -0.0253, -0.1171,  0.0889, -0.0373, -0.0839,  0.0038,\n",
      "         -0.1081, -0.1149,  0.0200, -0.0024, -0.0564,  0.1035, -0.0014, -0.0189,\n",
      "         -0.1159,  0.0062,  0.0709,  0.1052, -0.0520, -0.0087,  0.0838,  0.0807,\n",
      "         -0.0412, -0.0914,  0.0102,  0.0002, -0.0083, -0.1034, -0.0493, -0.0355,\n",
      "         -0.0335,  0.0315, -0.0364, -0.0659, -0.0209,  0.0814,  0.1154,  0.0851,\n",
      "         -0.0139, -0.1200,  0.0854,  0.0294, -0.0070,  0.0102, -0.0791, -0.0914,\n",
      "          0.0208, -0.0293, -0.0222,  0.1125,  0.0313,  0.0249,  0.0545, -0.0701],\n",
      "        [-0.1244,  0.0937,  0.0317,  0.0250, -0.0541, -0.0958, -0.0652,  0.0753,\n",
      "          0.0021, -0.0586,  0.0162,  0.1177, -0.0741,  0.0778,  0.0668,  0.0244,\n",
      "          0.1147, -0.0679, -0.0744,  0.1127,  0.0835,  0.1055, -0.0769,  0.1109,\n",
      "          0.0066,  0.0226,  0.0934, -0.0423, -0.1247,  0.0939, -0.0969,  0.0857,\n",
      "          0.0100,  0.0173, -0.0825,  0.0562,  0.0878, -0.0035,  0.1236,  0.0668,\n",
      "          0.0888,  0.0981, -0.0475,  0.0299, -0.0145,  0.0249,  0.0546, -0.0222,\n",
      "         -0.0647,  0.0054,  0.0262, -0.0702,  0.1106,  0.0396,  0.0554,  0.0819,\n",
      "          0.0665,  0.0858,  0.0240, -0.0665, -0.0957, -0.0613,  0.0783,  0.0679]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc.bias | Size: torch.Size([2]) | Values : tensor([0.0333, 0.0104], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the model\n",
    "model = ConvLSTM().to(device)\n",
    "\n",
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 5e-4\n",
    "batch_size = 64\n",
    "epochs = 200\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluate the model with torch.no_grad()\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlonmcu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
