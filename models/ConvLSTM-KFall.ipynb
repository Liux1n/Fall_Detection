{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(nn.Conv1d(in_channels=9, out_channels=64, kernel_size=7),\n",
    "                                   nn.BatchNorm1d(64),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool1d(2))\n",
    "        self.conv2 = nn.Sequential(nn.Conv1d(in_channels=64, out_channels=64, kernel_size=7),\n",
    "                                   nn.BatchNorm1d(64),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool1d(2))\n",
    "        self.conv3 = nn.Sequential(nn.Conv1d(in_channels=64, out_channels=64, kernel_size=7),\n",
    "                                   nn.BatchNorm1d(64),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool1d(2))\n",
    "        \n",
    "        self.lstm = nn.Sequential(nn.LSTM(input_size=64, hidden_size=64),\n",
    "                                  nn.Dropout(0.5),\n",
    "                                  nn.LSTM(input_size=64, hidden_size=64),\n",
    "                                  nn.Dropout(0.5))\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.Linear(in_features=64, out_features=2),\n",
    "                                nn.Softmax())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: ConvLSTM(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv1d(9, 64, kernel_size=(7,), stride=(1,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv1d(64, 64, kernel_size=(7,), stride=(1,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv1d(64, 64, kernel_size=(7,), stride=(1,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (lstm): Sequential(\n",
      "    (0): LSTM(64, 64)\n",
      "    (1): Dropout(p=0.5, inplace=False)\n",
      "    (2): LSTM(64, 64)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=2, bias=True)\n",
      "    (1): Softmax(dim=None)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: conv1.0.weight | Size: torch.Size([64, 9, 7]) | Values : tensor([[[ 0.0088, -0.0583, -0.1085, -0.0888,  0.1009, -0.0729, -0.0842],\n",
      "         [ 0.0224, -0.0990, -0.0484,  0.0531,  0.1113,  0.0549,  0.0623],\n",
      "         [ 0.0547, -0.0011, -0.0839, -0.0142,  0.0381,  0.0875,  0.1203],\n",
      "         [ 0.1037,  0.0601, -0.0248, -0.0692, -0.1031, -0.0061, -0.0505],\n",
      "         [ 0.0563,  0.0869, -0.0451,  0.0302, -0.0250,  0.0240,  0.0878],\n",
      "         [ 0.0678,  0.0182, -0.0836, -0.0388,  0.0905,  0.0543,  0.0575],\n",
      "         [ 0.0620, -0.0761, -0.0280, -0.1247, -0.0389,  0.0220, -0.0560],\n",
      "         [-0.0011, -0.0716, -0.0086, -0.0845,  0.1185, -0.0055,  0.0796],\n",
      "         [-0.1046,  0.0818, -0.0242,  0.0933, -0.1111,  0.0958, -0.0342]],\n",
      "\n",
      "        [[ 0.1145, -0.1230, -0.0989, -0.0764,  0.0857, -0.1236,  0.1169],\n",
      "         [ 0.0791, -0.0873, -0.0401, -0.1155,  0.0855, -0.0773,  0.0944],\n",
      "         [-0.0271, -0.0567, -0.0284, -0.0891,  0.0466, -0.0493,  0.1183],\n",
      "         [ 0.0634, -0.0085,  0.0086,  0.0468, -0.0495,  0.0957,  0.1031],\n",
      "         [-0.1147, -0.0887, -0.1044, -0.0495, -0.0859,  0.0933, -0.0200],\n",
      "         [-0.1037,  0.1003, -0.0700, -0.1253,  0.0765, -0.0523,  0.0640],\n",
      "         [ 0.0022,  0.0635, -0.0878, -0.0994, -0.0338,  0.0456, -0.0932],\n",
      "         [-0.0167, -0.0741, -0.1071,  0.0370, -0.0885, -0.0396,  0.1250],\n",
      "         [-0.0169, -0.0123,  0.0720,  0.0611,  0.0915, -0.0756,  0.1053]]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.0.bias | Size: torch.Size([64]) | Values : tensor([0.0634, 0.1066], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.1.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.1.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.0.weight | Size: torch.Size([64, 64, 7]) | Values : tensor([[[-1.2209e-02,  4.1274e-02, -3.9720e-02,  4.1081e-02, -1.2375e-02,\n",
      "           4.1113e-02,  1.2553e-02],\n",
      "         [-3.5905e-02,  2.7935e-02, -4.1974e-02, -2.7156e-02,  2.7733e-02,\n",
      "           1.3671e-02,  3.2051e-02],\n",
      "         [ 5.3116e-03, -2.0856e-02,  1.7624e-02, -2.7520e-02,  1.2216e-02,\n",
      "          -4.3999e-02,  4.6403e-02],\n",
      "         [-3.8805e-02, -2.2369e-02, -4.3260e-05,  9.3124e-03,  2.5714e-02,\n",
      "           3.9938e-03, -3.8120e-02],\n",
      "         [ 2.1668e-02, -5.9312e-03, -2.6753e-02, -2.7581e-02, -3.0796e-02,\n",
      "          -2.2431e-02,  4.2663e-02],\n",
      "         [ 1.6547e-02,  1.6127e-02, -3.1567e-02,  2.0177e-02,  1.9662e-02,\n",
      "           3.6868e-02, -4.4723e-02],\n",
      "         [-3.6943e-02,  5.7691e-03, -4.3054e-02,  5.7756e-03, -4.4869e-02,\n",
      "           4.6675e-02,  7.0816e-03],\n",
      "         [-8.3161e-03, -4.3034e-03,  2.3401e-02, -7.8615e-03,  4.6711e-02,\n",
      "           4.5039e-02,  7.6214e-03],\n",
      "         [ 2.8537e-03,  8.9642e-03,  2.0911e-02, -1.1368e-02, -3.0599e-02,\n",
      "           2.7446e-02,  2.7225e-02],\n",
      "         [-2.2001e-02, -1.3030e-02, -3.1127e-02, -3.4868e-02, -4.0458e-02,\n",
      "           2.2751e-02,  4.9146e-03],\n",
      "         [ 4.4333e-02,  1.4205e-02, -3.9941e-02,  3.2208e-02,  3.5691e-03,\n",
      "           4.0008e-03,  3.1841e-02],\n",
      "         [-6.1382e-03,  4.5841e-02, -2.6528e-02,  3.5105e-02,  4.6838e-02,\n",
      "          -3.6667e-02,  5.4822e-03],\n",
      "         [ 2.8408e-03,  7.3892e-03, -4.6087e-02, -2.3855e-02, -1.8730e-02,\n",
      "           6.9579e-03,  4.6645e-02],\n",
      "         [ 3.2285e-02,  1.2551e-02,  3.7739e-02,  1.2730e-02, -3.6146e-02,\n",
      "          -3.5600e-02,  3.6424e-02],\n",
      "         [ 3.4720e-02, -3.1829e-02, -3.9313e-03,  6.3733e-03,  1.3430e-02,\n",
      "          -3.9066e-03, -1.3960e-02],\n",
      "         [-7.9798e-03,  2.3000e-03, -2.6526e-02, -1.6557e-03, -2.9368e-02,\n",
      "          -4.3751e-02, -1.1306e-02],\n",
      "         [-4.4608e-02,  8.4013e-03, -3.4884e-03,  4.7050e-02,  3.3012e-02,\n",
      "           4.5986e-02, -2.4979e-02],\n",
      "         [ 1.0468e-02,  2.4966e-02,  2.8055e-02,  2.0467e-02,  4.2634e-02,\n",
      "          -3.9638e-03, -2.7546e-02],\n",
      "         [ 2.6135e-02,  2.8715e-02, -2.4158e-03, -1.3250e-02, -1.1929e-02,\n",
      "           1.4592e-02, -4.1952e-03],\n",
      "         [ 3.5662e-02, -1.0477e-02, -1.4296e-02, -1.6730e-02, -2.4760e-02,\n",
      "          -4.3925e-02,  4.5659e-02],\n",
      "         [-4.6691e-02, -1.0640e-02,  2.9184e-02, -3.7613e-03,  2.0508e-02,\n",
      "           3.7161e-02, -1.9217e-04],\n",
      "         [ 4.0146e-02,  3.5591e-03,  1.5642e-02,  1.5788e-03, -5.1462e-03,\n",
      "           3.9159e-02, -1.8249e-02],\n",
      "         [ 1.7899e-02,  8.7304e-03, -6.3772e-04,  5.4310e-03,  1.9811e-02,\n",
      "          -1.3127e-03,  4.6697e-02],\n",
      "         [ 6.1929e-03,  4.0603e-02,  7.0443e-03, -3.3027e-02, -1.4424e-03,\n",
      "          -5.9495e-03, -9.6150e-03],\n",
      "         [-1.2156e-02, -2.4823e-02, -1.2521e-02,  3.2036e-03,  4.3961e-02,\n",
      "          -9.5673e-03,  3.7220e-02],\n",
      "         [ 3.6821e-02, -4.2283e-02, -1.9050e-02,  4.2127e-02,  1.8583e-02,\n",
      "           1.8314e-02,  2.8519e-02],\n",
      "         [ 9.8639e-03,  1.8099e-02, -1.0898e-02, -3.3610e-02, -4.1866e-02,\n",
      "           2.8051e-03,  2.2997e-02],\n",
      "         [-4.5936e-02, -1.2166e-02,  3.3343e-02, -5.8325e-03, -1.8908e-02,\n",
      "          -2.3208e-02,  2.4641e-03],\n",
      "         [ 2.0959e-02,  4.0597e-02, -1.1568e-02, -3.6408e-02,  9.3207e-03,\n",
      "           4.0360e-02,  2.2750e-02],\n",
      "         [ 2.3601e-02,  1.1877e-02,  1.7964e-02,  3.6643e-02,  1.7338e-03,\n",
      "           3.0610e-02,  3.9785e-03],\n",
      "         [ 4.1942e-02, -2.6823e-02,  5.7501e-04,  1.7171e-02,  2.7769e-02,\n",
      "           4.3821e-02, -2.7957e-02],\n",
      "         [-1.1717e-02, -3.0929e-02, -3.5563e-02,  6.7986e-03, -7.5164e-03,\n",
      "          -4.4189e-02,  3.9376e-02],\n",
      "         [ 1.5728e-02,  1.5751e-02, -4.4749e-02,  1.0329e-03,  4.6603e-02,\n",
      "          -3.8815e-02,  4.6544e-02],\n",
      "         [ 6.9047e-04, -3.2656e-02,  3.2695e-02, -3.7478e-02,  1.2318e-02,\n",
      "          -5.5683e-03,  2.4426e-02],\n",
      "         [-7.3288e-03,  2.8653e-02,  1.4271e-02, -3.6290e-02, -2.7931e-02,\n",
      "          -5.7179e-04,  2.5467e-03],\n",
      "         [-3.3534e-02, -1.1188e-02,  4.6786e-02, -2.4574e-02, -8.0767e-03,\n",
      "          -1.1737e-02, -2.3063e-02],\n",
      "         [-1.5358e-02, -2.1141e-02, -2.0746e-02,  3.4176e-02, -3.1913e-02,\n",
      "           3.8410e-02,  5.7534e-03],\n",
      "         [ 4.1433e-02,  2.5683e-02,  4.0179e-02,  2.4917e-02,  1.2431e-02,\n",
      "           2.1207e-02, -1.5400e-02],\n",
      "         [ 5.2306e-03, -1.6284e-03, -1.4368e-02,  3.3652e-02,  1.5288e-02,\n",
      "           3.6625e-02,  4.0865e-02],\n",
      "         [ 1.6350e-02, -2.3216e-02, -9.5226e-03,  3.7746e-02,  1.0585e-03,\n",
      "          -4.6707e-02, -4.2422e-02],\n",
      "         [-2.8277e-02,  2.2930e-02, -1.6112e-02,  2.5433e-02, -4.1123e-02,\n",
      "          -1.9991e-02, -1.1259e-02],\n",
      "         [ 3.5096e-02, -1.7156e-02, -4.0628e-02, -3.7545e-02,  1.8542e-02,\n",
      "          -9.0389e-03,  4.1618e-02],\n",
      "         [ 9.5814e-03,  3.4829e-02,  2.3285e-03,  3.4417e-02, -1.2547e-02,\n",
      "           2.2209e-02, -1.9507e-02],\n",
      "         [ 4.6031e-02,  3.5717e-02, -2.8628e-02, -9.9853e-03, -2.2811e-02,\n",
      "           2.6808e-02,  4.0745e-02],\n",
      "         [-7.5811e-03, -2.0443e-02, -1.0787e-02, -3.0463e-02, -4.4911e-02,\n",
      "          -2.2295e-02,  9.8272e-03],\n",
      "         [-4.1478e-03, -4.6685e-02,  2.8853e-03, -3.7207e-02,  3.0166e-03,\n",
      "           1.7458e-02, -1.1897e-02],\n",
      "         [-1.6000e-02, -3.3429e-02,  2.0327e-03,  1.4570e-02, -3.8523e-02,\n",
      "           1.8829e-02, -3.5968e-02],\n",
      "         [-2.4439e-02,  1.5720e-02,  2.1255e-02,  1.3453e-02, -1.6068e-02,\n",
      "          -2.1118e-02,  3.8413e-02],\n",
      "         [ 3.7240e-02, -8.4681e-03,  2.7635e-02, -1.7848e-02,  4.0789e-02,\n",
      "          -1.5265e-02, -1.3747e-02],\n",
      "         [ 3.8972e-02, -4.6135e-02, -3.3197e-02, -2.9504e-02,  1.1297e-02,\n",
      "           5.3124e-03, -1.2221e-02],\n",
      "         [ 7.8129e-03,  3.3204e-02,  3.7627e-02, -4.2734e-02, -3.4493e-02,\n",
      "           2.8989e-02, -2.8141e-02],\n",
      "         [-3.8331e-02,  1.0655e-02,  2.4252e-02, -4.1651e-02, -2.8666e-02,\n",
      "           1.0838e-02, -2.5765e-02],\n",
      "         [ 9.5357e-03, -3.3230e-02, -3.9094e-02, -2.7625e-02, -2.6920e-02,\n",
      "          -3.8527e-03, -4.6897e-02],\n",
      "         [ 1.9800e-02,  1.3672e-02,  4.0079e-02,  3.7477e-02, -1.4614e-02,\n",
      "           1.4476e-02, -1.0576e-02],\n",
      "         [-1.1663e-02, -2.1785e-02,  2.0142e-02,  5.3441e-03,  1.3345e-02,\n",
      "          -2.4160e-02, -3.5289e-02],\n",
      "         [-3.4492e-02,  3.5933e-02,  4.0022e-02, -4.1875e-02,  4.2179e-03,\n",
      "          -2.2435e-02, -1.5102e-02],\n",
      "         [-2.7510e-02, -1.6258e-02,  3.5315e-02,  1.0896e-02, -1.0437e-02,\n",
      "          -2.5949e-02,  3.6581e-02],\n",
      "         [ 3.0983e-02,  3.6889e-02, -1.8514e-02,  1.2978e-02, -3.3542e-02,\n",
      "          -6.4730e-03,  1.2451e-02],\n",
      "         [-4.6731e-03, -2.7088e-02, -1.8661e-02, -3.5383e-02,  2.3255e-02,\n",
      "           2.3888e-02,  1.0575e-02],\n",
      "         [-4.4857e-02, -2.7895e-02, -9.1629e-03,  2.4968e-02, -1.9530e-02,\n",
      "           2.8342e-02,  2.3505e-02],\n",
      "         [ 4.3203e-02, -2.0147e-02,  2.6439e-02,  3.3614e-02,  3.9987e-02,\n",
      "           2.3954e-02,  4.2283e-02],\n",
      "         [-8.3436e-03, -5.0131e-03, -4.1214e-02, -2.0561e-03, -1.3030e-02,\n",
      "           4.5579e-02, -1.5301e-02],\n",
      "         [-4.6485e-02, -2.7584e-02,  1.0132e-02,  7.0505e-03,  3.8053e-02,\n",
      "           4.2070e-02,  3.1959e-02],\n",
      "         [ 2.5559e-02,  4.1488e-03, -3.1831e-02,  4.7297e-03, -1.8581e-02,\n",
      "          -2.6875e-02, -7.1026e-03]],\n",
      "\n",
      "        [[ 4.1510e-02,  4.0603e-02, -4.2453e-02,  2.1318e-02,  4.3177e-02,\n",
      "          -7.7791e-03, -8.3550e-03],\n",
      "         [ 3.8790e-02, -6.9294e-04, -4.5837e-02, -2.4805e-02,  4.2801e-02,\n",
      "           3.2224e-02, -3.6307e-02],\n",
      "         [ 4.2281e-02, -4.4043e-03,  3.3972e-02, -3.0291e-02,  2.5721e-02,\n",
      "           1.6043e-03,  4.0684e-02],\n",
      "         [-1.2851e-02, -2.9589e-02,  4.4813e-03, -6.7864e-03, -6.6772e-03,\n",
      "          -4.3482e-02,  2.1262e-02],\n",
      "         [-1.9728e-02, -4.2099e-02,  1.8016e-02, -2.4905e-02,  3.7853e-02,\n",
      "          -2.3577e-02, -4.9442e-03],\n",
      "         [ 9.4871e-03, -1.1706e-02, -1.8613e-02, -5.8314e-03, -1.9531e-02,\n",
      "           3.4534e-02,  1.8404e-02],\n",
      "         [-3.3443e-02,  2.5793e-02, -3.9670e-02, -1.9160e-02,  7.5684e-03,\n",
      "          -1.9269e-02,  2.9984e-02],\n",
      "         [ 4.0759e-02,  3.2783e-02, -1.9900e-02,  4.3097e-02,  1.3243e-02,\n",
      "           2.8497e-02,  2.8380e-02],\n",
      "         [-5.0262e-03,  5.3105e-03,  2.2985e-03, -1.6832e-02, -1.8907e-02,\n",
      "           4.0145e-02,  1.6156e-02],\n",
      "         [-4.6815e-02,  4.6500e-02,  1.6121e-03, -1.5359e-02,  2.4435e-02,\n",
      "          -1.9594e-02, -3.2915e-03],\n",
      "         [-4.3568e-02,  3.2708e-02, -3.1423e-02,  3.7134e-03, -6.8916e-03,\n",
      "          -3.8227e-02,  4.0713e-02],\n",
      "         [-1.2649e-02,  2.5097e-02, -2.4730e-02,  4.6482e-02,  1.7980e-02,\n",
      "           4.0895e-02, -6.7386e-03],\n",
      "         [ 3.9946e-02, -4.4042e-02,  1.3005e-02,  4.1686e-02,  3.3661e-02,\n",
      "          -2.5531e-02, -2.1074e-02],\n",
      "         [ 2.3652e-02, -3.0661e-02, -4.0053e-02, -3.1441e-02,  6.0116e-03,\n",
      "           4.2891e-02,  1.9832e-02],\n",
      "         [-1.9598e-02, -1.6126e-02,  1.1197e-02, -1.0716e-02,  3.6872e-02,\n",
      "          -2.8440e-02, -4.3484e-02],\n",
      "         [-4.5068e-02, -4.5896e-02, -2.7951e-02, -3.4983e-02,  1.4036e-02,\n",
      "          -1.7086e-02,  3.2229e-02],\n",
      "         [ 1.2935e-02,  2.7185e-02,  3.5990e-02,  3.6028e-02,  2.1500e-03,\n",
      "          -4.0162e-02,  1.8558e-03],\n",
      "         [-4.1349e-02, -1.9043e-02, -6.9990e-03,  6.5602e-03, -3.7734e-02,\n",
      "           8.2200e-03,  4.6700e-02],\n",
      "         [-3.5538e-03,  1.5598e-02, -2.2485e-02,  4.3533e-02, -3.6924e-02,\n",
      "          -2.2291e-02, -3.8051e-02],\n",
      "         [ 2.2350e-02,  1.6586e-02,  3.4992e-02, -3.3331e-02, -1.3706e-02,\n",
      "          -1.0107e-02, -2.6839e-02],\n",
      "         [ 1.7074e-03,  1.4685e-02,  4.1682e-02, -3.8539e-02, -3.5877e-02,\n",
      "           1.1912e-02,  2.3133e-02],\n",
      "         [-3.4542e-02, -2.5289e-02, -5.9492e-03, -4.6434e-02, -2.1302e-02,\n",
      "          -1.8812e-02,  4.2533e-02],\n",
      "         [ 2.8970e-02, -2.0540e-02,  5.0397e-03,  4.0458e-02,  3.4230e-02,\n",
      "          -2.4542e-02, -4.9503e-03],\n",
      "         [-1.4233e-02,  4.5522e-02,  1.2831e-02,  8.6217e-03, -1.1909e-02,\n",
      "          -1.7211e-02, -4.7725e-03],\n",
      "         [-2.5828e-02, -1.4918e-02,  1.9034e-02,  9.2458e-03,  3.8541e-02,\n",
      "          -2.4564e-03,  1.9287e-02],\n",
      "         [-3.4552e-02, -2.6738e-02,  2.4245e-02,  4.1543e-02,  1.7868e-02,\n",
      "          -1.2951e-02,  3.8911e-02],\n",
      "         [ 2.2535e-03, -2.0332e-02,  1.7719e-02, -4.5212e-02,  2.5916e-02,\n",
      "          -4.6028e-02, -1.6389e-03],\n",
      "         [ 2.8210e-02, -4.1169e-02, -2.4630e-02, -3.6919e-02,  3.4447e-02,\n",
      "          -7.2918e-03,  4.1544e-02],\n",
      "         [-2.0984e-02, -3.4139e-02, -2.8747e-02, -1.7119e-02, -1.4664e-02,\n",
      "           3.6694e-02, -1.9041e-02],\n",
      "         [-4.5126e-03,  1.7233e-02, -1.4207e-02,  3.7841e-02, -1.5667e-02,\n",
      "           2.2098e-02,  2.7742e-02],\n",
      "         [-2.4128e-02, -1.1284e-02,  3.1053e-02, -8.5049e-03,  1.4163e-02,\n",
      "          -4.5800e-02, -1.2021e-02],\n",
      "         [ 2.7863e-02,  4.4539e-03, -2.8194e-02, -4.1069e-02, -3.6797e-02,\n",
      "          -1.4902e-02,  3.4643e-02],\n",
      "         [-2.1579e-02, -2.0602e-02,  4.7194e-02, -1.6417e-02, -1.7483e-02,\n",
      "          -3.3324e-02, -1.4811e-02],\n",
      "         [-4.5680e-02, -3.1273e-02, -2.7943e-02,  2.1680e-02,  3.2463e-02,\n",
      "          -2.3183e-02,  4.5230e-02],\n",
      "         [-3.8646e-02, -1.8153e-02,  1.1543e-02, -4.2119e-02, -1.3604e-02,\n",
      "           9.2118e-03,  2.9179e-03],\n",
      "         [-3.3264e-02, -2.6652e-02,  1.8175e-02, -1.3185e-02,  6.0108e-03,\n",
      "          -1.3824e-02,  3.3253e-02],\n",
      "         [ 2.7952e-02,  1.0768e-03, -1.7327e-02, -1.5786e-02, -2.2774e-02,\n",
      "           1.0185e-02,  2.8464e-02],\n",
      "         [ 2.6026e-02, -4.6922e-02,  3.6455e-02,  4.3074e-02,  4.4848e-02,\n",
      "          -3.2525e-02,  2.7217e-03],\n",
      "         [ 2.4295e-02, -4.0380e-02, -3.5581e-02,  1.0610e-02, -6.4471e-03,\n",
      "          -1.1336e-02, -2.9591e-02],\n",
      "         [-3.2885e-02, -1.0006e-02,  7.0248e-03, -4.3677e-02, -9.6506e-05,\n",
      "           1.8414e-02, -3.2113e-02],\n",
      "         [-7.1422e-03, -2.6190e-02, -3.0534e-02, -2.0052e-02,  3.8117e-02,\n",
      "           3.3784e-02, -4.5324e-02],\n",
      "         [ 3.1450e-02, -4.4626e-02,  2.7323e-02,  1.5951e-02, -9.3129e-04,\n",
      "          -4.6533e-02,  2.2157e-02],\n",
      "         [ 6.8262e-04,  8.2705e-03,  3.5895e-02,  3.9270e-02, -5.8157e-05,\n",
      "           1.3476e-02,  4.3223e-02],\n",
      "         [-2.3360e-02, -3.4753e-02,  7.4943e-03, -6.0802e-03, -4.0281e-05,\n",
      "           1.4677e-02, -2.6436e-02],\n",
      "         [ 7.1241e-03, -4.0231e-03, -3.3007e-02,  4.1441e-02, -2.5680e-02,\n",
      "           2.6031e-02, -1.1216e-02],\n",
      "         [-2.4648e-02, -1.1873e-03, -1.7188e-02, -4.2139e-02,  2.4413e-03,\n",
      "          -1.1823e-02,  3.7765e-02],\n",
      "         [-4.6987e-02, -2.5800e-02, -3.7771e-02,  1.2846e-02,  4.4424e-02,\n",
      "           3.7059e-02,  1.0636e-04],\n",
      "         [-4.4306e-02,  4.1477e-02,  1.0506e-02, -1.0774e-02, -1.8912e-02,\n",
      "          -2.9864e-02,  3.7748e-02],\n",
      "         [-3.3462e-02, -1.0752e-03, -2.1248e-02,  2.6158e-03, -3.6337e-02,\n",
      "          -2.1221e-02, -3.7501e-02],\n",
      "         [-5.6717e-03,  1.1154e-02, -2.5373e-02,  2.0057e-02, -4.2815e-02,\n",
      "          -4.3516e-02, -4.6513e-03],\n",
      "         [ 1.0921e-02,  1.7011e-02, -1.8783e-02, -4.1432e-02, -1.7281e-02,\n",
      "           7.4042e-03,  9.9790e-03],\n",
      "         [-4.1974e-02, -3.4408e-02, -3.4253e-02,  4.2404e-02, -1.2672e-02,\n",
      "          -3.2767e-02,  3.0641e-02],\n",
      "         [ 4.3440e-02,  4.1251e-02, -7.5408e-03, -3.5835e-02,  1.9321e-02,\n",
      "           2.0353e-02,  3.7002e-02],\n",
      "         [-4.6439e-02, -4.2576e-02,  1.0497e-02,  3.5553e-02, -2.4488e-02,\n",
      "           1.8422e-03, -1.5498e-02],\n",
      "         [ 2.2156e-02, -1.0245e-03, -1.4695e-02,  1.5123e-02,  1.1346e-02,\n",
      "           2.9446e-04,  6.7462e-03],\n",
      "         [ 3.2908e-02, -3.4005e-02,  3.8015e-02, -2.5511e-02,  1.7672e-02,\n",
      "          -3.8901e-02,  3.6309e-02],\n",
      "         [-2.2021e-02, -1.7554e-02,  1.8939e-02,  2.1261e-03,  2.6406e-02,\n",
      "           1.6659e-02, -2.9720e-02],\n",
      "         [-4.5975e-02,  4.4287e-03,  3.4106e-02,  3.7939e-02,  4.2325e-02,\n",
      "          -6.6598e-03,  3.3509e-02],\n",
      "         [ 5.6460e-03,  1.6055e-02,  7.2010e-04,  6.8021e-03, -4.0068e-02,\n",
      "          -7.5528e-03,  3.4612e-02],\n",
      "         [ 4.1273e-02, -3.0600e-02,  3.1504e-02, -2.7365e-02,  3.7386e-02,\n",
      "          -6.6027e-03,  1.9248e-02],\n",
      "         [ 4.2561e-02, -3.0276e-02,  1.0960e-02, -3.7027e-02,  2.0868e-02,\n",
      "           3.7902e-02,  4.5157e-02],\n",
      "         [ 1.6695e-02,  4.6287e-02,  2.8161e-02, -4.1577e-02,  1.0126e-02,\n",
      "          -2.9269e-02, -3.2536e-02],\n",
      "         [ 2.3989e-02,  2.5644e-02,  6.4153e-03, -1.3260e-02,  2.6713e-02,\n",
      "           9.4579e-03, -5.3010e-03],\n",
      "         [ 3.6882e-02,  1.4443e-02,  9.6584e-03, -4.4886e-02,  4.0631e-02,\n",
      "           1.8610e-02, -2.4941e-02]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.0.bias | Size: torch.Size([64]) | Values : tensor([-0.0266, -0.0116], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.1.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.1.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv3.0.weight | Size: torch.Size([64, 64, 7]) | Values : tensor([[[-2.5122e-02,  1.4876e-02, -2.6888e-02, -2.4805e-02,  5.0046e-04,\n",
      "          -4.7108e-02,  1.3438e-02],\n",
      "         [-1.9322e-02, -2.4755e-02,  2.8400e-02,  1.4573e-02,  3.0851e-02,\n",
      "          -1.6976e-02,  4.5364e-02],\n",
      "         [-6.3036e-03, -6.5588e-03, -2.5569e-02,  1.4734e-02, -3.8779e-03,\n",
      "          -3.5897e-02,  4.2325e-02],\n",
      "         [-1.1036e-02, -3.8836e-02,  3.1883e-03,  4.1648e-02, -3.9973e-02,\n",
      "          -2.2552e-02, -5.9067e-03],\n",
      "         [-1.9809e-02, -1.3264e-02,  1.7199e-02,  5.3646e-03,  1.6512e-02,\n",
      "           2.5136e-02, -6.9204e-03],\n",
      "         [-3.9564e-02, -6.7049e-03,  1.1545e-02,  5.8002e-03, -4.2442e-02,\n",
      "          -2.6189e-02, -2.5379e-02],\n",
      "         [ 3.4300e-02, -2.5195e-02, -6.7841e-03, -1.2949e-02, -3.5817e-02,\n",
      "           1.0551e-02, -3.8657e-02],\n",
      "         [ 9.6940e-03,  4.5579e-02, -4.0343e-02,  2.1425e-02, -1.1106e-02,\n",
      "          -2.8208e-02,  2.6318e-02],\n",
      "         [ 1.3558e-02, -1.8058e-02,  2.2181e-02,  2.1804e-02, -1.9231e-02,\n",
      "          -5.3269e-03, -1.9682e-02],\n",
      "         [ 4.1406e-02, -1.8982e-02, -3.3665e-02,  2.9757e-02, -1.2491e-02,\n",
      "          -2.6150e-02, -1.5078e-02],\n",
      "         [-1.5681e-02, -1.3777e-02, -4.6975e-02,  8.6750e-03, -2.5532e-02,\n",
      "           2.5477e-02, -1.7160e-02],\n",
      "         [-3.1585e-02,  2.9633e-02,  4.4031e-02,  1.0202e-02, -3.6361e-02,\n",
      "          -8.7692e-05, -9.5156e-04],\n",
      "         [ 3.3556e-02, -3.4794e-02, -3.8531e-02,  4.0823e-02, -9.2312e-03,\n",
      "          -5.5310e-03,  3.9499e-02],\n",
      "         [ 1.8192e-02, -1.3076e-02, -2.7962e-02, -3.9065e-02,  7.4954e-03,\n",
      "           2.1030e-02, -1.1252e-02],\n",
      "         [ 4.3964e-03,  4.3815e-02,  4.0843e-02,  1.4980e-02, -1.7307e-02,\n",
      "           4.1707e-02,  1.5929e-02],\n",
      "         [ 4.3335e-02, -2.7070e-03, -1.6730e-02,  1.5449e-02,  4.0407e-03,\n",
      "          -2.2596e-02,  1.5449e-02],\n",
      "         [ 3.2308e-02,  1.6906e-02, -4.4140e-02,  3.7675e-02, -1.4726e-02,\n",
      "           1.9151e-02,  2.8286e-02],\n",
      "         [ 1.8446e-02, -1.6045e-02,  1.5137e-02, -1.2104e-02, -2.1109e-02,\n",
      "           4.7809e-03,  3.7239e-02],\n",
      "         [ 2.3415e-02, -1.1596e-02,  4.3871e-02,  4.2188e-02,  3.1716e-02,\n",
      "           3.5897e-02,  7.1968e-03],\n",
      "         [-2.5197e-02, -2.4522e-02,  5.0951e-03,  6.8506e-03,  4.0083e-03,\n",
      "          -1.9283e-02, -3.2565e-02],\n",
      "         [ 4.7782e-03, -1.2244e-02,  3.5284e-02, -2.5708e-02,  8.5821e-03,\n",
      "          -3.3697e-02,  8.3029e-05],\n",
      "         [-3.5458e-02,  3.5597e-02, -3.9501e-02,  2.8906e-02, -2.1506e-02,\n",
      "           1.6229e-02,  2.2139e-03],\n",
      "         [ 1.3877e-02, -2.0708e-02, -1.8349e-02, -1.6581e-02, -3.4429e-02,\n",
      "          -3.5461e-02, -1.6256e-02],\n",
      "         [-1.1063e-02, -2.4361e-02,  3.8791e-02,  1.9449e-02, -2.0413e-02,\n",
      "          -3.8488e-02,  1.9692e-02],\n",
      "         [ 3.3414e-02,  2.1273e-02, -4.0825e-02, -4.2464e-02,  3.6926e-02,\n",
      "          -1.6003e-02, -2.6248e-02],\n",
      "         [-4.2687e-02, -3.0438e-03, -4.4201e-02, -7.5082e-03, -1.8712e-02,\n",
      "          -1.7068e-02,  3.6883e-02],\n",
      "         [ 3.8312e-02,  4.6303e-02,  1.3084e-02,  1.5137e-02, -2.1045e-02,\n",
      "           5.0694e-04, -4.6507e-03],\n",
      "         [ 3.1469e-02,  2.8743e-02,  3.5112e-02, -1.6378e-02, -4.3896e-03,\n",
      "          -2.3123e-02, -4.3100e-03],\n",
      "         [-2.9715e-02, -1.7641e-02,  1.2742e-02,  2.7408e-03,  1.7660e-02,\n",
      "          -6.9853e-03, -1.8844e-02],\n",
      "         [ 1.4572e-02, -1.2271e-02, -4.3006e-02, -2.2790e-02, -3.6592e-02,\n",
      "          -1.2926e-02, -4.5606e-02],\n",
      "         [-6.7659e-03, -1.0235e-02, -3.8639e-02,  2.3200e-02, -2.8401e-02,\n",
      "           1.7073e-02,  4.5158e-02],\n",
      "         [ 3.5766e-02, -4.3034e-02,  4.0852e-02,  2.2876e-02,  2.4212e-02,\n",
      "           9.4277e-03, -4.4633e-02],\n",
      "         [-1.0117e-02, -2.0392e-02,  7.1678e-03, -3.2862e-02, -2.0621e-02,\n",
      "          -3.0605e-02, -2.7233e-02],\n",
      "         [-4.3200e-02,  1.3102e-02,  3.0391e-03, -4.6392e-02, -2.0514e-02,\n",
      "          -2.7129e-02, -7.1240e-03],\n",
      "         [-3.7934e-03, -3.3929e-02, -8.8147e-03, -3.8939e-02,  1.7843e-02,\n",
      "           8.8915e-03,  2.4538e-02],\n",
      "         [-2.6044e-02,  9.3449e-03, -4.3158e-02, -1.1054e-02, -1.9052e-02,\n",
      "          -3.7619e-02, -2.5115e-02],\n",
      "         [-2.2132e-02,  1.6300e-02,  3.8698e-02, -1.8435e-02,  1.1942e-02,\n",
      "          -3.4787e-02,  1.5484e-02],\n",
      "         [ 4.8427e-03, -3.1122e-02, -9.8184e-03,  4.6657e-02, -2.6702e-02,\n",
      "          -1.0642e-02, -1.0704e-02],\n",
      "         [ 3.6071e-02, -1.6700e-02, -4.7186e-02,  1.7885e-03, -2.8237e-02,\n",
      "          -1.0297e-02,  3.6255e-02],\n",
      "         [-1.3781e-03,  1.3983e-02,  2.9059e-02,  4.2238e-02, -2.4861e-02,\n",
      "          -6.8218e-03,  2.6497e-02],\n",
      "         [ 4.3185e-02,  1.6877e-02, -2.2569e-02, -1.5065e-02, -3.0222e-02,\n",
      "           1.1200e-02, -4.3928e-02],\n",
      "         [ 2.8580e-02,  3.8529e-02,  2.6627e-02, -2.4212e-02, -3.9316e-02,\n",
      "          -3.7876e-02,  1.9527e-02],\n",
      "         [ 2.5358e-02,  8.8273e-03, -1.2874e-02, -4.4101e-02, -4.3353e-02,\n",
      "          -1.4326e-02, -2.6798e-02],\n",
      "         [ 1.2254e-02, -2.8515e-02, -4.2009e-02,  1.4207e-02,  2.4243e-02,\n",
      "           3.8927e-02,  2.2167e-02],\n",
      "         [ 2.8138e-02, -2.4762e-03, -1.5749e-02, -5.6605e-03,  3.9209e-02,\n",
      "          -1.2499e-02,  2.5084e-02],\n",
      "         [-3.2251e-02,  3.8824e-02, -2.6503e-02,  1.3676e-03, -4.4294e-02,\n",
      "           2.3968e-02,  2.2595e-02],\n",
      "         [ 1.0737e-02,  4.0573e-02, -2.7256e-02,  9.7634e-03, -3.2743e-02,\n",
      "          -1.1116e-02,  1.1926e-02],\n",
      "         [-2.2525e-02,  4.3108e-02,  3.0517e-02, -3.0462e-02, -5.5392e-03,\n",
      "          -1.4475e-02, -5.6370e-04],\n",
      "         [ 2.1525e-02, -4.3767e-02,  2.8112e-02,  1.2872e-02,  2.1310e-02,\n",
      "          -2.3878e-02, -3.0636e-02],\n",
      "         [ 1.1421e-02, -1.3529e-02, -3.4728e-02, -1.5343e-02,  2.4159e-04,\n",
      "           8.0809e-03,  4.5429e-02],\n",
      "         [-7.2621e-03, -3.8622e-02,  3.1356e-02, -4.1359e-02, -1.9198e-02,\n",
      "          -2.9032e-02,  1.3415e-02],\n",
      "         [ 3.0136e-04, -8.6754e-03,  9.6429e-03,  2.2818e-02, -1.7266e-02,\n",
      "          -9.7856e-03, -4.0162e-02],\n",
      "         [-1.3827e-02,  4.3306e-02, -2.2285e-02, -2.5203e-02, -4.1762e-02,\n",
      "           3.7557e-02, -1.2496e-03],\n",
      "         [ 1.5640e-02,  3.1426e-02,  2.1216e-02,  2.5237e-02,  4.0624e-02,\n",
      "           5.4567e-03,  2.8316e-02],\n",
      "         [-9.5423e-03,  2.8877e-02, -6.0081e-03, -1.2391e-02, -4.7931e-03,\n",
      "          -3.6238e-02,  2.2771e-03],\n",
      "         [ 1.5162e-02,  4.0059e-02, -1.1928e-03,  4.6093e-02, -2.1624e-02,\n",
      "           3.4780e-02,  2.1264e-03],\n",
      "         [-3.4428e-02, -1.5789e-02,  3.2761e-02, -6.7000e-03,  3.1009e-02,\n",
      "           3.6800e-02,  6.1924e-03],\n",
      "         [ 1.1001e-02,  1.6388e-02,  3.5216e-02,  7.6451e-03,  2.8144e-02,\n",
      "           4.5575e-02,  1.3006e-02],\n",
      "         [ 4.1851e-02,  4.2783e-02, -1.3588e-03, -2.2772e-02,  4.0794e-02,\n",
      "           1.8966e-02,  1.4220e-02],\n",
      "         [ 4.0745e-03,  1.7125e-02,  1.4973e-02, -3.5368e-02,  1.3470e-03,\n",
      "           3.4117e-02,  6.7575e-03],\n",
      "         [-5.7567e-03, -4.1652e-02, -2.9364e-02,  9.9836e-04, -3.6678e-02,\n",
      "          -2.5981e-02, -3.3696e-02],\n",
      "         [ 3.1822e-02, -7.2874e-03,  3.4925e-02,  4.2689e-02,  1.2023e-03,\n",
      "           1.2147e-02, -4.0317e-02],\n",
      "         [-3.5321e-03, -2.7352e-02,  1.7922e-02, -1.7183e-02, -4.2792e-02,\n",
      "          -2.6347e-02,  2.3394e-02],\n",
      "         [-1.3186e-02, -1.4668e-02,  4.0037e-02, -2.2562e-02,  2.2391e-02,\n",
      "          -7.2093e-03,  7.9544e-03]],\n",
      "\n",
      "        [[-2.2771e-02,  6.3731e-03,  1.3236e-02, -1.5734e-02, -3.1131e-02,\n",
      "          -4.5700e-02,  7.6894e-03],\n",
      "         [ 7.6156e-03,  3.6888e-02, -3.3310e-02, -4.4515e-02, -2.2865e-02,\n",
      "           3.4874e-02, -3.4999e-02],\n",
      "         [-4.1235e-03,  4.4291e-03,  3.0249e-02, -1.8491e-02, -1.8479e-02,\n",
      "           2.6657e-03,  2.8123e-02],\n",
      "         [ 1.2278e-02,  2.1849e-02,  4.5467e-02,  2.5697e-02, -2.6526e-02,\n",
      "          -3.4483e-02,  9.8549e-03],\n",
      "         [ 1.8744e-02, -2.8569e-02, -3.4237e-02,  1.4299e-02,  1.7899e-04,\n",
      "           3.1369e-02,  2.5791e-02],\n",
      "         [ 2.5454e-02, -4.9605e-03,  4.2292e-02, -4.5003e-02,  2.2048e-02,\n",
      "           6.1571e-03, -2.4236e-02],\n",
      "         [-4.4961e-02,  4.0624e-02, -4.4201e-02,  2.1409e-02, -3.6179e-02,\n",
      "          -2.4441e-02,  2.3480e-02],\n",
      "         [-1.4466e-02,  5.6640e-03,  1.5813e-02,  1.8064e-02,  1.9780e-02,\n",
      "          -1.6853e-02,  3.8331e-02],\n",
      "         [-2.6111e-02, -1.4264e-02, -3.7857e-02,  1.9117e-02,  2.6246e-02,\n",
      "           8.8943e-03, -2.0197e-02],\n",
      "         [ 9.0199e-03,  3.1006e-02,  9.3407e-03,  5.8736e-03, -2.7297e-02,\n",
      "          -3.2117e-02, -9.4697e-03],\n",
      "         [ 5.3100e-03,  2.5409e-02,  8.7968e-03,  2.0924e-02, -1.8274e-02,\n",
      "          -1.0289e-02,  4.0408e-02],\n",
      "         [ 2.7965e-02,  1.6151e-02,  4.4546e-02, -2.9356e-02, -1.3057e-02,\n",
      "           2.2750e-03, -2.4538e-02],\n",
      "         [-7.5267e-03, -2.9858e-02,  2.8031e-02,  4.5305e-03, -7.0225e-03,\n",
      "           1.4250e-02,  1.3534e-02],\n",
      "         [-2.9560e-02, -3.4428e-02, -3.5072e-02,  2.2534e-02,  4.7739e-04,\n",
      "          -2.9373e-02, -1.4478e-02],\n",
      "         [-4.3548e-02, -2.4933e-02,  2.7520e-02,  1.5767e-02,  8.9093e-03,\n",
      "          -1.7879e-02,  4.3878e-02],\n",
      "         [ 4.5169e-02,  2.0428e-02,  3.4470e-03, -3.4246e-02,  2.7750e-02,\n",
      "           2.6975e-02, -8.7280e-03],\n",
      "         [-1.9108e-02,  2.8753e-02, -1.9925e-02,  3.7726e-02,  3.4062e-02,\n",
      "           2.8327e-02, -4.6844e-03],\n",
      "         [-2.3588e-03,  1.9510e-02, -4.1423e-03, -2.8625e-02,  2.1260e-02,\n",
      "          -1.3876e-02,  8.7366e-03],\n",
      "         [-1.1087e-02,  9.3714e-03, -6.7071e-03,  4.2636e-02, -3.3349e-02,\n",
      "          -6.5416e-03,  2.9746e-02],\n",
      "         [-6.9223e-03,  1.0166e-02,  1.5957e-02,  1.3893e-02, -3.8796e-02,\n",
      "           2.7469e-02, -3.6032e-02],\n",
      "         [ 2.4573e-02,  8.2818e-04, -4.0904e-04, -1.8246e-02,  3.8231e-02,\n",
      "          -3.4114e-02, -8.2840e-03],\n",
      "         [-3.1555e-02,  3.5521e-02, -2.6657e-02,  3.7454e-02, -2.9782e-02,\n",
      "           4.6203e-02, -2.2264e-02],\n",
      "         [ 3.2440e-02,  1.1505e-02,  2.7640e-02, -3.7521e-04, -2.3745e-02,\n",
      "           4.5662e-02, -3.6028e-02],\n",
      "         [ 1.2336e-02, -1.6698e-02,  3.9090e-02,  4.5671e-02, -4.2434e-02,\n",
      "          -1.2646e-02, -1.1130e-02],\n",
      "         [-1.0607e-02,  2.8829e-02, -3.2433e-02, -1.6978e-02, -1.7570e-02,\n",
      "           3.6621e-02, -4.3630e-02],\n",
      "         [ 3.4858e-02,  1.1825e-02,  3.4957e-02,  4.2928e-02, -2.6229e-02,\n",
      "           2.3911e-03,  7.0084e-03],\n",
      "         [-1.3547e-02, -3.0769e-02,  3.0261e-02,  1.7809e-02,  7.9007e-04,\n",
      "           5.3074e-04, -4.6314e-02],\n",
      "         [-2.1080e-02, -3.5587e-02,  4.1436e-02, -1.3141e-02,  1.6668e-02,\n",
      "          -2.9989e-02,  2.3383e-02],\n",
      "         [ 5.3617e-03, -1.5836e-02, -4.1711e-02,  2.9372e-02,  3.5190e-02,\n",
      "           2.7775e-02,  6.0411e-03],\n",
      "         [-1.4974e-02,  3.0740e-02,  2.9676e-02,  1.9028e-02,  2.3759e-02,\n",
      "          -2.1429e-02, -4.3919e-02],\n",
      "         [-2.5112e-02,  5.3234e-04, -4.3786e-02, -2.6229e-02,  1.5829e-02,\n",
      "          -1.2056e-02,  2.1657e-02],\n",
      "         [-2.5573e-02,  4.3723e-02, -1.2960e-02,  2.4086e-02, -4.2230e-02,\n",
      "           1.9739e-02,  1.9291e-02],\n",
      "         [ 4.0211e-02,  3.4208e-02, -4.1148e-02, -1.8285e-03, -4.3311e-03,\n",
      "           3.2772e-02, -3.1231e-02],\n",
      "         [-4.5669e-02, -7.6504e-03, -4.5387e-02, -2.7441e-03, -4.4527e-02,\n",
      "          -3.4482e-02,  2.5588e-02],\n",
      "         [ 1.5879e-02, -1.5465e-02, -2.3295e-02,  1.7096e-02,  3.3235e-02,\n",
      "          -2.7346e-02,  1.4692e-02],\n",
      "         [-3.2352e-02,  5.4235e-03,  1.8921e-02, -3.2434e-02, -1.0864e-02,\n",
      "           2.5809e-02,  4.0515e-02],\n",
      "         [-4.4574e-02, -2.2140e-02,  1.7185e-02,  3.9386e-02, -2.6943e-02,\n",
      "           1.0914e-03,  2.2569e-03],\n",
      "         [ 2.1800e-02, -1.7804e-02,  3.6929e-03, -3.2936e-02, -4.5466e-02,\n",
      "           2.8566e-02, -1.2635e-02],\n",
      "         [ 1.7324e-02, -1.2347e-03, -4.2395e-02,  2.8382e-03, -3.0665e-02,\n",
      "          -8.3010e-04,  3.6063e-02],\n",
      "         [-5.6783e-03,  4.2713e-02, -8.3291e-03, -2.9091e-02,  2.5799e-02,\n",
      "           4.6778e-02, -1.4488e-02],\n",
      "         [ 3.4075e-02, -2.9660e-02, -3.4635e-02, -9.9635e-03,  3.0711e-02,\n",
      "           1.0436e-02,  3.3095e-02],\n",
      "         [ 2.9410e-02, -3.1783e-02, -2.1482e-02,  3.1807e-02,  2.8583e-02,\n",
      "           3.8361e-02,  3.4311e-03],\n",
      "         [-1.8545e-02, -3.3067e-02, -2.2847e-02, -2.1101e-02, -1.5378e-02,\n",
      "           4.0209e-02, -4.3234e-02],\n",
      "         [ 1.8671e-02, -3.5334e-02,  2.2948e-02,  2.0220e-02, -1.7671e-03,\n",
      "          -5.0394e-03,  1.1397e-03],\n",
      "         [ 7.5771e-03,  2.1353e-02,  3.8021e-03,  3.7878e-02, -4.7199e-02,\n",
      "           4.3869e-02, -2.1204e-02],\n",
      "         [ 1.5556e-02, -7.9821e-03,  3.3686e-03,  3.1662e-02, -9.6482e-03,\n",
      "           3.5385e-02, -4.6346e-02],\n",
      "         [-3.8446e-02,  2.0041e-02,  2.3413e-02, -2.8921e-02,  1.7546e-02,\n",
      "          -1.9497e-02, -3.9425e-02],\n",
      "         [-2.0836e-02,  3.7419e-02,  4.4099e-02, -1.1714e-02, -1.4937e-02,\n",
      "          -4.1219e-02, -3.8171e-02],\n",
      "         [ 2.0789e-02,  2.8060e-03,  2.3110e-02, -2.1732e-02, -3.5385e-02,\n",
      "           1.7464e-02, -1.4761e-02],\n",
      "         [ 1.8357e-02, -1.1960e-02, -1.0850e-02, -1.0330e-02,  2.0597e-02,\n",
      "           3.3047e-02,  2.8508e-02],\n",
      "         [-4.2342e-02,  2.4888e-02,  3.8945e-02, -1.1311e-02,  4.6793e-02,\n",
      "          -8.4528e-03, -1.3792e-03],\n",
      "         [-2.0608e-02, -3.7590e-02, -4.9436e-03, -1.9226e-02, -9.9423e-03,\n",
      "          -1.4852e-02,  3.3462e-02],\n",
      "         [-3.1267e-02, -1.6066e-02,  1.3543e-02, -3.3148e-03,  2.8558e-02,\n",
      "           3.8503e-02, -3.6001e-03],\n",
      "         [ 4.6908e-02, -3.5971e-02,  2.3787e-02, -1.5765e-02,  3.2148e-02,\n",
      "          -1.2351e-02,  1.5477e-02],\n",
      "         [ 2.4336e-02, -2.1184e-02,  2.9372e-02, -4.3082e-02,  1.8616e-03,\n",
      "           2.3867e-02,  4.5590e-02],\n",
      "         [-4.4498e-02, -4.0400e-02,  1.8733e-02, -1.4685e-02,  1.6892e-02,\n",
      "          -3.1160e-02,  4.3117e-02],\n",
      "         [ 3.9090e-02, -3.6997e-03,  1.7981e-02, -1.1187e-02,  1.9180e-04,\n",
      "           3.1983e-02, -2.2306e-02],\n",
      "         [ 2.9894e-02,  4.2283e-02,  2.5357e-02, -1.3653e-03, -1.6580e-03,\n",
      "           1.7710e-02,  1.5326e-02],\n",
      "         [-1.2859e-02, -2.3943e-02, -4.4054e-02,  3.3488e-02, -2.0028e-02,\n",
      "           1.8925e-02, -3.7183e-02],\n",
      "         [-2.9008e-02,  4.5063e-04, -4.5942e-02,  1.5667e-02,  4.0574e-02,\n",
      "           3.1966e-02, -2.0418e-02],\n",
      "         [ 3.4067e-02,  3.5925e-02, -2.0052e-02, -4.1859e-02, -1.6425e-02,\n",
      "          -2.3886e-02,  7.7802e-03],\n",
      "         [ 1.1875e-02,  3.1514e-02, -3.5332e-02, -1.3526e-02,  6.2712e-03,\n",
      "          -2.2274e-02,  3.5564e-02],\n",
      "         [ 3.5591e-02, -1.2318e-02, -1.0525e-02,  1.2667e-02, -3.0121e-02,\n",
      "          -1.9822e-02, -3.6389e-02],\n",
      "         [ 8.3966e-03,  4.5155e-02,  1.0841e-02, -2.5529e-03, -1.2210e-02,\n",
      "           4.2812e-02, -8.3619e-03]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv3.0.bias | Size: torch.Size([64]) | Values : tensor([0.0017, 0.0199], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv3.1.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv3.1.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm.0.weight_ih_l0 | Size: torch.Size([256, 64]) | Values : tensor([[ 0.0944, -0.0897, -0.0322, -0.1093, -0.0564,  0.0360, -0.0821, -0.0127,\n",
      "          0.0686,  0.0461,  0.0024, -0.0895, -0.0790,  0.0811,  0.0114,  0.0168,\n",
      "          0.0292, -0.0755, -0.0193,  0.0495,  0.1201, -0.1021, -0.1152, -0.0746,\n",
      "         -0.0697,  0.1109,  0.1232, -0.1110, -0.0852,  0.1168,  0.1050, -0.0957,\n",
      "          0.1196,  0.1008, -0.0284, -0.0208,  0.0911,  0.0673,  0.0501,  0.0755,\n",
      "          0.0750,  0.1243,  0.0610,  0.0962, -0.1112,  0.0715,  0.0414,  0.1057,\n",
      "         -0.1020,  0.0381, -0.0234,  0.0905, -0.1138,  0.1094, -0.0916,  0.0577,\n",
      "          0.0681, -0.0446, -0.1165, -0.0543,  0.0712, -0.1158, -0.1060,  0.0320],\n",
      "        [-0.0212,  0.0850,  0.1190, -0.1061,  0.1043,  0.0847,  0.0412,  0.0718,\n",
      "         -0.0384,  0.1099, -0.0854, -0.0015, -0.1142, -0.0188, -0.1166,  0.0414,\n",
      "          0.0579,  0.0218,  0.1091,  0.0384,  0.1133,  0.0033, -0.0557,  0.0226,\n",
      "          0.0749, -0.0748, -0.1147,  0.1044,  0.0765, -0.0665, -0.0256,  0.0504,\n",
      "         -0.0287,  0.1062,  0.0902,  0.0417,  0.0157,  0.1046, -0.0352, -0.0287,\n",
      "         -0.1143, -0.1100, -0.0714,  0.0564,  0.0208,  0.0270,  0.0272, -0.0639,\n",
      "         -0.0787, -0.0013, -0.0293, -0.1193,  0.1241, -0.0369, -0.1166, -0.0100,\n",
      "          0.0376,  0.0219,  0.0208, -0.0226,  0.0428, -0.0832,  0.1099,  0.0778]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm.0.weight_hh_l0 | Size: torch.Size([256, 64]) | Values : tensor([[-0.0407,  0.0894, -0.0085, -0.0797,  0.0980,  0.1193, -0.0644, -0.0176,\n",
      "          0.1134, -0.0074, -0.0595, -0.0199, -0.0639,  0.0774, -0.0030,  0.0568,\n",
      "          0.0105,  0.0885,  0.0359,  0.1041, -0.1246,  0.0159, -0.0624,  0.1127,\n",
      "         -0.0089, -0.0567, -0.0772, -0.1193,  0.0374, -0.0646, -0.0378,  0.0079,\n",
      "          0.0639, -0.0545,  0.0552,  0.0607, -0.0943, -0.1000, -0.0125, -0.0061,\n",
      "         -0.0155, -0.0384, -0.0611, -0.0186, -0.0446, -0.1201, -0.0923, -0.0327,\n",
      "          0.0137, -0.0741,  0.0366,  0.0327, -0.0507,  0.0527, -0.1077, -0.0681,\n",
      "          0.0344,  0.0060,  0.0853, -0.0635,  0.0201,  0.1085, -0.1177,  0.0601],\n",
      "        [-0.0093, -0.0802, -0.0357,  0.1214, -0.0611, -0.0689,  0.0679, -0.1008,\n",
      "         -0.0840,  0.1222,  0.0320, -0.1163,  0.1098,  0.0039, -0.1065,  0.0397,\n",
      "          0.1094, -0.0435,  0.0896,  0.0014, -0.1173, -0.0248, -0.0117,  0.0751,\n",
      "          0.0093, -0.0531, -0.0376, -0.0252,  0.0500, -0.0852,  0.0900,  0.1159,\n",
      "          0.0284,  0.0213,  0.0301, -0.0308,  0.0864, -0.0349,  0.0922,  0.0977,\n",
      "          0.0941,  0.0198, -0.1116,  0.0734,  0.0204, -0.1195, -0.0492, -0.1059,\n",
      "          0.0782,  0.0904, -0.1123, -0.0178, -0.0533,  0.0290, -0.0460,  0.0412,\n",
      "         -0.1166, -0.0060, -0.0316, -0.0057,  0.0303, -0.1081, -0.0727,  0.0715]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm.0.bias_ih_l0 | Size: torch.Size([256]) | Values : tensor([-0.0266,  0.0990], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm.0.bias_hh_l0 | Size: torch.Size([256]) | Values : tensor([ 0.0807, -0.1122], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm.2.weight_ih_l0 | Size: torch.Size([256, 64]) | Values : tensor([[ 3.6560e-02, -1.1187e-01, -9.3038e-02, -2.0862e-02,  1.2489e-01,\n",
      "         -1.9730e-02,  4.5167e-02, -9.2846e-02, -2.5380e-02, -5.0488e-02,\n",
      "         -9.5021e-02, -9.2113e-02, -2.8338e-02, -3.4195e-02,  1.1770e-01,\n",
      "         -1.0244e-01, -1.1949e-01,  9.9262e-02,  9.9673e-02,  7.8428e-02,\n",
      "          7.2184e-02, -1.5318e-02,  1.8897e-02, -4.2392e-02, -1.1627e-01,\n",
      "          1.0558e-01, -5.9533e-02,  4.6601e-02,  1.4356e-02,  8.4283e-02,\n",
      "          1.2789e-02, -8.4748e-02, -8.8581e-02, -6.4647e-02, -5.8180e-03,\n",
      "         -9.3691e-03, -2.1804e-02, -4.2538e-02,  8.4071e-02, -8.0946e-02,\n",
      "         -1.0571e-01,  1.1531e-01, -8.2286e-02,  3.2841e-02, -1.7946e-02,\n",
      "          1.0732e-01, -7.0307e-02, -2.9165e-02, -1.0570e-01,  9.7989e-02,\n",
      "         -3.1807e-02, -7.5020e-02, -5.8603e-03, -9.5414e-02,  9.1002e-02,\n",
      "         -1.1558e-01,  4.8574e-02, -8.8036e-02,  1.2074e-01, -1.2154e-01,\n",
      "          1.2124e-01, -8.2742e-02, -1.1959e-01,  3.2302e-02],\n",
      "        [ 4.3617e-02, -1.4001e-02,  1.1412e-02, -9.7357e-02, -7.5740e-02,\n",
      "         -6.8657e-02,  4.0280e-02,  1.0623e-01,  5.6407e-02,  9.2317e-02,\n",
      "          7.9956e-02,  6.2346e-02,  7.7897e-03, -8.3429e-02,  1.1661e-01,\n",
      "          1.5306e-02, -8.0258e-02, -4.1442e-02, -9.6729e-02,  4.3145e-02,\n",
      "          1.6834e-02,  5.5705e-02,  9.5848e-02, -1.1372e-02, -9.6692e-03,\n",
      "         -9.0256e-03, -9.1666e-02, -9.9573e-02,  1.0390e-01, -2.7015e-02,\n",
      "          1.0546e-01,  5.1581e-02,  1.0227e-01, -1.1709e-02, -2.7893e-02,\n",
      "          4.9884e-02, -6.0015e-02, -6.1064e-02, -1.0695e-04,  2.7318e-02,\n",
      "         -8.5164e-02,  1.3394e-02, -4.8839e-02, -8.0900e-02, -3.1618e-02,\n",
      "          3.2072e-02,  1.7586e-02, -6.8661e-02, -2.8561e-02,  5.4488e-02,\n",
      "         -5.4146e-02,  8.2640e-02, -1.0711e-01, -8.6420e-02,  1.4322e-02,\n",
      "          4.8397e-02, -9.4703e-04,  8.2951e-03,  8.2024e-02,  5.2204e-02,\n",
      "         -1.3336e-02,  3.3224e-02,  5.5884e-02,  5.3725e-02]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm.2.weight_hh_l0 | Size: torch.Size([256, 64]) | Values : tensor([[ 0.0959,  0.0428,  0.0052, -0.0753, -0.0293,  0.0917,  0.0071, -0.0952,\n",
      "         -0.0300, -0.0244,  0.1102,  0.0597, -0.0521, -0.0073,  0.0982,  0.0188,\n",
      "         -0.0019,  0.0510,  0.0593,  0.1134, -0.0692, -0.1068,  0.0098,  0.0301,\n",
      "          0.1112, -0.0917, -0.1155, -0.0411,  0.0378, -0.0258, -0.0251, -0.0838,\n",
      "          0.0784,  0.0243, -0.0384, -0.0655, -0.0017, -0.0177,  0.0940,  0.0473,\n",
      "          0.0012, -0.0955, -0.0709, -0.0670, -0.0271,  0.0114, -0.0918, -0.0424,\n",
      "          0.0276, -0.0708, -0.0794, -0.1131, -0.0523, -0.0558,  0.0292, -0.0254,\n",
      "          0.0163, -0.0633,  0.0913,  0.0708, -0.1045, -0.0610,  0.1167, -0.1062],\n",
      "        [-0.0357,  0.0938,  0.0503,  0.0034,  0.0926,  0.0676, -0.0872,  0.0181,\n",
      "         -0.0992, -0.0297,  0.0639, -0.0151, -0.0119,  0.1117,  0.0483, -0.0695,\n",
      "         -0.0232,  0.0046,  0.1101, -0.0308,  0.0856,  0.0501, -0.1160,  0.0654,\n",
      "         -0.0956,  0.0842,  0.0881, -0.0038,  0.0214,  0.0720, -0.1148, -0.0990,\n",
      "          0.0233, -0.0443, -0.1058,  0.0021, -0.0990, -0.1022, -0.0118,  0.0500,\n",
      "          0.0806,  0.0345,  0.0778, -0.0844,  0.0342, -0.0376,  0.0095,  0.0903,\n",
      "         -0.0773,  0.0658, -0.1229, -0.1168,  0.0373,  0.0848, -0.0076, -0.0938,\n",
      "          0.0423, -0.1122, -0.0362,  0.0145,  0.0144, -0.0460, -0.0557,  0.1049]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm.2.bias_ih_l0 | Size: torch.Size([256]) | Values : tensor([ 0.1068, -0.0744], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm.2.bias_hh_l0 | Size: torch.Size([256]) | Values : tensor([0.0789, 0.0515], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc.0.weight | Size: torch.Size([2, 64]) | Values : tensor([[ 0.1087, -0.0790,  0.0105, -0.1228, -0.0268, -0.0373, -0.1094, -0.0433,\n",
      "          0.0118,  0.0147,  0.0884, -0.1009, -0.0315,  0.0252,  0.0255,  0.0896,\n",
      "         -0.0593, -0.0891, -0.0138,  0.0651, -0.0114, -0.1085, -0.0471,  0.0606,\n",
      "         -0.0373, -0.0314, -0.1042,  0.0148, -0.0225,  0.0271, -0.1091, -0.0153,\n",
      "          0.0101,  0.1214, -0.1019,  0.0784, -0.0641, -0.0287,  0.0781, -0.0216,\n",
      "          0.0521,  0.0463, -0.0434,  0.0169,  0.0989,  0.0071,  0.0459, -0.0107,\n",
      "          0.0398,  0.0990, -0.1057,  0.0570,  0.0727,  0.0736, -0.0715, -0.0023,\n",
      "          0.1120,  0.1249, -0.0345,  0.0923, -0.0267, -0.0483, -0.0210,  0.1157],\n",
      "        [ 0.0229,  0.0799, -0.0340, -0.0551,  0.0917, -0.1128, -0.0447,  0.1125,\n",
      "         -0.0242,  0.0608,  0.0419,  0.0473, -0.0383, -0.1035, -0.0969,  0.0528,\n",
      "         -0.0448,  0.0433, -0.0408, -0.0167, -0.0210, -0.0359,  0.0620,  0.1059,\n",
      "          0.0614,  0.0738, -0.0417, -0.0312,  0.1111, -0.0002,  0.1009, -0.1058,\n",
      "          0.0827, -0.0285,  0.0196,  0.0115, -0.0974, -0.0870, -0.0563,  0.0780,\n",
      "          0.1188,  0.0935,  0.1216,  0.0756, -0.0530,  0.1178, -0.0784, -0.1122,\n",
      "          0.0541,  0.0719, -0.0482,  0.0194,  0.0518,  0.0244, -0.0491, -0.0866,\n",
      "         -0.0396,  0.0882,  0.0259,  0.0144, -0.0954, -0.0770,  0.0034,  0.0104]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc.0.bias | Size: torch.Size([2]) | Values : tensor([ 0.0597, -0.0810], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the model\n",
    "model = ConvLSTM().to(device)\n",
    "\n",
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 5e-4\n",
    "batch_size = 64\n",
    "epochs = 200\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluate the model with torch.no_grad()\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlonmcu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
