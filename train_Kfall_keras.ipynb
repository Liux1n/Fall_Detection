{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import plot_confusion_matrix, plot_confusion_matrix, get_gzipped_model_size\n",
    "from data_organizer_Kfall import DataOrganizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import models, optimizers, callbacks\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\n",
    "from models.ConvLSTM import ConvLSTM\n",
    "from models.ConvLSTM_VGG import ConvLSTM_VGG\n",
    "from models.TinyFallNet import TinyFallNet\n",
    "from models.ResNet24 import ResNet24\n",
    "from models.TinyFallNet_6axis import TinyFallNet_6axis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"TinyFallNet_6axis\" # \"ConvLSTM\" or \"ConvLSTM_VGG\" or \"TinyFallNet\" or \"ResNet24\" or \"TinyFallNet_6axis\"\n",
    "load_from_checkpoint = False\n",
    "\n",
    "if not os.path.exists(\"saved_models\"):\n",
    "    os.makedirs(\"saved_models\")\n",
    "\n",
    "if load_from_checkpoint:\n",
    "    model = models.load_model('./saved_models/'+model_name+'.keras')\n",
    "else:\n",
    "    if model_name == \"ConvLSTM\":\n",
    "        model = ConvLSTM()\n",
    "    elif model_name == \"ConvLSTM_VGG\":\n",
    "        model = ConvLSTM_VGG()\n",
    "    elif model_name == \"TinyFallNet\":\n",
    "        model = TinyFallNet()\n",
    "    elif model_name == \"ResNet24\":\n",
    "        model = ResNet24()\n",
    "    elif model_name == \"TinyFallNet_6axis\":\n",
    "        model = TinyFallNet_6axis()\n",
    "    else:\n",
    "        print(\"Please select a valid model name\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/32 folder...\n",
      "Processing 2/32 folder...\n",
      "Processing 3/32 folder...\n",
      "Processing 4/32 folder...\n",
      "Processing 5/32 folder...\n",
      "Processing 6/32 folder...\n",
      "Processing 7/32 folder...\n",
      "Processing 8/32 folder...\n",
      "Processing 9/32 folder...\n",
      "Processing 10/32 folder...\n",
      "Processing 11/32 folder...\n",
      "Processing 12/32 folder...\n",
      "Processing 13/32 folder...\n",
      "Processing 14/32 folder...\n",
      "Processing 15/32 folder...\n",
      "Processing 16/32 folder...\n",
      "Processing 17/32 folder...\n",
      "Processing 18/32 folder...\n",
      "Processing 19/32 folder...\n",
      "Processing 20/32 folder...\n",
      "Processing 21/32 folder...\n",
      "Processing 22/32 folder...\n",
      "Processing 23/32 folder...\n",
      "Processing 24/32 folder...\n",
      "Processing 25/32 folder...\n",
      "Processing 26/32 folder...\n",
      "Processing 27/32 folder...\n",
      "Processing 28/32 folder...\n",
      "Processing 29/32 folder...\n",
      "Processing 30/32 folder...\n",
      "Processing 31/32 folder...\n",
      "Processing 32/32 folder...\n",
      "in_channels:  6\n",
      "data.shape:  (25576, 50, 6)\n",
      "B_size:  25020\n",
      "A_size:  556\n",
      "data:  [ 0.02      -0.996      0.16      -1.9480572 -1.2032118  0.5156622]\n",
      "(250, 50, 6)\n"
     ]
    }
   ],
   "source": [
    "# mac\n",
    "sensor_data_folder = '/Users/liuxinqing/Documents/Kfall/sensor_data'  # Update with the path to sensor data\n",
    "label_data_folder = '/Users/liuxinqing/Documents/Kfall/label_data'  \n",
    "# windows \n",
    "#sensor_data_folder = 'G:\\MLonMCU\\Kfall_dataset\\sensor_data'  # Update with the path to sensor data\n",
    "#label_data_folder = 'G:\\MLonMCU\\Kfall_dataset\\label_data' \n",
    "# linux\n",
    "# sensor_data_folder = '/home/liyinrong/Projects/MLonMCU/Final/Fall_Detection/datasets/KFall/sensor_data'  # Update with the path to sensor data\n",
    "# label_data_folder = '/home/liyinrong/Projects/MLonMCU/Final/Fall_Detection/datasets/KFall/label_data'  \n",
    "\n",
    "#window_size = 256\n",
    "# Kfall: window_size = 50\n",
    "window_size = 50\n",
    "threshold = 0.4\n",
    "num_window_fall_data = 50\n",
    "num_window_not_fall_data = 5\n",
    "mode = 'ACC+GYRO' # 'ACC' or 'ACC+GYRO' or 'ACC+GYRO+MAG'\n",
    "\n",
    "data, label = DataOrganizer(sensor_data_folder, \n",
    "                            label_data_folder, \n",
    "                            window_size, \n",
    "                            threshold, \n",
    "                            num_window_fall_data, \n",
    "                            num_window_not_fall_data,\n",
    "                            mode)\n",
    "\n",
    "in_channels = data.shape[2]\n",
    "\n",
    "print('in_channels: ', in_channels)\n",
    "# the input data should have the shape (batch_size, in_channels, sequence_length)\n",
    "#data = data.reshape(data.shape[0], in_channels, -1)\n",
    "print('data.shape: ', data.shape)\n",
    "\n",
    "label = label.astype(np.int64)\n",
    "# one-hot encoding\n",
    "#label = to_categorical(label, num_classes=2)\n",
    "# transpose the data to (batch_size, sequence_length, in_channels)\n",
    "#data = np.transpose(data, (0, 2, 1))\n",
    "data = data.reshape(data.shape[0], 50, in_channels)\n",
    "# normalize the data\n",
    "# Initialize a new scaling object for normalizing input data\n",
    "# Z-score normalization\n",
    "\n",
    "# (y == 0).sum()\n",
    "B_size = (label == 0).sum()\n",
    "A_size = (label == 1).sum()\n",
    "print('B_size: ', B_size)\t\n",
    "print('A_size: ', A_size)\n",
    "# transpose the data to (batch_size, in_channels, sequence_length)\n",
    "#data = np.transpose(data, (0, 2, 1))\n",
    "print('data: ', data[0][0])\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "#print(np.unique(y_train)) # [0 1]\n",
    "y_train = y_train.astype(np.int64)\n",
    "y_test = y_test.astype(np.int64)\n",
    "\n",
    "# select the test data that is not zero\n",
    "X_test_true = X_test[y_test != 0]\n",
    "y_test_true = y_test[y_test != 0]\n",
    "# length of the test data\n",
    "test_len = X_test_true.shape[0]\n",
    "X_test_false = X_test[y_test == 0]\n",
    "y_test_false = y_test[y_test == 0]\n",
    "# X_test.shape:  (17, 50, 9)\n",
    "# randomly len number of test data that is zero\n",
    "index = np.random.choice(X_test_false.shape[0], test_len, replace=False)\n",
    "# X_test.shape:  (17, 50, 9)\n",
    "# randomly len number of test data that is zero\n",
    "#index = np.random.choice(X_test_false.shape[0], len, replace=False)\n",
    "\n",
    "X_test_false = X_test[index]\n",
    "y_test_false = y_test[index]\n",
    "\n",
    "# concatenate the true and false test data\n",
    "X_test = np.concatenate((X_test_true, X_test_false), axis=0)\n",
    "y_test = np.concatenate((y_test_true, y_test_false), axis=0)\n",
    "#X_test = X_test[y_test != 0]\n",
    "#y_test = y_test[y_test != 0]\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 5e-4\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "factor = 0.5\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"TinyFallNet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 50, 6)]              0         []                            \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 1, 50, 6)             0         ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 1, 48, 64)            1216      ['reshape[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 1, 24, 64)            0         ['conv2d[0][0]']              \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 1, 24, 16)            1040      ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 1, 24, 16)            64        ['conv2d_2[0][0]']            \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                (None, 1, 24, 16)            0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 1, 24, 16)            784       ['re_lu[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 1, 24, 16)            64        ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)              (None, 1, 24, 16)            0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 1, 24, 64)            1088      ['re_lu_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 1, 24, 64)            256       ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 1, 24, 64)            4160      ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 1, 24, 64)            0         ['batch_normalization_2[0][0]'\n",
      "                                                                    , 'conv2d_1[0][0]']           \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)              (None, 1, 24, 64)            0         ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 1, 24, 16)            1040      ['re_lu_2[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 1, 24, 16)            64        ['conv2d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)              (None, 1, 24, 16)            0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 1, 24, 16)            784       ['re_lu_3[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 1, 24, 16)            64        ['conv2d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)              (None, 1, 24, 16)            0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 1, 24, 64)            1088      ['re_lu_4[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 1, 24, 64)            256       ['conv2d_8[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 1, 24, 64)            4160      ['re_lu_2[0][0]']             \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 1, 24, 64)            0         ['batch_normalization_5[0][0]'\n",
      "                                                                    , 'conv2d_5[0][0]']           \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)              (None, 1, 24, 64)            0         ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 1, 24, 16)            1040      ['re_lu_5[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 1, 24, 16)            64        ['conv2d_10[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)              (None, 1, 24, 16)            0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 1, 24, 16)            784       ['re_lu_6[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 1, 24, 16)            64        ['conv2d_11[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)              (None, 1, 24, 16)            0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 1, 24, 64)            1088      ['re_lu_7[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 1, 24, 64)            256       ['conv2d_12[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 1, 24, 64)            4160      ['re_lu_5[0][0]']             \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, 1, 24, 64)            0         ['batch_normalization_8[0][0]'\n",
      "                                                                    , 'conv2d_9[0][0]']           \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)              (None, 1, 24, 64)            0         ['add_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 1, 24, 16)            1040      ['re_lu_8[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 1, 24, 16)            64        ['conv2d_14[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)              (None, 1, 24, 16)            0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 1, 24, 16)            784       ['re_lu_9[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 1, 24, 16)            64        ['conv2d_15[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)             (None, 1, 24, 16)            0         ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 1, 24, 64)            1088      ['re_lu_10[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 1, 24, 64)            256       ['conv2d_16[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 1, 24, 64)            4160      ['re_lu_8[0][0]']             \n",
      "                                                                                                  \n",
      " add_3 (Add)                 (None, 1, 24, 64)            0         ['batch_normalization_11[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'conv2d_13[0][0]']           \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)             (None, 1, 24, 64)            0         ['add_3[0][0]']               \n",
      "                                                                                                  \n",
      " average_pooling2d (Average  (None, 1, 12, 64)            0         ['re_lu_11[0][0]']            \n",
      " Pooling2D)                                                                                       \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 768)                  0         ['average_pooling2d[0][0]']   \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 2)                    1538      ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 32578 (127.26 KB)\n",
      "Trainable params: 31810 (124.26 KB)\n",
      "Non-trainable params: 768 (3.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizers.Adam(learning_rate=learning_rate), \n",
    "            loss='categorical_crossentropy',\n",
    "            #loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy'])\n",
    "model.build(input_shape=(None, 50, 9))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train.shape:  (16368, 2)\n",
      "y_val.shape:  (4092, 2)\n",
      "X_train.shape:  (16368, 50, 6)\n",
      "y_train.shape:  (16368, 2)\n",
      "Epoch 1/50\n",
      "256/256 [==============================] - 5s 14ms/step - loss: 1.6908 - accuracy: 0.7769 - val_loss: 0.6435 - val_accuracy: 0.8174 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "256/256 [==============================] - 4s 14ms/step - loss: 0.7314 - accuracy: 0.8744 - val_loss: 0.3822 - val_accuracy: 0.8942 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "256/256 [==============================] - 4s 14ms/step - loss: 0.6046 - accuracy: 0.8906 - val_loss: 0.2549 - val_accuracy: 0.9338 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "256/256 [==============================] - 4s 14ms/step - loss: 0.6364 - accuracy: 0.8860 - val_loss: 0.3913 - val_accuracy: 0.8675 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "256/256 [==============================] - 4s 14ms/step - loss: 0.5619 - accuracy: 0.8924 - val_loss: 0.3148 - val_accuracy: 0.9052 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "256/256 [==============================] - 4s 14ms/step - loss: 0.4604 - accuracy: 0.9066 - val_loss: 0.2423 - val_accuracy: 0.9260 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "256/256 [==============================] - 4s 14ms/step - loss: 0.3960 - accuracy: 0.9217 - val_loss: 0.1627 - val_accuracy: 0.9519 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "256/256 [==============================] - 4s 14ms/step - loss: 0.4016 - accuracy: 0.9195 - val_loss: 0.1813 - val_accuracy: 0.9477 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "256/256 [==============================] - 4s 14ms/step - loss: 0.4425 - accuracy: 0.9136 - val_loss: 0.2214 - val_accuracy: 0.9289 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "256/256 [==============================] - 4s 14ms/step - loss: 0.4329 - accuracy: 0.9095 - val_loss: 0.1900 - val_accuracy: 0.9428 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "256/256 [==============================] - 4s 14ms/step - loss: 0.3908 - accuracy: 0.9202 - val_loss: 0.2554 - val_accuracy: 0.9218 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "256/256 [==============================] - ETA: 0s - loss: 0.3257 - accuracy: 0.9286\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "256/256 [==============================] - 4s 14ms/step - loss: 0.3257 - accuracy: 0.9286 - val_loss: 0.1782 - val_accuracy: 0.9504 - lr: 5.0000e-04\n",
      "Epoch 12: early stopping\n"
     ]
    }
   ],
   "source": [
    "\"\"\" train(train_dataloader, model_ConvLSTM, loss_fn, optimizer,val_dataloader, \n",
    "           patience=patience, scheduler=scheduler, epochs=epochs, device=device, B_size=B_size, A_size=A_size) \"\"\"\n",
    "# Train the model\n",
    "# Train the model without using batches\n",
    "# Compile the model\n",
    "# Ensure y_train and y_val are one-hot encoded only once\n",
    "if y_train.ndim == 1:\n",
    "    y_train = to_categorical(y_train)\n",
    "if y_val.ndim == 1:\n",
    "    y_val = to_categorical(y_val)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('y_val.shape: ', y_val.shape)\n",
    "\n",
    "# Calculate class weights\n",
    "B_multiplier = 1\n",
    "A_multiplier = B_size / A_size\n",
    "class_weight = {0: B_multiplier, 1: A_multiplier}\n",
    "\n",
    "# Ensure y_train and y_val are one-hot encoded only once\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=patience)\n",
    "lrs = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=factor, patience=patience, verbose=1)\n",
    "print('X_train.shape: ', X_train.shape) # (23291, 50, 9)\n",
    "print('y_train.shape: ', y_train.shape) # (23291,)\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "          validation_data=(X_val, y_val), \n",
    "          epochs=epochs, \n",
    "          batch_size=batch_size,\n",
    "          callbacks=[es, lrs],\n",
    "          class_weight=class_weight) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2903b3280>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.shape:  (250, 50, 6)\n",
      "8/8 - 0s - loss: 0.5075 - accuracy: 0.8480 - 47ms/epoch - 6ms/step\n",
      "Test loss: [0.5075323581695557, 0.8479999899864197]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "if y_test.ndim == 1:\n",
    "    y_test = to_categorical(y_test)\n",
    "test_loss = model.evaluate(X_test, y_test, verbose=2)\n",
    "print('Test loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n",
      "[[114   4]\n",
      " [ 34  98]]\n",
      "Confusion matrix, without normalization\n",
      "[[114   4]\n",
      " [ 34  98]]\n",
      "accuracy:  0.848\n",
      "f1_score:  0.8376068376068376\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert y_test back to its original form\n",
    "y_test_original = np.argmax(y_test, axis=-1)\n",
    "\n",
    "# Get the model's predictions\n",
    "predictions = np.argmax(model.predict(X_test), axis=-1)\n",
    "\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test_original, predictions)\n",
    "\n",
    "print(cm)\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(cm, classes=['Not Fall', 'Fall'], normalize=False, title='Confusion Matrix')\n",
    "\n",
    "# get accuracy\n",
    "accuracy_fp = (cm[0][0] + cm[1][1]) / np.sum(cm)\n",
    "print('accuracy: ', accuracy_fp)\n",
    "# f1 score\n",
    "precision_fp = cm[1][1] / (cm[1][1] + cm[0][1])\n",
    "recall_fp = cm[1][1] / (cm[1][1] + cm[1][0])\n",
    "f1_score_fp = 2 * precision_fp * recall_fp / (precision_fp + recall_fp)\n",
    "print('f1_score: ', f1_score_fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/6j/7v412jf92t1f972gcdmx7l8w0000gn/T/tmpdsxr0trs/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/6j/7v412jf92t1f972gcdmx7l8w0000gn/T/tmpdsxr0trs/assets\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "2023-12-14 10:28:52.617859: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2023-12-14 10:28:52.617877: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2023-12-14 10:28:52.618482: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/6j/7v412jf92t1f972gcdmx7l8w0000gn/T/tmpdsxr0trs\n",
      "2023-12-14 10:28:52.624089: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2023-12-14 10:28:52.624102: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/6j/7v412jf92t1f972gcdmx7l8w0000gn/T/tmpdsxr0trs\n",
      "2023-12-14 10:28:52.634415: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2023-12-14 10:28:52.639917: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-12-14 10:28:52.832508: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/6j/7v412jf92t1f972gcdmx7l8w0000gn/T/tmpdsxr0trs\n",
      "2023-12-14 10:28:52.890058: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 271575 microseconds.\n",
      "2023-12-14 10:28:52.955584: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 42, Total Ops 75, % non-converted = 56.00 %\n",
      " * 42 ARITH ops\n",
      "\n",
      "- arith.constant:   42 occurrences  (f32: 36, i32: 6)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 17)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (i32: 1)\n",
      "  (f32: 2)\n",
      "  (i32: 1)\n",
      "  (f32: 1)\n",
      "  (i32: 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "139040"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('./saved_models/'+model_name+'.keras')\n",
    "# convert the model to tflite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "if model_name==\"ConvLSTM\" or model_name==\"ConvLSTM_VGG\":\n",
    "    converter._experimental_lower_tensor_list_ops = False\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "model_tflite = converter.convert()\n",
    "# save the model\n",
    "open('./saved_models/'+model_name+'.tflite', \"wb\").write(model_tflite)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for ConvLSTM model\n",
    "if model_name==\"ConvLSTM\" or model_name==\"ConvLSTM_VGG\":\n",
    "    def representative_data_gen():\n",
    "        for input_value in tf.data.Dataset.from_tensor_slices(X_train.astype('float32')).batch(1).take(100):\n",
    "            yield [input_value]\n",
    "\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = representative_data_gen\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "    converter._experimental_lower_tensor_list_ops = False\n",
    "    converter.inference_input_type = tf.float32\n",
    "    converter.inference_output_type = tf.int8\n",
    "\n",
    "    tflite_q_model = converter.convert()\n",
    "    interpreter = tf.lite.Interpreter(model_content=tflite_q_model)\n",
    "    input_type = interpreter.get_input_details()[0]['dtype']\n",
    "    print('input: ', input_type)\n",
    "    output_type = interpreter.get_output_details()[0]['dtype']\n",
    "    print('output: ', output_type)\n",
    "    # Save the quantized model to disk\n",
    "    open('./saved_models/'+model_name+'_q.tflite', \"wb\").write(tflite_q_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"TinyFallNet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 50, 6)]              0         []                            \n",
      "                                                                                                  \n",
      " quantize_layer (QuantizeLa  (None, 50, 6)                3         ['input_1[0][0]']             \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " quant_reshape (QuantizeWra  (None, 1, 50, 6)             1         ['quantize_layer[0][0]']      \n",
      " pperV2)                                                                                          \n",
      "                                                                                                  \n",
      " quant_conv2d (QuantizeWrap  (None, 1, 48, 64)            1347      ['quant_reshape[0][0]']       \n",
      " perV2)                                                                                           \n",
      "                                                                                                  \n",
      " quant_max_pooling2d (Quant  (None, 1, 24, 64)            1         ['quant_conv2d[0][0]']        \n",
      " izeWrapperV2)                                                                                    \n",
      "                                                                                                  \n",
      " quant_conv2d_2 (QuantizeWr  (None, 1, 24, 16)            1073      ['quant_max_pooling2d[0][0]'] \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_batch_normalization   (None, 1, 24, 16)            65        ['quant_conv2d_2[0][0]']      \n",
      " (QuantizeWrapperV2)                                                                              \n",
      "                                                                                                  \n",
      " quant_re_lu (QuantizeWrapp  (None, 1, 24, 16)            3         ['quant_batch_normalization[0]\n",
      " erV2)                                                              [0]']                         \n",
      "                                                                                                  \n",
      " quant_conv2d_3 (QuantizeWr  (None, 1, 24, 16)            817       ['quant_re_lu[0][0]']         \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_3[0][0]']      \n",
      " 1 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_re_lu_1 (QuantizeWra  (None, 1, 24, 16)            3         ['quant_batch_normalization_1[\n",
      " pperV2)                                                            0][0]']                       \n",
      "                                                                                                  \n",
      " quant_conv2d_4 (QuantizeWr  (None, 1, 24, 64)            1217      ['quant_re_lu_1[0][0]']       \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 64)            259       ['quant_conv2d_4[0][0]']      \n",
      " 2 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_conv2d_1 (QuantizeWr  (None, 1, 24, 64)            4291      ['quant_max_pooling2d[0][0]'] \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_add (QuantizeWrapper  (None, 1, 24, 64)            1         ['quant_batch_normalization_2[\n",
      " V2)                                                                0][0]',                       \n",
      "                                                                     'quant_conv2d_1[0][0]']      \n",
      "                                                                                                  \n",
      " quant_re_lu_2 (QuantizeWra  (None, 1, 24, 64)            3         ['quant_add[0][0]']           \n",
      " pperV2)                                                                                          \n",
      "                                                                                                  \n",
      " quant_conv2d_6 (QuantizeWr  (None, 1, 24, 16)            1073      ['quant_re_lu_2[0][0]']       \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_6[0][0]']      \n",
      " 3 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_re_lu_3 (QuantizeWra  (None, 1, 24, 16)            3         ['quant_batch_normalization_3[\n",
      " pperV2)                                                            0][0]']                       \n",
      "                                                                                                  \n",
      " quant_conv2d_7 (QuantizeWr  (None, 1, 24, 16)            817       ['quant_re_lu_3[0][0]']       \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_7[0][0]']      \n",
      " 4 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_re_lu_4 (QuantizeWra  (None, 1, 24, 16)            3         ['quant_batch_normalization_4[\n",
      " pperV2)                                                            0][0]']                       \n",
      "                                                                                                  \n",
      " quant_conv2d_8 (QuantizeWr  (None, 1, 24, 64)            1217      ['quant_re_lu_4[0][0]']       \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 64)            259       ['quant_conv2d_8[0][0]']      \n",
      " 5 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_conv2d_5 (QuantizeWr  (None, 1, 24, 64)            4291      ['quant_re_lu_2[0][0]']       \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_add_1 (QuantizeWrapp  (None, 1, 24, 64)            1         ['quant_batch_normalization_5[\n",
      " erV2)                                                              0][0]',                       \n",
      "                                                                     'quant_conv2d_5[0][0]']      \n",
      "                                                                                                  \n",
      " quant_re_lu_5 (QuantizeWra  (None, 1, 24, 64)            3         ['quant_add_1[0][0]']         \n",
      " pperV2)                                                                                          \n",
      "                                                                                                  \n",
      " quant_conv2d_10 (QuantizeW  (None, 1, 24, 16)            1073      ['quant_re_lu_5[0][0]']       \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_10[0][0]']     \n",
      " 6 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_re_lu_6 (QuantizeWra  (None, 1, 24, 16)            3         ['quant_batch_normalization_6[\n",
      " pperV2)                                                            0][0]']                       \n",
      "                                                                                                  \n",
      " quant_conv2d_11 (QuantizeW  (None, 1, 24, 16)            817       ['quant_re_lu_6[0][0]']       \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_11[0][0]']     \n",
      " 7 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_re_lu_7 (QuantizeWra  (None, 1, 24, 16)            3         ['quant_batch_normalization_7[\n",
      " pperV2)                                                            0][0]']                       \n",
      "                                                                                                  \n",
      " quant_conv2d_12 (QuantizeW  (None, 1, 24, 64)            1217      ['quant_re_lu_7[0][0]']       \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 64)            259       ['quant_conv2d_12[0][0]']     \n",
      " 8 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_conv2d_9 (QuantizeWr  (None, 1, 24, 64)            4291      ['quant_re_lu_5[0][0]']       \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_add_2 (QuantizeWrapp  (None, 1, 24, 64)            1         ['quant_batch_normalization_8[\n",
      " erV2)                                                              0][0]',                       \n",
      "                                                                     'quant_conv2d_9[0][0]']      \n",
      "                                                                                                  \n",
      " quant_re_lu_8 (QuantizeWra  (None, 1, 24, 64)            3         ['quant_add_2[0][0]']         \n",
      " pperV2)                                                                                          \n",
      "                                                                                                  \n",
      " quant_conv2d_14 (QuantizeW  (None, 1, 24, 16)            1073      ['quant_re_lu_8[0][0]']       \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_14[0][0]']     \n",
      " 9 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_re_lu_9 (QuantizeWra  (None, 1, 24, 16)            3         ['quant_batch_normalization_9[\n",
      " pperV2)                                                            0][0]']                       \n",
      "                                                                                                  \n",
      " quant_conv2d_15 (QuantizeW  (None, 1, 24, 16)            817       ['quant_re_lu_9[0][0]']       \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_15[0][0]']     \n",
      " 10 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_10 (QuantizeWr  (None, 1, 24, 16)            3         ['quant_batch_normalization_10\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_16 (QuantizeW  (None, 1, 24, 64)            1217      ['quant_re_lu_10[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 64)            259       ['quant_conv2d_16[0][0]']     \n",
      " 11 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_conv2d_13 (QuantizeW  (None, 1, 24, 64)            4291      ['quant_re_lu_8[0][0]']       \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_add_3 (QuantizeWrapp  (None, 1, 24, 64)            1         ['quant_batch_normalization_11\n",
      " erV2)                                                              [0][0]',                      \n",
      "                                                                     'quant_conv2d_13[0][0]']     \n",
      "                                                                                                  \n",
      " quant_re_lu_11 (QuantizeWr  (None, 1, 24, 64)            3         ['quant_add_3[0][0]']         \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_average_pooling2d (Q  (None, 1, 12, 64)            3         ['quant_re_lu_11[0][0]']      \n",
      " uantizeWrapperV2)                                                                                \n",
      "                                                                                                  \n",
      " quant_flatten (QuantizeWra  (None, 768)                  1         ['quant_average_pooling2d[0][0\n",
      " pperV2)                                                            ]']                           \n",
      "                                                                                                  \n",
      " quant_dense (QuantizeWrapp  (None, 2)                    1543      ['quant_flatten[0][0]']       \n",
      " erV2)                                                                                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 34087 (133.15 KB)\n",
      "Trainable params: 31810 (124.26 KB)\n",
      "Non-trainable params: 2277 (8.89 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "q_model = tfmot.quantization.keras.quantize_model(model)\n",
    "q_model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "                loss='categorical_crossentropy',\n",
    "                #loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "q_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/6j/7v412jf92t1f972gcdmx7l8w0000gn/T/tmp_ttt0cor/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/6j/7v412jf92t1f972gcdmx7l8w0000gn/T/tmp_ttt0cor/assets\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "/Users/liuxinqing/opt/anaconda3/envs/fall_detection/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2023-12-14 10:29:00.220262: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2023-12-14 10:29:00.220277: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2023-12-14 10:29:00.220464: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/6j/7v412jf92t1f972gcdmx7l8w0000gn/T/tmp_ttt0cor\n",
      "2023-12-14 10:29:00.231921: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2023-12-14 10:29:00.231940: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/6j/7v412jf92t1f972gcdmx7l8w0000gn/T/tmp_ttt0cor\n",
      "2023-12-14 10:29:00.262876: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-12-14 10:29:00.486810: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/6j/7v412jf92t1f972gcdmx7l8w0000gn/T/tmp_ttt0cor\n",
      "2023-12-14 10:29:00.567416: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 346948 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 6, Total Ops 77, % non-converted = 7.79 %\n",
      " * 6 ARITH ops\n",
      "\n",
      "- arith.constant:    6 occurrences  (i32: 6)\n",
      "\n",
      "\n",
      "\n",
      "  (uq_8: 4)\n",
      "  (uq_8: 1)\n",
      "  (uq_8: 17)\n",
      "  (f32: 1)\n",
      "  (uq_8: 1)\n",
      "  (uq_8: 1)\n",
      "  (i32: 1)\n",
      "  (uq_8: 18, uq_32: 18)\n",
      "  (uq_8: 1)\n",
      "  (uq_8: 2)\n",
      "  (i32: 1)\n",
      "  (uq_8: 1)\n",
      "  (i32: 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.float32'>\n",
      "output:  <class 'numpy.int8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: INT8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "69080"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_model.save('./saved_models/'+model_name+'_q.keras')\n",
    "# convert the QAT model to a fully quantized model using TFLite\n",
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(X_train.astype('float32')).batch(1).take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "# Set up the converter for quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# This is required for full integer quantization (including input and output)\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.float32  # Keep input as float32\n",
    "converter.inference_output_type = tf.int8  # Keep output as float32\n",
    "\n",
    "# Convert the model\n",
    "tflite_q_model = converter.convert()\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_q_model)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)\n",
    "# Save the quantized model to disk\n",
    "open('./saved_models/'+model_name+'_q.tflite', \"wb\").write(tflite_q_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train.shape:  (16368, 2)\n",
      "y_val.shape:  (4092, 2)\n",
      "Epoch 1/50\n",
      "256/256 [==============================] - 7s 19ms/step - loss: 0.6160 - accuracy: 0.8427 - val_loss: 0.1017 - val_accuracy: 0.9673 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 0.4432 - accuracy: 0.8972 - val_loss: 0.2280 - val_accuracy: 0.9157 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 0.3770 - accuracy: 0.9209 - val_loss: 0.3353 - val_accuracy: 0.8952 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 0.3939 - accuracy: 0.9169 - val_loss: 0.2487 - val_accuracy: 0.9311 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 0.3859 - accuracy: 0.9227 - val_loss: 0.2295 - val_accuracy: 0.9260 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3192 - accuracy: 0.9365\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 0.3188 - accuracy: 0.9365 - val_loss: 0.1517 - val_accuracy: 0.9519 - lr: 5.0000e-04\n",
      "Epoch 6: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Ensure y_train and y_val are one-hot encoded only once\n",
    "if y_train.ndim == 1:\n",
    "    y_train = to_categorical(y_train)\n",
    "if y_val.ndim == 1:\n",
    "    y_val = to_categorical(y_val)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('y_val.shape: ', y_val.shape)\n",
    "\n",
    "q_history = q_model.fit(X_train, y_train, \n",
    "            validation_data=(X_val, y_val), \n",
    "            epochs=epochs, \n",
    "            batch_size=batch_size,\n",
    "            callbacks=[es, lrs],\n",
    "            class_weight=class_weight) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/6j/7v412jf92t1f972gcdmx7l8w0000gn/T/tmp_a7_4jyl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/6j/7v412jf92t1f972gcdmx7l8w0000gn/T/tmp_a7_4jyl/assets\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "/Users/liuxinqing/opt/anaconda3/envs/fall_detection/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2023-12-14 10:29:40.679652: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2023-12-14 10:29:40.679666: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2023-12-14 10:29:40.679840: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/6j/7v412jf92t1f972gcdmx7l8w0000gn/T/tmp_a7_4jyl\n",
      "2023-12-14 10:29:40.693855: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2023-12-14 10:29:40.693873: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/6j/7v412jf92t1f972gcdmx7l8w0000gn/T/tmp_a7_4jyl\n",
      "2023-12-14 10:29:40.728293: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-12-14 10:29:41.068749: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/6j/7v412jf92t1f972gcdmx7l8w0000gn/T/tmp_a7_4jyl\n",
      "2023-12-14 10:29:41.175457: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 495617 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 6, Total Ops 78, % non-converted = 7.69 %\n",
      " * 6 ARITH ops\n",
      "\n",
      "- arith.constant:    6 occurrences  (i32: 6)\n",
      "\n",
      "\n",
      "\n",
      "  (uq_8: 4)\n",
      "  (uq_8: 1)\n",
      "  (uq_8: 17)\n",
      "  (f32: 1)\n",
      "  (uq_8: 1)\n",
      "  (uq_8: 1)\n",
      "  (i32: 1)\n",
      "  (uq_8: 18, uq_32: 18)\n",
      "  (uq_8: 2)\n",
      "  (uq_8: 2)\n",
      "  (i32: 1)\n",
      "  (uq_8: 1)\n",
      "  (i32: 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.float32'>\n",
      "output:  <class 'numpy.int8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: INT8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "69312"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_model.save('./saved_models/'+model_name+'_qat.keras')  # The file needs to end with the .keras extension\n",
    "# convert the QAT model to a fully quantized model using TFLite\n",
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(X_train.astype('float32')).batch(1).take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "# Set up the converter for quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# This is required for full integer quantization (including input and output)\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.float32  # Keep input as float32\n",
    "converter.inference_output_type = tf.int8  # Keep output as float32\n",
    "\n",
    "# Convert the model\n",
    "tflite_q_model = converter.convert()\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_q_model)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)\n",
    "# Save the quantized model to disk\n",
    "open('./saved_models/'+model_name+'_qat.tflite', \"wb\").write(tflite_q_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"TinyFallNet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 50, 6)]              0         []                            \n",
      "                                                                                                  \n",
      " prune_low_magnitude_reshap  (None, 1, 50, 6)             1         ['input_1[0][0]']             \n",
      " e (PruneLowMagnitude)                                                                            \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 48, 64)            2370      ['prune_low_magnitude_reshape[\n",
      "  (PruneLowMagnitude)                                               0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_max_po  (None, 1, 24, 64)            1         ['prune_low_magnitude_conv2d[0\n",
      " oling2d (PruneLowMagnitude                                         ][0]']                        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 16)            2066      ['prune_low_magnitude_max_pool\n",
      " _2 (PruneLowMagnitude)                                             ing2d[0][0]']                 \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 16)            65        ['prune_low_magnitude_conv2d_2\n",
      " normalization (PruneLowMag                                         [0][0]']                      \n",
      " nitude)                                                                                          \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu   (None, 1, 24, 16)            1         ['prune_low_magnitude_batch_no\n",
      " (PruneLowMagnitude)                                                rmalization[0][0]']           \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 16)            1554      ['prune_low_magnitude_re_lu[0]\n",
      " _3 (PruneLowMagnitude)                                             [0]']                         \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 16)            65        ['prune_low_magnitude_conv2d_3\n",
      " normalization_1 (PruneLowM                                         [0][0]']                      \n",
      " agnitude)                                                                                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 1 (PruneLowMagnitude)                                              rmalization_1[0][0]']         \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 64)            2114      ['prune_low_magnitude_re_lu_1[\n",
      " _4 (PruneLowMagnitude)                                             0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 64)            257       ['prune_low_magnitude_conv2d_4\n",
      " normalization_2 (PruneLowM                                         [0][0]']                      \n",
      " agnitude)                                                                                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 64)            8258      ['prune_low_magnitude_max_pool\n",
      " _1 (PruneLowMagnitude)                                             ing2d[0][0]']                 \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add (P  (None, 1, 24, 64)            1         ['prune_low_magnitude_batch_no\n",
      " runeLowMagnitude)                                                  rmalization_2[0][0]',         \n",
      "                                                                     'prune_low_magnitude_conv2d_1\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 64)            1         ['prune_low_magnitude_add[0][0\n",
      " 2 (PruneLowMagnitude)                                              ]']                           \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 16)            2066      ['prune_low_magnitude_re_lu_2[\n",
      " _6 (PruneLowMagnitude)                                             0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 16)            65        ['prune_low_magnitude_conv2d_6\n",
      " normalization_3 (PruneLowM                                         [0][0]']                      \n",
      " agnitude)                                                                                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 3 (PruneLowMagnitude)                                              rmalization_3[0][0]']         \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 16)            1554      ['prune_low_magnitude_re_lu_3[\n",
      " _7 (PruneLowMagnitude)                                             0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 16)            65        ['prune_low_magnitude_conv2d_7\n",
      " normalization_4 (PruneLowM                                         [0][0]']                      \n",
      " agnitude)                                                                                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 4 (PruneLowMagnitude)                                              rmalization_4[0][0]']         \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 64)            2114      ['prune_low_magnitude_re_lu_4[\n",
      " _8 (PruneLowMagnitude)                                             0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 64)            257       ['prune_low_magnitude_conv2d_8\n",
      " normalization_5 (PruneLowM                                         [0][0]']                      \n",
      " agnitude)                                                                                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 64)            8258      ['prune_low_magnitude_re_lu_2[\n",
      " _5 (PruneLowMagnitude)                                             0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_1   (None, 1, 24, 64)            1         ['prune_low_magnitude_batch_no\n",
      " (PruneLowMagnitude)                                                rmalization_5[0][0]',         \n",
      "                                                                     'prune_low_magnitude_conv2d_5\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 64)            1         ['prune_low_magnitude_add_1[0]\n",
      " 5 (PruneLowMagnitude)                                              [0]']                         \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 16)            2066      ['prune_low_magnitude_re_lu_5[\n",
      " _10 (PruneLowMagnitude)                                            0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 16)            65        ['prune_low_magnitude_conv2d_1\n",
      " normalization_6 (PruneLowM                                         0[0][0]']                     \n",
      " agnitude)                                                                                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 6 (PruneLowMagnitude)                                              rmalization_6[0][0]']         \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 16)            1554      ['prune_low_magnitude_re_lu_6[\n",
      " _11 (PruneLowMagnitude)                                            0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 16)            65        ['prune_low_magnitude_conv2d_1\n",
      " normalization_7 (PruneLowM                                         1[0][0]']                     \n",
      " agnitude)                                                                                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 7 (PruneLowMagnitude)                                              rmalization_7[0][0]']         \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 64)            2114      ['prune_low_magnitude_re_lu_7[\n",
      " _12 (PruneLowMagnitude)                                            0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 64)            257       ['prune_low_magnitude_conv2d_1\n",
      " normalization_8 (PruneLowM                                         2[0][0]']                     \n",
      " agnitude)                                                                                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 64)            8258      ['prune_low_magnitude_re_lu_5[\n",
      " _9 (PruneLowMagnitude)                                             0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_2   (None, 1, 24, 64)            1         ['prune_low_magnitude_batch_no\n",
      " (PruneLowMagnitude)                                                rmalization_8[0][0]',         \n",
      "                                                                     'prune_low_magnitude_conv2d_9\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 64)            1         ['prune_low_magnitude_add_2[0]\n",
      " 8 (PruneLowMagnitude)                                              [0]']                         \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 16)            2066      ['prune_low_magnitude_re_lu_8[\n",
      " _14 (PruneLowMagnitude)                                            0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 16)            65        ['prune_low_magnitude_conv2d_1\n",
      " normalization_9 (PruneLowM                                         4[0][0]']                     \n",
      " agnitude)                                                                                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 9 (PruneLowMagnitude)                                              rmalization_9[0][0]']         \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 16)            1554      ['prune_low_magnitude_re_lu_9[\n",
      " _15 (PruneLowMagnitude)                                            0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 16)            65        ['prune_low_magnitude_conv2d_1\n",
      " normalization_10 (PruneLow                                         5[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 10 (PruneLowMagnitude)                                             rmalization_10[0][0]']        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 64)            2114      ['prune_low_magnitude_re_lu_10\n",
      " _16 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 64)            257       ['prune_low_magnitude_conv2d_1\n",
      " normalization_11 (PruneLow                                         6[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 64)            8258      ['prune_low_magnitude_re_lu_8[\n",
      " _13 (PruneLowMagnitude)                                            0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_3   (None, 1, 24, 64)            1         ['prune_low_magnitude_batch_no\n",
      " (PruneLowMagnitude)                                                rmalization_11[0][0]',        \n",
      "                                                                     'prune_low_magnitude_conv2d_1\n",
      "                                                                    3[0][0]']                     \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 64)            1         ['prune_low_magnitude_add_3[0]\n",
      " 11 (PruneLowMagnitude)                                             [0]']                         \n",
      "                                                                                                  \n",
      " prune_low_magnitude_averag  (None, 1, 12, 64)            1         ['prune_low_magnitude_re_lu_11\n",
      " e_pooling2d (PruneLowMagni                                         [0][0]']                      \n",
      " tude)                                                                                            \n",
      "                                                                                                  \n",
      " prune_low_magnitude_flatte  (None, 768)                  1         ['prune_low_magnitude_average_\n",
      " n (PruneLowMagnitude)                                              pooling2d[0][0]']             \n",
      "                                                                                                  \n",
      " prune_low_magnitude_dense   (None, 2)                    3076      ['prune_low_magnitude_flatten[\n",
      " (PruneLowMagnitude)                                                0][0]']                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 62982 (246.22 KB)\n",
      "Trainable params: 31810 (124.26 KB)\n",
      "Non-trainable params: 31172 (121.96 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Unstrucutred pruning with constant sparsity\n",
    "pruning_params = {\n",
    "        'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(0.5, begin_step=2000, frequency=100),\n",
    "}\n",
    "\n",
    "ups = pruning_callbacks.UpdatePruningStep()\n",
    "# Create a pruning model\n",
    "pruned_model_unstructured = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "pruned_model_unstructured.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "                loss='categorical_crossentropy',\n",
    "                #loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "pruned_model_unstructured.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "256/256 [==============================] - 8s 15ms/step - loss: 0.3690 - accuracy: 0.9266 - val_loss: 0.2633 - val_accuracy: 0.9137 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "256/256 [==============================] - 4s 15ms/step - loss: 0.3554 - accuracy: 0.9287 - val_loss: 0.3223 - val_accuracy: 0.9106 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "256/256 [==============================] - 4s 15ms/step - loss: 0.3675 - accuracy: 0.9226 - val_loss: 0.2133 - val_accuracy: 0.9389 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "256/256 [==============================] - 4s 15ms/step - loss: 0.3600 - accuracy: 0.9288 - val_loss: 0.2565 - val_accuracy: 0.9245 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "256/256 [==============================] - 4s 15ms/step - loss: 0.2972 - accuracy: 0.9359 - val_loss: 0.2944 - val_accuracy: 0.9152 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "256/256 [==============================] - 4s 15ms/step - loss: 0.3829 - accuracy: 0.9223 - val_loss: 0.2235 - val_accuracy: 0.9370 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "256/256 [==============================] - 4s 15ms/step - loss: 0.2635 - accuracy: 0.9445 - val_loss: 0.1904 - val_accuracy: 0.9399 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "256/256 [==============================] - 4s 15ms/step - loss: 0.3162 - accuracy: 0.9321 - val_loss: 0.2722 - val_accuracy: 0.8959 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "256/256 [==============================] - 4s 15ms/step - loss: 0.3534 - accuracy: 0.9168 - val_loss: 0.1923 - val_accuracy: 0.9406 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "256/256 [==============================] - 4s 15ms/step - loss: 0.2743 - accuracy: 0.9385 - val_loss: 0.1431 - val_accuracy: 0.9516 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "256/256 [==============================] - 4s 15ms/step - loss: 0.2467 - accuracy: 0.9434 - val_loss: 0.1334 - val_accuracy: 0.9575 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "256/256 [==============================] - 4s 15ms/step - loss: 0.2140 - accuracy: 0.9534 - val_loss: 0.1732 - val_accuracy: 0.9482 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "256/256 [==============================] - 4s 16ms/step - loss: 0.1805 - accuracy: 0.9582 - val_loss: 0.1130 - val_accuracy: 0.9663 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "256/256 [==============================] - 4s 15ms/step - loss: 0.1877 - accuracy: 0.9578 - val_loss: 0.1799 - val_accuracy: 0.9460 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "256/256 [==============================] - 4s 15ms/step - loss: 0.1730 - accuracy: 0.9620 - val_loss: 0.1299 - val_accuracy: 0.9616 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "256/256 [==============================] - 4s 15ms/step - loss: 0.1422 - accuracy: 0.9677 - val_loss: 0.1132 - val_accuracy: 0.9680 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "256/256 [==============================] - 4s 15ms/step - loss: 0.1177 - accuracy: 0.9725 - val_loss: 0.1157 - val_accuracy: 0.9670 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "256/256 [==============================] - ETA: 0s - loss: 0.1479 - accuracy: 0.9691\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "256/256 [==============================] - 4s 15ms/step - loss: 0.1479 - accuracy: 0.9691 - val_loss: 0.1637 - val_accuracy: 0.9565 - lr: 5.0000e-04\n",
      "Epoch 18: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2cd3ed490>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_model_unstructured.fit(X_train, y_train, \n",
    "            validation_data=(X_val, y_val), \n",
    "            epochs=epochs, \n",
    "            batch_size=batch_size,\n",
    "            callbacks=[es, lrs, ups],\n",
    "            class_weight=class_weight) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned model loss:  0.36247652769088745\n",
      "Pruned model accuracy:  0.8999999761581421\n",
      "Full-precision model accuracy:  0.848\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the test set\n",
    "pruned_loss_unstructured, pruned_acc_unstructured = pruned_model_unstructured.evaluate(X_test, y_test, verbose=0)\n",
    "print('Pruned model loss: ', pruned_loss_unstructured)\n",
    "print('Pruned model accuracy: ', pruned_acc_unstructured)\n",
    "print('Full-precision model accuracy: ', accuracy_fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/6j/7v412jf92t1f972gcdmx7l8w0000gn/T/tmpmyaikszo/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/6j/7v412jf92t1f972gcdmx7l8w0000gn/T/tmpmyaikszo/assets\n",
      "2023-12-14 10:30:58.160124: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2023-12-14 10:30:58.160138: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2023-12-14 10:30:58.160295: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/6j/7v412jf92t1f972gcdmx7l8w0000gn/T/tmpmyaikszo\n",
      "2023-12-14 10:30:58.164440: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2023-12-14 10:30:58.164448: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/6j/7v412jf92t1f972gcdmx7l8w0000gn/T/tmpmyaikszo\n",
      "2023-12-14 10:30:58.174746: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-12-14 10:30:58.265955: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/6j/7v412jf92t1f972gcdmx7l8w0000gn/T/tmpmyaikszo\n",
      "2023-12-14 10:30:58.301759: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 141463 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 42, Total Ops 75, % non-converted = 56.00 %\n",
      " * 42 ARITH ops\n",
      "\n",
      "- arith.constant:   42 occurrences  (f32: 36, i32: 6)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 17)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (i32: 1)\n",
      "  (f32: 2)\n",
      "  (i32: 1)\n",
      "  (f32: 1)\n",
      "  (i32: 1)\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "pruned_model_unstructured.save('./saved_models/'+model_name+'_pruned_unstructured.keras')  # The file needs to end with the .keras extension\n",
    "#print('Saved pruned Keras model to:', os.path.abspath(pruned_keras_file_unstructured))\n",
    "\n",
    "# Conversion to TF Lite\n",
    "pruned_model_unstructured_for_export = tfmot.sparsity.keras.strip_pruning(pruned_model_unstructured)\n",
    "\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model_unstructured_for_export)\n",
    "pruned_tflite_model_unstructured = converter.convert()\n",
    "\n",
    "# Save the model\n",
    "pruned_tflite_file_unstructured = './saved_models/'+model_name+'_pruned_unstructured.tflite'\n",
    "\n",
    "with open(pruned_tflite_file_unstructured, 'wb') as f:\n",
    "    f.write(pruned_tflite_model_unstructured)\n",
    "\n",
    "# print('Saved pruned TFLite model to:', os.path.abspath(pruned_tflite_file_unstructured))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the unstructured pruned model:  76507\n",
      "Size of the full-precision model:  120106\n",
      "The achieved compression ratio is 1.57x\n"
     ]
    }
   ],
   "source": [
    "# compare the size of the pruned model and the full-precision model\n",
    "print('Size of the unstructured pruned model: ', get_gzipped_model_size('./saved_models/'+model_name+'_pruned_unstructured.tflite'))\n",
    "print('Size of the full-precision model: ', get_gzipped_model_size('./saved_models/'+model_name+'.tflite'))\n",
    "print(\"The achieved compression ratio is %.2fx\" % (get_gzipped_model_size('./saved_models/'+model_name+'.tflite') / get_gzipped_model_size('./saved_models/'+model_name+'_pruned_unstructured.tflite')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PQAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"TinyFallNet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 50, 6)]              0         []                            \n",
      "                                                                                                  \n",
      " quantize_layer_1 (Quantize  (None, 50, 6)                3         ['input_1[0][0]']             \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " quant_reshape (QuantizeWra  (None, 1, 50, 6)             1         ['quantize_layer_1[0][0]']    \n",
      " pperV2)                                                                                          \n",
      "                                                                                                  \n",
      " quant_conv2d (QuantizeWrap  (None, 1, 48, 64)            1347      ['quant_reshape[0][0]']       \n",
      " perV2)                                                                                           \n",
      "                                                                                                  \n",
      " quant_max_pooling2d (Quant  (None, 1, 24, 64)            1         ['quant_conv2d[0][0]']        \n",
      " izeWrapperV2)                                                                                    \n",
      "                                                                                                  \n",
      " quant_conv2d_2 (QuantizeWr  (None, 1, 24, 16)            1073      ['quant_max_pooling2d[0][0]'] \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_batch_normalization   (None, 1, 24, 16)            65        ['quant_conv2d_2[0][0]']      \n",
      " (QuantizeWrapperV2)                                                                              \n",
      "                                                                                                  \n",
      " quant_re_lu (QuantizeWrapp  (None, 1, 24, 16)            3         ['quant_batch_normalization[0]\n",
      " erV2)                                                              [0]']                         \n",
      "                                                                                                  \n",
      " quant_conv2d_3 (QuantizeWr  (None, 1, 24, 16)            817       ['quant_re_lu[0][0]']         \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_3[0][0]']      \n",
      " 1 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_re_lu_1 (QuantizeWra  (None, 1, 24, 16)            3         ['quant_batch_normalization_1[\n",
      " pperV2)                                                            0][0]']                       \n",
      "                                                                                                  \n",
      " quant_conv2d_4 (QuantizeWr  (None, 1, 24, 64)            1217      ['quant_re_lu_1[0][0]']       \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 64)            259       ['quant_conv2d_4[0][0]']      \n",
      " 2 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_conv2d_1 (QuantizeWr  (None, 1, 24, 64)            4291      ['quant_max_pooling2d[0][0]'] \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_add (QuantizeWrapper  (None, 1, 24, 64)            1         ['quant_batch_normalization_2[\n",
      " V2)                                                                0][0]',                       \n",
      "                                                                     'quant_conv2d_1[0][0]']      \n",
      "                                                                                                  \n",
      " quant_re_lu_2 (QuantizeWra  (None, 1, 24, 64)            3         ['quant_add[0][0]']           \n",
      " pperV2)                                                                                          \n",
      "                                                                                                  \n",
      " quant_conv2d_6 (QuantizeWr  (None, 1, 24, 16)            1073      ['quant_re_lu_2[0][0]']       \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_6[0][0]']      \n",
      " 3 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_re_lu_3 (QuantizeWra  (None, 1, 24, 16)            3         ['quant_batch_normalization_3[\n",
      " pperV2)                                                            0][0]']                       \n",
      "                                                                                                  \n",
      " quant_conv2d_7 (QuantizeWr  (None, 1, 24, 16)            817       ['quant_re_lu_3[0][0]']       \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_7[0][0]']      \n",
      " 4 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_re_lu_4 (QuantizeWra  (None, 1, 24, 16)            3         ['quant_batch_normalization_4[\n",
      " pperV2)                                                            0][0]']                       \n",
      "                                                                                                  \n",
      " quant_conv2d_8 (QuantizeWr  (None, 1, 24, 64)            1217      ['quant_re_lu_4[0][0]']       \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 64)            259       ['quant_conv2d_8[0][0]']      \n",
      " 5 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_conv2d_5 (QuantizeWr  (None, 1, 24, 64)            4291      ['quant_re_lu_2[0][0]']       \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_add_1 (QuantizeWrapp  (None, 1, 24, 64)            1         ['quant_batch_normalization_5[\n",
      " erV2)                                                              0][0]',                       \n",
      "                                                                     'quant_conv2d_5[0][0]']      \n",
      "                                                                                                  \n",
      " quant_re_lu_5 (QuantizeWra  (None, 1, 24, 64)            3         ['quant_add_1[0][0]']         \n",
      " pperV2)                                                                                          \n",
      "                                                                                                  \n",
      " quant_conv2d_10 (QuantizeW  (None, 1, 24, 16)            1073      ['quant_re_lu_5[0][0]']       \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_10[0][0]']     \n",
      " 6 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_re_lu_6 (QuantizeWra  (None, 1, 24, 16)            3         ['quant_batch_normalization_6[\n",
      " pperV2)                                                            0][0]']                       \n",
      "                                                                                                  \n",
      " quant_conv2d_11 (QuantizeW  (None, 1, 24, 16)            817       ['quant_re_lu_6[0][0]']       \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_11[0][0]']     \n",
      " 7 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_re_lu_7 (QuantizeWra  (None, 1, 24, 16)            3         ['quant_batch_normalization_7[\n",
      " pperV2)                                                            0][0]']                       \n",
      "                                                                                                  \n",
      " quant_conv2d_12 (QuantizeW  (None, 1, 24, 64)            1217      ['quant_re_lu_7[0][0]']       \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 64)            259       ['quant_conv2d_12[0][0]']     \n",
      " 8 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_conv2d_9 (QuantizeWr  (None, 1, 24, 64)            4291      ['quant_re_lu_5[0][0]']       \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_add_2 (QuantizeWrapp  (None, 1, 24, 64)            1         ['quant_batch_normalization_8[\n",
      " erV2)                                                              0][0]',                       \n",
      "                                                                     'quant_conv2d_9[0][0]']      \n",
      "                                                                                                  \n",
      " quant_re_lu_8 (QuantizeWra  (None, 1, 24, 64)            3         ['quant_add_2[0][0]']         \n",
      " pperV2)                                                                                          \n",
      "                                                                                                  \n",
      " quant_conv2d_14 (QuantizeW  (None, 1, 24, 16)            1073      ['quant_re_lu_8[0][0]']       \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_14[0][0]']     \n",
      " 9 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_re_lu_9 (QuantizeWra  (None, 1, 24, 16)            3         ['quant_batch_normalization_9[\n",
      " pperV2)                                                            0][0]']                       \n",
      "                                                                                                  \n",
      " quant_conv2d_15 (QuantizeW  (None, 1, 24, 16)            817       ['quant_re_lu_9[0][0]']       \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_15[0][0]']     \n",
      " 10 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_10 (QuantizeWr  (None, 1, 24, 16)            3         ['quant_batch_normalization_10\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_16 (QuantizeW  (None, 1, 24, 64)            1217      ['quant_re_lu_10[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 64)            259       ['quant_conv2d_16[0][0]']     \n",
      " 11 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_conv2d_13 (QuantizeW  (None, 1, 24, 64)            4291      ['quant_re_lu_8[0][0]']       \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_add_3 (QuantizeWrapp  (None, 1, 24, 64)            1         ['quant_batch_normalization_11\n",
      " erV2)                                                              [0][0]',                      \n",
      "                                                                     'quant_conv2d_13[0][0]']     \n",
      "                                                                                                  \n",
      " quant_re_lu_11 (QuantizeWr  (None, 1, 24, 64)            3         ['quant_add_3[0][0]']         \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_average_pooling2d (Q  (None, 1, 12, 64)            3         ['quant_re_lu_11[0][0]']      \n",
      " uantizeWrapperV2)                                                                                \n",
      "                                                                                                  \n",
      " quant_flatten (QuantizeWra  (None, 768)                  1         ['quant_average_pooling2d[0][0\n",
      " pperV2)                                                            ]']                           \n",
      "                                                                                                  \n",
      " quant_dense (QuantizeWrapp  (None, 2)                    1543      ['quant_flatten[0][0]']       \n",
      " erV2)                                                                                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 34087 (133.15 KB)\n",
      "Trainable params: 31810 (124.26 KB)\n",
      "Non-trainable params: 2277 (8.89 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# PQAT\n",
    "quant_aware_annotate_model = tfmot.quantization.keras.quantize_annotate_model(\n",
    "              pruned_model_unstructured_for_export)\n",
    "\n",
    "pruned_qat_model = tfmot.quantization.keras.quantize_apply(quant_aware_annotate_model,\n",
    "                   tfmot.experimental.combine.Default8BitPrunePreserveQuantizeScheme())\n",
    "\n",
    "pruned_qat_model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "pruned_qat_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (16368, 50, 6)\n",
      "y_train.shape:  (16368, 2)\n",
      "64\n",
      "Epoch 1/50\n",
      "256/256 [==============================] - 7s 19ms/step - loss: 0.7077 - accuracy: 0.8682 - val_loss: 0.1728 - val_accuracy: 0.9318 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "256/256 [==============================] - 5s 18ms/step - loss: 0.3298 - accuracy: 0.9242 - val_loss: 0.2223 - val_accuracy: 0.9194 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 0.2368 - accuracy: 0.9470 - val_loss: 0.1414 - val_accuracy: 0.9514 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "256/256 [==============================] - 5s 18ms/step - loss: 0.1890 - accuracy: 0.9597 - val_loss: 0.1743 - val_accuracy: 0.9460 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "256/256 [==============================] - 5s 18ms/step - loss: 0.1735 - accuracy: 0.9600 - val_loss: 0.1057 - val_accuracy: 0.9673 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 0.1738 - accuracy: 0.9612 - val_loss: 0.1439 - val_accuracy: 0.9548 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "256/256 [==============================] - 5s 18ms/step - loss: 0.1533 - accuracy: 0.9661 - val_loss: 0.1954 - val_accuracy: 0.9409 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "256/256 [==============================] - 5s 18ms/step - loss: 0.1540 - accuracy: 0.9687 - val_loss: 0.1592 - val_accuracy: 0.9575 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "256/256 [==============================] - 5s 18ms/step - loss: 0.1633 - accuracy: 0.9652 - val_loss: 0.1482 - val_accuracy: 0.9638 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "253/256 [============================>.] - ETA: 0s - loss: 0.1780 - accuracy: 0.9666\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "256/256 [==============================] - 5s 18ms/step - loss: 0.1788 - accuracy: 0.9660 - val_loss: 0.2193 - val_accuracy: 0.9416 - lr: 5.0000e-04\n",
      "Epoch 10: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2d28e8310>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('X_train.shape: ', X_train.shape) # (16362, 50, 9)\n",
    "print('y_train.shape: ', y_train.shape) # (16362, 2)\n",
    "print(batch_size)\n",
    "pruned_qat_model.fit(X_train, y_train, \n",
    "            validation_data=(X_val, y_val), \n",
    "            epochs=epochs, \n",
    "            batch_size=batch_size,\n",
    "            callbacks=[es, lrs],\n",
    "            class_weight=class_weight) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned QAT model loss:  0.5544710755348206\n",
      "Pruned QAT model accuracy:  0.8759999871253967\n",
      "Full-precision model accuracy:  0.848\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the test set\n",
    "pruned_qat_loss, pruned_qat_acc = pruned_qat_model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Pruned QAT model loss: ', pruned_qat_loss)\n",
    "print('Pruned QAT model accuracy: ', pruned_qat_acc)\n",
    "print('Full-precision model accuracy: ', accuracy_fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/6j/7v412jf92t1f972gcdmx7l8w0000gn/T/tmpaad6j4ho/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/6j/7v412jf92t1f972gcdmx7l8w0000gn/T/tmpaad6j4ho/assets\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "/Users/liuxinqing/opt/anaconda3/envs/fall_detection/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2023-12-14 10:31:55.399109: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2023-12-14 10:31:55.399129: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2023-12-14 10:31:55.399335: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/6j/7v412jf92t1f972gcdmx7l8w0000gn/T/tmpaad6j4ho\n",
      "2023-12-14 10:31:55.411522: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2023-12-14 10:31:55.411535: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/6j/7v412jf92t1f972gcdmx7l8w0000gn/T/tmpaad6j4ho\n",
      "2023-12-14 10:31:55.447075: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-12-14 10:31:55.766636: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/6j/7v412jf92t1f972gcdmx7l8w0000gn/T/tmpaad6j4ho\n",
      "2023-12-14 10:31:55.869815: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 470479 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 6, Total Ops 78, % non-converted = 7.69 %\n",
      " * 6 ARITH ops\n",
      "\n",
      "- arith.constant:    6 occurrences  (i32: 6)\n",
      "\n",
      "\n",
      "\n",
      "  (uq_8: 4)\n",
      "  (uq_8: 1)\n",
      "  (uq_8: 17)\n",
      "  (f32: 1)\n",
      "  (uq_8: 1)\n",
      "  (uq_8: 1)\n",
      "  (i32: 1)\n",
      "  (uq_8: 18, uq_32: 18)\n",
      "  (uq_8: 2)\n",
      "  (uq_8: 2)\n",
      "  (i32: 1)\n",
      "  (uq_8: 1)\n",
      "  (i32: 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "69488"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_qat_model.save('./saved_models/'+model_name+'_pqat.keras')  # The file needs to end with the .keras extension\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(pruned_qat_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "pruned_qat_tflite_model = converter.convert()\n",
    "\n",
    "# Save the model\n",
    "open('./saved_models/'+model_name+'_pqat.tflite', \"wb\").write(pruned_qat_tflite_model)\n",
    "\n",
    "# write TFLite model to a C source (or header) file\n",
    "#c_model_name = 'pruned_qat_fmnist'\n",
    "\n",
    "#with open('cfiles/' + c_model_name + '.h', 'w') as file:\n",
    "#    file.write(hex_to_c_array(pruned_qat_tflite_model, c_model_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "WARNING: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors (tensor#29 is a dynamic-sized tensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  {'name': 'serving_default_input_1:0', 'index': 0, 'shape': array([ 1, 50,  6], dtype=int32), 'shape_signature': array([-1, 50,  6], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "output:  {'name': 'StatefulPartitionedCall:0', 'index': 75, 'shape': array([1, 2], dtype=int32), 'shape_signature': array([-1,  2], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "Evaluated on  0 .\n",
      "Evaluated on  100 .\n",
      "Evaluated on  200 .\n",
      "[[110   8]\n",
      " [ 28 104]]\n",
      "Confusion matrix, without normalization\n",
      "[[110   8]\n",
      " [ 28 104]]\n",
      "f1_score:  0.8524590163934426\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the quantized model\n",
    "X_test_int8 = X_test.astype('float32')\n",
    "y_test_int8 = y_test.astype('int8')\n",
    "# Load the model into an interpreter\n",
    "interpreter = tf.lite.Interpreter(model_content= pruned_qat_tflite_model)\n",
    "# Allocate memory for the model's input Tensor(s)\n",
    "interpreter.allocate_tensors()\n",
    "# Get the model input and output details\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "print(\"input: \", input_details)\n",
    "print(\"output: \", output_details)\n",
    "predictions = np.zeros(X_test.shape[0])\n",
    "for i, test_data in enumerate(X_test_int8):\n",
    "    test_data = np.expand_dims(test_data, axis=0)\n",
    "    #print(test_data.shape)\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_data)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "    if i%100 == 0:\n",
    "        # print(\"Evaluated on %d images.\" % test_image_index)\n",
    "        print('Evaluated on ', i, '.')\n",
    "    predictions[i] = output.argmax()\n",
    "\n",
    "gt = np.argmax(y_test_int8, axis=-1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(gt, predictions)\n",
    "\n",
    "print(cm)\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(cm, classes=['Not Fall', 'Fall'], normalize=False, title='Confusion Matrix')\n",
    "\n",
    "# get accuracy\n",
    "#accuracy_fp = (cm[0][0] + cm[1][1]) / np.sum(cm)\n",
    "#print('accuracy: ', accuracy_fp)\n",
    "\n",
    "f1_score = 2 * cm[1][1] / (2 * cm[1][1] + cm[0][1] + cm[1][0])\n",
    "print('f1_score: ', f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the pruned QAT model:  33275\n",
      "Size of th QAT model:  42843\n",
      "Size of the full-precision model:  120106\n",
      "The achieved compression ratio is 3.61x\n"
     ]
    }
   ],
   "source": [
    "# compare the size of the pruned model and the full-precision model\n",
    "print('Size of the pruned QAT model: ', get_gzipped_model_size('./saved_models/'+model_name+'_pqat.tflite'))\n",
    "print('Size of th QAT model: ', get_gzipped_model_size('./saved_models/'+model_name+'_qat.tflite'))\n",
    "print('Size of the full-precision model: ', get_gzipped_model_size('./saved_models/'+model_name+'.tflite'))\n",
    "print(\"The achieved compression ratio is %.2fx\" % (get_gzipped_model_size('saved_models/'+ model_name+ '.tflite') / get_gzipped_model_size('./saved_models/'+model_name+'_pqat.tflite')))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fall_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
