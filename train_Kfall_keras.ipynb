{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 21:13:26.128069: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-10 21:13:26.128129: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-10 21:13:26.129285: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-10 21:13:26.142344: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-10 21:13:27.116468: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.signal import resample\n",
    "from utils import plot_confusion_matrix, plot_confusion_matrix, get_gzipped_model_size\n",
    "from data_organizer_Kfall import DataOrganizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import models, optimizers, callbacks\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 21:13:32.676885: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 21:13:32.733868: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 21:13:32.733945: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 21:13:32.737967: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 21:13:32.738149: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 21:13:32.738231: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 21:13:34.030801: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 21:13:34.030960: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 21:13:34.030988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-12-10 21:13:34.031068: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-10 21:13:34.031095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3411 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model_name = \"TinyFallNet\" # \"ConvLSTM\" or \"ConvLSTM_VGG\" or \"TinyFallNet\" or \"ResNet24\"\n",
    "\n",
    "if model_name == \"ConvLSTM\":\n",
    "    from models.ConvLSTM import ConvLSTM\n",
    "    model = ConvLSTM()\n",
    "elif model_name == \"ConvLSTM_VGG\":\n",
    "    from models.ConvLSTM_VGG import ConvLSTM_VGG\n",
    "    model = ConvLSTM_VGG()\n",
    "elif model_name == \"TinyFallNet\":\n",
    "    from models.TinyFallNet import TinyFallNet\n",
    "    model = TinyFallNet()\n",
    "elif model_name == \"ResNet24\":\n",
    "    from models.ResNet24 import ResNet24\n",
    "    model = ResNet24()\n",
    "else:\n",
    "    print(\"Please select a valid model name\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/32 folder...\n",
      "Processing 2/32 folder...\n",
      "Processing 3/32 folder...\n",
      "Processing 4/32 folder...\n",
      "Processing 5/32 folder...\n",
      "Processing 6/32 folder...\n",
      "Processing 7/32 folder...\n",
      "Processing 8/32 folder...\n",
      "Processing 9/32 folder...\n",
      "Processing 10/32 folder...\n",
      "Processing 11/32 folder...\n",
      "Processing 12/32 folder...\n",
      "Processing 13/32 folder...\n",
      "Processing 14/32 folder...\n",
      "Processing 15/32 folder...\n",
      "Processing 16/32 folder...\n",
      "Processing 17/32 folder...\n",
      "Processing 18/32 folder...\n",
      "Processing 19/32 folder...\n",
      "Processing 20/32 folder...\n",
      "Processing 21/32 folder...\n",
      "Processing 22/32 folder...\n",
      "Processing 23/32 folder...\n",
      "Processing 24/32 folder...\n",
      "Processing 25/32 folder...\n",
      "Processing 26/32 folder...\n",
      "Processing 27/32 folder...\n",
      "Processing 28/32 folder...\n",
      "Processing 29/32 folder...\n",
      "Processing 30/32 folder...\n",
      "Processing 31/32 folder...\n",
      "Processing 32/32 folder...\n",
      "in_channels:  9\n",
      "data.shape:  (25602, 50, 9)\n",
      "B_size:  25020\n",
      "A_size:  582\n",
      "data:  [ 3.40000000e-02 -1.02800000e+00 -3.70000000e-02 -2.29183200e+00\n",
      " -1.11726810e+01  1.08862020e+00  8.75995486e+01  4.06800180e+00\n",
      "  5.39726436e+00]\n",
      "(230, 50, 9)\n"
     ]
    }
   ],
   "source": [
    "# mac\n",
    "# sensor_data_folder = '/Users/liuxinqing/Documents/Kfall/sensor_data'  # Update with the path to sensor data\n",
    "# label_data_folder = '/Users/liuxinqing/Documents/Kfall/label_data'  \n",
    "# windows \n",
    "#sensor_data_folder = 'G:\\MLonMCU\\Kfall_dataset\\sensor_data'  # Update with the path to sensor data\n",
    "#label_data_folder = 'G:\\MLonMCU\\Kfall_dataset\\label_data' \n",
    "# linux\n",
    "sensor_data_folder = '/home/liyinrong/Projects/MLonMCU/Final/Fall_Detection/datasets/KFall/sensor_data'  # Update with the path to sensor data\n",
    "label_data_folder = '/home/liyinrong/Projects/MLonMCU/Final/Fall_Detection/datasets/KFall/label_data'  \n",
    "\n",
    "#window_size = 256\n",
    "# Kfall: window_size = 50\n",
    "window_size = 50\n",
    "threshold = 0.4\n",
    "num_window_fall_data = 50\n",
    "num_window_not_fall_data = 5\n",
    "\n",
    "data, label = DataOrganizer(sensor_data_folder, \n",
    "                            label_data_folder, \n",
    "                            window_size, \n",
    "                            threshold, \n",
    "                            num_window_fall_data, \n",
    "                            num_window_not_fall_data)\n",
    "\n",
    "in_channels = 9\n",
    "print('in_channels: ', in_channels)\n",
    "# the input data should have the shape (batch_size, in_channels, sequence_length)\n",
    "#data = data.reshape(data.shape[0], in_channels, -1)\n",
    "print('data.shape: ', data.shape)\n",
    "\n",
    "label = label.astype(np.int64)\n",
    "# one-hot encoding\n",
    "#label = to_categorical(label, num_classes=2)\n",
    "# transpose the data to (batch_size, sequence_length, in_channels)\n",
    "#data = np.transpose(data, (0, 2, 1))\n",
    "data = data.reshape(data.shape[0], 50, 9)\n",
    "# normalize the data\n",
    "# Initialize a new scaling object for normalizing input data\n",
    "# Z-score normalization\n",
    "\n",
    "# (y == 0).sum()\n",
    "B_size = (label == 0).sum()\n",
    "A_size = (label == 1).sum()\n",
    "print('B_size: ', B_size)\t\n",
    "print('A_size: ', A_size)\n",
    "# transpose the data to (batch_size, in_channels, sequence_length)\n",
    "#data = np.transpose(data, (0, 2, 1))\n",
    "print('data: ', data[0][0])\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "#print(np.unique(y_train)) # [0 1]\n",
    "y_train = y_train.astype(np.int64)\n",
    "y_test = y_test.astype(np.int64)\n",
    "\n",
    "# select the test data that is not zero\n",
    "X_test_true = X_test[y_test != 0]\n",
    "y_test_true = y_test[y_test != 0]\n",
    "# length of the test data\n",
    "test_len = X_test_true.shape[0]\n",
    "X_test_false = X_test[y_test == 0]\n",
    "y_test_false = y_test[y_test == 0]\n",
    "# X_test.shape:  (17, 50, 9)\n",
    "# randomly len number of test data that is zero\n",
    "index = np.random.choice(X_test_false.shape[0], test_len, replace=False)\n",
    "# X_test.shape:  (17, 50, 9)\n",
    "# randomly len number of test data that is zero\n",
    "#index = np.random.choice(X_test_false.shape[0], len, replace=False)\n",
    "\n",
    "X_test_false = X_test[index]\n",
    "y_test_false = y_test[index]\n",
    "\n",
    "# concatenate the true and false test data\n",
    "X_test = np.concatenate((X_test_true, X_test_false), axis=0)\n",
    "y_test = np.concatenate((y_test_true, y_test_false), axis=0)\n",
    "#X_test = X_test[y_test != 0]\n",
    "#y_test = y_test[y_test != 0]\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 5e-4\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"TinyFallNet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 50, 9)]              0         []                            \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 1, 50, 9)             0         ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 1, 48, 64)            1792      ['reshape[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 1, 24, 64)            0         ['conv2d[0][0]']              \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 1, 24, 16)            1040      ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 1, 24, 16)            64        ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)              (None, 1, 24, 16)            0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 1, 24, 16)            784       ['re_lu_3[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 1, 24, 16)            64        ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)              (None, 1, 24, 16)            0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 1, 24, 64)            1088      ['re_lu_4[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 1, 24, 64)            256       ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 1, 24, 64)            4160      ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 1, 24, 64)            0         ['batch_normalization_5[0][0]'\n",
      "                                                                    , 'conv2d_1[0][0]']           \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)              (None, 1, 24, 64)            0         ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 1, 24, 16)            1040      ['re_lu_5[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 1, 24, 16)            64        ['conv2d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)              (None, 1, 24, 16)            0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 1, 24, 16)            784       ['re_lu_6[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 1, 24, 16)            64        ['conv2d_7[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)              (None, 1, 24, 16)            0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 1, 24, 64)            1088      ['re_lu_7[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 1, 24, 64)            256       ['conv2d_8[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 1, 24, 64)            4160      ['re_lu_5[0][0]']             \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 1, 24, 64)            0         ['batch_normalization_8[0][0]'\n",
      "                                                                    , 'conv2d_5[0][0]']           \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)              (None, 1, 24, 64)            0         ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 1, 24, 16)            1040      ['re_lu_8[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 1, 24, 16)            64        ['conv2d_10[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)              (None, 1, 24, 16)            0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 1, 24, 16)            784       ['re_lu_9[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 1, 24, 16)            64        ['conv2d_11[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)             (None, 1, 24, 16)            0         ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 1, 24, 64)            1088      ['re_lu_10[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 1, 24, 64)            256       ['conv2d_12[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 1, 24, 64)            4160      ['re_lu_8[0][0]']             \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, 1, 24, 64)            0         ['batch_normalization_11[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'conv2d_9[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)             (None, 1, 24, 64)            0         ['add_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 1, 24, 16)            1040      ['re_lu_11[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 1, 24, 16)            64        ['conv2d_14[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)             (None, 1, 24, 16)            0         ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 1, 24, 16)            784       ['re_lu_12[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 1, 24, 16)            64        ['conv2d_15[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_13 (ReLU)             (None, 1, 24, 16)            0         ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 1, 24, 64)            1088      ['re_lu_13[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (None, 1, 24, 64)            256       ['conv2d_16[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 1, 24, 64)            4160      ['re_lu_11[0][0]']            \n",
      "                                                                                                  \n",
      " add_3 (Add)                 (None, 1, 24, 64)            0         ['batch_normalization_14[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'conv2d_13[0][0]']           \n",
      "                                                                                                  \n",
      " re_lu_14 (ReLU)             (None, 1, 24, 64)            0         ['add_3[0][0]']               \n",
      "                                                                                                  \n",
      " average_pooling2d (Average  (None, 1, 12, 64)            0         ['re_lu_14[0][0]']            \n",
      " Pooling2D)                                                                                       \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 768)                  0         ['average_pooling2d[0][0]']   \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 2)                    1538      ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 33154 (129.51 KB)\n",
      "Trainable params: 32386 (126.51 KB)\n",
      "Non-trainable params: 768 (3.00 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizers.Adam(learning_rate=learning_rate), \n",
    "            loss='categorical_crossentropy',\n",
    "            #loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=['accuracy'])\n",
    "model.build(input_shape=(None, 50, 9))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train.shape:  (16384, 2)\n",
      "y_val.shape:  (4097, 2)\n",
      "X_train.shape:  (16384, 50, 9)\n",
      "y_train.shape:  (16384, 2)\n",
      "Epoch 1/50\n",
      "256/256 [==============================] - 13s 23ms/step - loss: 1.5761 - accuracy: 0.8129 - val_loss: 0.3823 - val_accuracy: 0.8994 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 0.7098 - accuracy: 0.8772 - val_loss: 0.4687 - val_accuracy: 0.8665 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 0.5412 - accuracy: 0.8978 - val_loss: 0.3020 - val_accuracy: 0.8980 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 0.4720 - accuracy: 0.9099 - val_loss: 0.1643 - val_accuracy: 0.9497 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 0.3963 - accuracy: 0.9252 - val_loss: 0.1255 - val_accuracy: 0.9644 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "256/256 [==============================] - 5s 19ms/step - loss: 0.4374 - accuracy: 0.9161 - val_loss: 0.2673 - val_accuracy: 0.9126 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 0.4707 - accuracy: 0.9159 - val_loss: 0.2218 - val_accuracy: 0.9363 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 0.3839 - accuracy: 0.9244 - val_loss: 0.2474 - val_accuracy: 0.9253 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 0.3464 - accuracy: 0.9341 - val_loss: 0.4326 - val_accuracy: 0.8697 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3751 - accuracy: 0.9254\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 0.3740 - accuracy: 0.9255 - val_loss: 0.2120 - val_accuracy: 0.9375 - lr: 5.0000e-04\n",
      "Epoch 10: early stopping\n"
     ]
    }
   ],
   "source": [
    "\"\"\" train(train_dataloader, model_ConvLSTM, loss_fn, optimizer,val_dataloader, \n",
    "           patience=patience, scheduler=scheduler, epochs=epochs, device=device, B_size=B_size, A_size=A_size) \"\"\"\n",
    "# Train the model\n",
    "# Train the model without using batches\n",
    "# Compile the model\n",
    "# Ensure y_train and y_val are one-hot encoded only once\n",
    "if y_train.ndim == 1:\n",
    "    y_train = to_categorical(y_train)\n",
    "if y_val.ndim == 1:\n",
    "    y_val = to_categorical(y_val)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('y_val.shape: ', y_val.shape)\n",
    "\n",
    "# Calculate class weights\n",
    "B_multiplier = 1\n",
    "A_multiplier = B_size / A_size\n",
    "class_weight = {0: B_multiplier, 1: A_multiplier}\n",
    "\n",
    "# Ensure y_train and y_val are one-hot encoded only once\n",
    "es = callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=patience)\n",
    "lrs = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=patience, verbose=1)\n",
    "print('X_train.shape: ', X_train.shape) # (23291, 50, 9)\n",
    "print('y_train.shape: ', y_train.shape) # (23291,)\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "          validation_data=(X_val, y_val), \n",
    "          epochs=epochs, \n",
    "          batch_size=batch_size,\n",
    "          callbacks=[es, lrs],\n",
    "          class_weight=class_weight) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f751619a7d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.shape:  (230, 50, 9)\n",
      "8/8 - 1s - loss: 0.1997 - accuracy: 0.9478 - 553ms/epoch - 69ms/step\n",
      "Test loss: [0.19974111020565033, 0.947826087474823]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "if y_test.ndim == 1:\n",
    "    y_test = to_categorical(y_test)\n",
    "test_loss = model.evaluate(X_test, y_test, verbose=2)\n",
    "print('Test loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step\n",
      "[[107   5]\n",
      " [  7 111]]\n",
      "Confusion matrix, without normalization\n",
      "[[107   5]\n",
      " [  7 111]]\n",
      "accuracy:  0.9478260869565217\n",
      "f1_score:  0.9487179487179486\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert y_test back to its original form\n",
    "y_test_original = np.argmax(y_test, axis=-1)\n",
    "\n",
    "# Get the model's predictions\n",
    "predictions = np.argmax(model.predict(X_test), axis=-1)\n",
    "\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test_original, predictions)\n",
    "\n",
    "print(cm)\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(cm, classes=['Not Fall', 'Fall'], normalize=False, title='Confusion Matrix')\n",
    "\n",
    "# get accuracy\n",
    "accuracy_fp = (cm[0][0] + cm[1][1]) / np.sum(cm)\n",
    "print('accuracy: ', accuracy_fp)\n",
    "# f1 score\n",
    "precision_fp = cm[1][1] / (cm[1][1] + cm[0][1])\n",
    "recall_fp = cm[1][1] / (cm[1][1] + cm[1][0])\n",
    "f1_score_fp = 2 * precision_fp * recall_fp / (precision_fp + recall_fp)\n",
    "print('f1_score: ', f1_score_fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpdowdryw2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpdowdryw2/assets\n",
      "2023-12-10 20:49:09.076616: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2023-12-10 20:49:09.076676: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2023-12-10 20:49:09.076894: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpdowdryw2\n",
      "2023-12-10 20:49:09.081684: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2023-12-10 20:49:09.081708: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpdowdryw2\n",
      "2023-12-10 20:49:09.103466: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-12-10 20:49:09.340391: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpdowdryw2\n",
      "2023-12-10 20:49:09.414378: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 337489 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 42, Total Ops 75, % non-converted = 56.00 %\n",
      " * 42 ARITH ops\n",
      "\n",
      "- arith.constant:   42 occurrences  (f32: 36, i32: 6)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 17)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (i32: 1)\n",
      "  (f32: 2)\n",
      "  (i32: 1)\n",
      "  (f32: 1)\n",
      "  (i32: 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "141308"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('./saved_models/'+model_name+'.keras')\n",
    "# convert the model to tflite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "if model_name==\"ConvLSTM_VGG\":\n",
    "    converter._experimental_lower_tensor_list_ops = False\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "model_tflite = converter.convert()\n",
    "# save the model\n",
    "open('./saved_models/'+model_name+'.tflite', \"wb\").write(model_tflite)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"TinyFallNet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 50, 9)]              0         []                            \n",
      "                                                                                                  \n",
      " quantize_layer (QuantizeLa  (None, 50, 9)                3         ['input_1[0][0]']             \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " quant_reshape (QuantizeWra  (None, 1, 50, 9)             1         ['quantize_layer[0][0]']      \n",
      " pperV2)                                                                                          \n",
      "                                                                                                  \n",
      " quant_conv2d (QuantizeWrap  (None, 1, 48, 64)            1923      ['quant_reshape[0][0]']       \n",
      " perV2)                                                                                           \n",
      "                                                                                                  \n",
      " quant_max_pooling2d (Quant  (None, 1, 24, 64)            1         ['quant_conv2d[0][0]']        \n",
      " izeWrapperV2)                                                                                    \n",
      "                                                                                                  \n",
      " quant_conv2d_2 (QuantizeWr  (None, 1, 24, 16)            1073      ['quant_max_pooling2d[0][0]'] \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_2[0][0]']      \n",
      " 3 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_re_lu_3 (QuantizeWra  (None, 1, 24, 16)            3         ['quant_batch_normalization_3[\n",
      " pperV2)                                                            0][0]']                       \n",
      "                                                                                                  \n",
      " quant_conv2d_3 (QuantizeWr  (None, 1, 24, 16)            817       ['quant_re_lu_3[0][0]']       \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_3[0][0]']      \n",
      " 4 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_re_lu_4 (QuantizeWra  (None, 1, 24, 16)            3         ['quant_batch_normalization_4[\n",
      " pperV2)                                                            0][0]']                       \n",
      "                                                                                                  \n",
      " quant_conv2d_4 (QuantizeWr  (None, 1, 24, 64)            1217      ['quant_re_lu_4[0][0]']       \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 64)            259       ['quant_conv2d_4[0][0]']      \n",
      " 5 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_conv2d_1 (QuantizeWr  (None, 1, 24, 64)            4291      ['quant_max_pooling2d[0][0]'] \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_add (QuantizeWrapper  (None, 1, 24, 64)            1         ['quant_batch_normalization_5[\n",
      " V2)                                                                0][0]',                       \n",
      "                                                                     'quant_conv2d_1[0][0]']      \n",
      "                                                                                                  \n",
      " quant_re_lu_5 (QuantizeWra  (None, 1, 24, 64)            3         ['quant_add[0][0]']           \n",
      " pperV2)                                                                                          \n",
      "                                                                                                  \n",
      " quant_conv2d_6 (QuantizeWr  (None, 1, 24, 16)            1073      ['quant_re_lu_5[0][0]']       \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_6[0][0]']      \n",
      " 6 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_re_lu_6 (QuantizeWra  (None, 1, 24, 16)            3         ['quant_batch_normalization_6[\n",
      " pperV2)                                                            0][0]']                       \n",
      "                                                                                                  \n",
      " quant_conv2d_7 (QuantizeWr  (None, 1, 24, 16)            817       ['quant_re_lu_6[0][0]']       \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_7[0][0]']      \n",
      " 7 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_re_lu_7 (QuantizeWra  (None, 1, 24, 16)            3         ['quant_batch_normalization_7[\n",
      " pperV2)                                                            0][0]']                       \n",
      "                                                                                                  \n",
      " quant_conv2d_8 (QuantizeWr  (None, 1, 24, 64)            1217      ['quant_re_lu_7[0][0]']       \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 64)            259       ['quant_conv2d_8[0][0]']      \n",
      " 8 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_conv2d_5 (QuantizeWr  (None, 1, 24, 64)            4291      ['quant_re_lu_5[0][0]']       \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_add_1 (QuantizeWrapp  (None, 1, 24, 64)            1         ['quant_batch_normalization_8[\n",
      " erV2)                                                              0][0]',                       \n",
      "                                                                     'quant_conv2d_5[0][0]']      \n",
      "                                                                                                  \n",
      " quant_re_lu_8 (QuantizeWra  (None, 1, 24, 64)            3         ['quant_add_1[0][0]']         \n",
      " pperV2)                                                                                          \n",
      "                                                                                                  \n",
      " quant_conv2d_10 (QuantizeW  (None, 1, 24, 16)            1073      ['quant_re_lu_8[0][0]']       \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_10[0][0]']     \n",
      " 9 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_re_lu_9 (QuantizeWra  (None, 1, 24, 16)            3         ['quant_batch_normalization_9[\n",
      " pperV2)                                                            0][0]']                       \n",
      "                                                                                                  \n",
      " quant_conv2d_11 (QuantizeW  (None, 1, 24, 16)            817       ['quant_re_lu_9[0][0]']       \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_11[0][0]']     \n",
      " 10 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_10 (QuantizeWr  (None, 1, 24, 16)            3         ['quant_batch_normalization_10\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_12 (QuantizeW  (None, 1, 24, 64)            1217      ['quant_re_lu_10[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 64)            259       ['quant_conv2d_12[0][0]']     \n",
      " 11 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_conv2d_9 (QuantizeWr  (None, 1, 24, 64)            4291      ['quant_re_lu_8[0][0]']       \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_add_2 (QuantizeWrapp  (None, 1, 24, 64)            1         ['quant_batch_normalization_11\n",
      " erV2)                                                              [0][0]',                      \n",
      "                                                                     'quant_conv2d_9[0][0]']      \n",
      "                                                                                                  \n",
      " quant_re_lu_11 (QuantizeWr  (None, 1, 24, 64)            3         ['quant_add_2[0][0]']         \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_conv2d_14 (QuantizeW  (None, 1, 24, 16)            1073      ['quant_re_lu_11[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_14[0][0]']     \n",
      " 12 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_12 (QuantizeWr  (None, 1, 24, 16)            3         ['quant_batch_normalization_12\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_15 (QuantizeW  (None, 1, 24, 16)            817       ['quant_re_lu_12[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_15[0][0]']     \n",
      " 13 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_13 (QuantizeWr  (None, 1, 24, 16)            3         ['quant_batch_normalization_13\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_16 (QuantizeW  (None, 1, 24, 64)            1217      ['quant_re_lu_13[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 64)            259       ['quant_conv2d_16[0][0]']     \n",
      " 14 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_conv2d_13 (QuantizeW  (None, 1, 24, 64)            4291      ['quant_re_lu_11[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_add_3 (QuantizeWrapp  (None, 1, 24, 64)            1         ['quant_batch_normalization_14\n",
      " erV2)                                                              [0][0]',                      \n",
      "                                                                     'quant_conv2d_13[0][0]']     \n",
      "                                                                                                  \n",
      " quant_re_lu_14 (QuantizeWr  (None, 1, 24, 64)            3         ['quant_add_3[0][0]']         \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_average_pooling2d (Q  (None, 1, 12, 64)            3         ['quant_re_lu_14[0][0]']      \n",
      " uantizeWrapperV2)                                                                                \n",
      "                                                                                                  \n",
      " quant_flatten_1 (QuantizeW  (None, 768)                  1         ['quant_average_pooling2d[0][0\n",
      " rapperV2)                                                          ]']                           \n",
      "                                                                                                  \n",
      " quant_dense_2 (QuantizeWra  (None, 2)                    1543      ['quant_flatten_1[0][0]']     \n",
      " pperV2)                                                                                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 34663 (135.40 KB)\n",
      "Trainable params: 32386 (126.51 KB)\n",
      "Non-trainable params: 2277 (8.89 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.load_model('./saved_models/'+model_name+'.keras')\n",
    "q_model = tfmot.quantization.keras.quantize_model(model)\n",
    "q_model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "                loss='categorical_crossentropy',\n",
    "                #loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "q_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpr12l9ff_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpr12l9ff_/assets\n",
      "/home/liyinrong/miniconda3/envs/tensorflow-dev/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2023-12-10 20:49:48.662043: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2023-12-10 20:49:48.662131: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2023-12-10 20:49:48.662401: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpr12l9ff_\n",
      "2023-12-10 20:49:48.674117: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2023-12-10 20:49:48.674149: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpr12l9ff_\n",
      "2023-12-10 20:49:48.714119: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-12-10 20:49:48.970213: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpr12l9ff_\n",
      "2023-12-10 20:49:49.063049: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 400651 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 6, Total Ops 77, % non-converted = 7.79 %\n",
      " * 6 ARITH ops\n",
      "\n",
      "- arith.constant:    6 occurrences  (i32: 6)\n",
      "\n",
      "\n",
      "\n",
      "  (uq_8: 4)\n",
      "  (uq_8: 1)\n",
      "  (uq_8: 17)\n",
      "  (f32: 1)\n",
      "  (uq_8: 1)\n",
      "  (uq_8: 1)\n",
      "  (i32: 1)\n",
      "  (uq_8: 18, uq_32: 18)\n",
      "  (uq_8: 1)\n",
      "  (uq_8: 2)\n",
      "  (i32: 1)\n",
      "  (uq_8: 1)\n",
      "  (i32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: INT8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.float32'>\n",
      "output:  <class 'numpy.int8'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "69624"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_model.save('./saved_models/'+model_name+'_q.keras')\n",
    "# convert the QAT model to a fully quantized model using TFLite\n",
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(X_train.astype('float32')).batch(1).take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "# Set up the converter for quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# This is required for full integer quantization (including input and output)\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.float32  # Keep input as float32\n",
    "converter.inference_output_type = tf.int8  # Keep output as float32\n",
    "\n",
    "# Convert the model\n",
    "tflite_q_model = converter.convert()\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_q_model)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)\n",
    "# Save the quantized model to disk\n",
    "open('./saved_models/'+model_name+'_q.tflite', \"wb\").write(tflite_q_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train.shape:  (16384, 2)\n",
      "y_val.shape:  (4097, 2)\n",
      "Epoch 1/50\n",
      "256/256 [==============================] - 31s 88ms/step - loss: 0.7379 - accuracy: 0.8407 - val_loss: 0.2523 - val_accuracy: 0.8938 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "256/256 [==============================] - 22s 85ms/step - loss: 0.4672 - accuracy: 0.8992 - val_loss: 0.2058 - val_accuracy: 0.9199 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "256/256 [==============================] - 22s 87ms/step - loss: 0.3603 - accuracy: 0.9186 - val_loss: 0.3481 - val_accuracy: 0.8926 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "256/256 [==============================] - 23s 89ms/step - loss: 0.3387 - accuracy: 0.9258 - val_loss: 0.2232 - val_accuracy: 0.9295 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "256/256 [==============================] - 22s 86ms/step - loss: 0.3083 - accuracy: 0.9333 - val_loss: 0.1550 - val_accuracy: 0.9522 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "256/256 [==============================] - 22s 85ms/step - loss: 0.3756 - accuracy: 0.9184 - val_loss: 0.1782 - val_accuracy: 0.9412 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "256/256 [==============================] - 23s 91ms/step - loss: 0.3538 - accuracy: 0.9285 - val_loss: 0.4417 - val_accuracy: 0.8660 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "256/256 [==============================] - 22s 86ms/step - loss: 0.3915 - accuracy: 0.9263 - val_loss: 0.2023 - val_accuracy: 0.9395 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "256/256 [==============================] - 23s 90ms/step - loss: 0.3459 - accuracy: 0.9316 - val_loss: 0.2058 - val_accuracy: 0.9473 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "256/256 [==============================] - ETA: 0s - loss: 0.3067 - accuracy: 0.9370\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "256/256 [==============================] - 22s 87ms/step - loss: 0.3067 - accuracy: 0.9370 - val_loss: 0.1604 - val_accuracy: 0.9497 - lr: 5.0000e-04\n",
      "Epoch 10: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Ensure y_train and y_val are one-hot encoded only once\n",
    "if y_train.ndim == 1:\n",
    "    y_train = to_categorical(y_train)\n",
    "if y_val.ndim == 1:\n",
    "    y_val = to_categorical(y_val)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('y_val.shape: ', y_val.shape)\n",
    "\n",
    "q_history = q_model.fit(X_train, y_train, \n",
    "            validation_data=(X_val, y_val), \n",
    "            epochs=epochs, \n",
    "            batch_size=batch_size,\n",
    "            callbacks=[es, lrs],\n",
    "            class_weight=class_weight) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpqckl5l3y/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpqckl5l3y/assets\n",
      "/home/liyinrong/miniconda3/envs/tensorflow-dev/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.float32'>\n",
      "output:  <class 'numpy.int8'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 20:55:36.232474: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2023-12-10 20:55:36.232533: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2023-12-10 20:55:36.232703: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpqckl5l3y\n",
      "2023-12-10 20:55:36.242056: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2023-12-10 20:55:36.242085: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpqckl5l3y\n",
      "2023-12-10 20:55:36.286959: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-12-10 20:55:36.730047: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpqckl5l3y\n",
      "2023-12-10 20:55:36.862110: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 629409 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 6, Total Ops 78, % non-converted = 7.69 %\n",
      " * 6 ARITH ops\n",
      "\n",
      "- arith.constant:    6 occurrences  (i32: 6)\n",
      "\n",
      "\n",
      "\n",
      "  (uq_8: 4)\n",
      "  (uq_8: 1)\n",
      "  (uq_8: 17)\n",
      "  (f32: 1)\n",
      "  (uq_8: 1)\n",
      "  (uq_8: 1)\n",
      "  (i32: 1)\n",
      "  (uq_8: 18, uq_32: 18)\n",
      "  (uq_8: 2)\n",
      "  (uq_8: 2)\n",
      "  (i32: 1)\n",
      "  (uq_8: 1)\n",
      "  (i32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: INT8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "69912"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_model.save('./saved_models/'+model_name+'_qat.keras')  # The file needs to end with the .keras extension\n",
    "# convert the QAT model to a fully quantized model using TFLite\n",
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(X_train.astype('float32')).batch(1).take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "# Set up the converter for quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# This is required for full integer quantization (including input and output)\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.float32  # Keep input as float32\n",
    "converter.inference_output_type = tf.int8  # Keep output as float32\n",
    "\n",
    "# Convert the model\n",
    "tflite_q_model = converter.convert()\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_content=tflite_q_model)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)\n",
    "# Save the quantized model to disk\n",
    "open('./saved_models/'+model_name+'_qat.tflite', \"wb\").write(tflite_q_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"TinyFallNet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 50, 9)]              0         []                            \n",
      "                                                                                                  \n",
      " prune_low_magnitude_reshap  (None, 1, 50, 9)             1         ['input_1[0][0]']             \n",
      " e (PruneLowMagnitude)                                                                            \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 48, 64)            3522      ['prune_low_magnitude_reshape[\n",
      "  (PruneLowMagnitude)                                               0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_max_po  (None, 1, 24, 64)            1         ['prune_low_magnitude_conv2d[0\n",
      " oling2d (PruneLowMagnitude                                         ][0]']                        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 16)            2066      ['prune_low_magnitude_max_pool\n",
      " _2 (PruneLowMagnitude)                                             ing2d[0][0]']                 \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 16)            65        ['prune_low_magnitude_conv2d_2\n",
      " normalization_3 (PruneLowM                                         [0][0]']                      \n",
      " agnitude)                                                                                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 3 (PruneLowMagnitude)                                              rmalization_3[0][0]']         \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 16)            1554      ['prune_low_magnitude_re_lu_3[\n",
      " _3 (PruneLowMagnitude)                                             0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 16)            65        ['prune_low_magnitude_conv2d_3\n",
      " normalization_4 (PruneLowM                                         [0][0]']                      \n",
      " agnitude)                                                                                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 4 (PruneLowMagnitude)                                              rmalization_4[0][0]']         \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 64)            2114      ['prune_low_magnitude_re_lu_4[\n",
      " _4 (PruneLowMagnitude)                                             0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 64)            257       ['prune_low_magnitude_conv2d_4\n",
      " normalization_5 (PruneLowM                                         [0][0]']                      \n",
      " agnitude)                                                                                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 64)            8258      ['prune_low_magnitude_max_pool\n",
      " _1 (PruneLowMagnitude)                                             ing2d[0][0]']                 \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add (P  (None, 1, 24, 64)            1         ['prune_low_magnitude_batch_no\n",
      " runeLowMagnitude)                                                  rmalization_5[0][0]',         \n",
      "                                                                     'prune_low_magnitude_conv2d_1\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 64)            1         ['prune_low_magnitude_add[0][0\n",
      " 5 (PruneLowMagnitude)                                              ]']                           \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 16)            2066      ['prune_low_magnitude_re_lu_5[\n",
      " _6 (PruneLowMagnitude)                                             0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 16)            65        ['prune_low_magnitude_conv2d_6\n",
      " normalization_6 (PruneLowM                                         [0][0]']                      \n",
      " agnitude)                                                                                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 6 (PruneLowMagnitude)                                              rmalization_6[0][0]']         \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 16)            1554      ['prune_low_magnitude_re_lu_6[\n",
      " _7 (PruneLowMagnitude)                                             0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 16)            65        ['prune_low_magnitude_conv2d_7\n",
      " normalization_7 (PruneLowM                                         [0][0]']                      \n",
      " agnitude)                                                                                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 7 (PruneLowMagnitude)                                              rmalization_7[0][0]']         \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 64)            2114      ['prune_low_magnitude_re_lu_7[\n",
      " _8 (PruneLowMagnitude)                                             0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 64)            257       ['prune_low_magnitude_conv2d_8\n",
      " normalization_8 (PruneLowM                                         [0][0]']                      \n",
      " agnitude)                                                                                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 64)            8258      ['prune_low_magnitude_re_lu_5[\n",
      " _5 (PruneLowMagnitude)                                             0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_1   (None, 1, 24, 64)            1         ['prune_low_magnitude_batch_no\n",
      " (PruneLowMagnitude)                                                rmalization_8[0][0]',         \n",
      "                                                                     'prune_low_magnitude_conv2d_5\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 64)            1         ['prune_low_magnitude_add_1[0]\n",
      " 8 (PruneLowMagnitude)                                              [0]']                         \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 16)            2066      ['prune_low_magnitude_re_lu_8[\n",
      " _10 (PruneLowMagnitude)                                            0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 16)            65        ['prune_low_magnitude_conv2d_1\n",
      " normalization_9 (PruneLowM                                         0[0][0]']                     \n",
      " agnitude)                                                                                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 9 (PruneLowMagnitude)                                              rmalization_9[0][0]']         \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 16)            1554      ['prune_low_magnitude_re_lu_9[\n",
      " _11 (PruneLowMagnitude)                                            0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 16)            65        ['prune_low_magnitude_conv2d_1\n",
      " normalization_10 (PruneLow                                         1[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 10 (PruneLowMagnitude)                                             rmalization_10[0][0]']        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 64)            2114      ['prune_low_magnitude_re_lu_10\n",
      " _12 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 64)            257       ['prune_low_magnitude_conv2d_1\n",
      " normalization_11 (PruneLow                                         2[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 64)            8258      ['prune_low_magnitude_re_lu_8[\n",
      " _9 (PruneLowMagnitude)                                             0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_2   (None, 1, 24, 64)            1         ['prune_low_magnitude_batch_no\n",
      " (PruneLowMagnitude)                                                rmalization_11[0][0]',        \n",
      "                                                                     'prune_low_magnitude_conv2d_9\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 64)            1         ['prune_low_magnitude_add_2[0]\n",
      " 11 (PruneLowMagnitude)                                             [0]']                         \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 16)            2066      ['prune_low_magnitude_re_lu_11\n",
      " _14 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 16)            65        ['prune_low_magnitude_conv2d_1\n",
      " normalization_12 (PruneLow                                         4[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 12 (PruneLowMagnitude)                                             rmalization_12[0][0]']        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 16)            1554      ['prune_low_magnitude_re_lu_12\n",
      " _15 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 16)            65        ['prune_low_magnitude_conv2d_1\n",
      " normalization_13 (PruneLow                                         5[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 13 (PruneLowMagnitude)                                             rmalization_13[0][0]']        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 64)            2114      ['prune_low_magnitude_re_lu_13\n",
      " _16 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 24, 64)            257       ['prune_low_magnitude_conv2d_1\n",
      " normalization_14 (PruneLow                                         6[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 24, 64)            8258      ['prune_low_magnitude_re_lu_11\n",
      " _13 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_3   (None, 1, 24, 64)            1         ['prune_low_magnitude_batch_no\n",
      " (PruneLowMagnitude)                                                rmalization_14[0][0]',        \n",
      "                                                                     'prune_low_magnitude_conv2d_1\n",
      "                                                                    3[0][0]']                     \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 24, 64)            1         ['prune_low_magnitude_add_3[0]\n",
      " 14 (PruneLowMagnitude)                                             [0]']                         \n",
      "                                                                                                  \n",
      " prune_low_magnitude_averag  (None, 1, 12, 64)            1         ['prune_low_magnitude_re_lu_14\n",
      " e_pooling2d (PruneLowMagni                                         [0][0]']                      \n",
      " tude)                                                                                            \n",
      "                                                                                                  \n",
      " prune_low_magnitude_flatte  (None, 768)                  1         ['prune_low_magnitude_average_\n",
      " n_1 (PruneLowMagnitude)                                            pooling2d[0][0]']             \n",
      "                                                                                                  \n",
      " prune_low_magnitude_dense_  (None, 2)                    3076      ['prune_low_magnitude_flatten_\n",
      " 2 (PruneLowMagnitude)                                              1[0][0]']                     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 64134 (250.72 KB)\n",
      "Trainable params: 32386 (126.51 KB)\n",
      "Non-trainable params: 31748 (124.21 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Unstrucutred pruning with constant sparsity\n",
    "pruning_params = {\n",
    "        'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(0.5, begin_step=2000, frequency=100),\n",
    "}\n",
    "\n",
    "# Create a pruning model\n",
    "pruned_model_unstructured = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "pruned_model_unstructured.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "                loss='categorical_crossentropy',\n",
    "                #loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "pruned_model_unstructured.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "256/256 [==============================] - 27s 47ms/step - loss: 0.4478 - accuracy: 0.9227 - val_loss: 0.2168 - val_accuracy: 0.9375 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "256/256 [==============================] - 11s 44ms/step - loss: 0.4022 - accuracy: 0.9233 - val_loss: 0.2707 - val_accuracy: 0.9221 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "256/256 [==============================] - 11s 45ms/step - loss: 0.2752 - accuracy: 0.9426 - val_loss: 0.1428 - val_accuracy: 0.9609 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "256/256 [==============================] - 11s 43ms/step - loss: 0.2892 - accuracy: 0.9426 - val_loss: 0.1520 - val_accuracy: 0.9492 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "256/256 [==============================] - 11s 43ms/step - loss: 0.2797 - accuracy: 0.9425 - val_loss: 0.1757 - val_accuracy: 0.9512 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "256/256 [==============================] - 12s 45ms/step - loss: 0.2852 - accuracy: 0.9418 - val_loss: 0.1789 - val_accuracy: 0.9470 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "256/256 [==============================] - 11s 43ms/step - loss: 0.2644 - accuracy: 0.9451 - val_loss: 0.2113 - val_accuracy: 0.9400 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.3988 - accuracy: 0.9261\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "256/256 [==============================] - 12s 48ms/step - loss: 0.4007 - accuracy: 0.9261 - val_loss: 0.3294 - val_accuracy: 0.8987 - lr: 5.0000e-04\n",
      "Epoch 8: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f751694df60>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_model_unstructured.fit(X_train, y_train, \n",
    "            validation_data=(X_val, y_val), \n",
    "            epochs=epochs, \n",
    "            batch_size=batch_size,\n",
    "            callbacks=[es, lrs, pruning_callbacks.UpdatePruningStep()],\n",
    "            class_weight=class_weight) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned model loss:  0.3292510509490967\n",
      "Pruned model accuracy:  0.8826087117195129\n",
      "Full-precision model accuracy:  0.9478260869565217\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the test set\n",
    "pruned_loss_unstructured, pruned_acc_unstructured = pruned_model_unstructured.evaluate(X_test, y_test, verbose=0)\n",
    "print('Pruned model loss: ', pruned_loss_unstructured)\n",
    "print('Pruned model accuracy: ', pruned_acc_unstructured)\n",
    "print('Full-precision model accuracy: ', accuracy_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0y0b2zhp/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0y0b2zhp/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the unstructured pruned model:  77733\n",
      "Size of the full-precision model:  122558\n",
      "The achieved compression ratio is 1.00x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 20:58:31.296864: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2023-12-10 20:58:31.296915: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2023-12-10 20:58:31.297089: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp0y0b2zhp\n",
      "2023-12-10 20:58:31.300618: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2023-12-10 20:58:31.300650: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp0y0b2zhp\n",
      "2023-12-10 20:58:31.314618: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-12-10 20:58:31.433746: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp0y0b2zhp\n",
      "2023-12-10 20:58:31.484502: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 187413 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 42, Total Ops 75, % non-converted = 56.00 %\n",
      " * 42 ARITH ops\n",
      "\n",
      "- arith.constant:   42 occurrences  (f32: 36, i32: 6)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 17)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (i32: 1)\n",
      "  (f32: 2)\n",
      "  (i32: 1)\n",
      "  (f32: 1)\n",
      "  (i32: 1)\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "pruned_model_unstructured.save('./saved_models/'+model_name+'_pruned_unstructured.keras')  # The file needs to end with the .keras extension\n",
    "#print('Saved pruned Keras model to:', os.path.abspath(pruned_keras_file_unstructured))\n",
    "\n",
    "# Conversion to TF Lite\n",
    "pruned_model_unstructured_for_export = tfmot.sparsity.keras.strip_pruning(pruned_model_unstructured)\n",
    "\n",
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model_unstructured_for_export)\n",
    "pruned_tflite_model_unstructured = converter.convert()\n",
    "\n",
    "# Save the model\n",
    "pruned_tflite_file_unstructured = './saved_models/'+model_name+'_pruned_unstructured.tflite'\n",
    "\n",
    "with open(pruned_tflite_file_unstructured, 'wb') as f:\n",
    "    f.write(pruned_tflite_model_unstructured)\n",
    "\n",
    "# print('Saved pruned TFLite model to:', os.path.abspath(pruned_tflite_file_unstructured))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the size of the pruned model and the full-precision model\n",
    "print('Size of the unstructured pruned model: ', get_gzipped_model_size('./saved_models/'+model_name+'_pruned_unstructured.tflite'))\n",
    "print('Size of the full-precision model: ', get_gzipped_model_size('./saved_models/'+model_name+'.tflite'))\n",
    "print(\"The achieved compression ratio is %.2fx\" % (get_gzipped_model_size('./saved_models/'+model_name+'.tflite') / get_gzipped_model_size('./saved_models/'+model_name+'_pruned_unstructured.tflite')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PQAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"TinyFallNet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 50, 9)]              0         []                            \n",
      "                                                                                                  \n",
      " quantize_layer_1 (Quantize  (None, 50, 9)                3         ['input_1[0][0]']             \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " quant_reshape (QuantizeWra  (None, 1, 50, 9)             1         ['quantize_layer_1[0][0]']    \n",
      " pperV2)                                                                                          \n",
      "                                                                                                  \n",
      " quant_conv2d (QuantizeWrap  (None, 1, 48, 64)            1923      ['quant_reshape[0][0]']       \n",
      " perV2)                                                                                           \n",
      "                                                                                                  \n",
      " quant_max_pooling2d (Quant  (None, 1, 24, 64)            1         ['quant_conv2d[0][0]']        \n",
      " izeWrapperV2)                                                                                    \n",
      "                                                                                                  \n",
      " quant_conv2d_2 (QuantizeWr  (None, 1, 24, 16)            1073      ['quant_max_pooling2d[0][0]'] \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_2[0][0]']      \n",
      " 3 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_re_lu_3 (QuantizeWra  (None, 1, 24, 16)            3         ['quant_batch_normalization_3[\n",
      " pperV2)                                                            0][0]']                       \n",
      "                                                                                                  \n",
      " quant_conv2d_3 (QuantizeWr  (None, 1, 24, 16)            817       ['quant_re_lu_3[0][0]']       \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_3[0][0]']      \n",
      " 4 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_re_lu_4 (QuantizeWra  (None, 1, 24, 16)            3         ['quant_batch_normalization_4[\n",
      " pperV2)                                                            0][0]']                       \n",
      "                                                                                                  \n",
      " quant_conv2d_4 (QuantizeWr  (None, 1, 24, 64)            1217      ['quant_re_lu_4[0][0]']       \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 64)            259       ['quant_conv2d_4[0][0]']      \n",
      " 5 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_conv2d_1 (QuantizeWr  (None, 1, 24, 64)            4291      ['quant_max_pooling2d[0][0]'] \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_add (QuantizeWrapper  (None, 1, 24, 64)            1         ['quant_batch_normalization_5[\n",
      " V2)                                                                0][0]',                       \n",
      "                                                                     'quant_conv2d_1[0][0]']      \n",
      "                                                                                                  \n",
      " quant_re_lu_5 (QuantizeWra  (None, 1, 24, 64)            3         ['quant_add[0][0]']           \n",
      " pperV2)                                                                                          \n",
      "                                                                                                  \n",
      " quant_conv2d_6 (QuantizeWr  (None, 1, 24, 16)            1073      ['quant_re_lu_5[0][0]']       \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_6[0][0]']      \n",
      " 6 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_re_lu_6 (QuantizeWra  (None, 1, 24, 16)            3         ['quant_batch_normalization_6[\n",
      " pperV2)                                                            0][0]']                       \n",
      "                                                                                                  \n",
      " quant_conv2d_7 (QuantizeWr  (None, 1, 24, 16)            817       ['quant_re_lu_6[0][0]']       \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_7[0][0]']      \n",
      " 7 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_re_lu_7 (QuantizeWra  (None, 1, 24, 16)            3         ['quant_batch_normalization_7[\n",
      " pperV2)                                                            0][0]']                       \n",
      "                                                                                                  \n",
      " quant_conv2d_8 (QuantizeWr  (None, 1, 24, 64)            1217      ['quant_re_lu_7[0][0]']       \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 64)            259       ['quant_conv2d_8[0][0]']      \n",
      " 8 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_conv2d_5 (QuantizeWr  (None, 1, 24, 64)            4291      ['quant_re_lu_5[0][0]']       \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_add_1 (QuantizeWrapp  (None, 1, 24, 64)            1         ['quant_batch_normalization_8[\n",
      " erV2)                                                              0][0]',                       \n",
      "                                                                     'quant_conv2d_5[0][0]']      \n",
      "                                                                                                  \n",
      " quant_re_lu_8 (QuantizeWra  (None, 1, 24, 64)            3         ['quant_add_1[0][0]']         \n",
      " pperV2)                                                                                          \n",
      "                                                                                                  \n",
      " quant_conv2d_10 (QuantizeW  (None, 1, 24, 16)            1073      ['quant_re_lu_8[0][0]']       \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_10[0][0]']     \n",
      " 9 (QuantizeWrapperV2)                                                                            \n",
      "                                                                                                  \n",
      " quant_re_lu_9 (QuantizeWra  (None, 1, 24, 16)            3         ['quant_batch_normalization_9[\n",
      " pperV2)                                                            0][0]']                       \n",
      "                                                                                                  \n",
      " quant_conv2d_11 (QuantizeW  (None, 1, 24, 16)            817       ['quant_re_lu_9[0][0]']       \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_11[0][0]']     \n",
      " 10 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_10 (QuantizeWr  (None, 1, 24, 16)            3         ['quant_batch_normalization_10\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_12 (QuantizeW  (None, 1, 24, 64)            1217      ['quant_re_lu_10[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 64)            259       ['quant_conv2d_12[0][0]']     \n",
      " 11 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_conv2d_9 (QuantizeWr  (None, 1, 24, 64)            4291      ['quant_re_lu_8[0][0]']       \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_add_2 (QuantizeWrapp  (None, 1, 24, 64)            1         ['quant_batch_normalization_11\n",
      " erV2)                                                              [0][0]',                      \n",
      "                                                                     'quant_conv2d_9[0][0]']      \n",
      "                                                                                                  \n",
      " quant_re_lu_11 (QuantizeWr  (None, 1, 24, 64)            3         ['quant_add_2[0][0]']         \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_conv2d_14 (QuantizeW  (None, 1, 24, 16)            1073      ['quant_re_lu_11[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_14[0][0]']     \n",
      " 12 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_12 (QuantizeWr  (None, 1, 24, 16)            3         ['quant_batch_normalization_12\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_15 (QuantizeW  (None, 1, 24, 16)            817       ['quant_re_lu_12[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 16)            65        ['quant_conv2d_15[0][0]']     \n",
      " 13 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_13 (QuantizeWr  (None, 1, 24, 16)            3         ['quant_batch_normalization_13\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_16 (QuantizeW  (None, 1, 24, 64)            1217      ['quant_re_lu_13[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 24, 64)            259       ['quant_conv2d_16[0][0]']     \n",
      " 14 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_conv2d_13 (QuantizeW  (None, 1, 24, 64)            4291      ['quant_re_lu_11[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_add_3 (QuantizeWrapp  (None, 1, 24, 64)            1         ['quant_batch_normalization_14\n",
      " erV2)                                                              [0][0]',                      \n",
      "                                                                     'quant_conv2d_13[0][0]']     \n",
      "                                                                                                  \n",
      " quant_re_lu_14 (QuantizeWr  (None, 1, 24, 64)            3         ['quant_add_3[0][0]']         \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_average_pooling2d (Q  (None, 1, 12, 64)            3         ['quant_re_lu_14[0][0]']      \n",
      " uantizeWrapperV2)                                                                                \n",
      "                                                                                                  \n",
      " quant_flatten_1 (QuantizeW  (None, 768)                  1         ['quant_average_pooling2d[0][0\n",
      " rapperV2)                                                          ]']                           \n",
      "                                                                                                  \n",
      " quant_dense_2 (QuantizeWra  (None, 2)                    1543      ['quant_flatten_1[0][0]']     \n",
      " pperV2)                                                                                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 34663 (135.40 KB)\n",
      "Trainable params: 32386 (126.51 KB)\n",
      "Non-trainable params: 2277 (8.89 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# PQAT\n",
    "quant_aware_annotate_model = tfmot.quantization.keras.quantize_annotate_model(\n",
    "              pruned_model_unstructured_for_export)\n",
    "\n",
    "pruned_qat_model = tfmot.quantization.keras.quantize_apply(quant_aware_annotate_model,\n",
    "                   tfmot.experimental.combine.Default8BitPrunePreserveQuantizeScheme())\n",
    "\n",
    "pruned_qat_model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "pruned_qat_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (16384, 50, 9)\n",
      "y_train.shape:  (16384, 2)\n",
      "64\n",
      "Epoch 1/50\n",
      "256/256 [==============================] - 33s 93ms/step - loss: 0.7766 - accuracy: 0.8300 - val_loss: 0.2036 - val_accuracy: 0.9177 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "256/256 [==============================] - 22s 88ms/step - loss: 0.3962 - accuracy: 0.9116 - val_loss: 0.1793 - val_accuracy: 0.9348 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "256/256 [==============================] - 23s 90ms/step - loss: 0.3216 - accuracy: 0.9235 - val_loss: 0.1662 - val_accuracy: 0.9402 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "256/256 [==============================] - 23s 92ms/step - loss: 0.3149 - accuracy: 0.9293 - val_loss: 0.1733 - val_accuracy: 0.9414 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "256/256 [==============================] - 24s 94ms/step - loss: 0.2542 - accuracy: 0.9425 - val_loss: 0.1353 - val_accuracy: 0.9556 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "256/256 [==============================] - 24s 93ms/step - loss: 0.2329 - accuracy: 0.9481 - val_loss: 0.1548 - val_accuracy: 0.9448 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "256/256 [==============================] - 24s 93ms/step - loss: 0.2257 - accuracy: 0.9487 - val_loss: 0.1378 - val_accuracy: 0.9512 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "256/256 [==============================] - 22s 88ms/step - loss: 0.1782 - accuracy: 0.9587 - val_loss: 0.1721 - val_accuracy: 0.9446 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "256/256 [==============================] - 23s 89ms/step - loss: 0.1782 - accuracy: 0.9594 - val_loss: 0.1218 - val_accuracy: 0.9600 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "256/256 [==============================] - 23s 88ms/step - loss: 0.2101 - accuracy: 0.9545 - val_loss: 0.1832 - val_accuracy: 0.9434 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "256/256 [==============================] - 22s 86ms/step - loss: 0.1744 - accuracy: 0.9619 - val_loss: 0.1411 - val_accuracy: 0.9585 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "256/256 [==============================] - 23s 89ms/step - loss: 0.1678 - accuracy: 0.9641 - val_loss: 0.1237 - val_accuracy: 0.9585 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "256/256 [==============================] - 22s 85ms/step - loss: 0.1729 - accuracy: 0.9603 - val_loss: 0.1308 - val_accuracy: 0.9590 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "256/256 [==============================] - ETA: 0s - loss: 0.1838 - accuracy: 0.9615\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "256/256 [==============================] - 22s 85ms/step - loss: 0.1838 - accuracy: 0.9615 - val_loss: 0.1462 - val_accuracy: 0.9544 - lr: 5.0000e-04\n",
      "Epoch 14: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f75162af670>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('X_train.shape: ', X_train.shape) # (16362, 50, 9)\n",
    "print('y_train.shape: ', y_train.shape) # (16362, 2)\n",
    "print(batch_size)\n",
    "pruned_qat_model.fit(X_train, y_train, \n",
    "            validation_data=(X_val, y_val), \n",
    "            epochs=epochs, \n",
    "            batch_size=batch_size,\n",
    "            callbacks=[es, lrs, pruning_callbacks.UpdatePruningStep()],\n",
    "            class_weight=class_weight) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned QAT model loss:  0.22536268830299377\n",
      "Pruned QAT model accuracy:  0.9217391014099121\n",
      "Full-precision model accuracy:  0.9478260869565217\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the test set\n",
    "pruned_qat_loss, pruned_qat_acc = pruned_qat_model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Pruned QAT model loss: ', pruned_qat_loss)\n",
    "print('Pruned QAT model accuracy: ', pruned_qat_acc)\n",
    "print('Full-precision model accuracy: ', accuracy_fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0ovnamy2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp0ovnamy2/assets\n",
      "/home/liyinrong/miniconda3/envs/tensorflow-dev/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2023-12-10 21:05:13.995673: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2023-12-10 21:05:13.995750: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2023-12-10 21:05:13.996096: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp0ovnamy2\n",
      "2023-12-10 21:05:14.009020: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2023-12-10 21:05:14.009069: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp0ovnamy2\n",
      "2023-12-10 21:05:14.060891: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-12-10 21:05:14.470160: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp0ovnamy2\n",
      "2023-12-10 21:05:14.593197: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 597107 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 6, Total Ops 78, % non-converted = 7.69 %\n",
      " * 6 ARITH ops\n",
      "\n",
      "- arith.constant:    6 occurrences  (i32: 6)\n",
      "\n",
      "\n",
      "\n",
      "  (uq_8: 4)\n",
      "  (uq_8: 1)\n",
      "  (uq_8: 17)\n",
      "  (f32: 1)\n",
      "  (uq_8: 1)\n",
      "  (uq_8: 1)\n",
      "  (i32: 1)\n",
      "  (uq_8: 18, uq_32: 18)\n",
      "  (uq_8: 2)\n",
      "  (uq_8: 2)\n",
      "  (i32: 1)\n",
      "  (uq_8: 1)\n",
      "  (i32: 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "70096"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(pruned_qat_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "pruned_qat_tflite_model = converter.convert()\n",
    "\n",
    "# Save the model\n",
    "open('./saved_models/'+model_name+'_pqat.tflite', \"wb\").write(pruned_qat_tflite_model)\n",
    "\n",
    "# write TFLite model to a C source (or header) file\n",
    "#c_model_name = 'pruned_qat_fmnist'\n",
    "\n",
    "#with open('cfiles/' + c_model_name + '.h', 'w') as file:\n",
    "#    file.write(hex_to_c_array(pruned_qat_tflite_model, c_model_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  {'name': 'serving_default_input_1:0', 'index': 0, 'shape': array([ 1, 50,  9], dtype=int32), 'shape_signature': array([-1, 50,  9], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "output:  {'name': 'StatefulPartitionedCall:0', 'index': 75, 'shape': array([1, 2], dtype=int32), 'shape_signature': array([-1,  2], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "Evaluated on  0 .\n",
      "Evaluated on  100 .\n",
      "Evaluated on  200 .\n",
      "[[107   5]\n",
      " [ 12 106]]\n",
      "Confusion matrix, without normalization\n",
      "[[107   5]\n",
      " [ 12 106]]\n",
      "f1_score:  0.925764192139738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "WARNING: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors (tensor#29 is a dynamic-sized tensor).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the quantized model\n",
    "X_test_int8 = X_test.astype('float32')\n",
    "y_test_int8 = y_test.astype('int8')\n",
    "# Load the model into an interpreter\n",
    "interpreter = tf.lite.Interpreter(model_content= pruned_qat_tflite_model)\n",
    "# Allocate memory for the model's input Tensor(s)\n",
    "interpreter.allocate_tensors()\n",
    "# Get the model input and output details\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "print(\"input: \", input_details)\n",
    "print(\"output: \", output_details)\n",
    "predictions = np.zeros(X_test.shape[0])\n",
    "for i, test_data in enumerate(X_test_int8):\n",
    "    test_data = np.expand_dims(test_data, axis=0)\n",
    "    #print(test_data.shape)\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_data)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "    if i%100 == 0:\n",
    "        # print(\"Evaluated on %d images.\" % test_image_index)\n",
    "        print('Evaluated on ', i, '.')\n",
    "    predictions[i] = output.argmax()\n",
    "\n",
    "gt = np.argmax(y_test_int8, axis=-1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(gt, predictions)\n",
    "\n",
    "print(cm)\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(cm, classes=['Not Fall', 'Fall'], normalize=False, title='Confusion Matrix')\n",
    "\n",
    "# get accuracy\n",
    "#accuracy_fp = (cm[0][0] + cm[1][1]) / np.sum(cm)\n",
    "#print('accuracy: ', accuracy_fp)\n",
    "\n",
    "f1_score = 2 * cm[1][1] / (2 * cm[1][1] + cm[0][1] + cm[1][0])\n",
    "print('f1_score: ', f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the pruned QAT model:  33696\n",
      "Size of th QAT model:  43330\n",
      "Size of the full-precision model:  122558\n",
      "The achieved compression ratio is 3.64x\n"
     ]
    }
   ],
   "source": [
    "# compare the size of the pruned model and the full-precision model\n",
    "print('Size of the pruned QAT model: ', get_gzipped_model_size('./saved_models/'+model_name+'_pqat.tflite'))\n",
    "print('Size of th QAT model: ', get_gzipped_model_size('./saved_models/'+model_name+'_qat.tflite'))\n",
    "print('Size of the full-precision model: ', get_gzipped_model_size('./saved_models/'+model_name+'.tflite'))\n",
    "print(\"The achieved compression ratio is %.2fx\" % (get_gzipped_model_size('saved_models/TinyFallNet.tflite') / get_gzipped_model_size('./saved_models/'+model_name+'_pqat.tflite')))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fall_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
