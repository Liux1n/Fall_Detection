{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.signal import resample\n",
    "\n",
    "from data_organizer_Kfall import DataOrganizer\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from utils import train, test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/32 folder...\n",
      "Processing 2/32 folder...\n",
      "Processing 3/32 folder...\n",
      "Processing 4/32 folder...\n",
      "Processing 5/32 folder...\n",
      "Processing 6/32 folder...\n",
      "Processing 7/32 folder...\n",
      "Processing 8/32 folder...\n",
      "Processing 9/32 folder...\n",
      "Processing 10/32 folder...\n",
      "Processing 11/32 folder...\n",
      "Processing 12/32 folder...\n",
      "Processing 13/32 folder...\n",
      "Processing 14/32 folder...\n",
      "Processing 15/32 folder...\n",
      "Processing 16/32 folder...\n",
      "Processing 17/32 folder...\n",
      "Processing 18/32 folder...\n",
      "Processing 19/32 folder...\n",
      "Processing 20/32 folder...\n",
      "Processing 21/32 folder...\n",
      "Processing 22/32 folder...\n",
      "Processing 23/32 folder...\n",
      "Processing 24/32 folder...\n",
      "Processing 25/32 folder...\n",
      "Processing 26/32 folder...\n",
      "Processing 27/32 folder...\n",
      "Processing 28/32 folder...\n",
      "Processing 29/32 folder...\n",
      "Processing 30/32 folder...\n",
      "Processing 31/32 folder...\n",
      "Processing 32/32 folder...\n"
     ]
    }
   ],
   "source": [
    "# mac\n",
    "#sensor_data_folder = '/Users/liuxinqing/Documents/Kfall/sensor_data'  # Update with the path to sensor data\n",
    "#label_data_folder = '/Users/liuxinqing/Documents/Kfall/label_data'  \n",
    "# windows \n",
    "sensor_data_folder = 'G:\\MLonMCU\\Kfall_dataset\\sensor_data'  # Update with the path to sensor data\n",
    "label_data_folder = 'G:\\MLonMCU\\Kfall_dataset\\label_data' \n",
    "\n",
    "#window_size = 256\n",
    "# Kfall: window_size = 50\n",
    "window_size = 50\n",
    "threshold = 0.1\n",
    "num_window_fall_data = 50\n",
    "num_window_not_fall_data = 5\n",
    "\n",
    "data, label = DataOrganizer(sensor_data_folder, \n",
    "                            label_data_folder, \n",
    "                            window_size, \n",
    "                            threshold, \n",
    "                            num_window_fall_data, \n",
    "                            num_window_not_fall_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_channels:  50\n",
      "data.shape:  (25743, 50, 9)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "in_channels = data.shape[1]\n",
    "print('in_channels: ', in_channels)\n",
    "# the input data should have the shape (batch_size, in_channels, sequence_length)\n",
    "#data = data.reshape(data.shape[0], in_channels, -1)\n",
    "print('data.shape: ', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_size:  25020\n",
      "A_size:  723\n",
      "(58, 50, 9)\n",
      "X_train_tensor.dtype:  torch.float64\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "label = label.astype(np.int64)\n",
    "# (y == 0).sum()\n",
    "B_size = (label == 0).sum()\n",
    "A_size = (label == 1).sum()\n",
    "print('B_size: ', B_size)\t\n",
    "print('A_size: ', A_size)\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.05, random_state=42)\n",
    "\n",
    "# Further split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.05, random_state=42)\n",
    "\n",
    "#print(np.unique(y_train)) # [0 1]\n",
    "y_train = y_train.astype(np.int64)\n",
    "y_test = y_test.astype(np.int64)\n",
    "\n",
    "\n",
    "# select the test data that is not zero\n",
    "X_test_true = X_test[y_test != 0]\n",
    "y_test_true = y_test[y_test != 0]\n",
    "# length of the test data\n",
    "test_len = X_test_true.shape[0]\n",
    "X_test_false = X_test[y_test == 0]\n",
    "y_test_false = y_test[y_test == 0]\n",
    "# X_test.shape:  (17, 50, 9)\n",
    "# randomly len number of test data that is zero\n",
    "index = np.random.choice(X_test_false.shape[0], test_len, replace=False)\n",
    "# X_test.shape:  (17, 50, 9)\n",
    "# randomly len number of test data that is zero\n",
    "#index = np.random.choice(X_test_false.shape[0], len, replace=False)\n",
    "\n",
    "\n",
    "X_test_false = X_test[index]\n",
    "y_test_false = y_test[index]\n",
    "\n",
    "# concatenate the true and false test data\n",
    "X_test = np.concatenate((X_test_true, X_test_false), axis=0)\n",
    "y_test = np.concatenate((y_test_true, y_test_false), axis=0)\n",
    "#X_test = X_test[y_test != 0]\n",
    "#y_test = y_test[y_test != 0]\n",
    "print(X_test.shape)\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.from_numpy(X_train)\n",
    "y_train_tensor = torch.from_numpy(y_train)\n",
    "X_val_tensor = torch.from_numpy(X_val)\n",
    "y_val_tensor = torch.from_numpy(y_val)\n",
    "X_test_tensor = torch.from_numpy(X_test)\n",
    "y_test_tensor = torch.from_numpy(y_test)\n",
    "\n",
    "\n",
    "# print datatype of X_train_tensor\n",
    "X_train_tensor = X_train_tensor.double()\n",
    "print('X_train_tensor.dtype: ', X_train_tensor.dtype)\n",
    "X_test = X_train_tensor.double()\n",
    "\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 5e-4\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(nn.Conv1d(in_channels=9, out_channels=64, kernel_size=3, padding=1),\n",
    "                                   nn.BatchNorm1d(64),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool1d(2))\n",
    "        self.conv2 = nn.Sequential(nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "                                   nn.BatchNorm1d(64),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool1d(2))\n",
    "        self.conv3 = nn.Sequential(nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "                                   nn.BatchNorm1d(64),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool1d(2))\n",
    "\n",
    "        # LSTM layers\n",
    "        self.lstm1 = nn.LSTM(input_size=64, hidden_size=64, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.lstm2 = nn.LSTM(input_size=64, hidden_size=64, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc = nn.Linear(64, 2)  # No need for softmax here when using nn.CrossEntropyLoss\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = x.transpose(1, 2)  # Transpose to have the correct dimensions for Conv1d (batch, channels, length)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        # Prepare for LSTM\n",
    "        x = x.transpose(1, 2)  # Transpose back to (batch, seq_len, features)\n",
    "        \n",
    "        # LSTM layers\n",
    "        x, _ = self.lstm1(x)  # Only take the output, ignore hidden states\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm2(x)  # Only take the output, ignore hidden states\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        # Take the outputs of the last time step\n",
    "        x = x[:, -1, :]\n",
    "        \n",
    "        # Fully connected layer\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: ConvLSTM(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv1d(9, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (lstm1): LSTM(64, 64, batch_first=True)\n",
      "  (dropout1): Dropout(p=0.5, inplace=False)\n",
      "  (lstm2): LSTM(64, 64, batch_first=True)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "Layer: conv1.0.weight | Size: torch.Size([64, 9, 3]) | Values : tensor([[[-0.1507,  0.1612,  0.1651],\n",
      "         [ 0.1912, -0.1131,  0.0360],\n",
      "         [ 0.1272,  0.0811, -0.0859],\n",
      "         [-0.1325,  0.0079, -0.1032],\n",
      "         [-0.0307, -0.1003,  0.1187],\n",
      "         [-0.1916, -0.0495,  0.0966],\n",
      "         [-0.1424, -0.0791, -0.0842],\n",
      "         [-0.1141, -0.1124, -0.1090],\n",
      "         [-0.0024, -0.1888, -0.1741]],\n",
      "\n",
      "        [[ 0.1453,  0.0325, -0.1730],\n",
      "         [ 0.1803,  0.0251,  0.0602],\n",
      "         [-0.0186,  0.1129, -0.0809],\n",
      "         [-0.1299, -0.0377, -0.1663],\n",
      "         [-0.0343,  0.0303, -0.0939],\n",
      "         [ 0.1410,  0.1674, -0.1544],\n",
      "         [ 0.1031, -0.1112, -0.0920],\n",
      "         [ 0.1516, -0.0422, -0.1423],\n",
      "         [-0.0966, -0.1792,  0.1592]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.0.bias | Size: torch.Size([64]) | Values : tensor([0.1111, 0.0821], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.1.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.1.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.0.weight | Size: torch.Size([64, 64, 3]) | Values : tensor([[[-2.0389e-02,  6.3111e-02, -4.4554e-04],\n",
      "         [ 4.7491e-02,  4.6825e-02, -1.8601e-02],\n",
      "         [-8.8137e-03,  2.0115e-02,  6.6131e-02],\n",
      "         [-8.5662e-03,  4.8925e-03, -1.0970e-03],\n",
      "         [-3.3689e-03, -2.8133e-02, -6.8862e-02],\n",
      "         [ 4.6976e-02,  3.2747e-02,  6.2154e-02],\n",
      "         [ 2.4618e-02,  3.1935e-02,  3.3131e-02],\n",
      "         [ 6.5103e-02,  4.9021e-02, -5.2935e-02],\n",
      "         [ 6.6479e-02, -8.5796e-03, -3.2799e-02],\n",
      "         [ 1.2673e-02,  1.4884e-02,  3.8534e-02],\n",
      "         [-6.2457e-02, -1.4961e-02,  3.9445e-02],\n",
      "         [-2.4705e-02,  6.7526e-02,  1.4085e-02],\n",
      "         [ 3.3500e-02,  2.2051e-02,  4.2091e-02],\n",
      "         [ 6.7675e-02,  2.6826e-02, -4.0422e-02],\n",
      "         [-3.9248e-02, -3.2574e-02, -3.1197e-02],\n",
      "         [ 3.9230e-02,  2.8751e-02, -2.1914e-02],\n",
      "         [-2.1066e-03,  6.2983e-02, -6.7885e-02],\n",
      "         [-4.8345e-02,  5.2055e-02,  2.4849e-02],\n",
      "         [ 3.5867e-02, -6.5073e-05,  3.5197e-02],\n",
      "         [-1.9207e-02,  6.8709e-02, -4.7152e-03],\n",
      "         [ 5.3304e-02,  2.6340e-02,  5.7347e-02],\n",
      "         [-5.0408e-03,  4.8056e-02, -4.9526e-02],\n",
      "         [-1.3468e-02,  6.4177e-03, -2.0629e-02],\n",
      "         [-3.4815e-02, -5.3162e-02,  6.7906e-02],\n",
      "         [-3.2817e-03,  5.3050e-02,  1.2508e-02],\n",
      "         [ 3.4669e-03, -5.9986e-02,  6.8838e-02],\n",
      "         [ 5.7680e-02,  2.8066e-03, -4.3739e-02],\n",
      "         [ 5.8193e-02, -2.1950e-02, -1.4606e-03],\n",
      "         [ 9.4328e-03,  2.8861e-02,  1.8088e-02],\n",
      "         [ 4.3389e-02, -1.8361e-02,  2.2535e-02],\n",
      "         [ 4.1107e-03, -4.6679e-02, -5.5643e-02],\n",
      "         [ 1.1531e-02,  2.9127e-03,  1.8316e-02],\n",
      "         [ 4.5900e-03, -1.3954e-02, -2.6581e-02],\n",
      "         [ 5.4157e-02,  4.1944e-02, -2.2256e-02],\n",
      "         [-3.0364e-02,  2.4855e-03,  1.5246e-02],\n",
      "         [ 5.9923e-03, -5.7534e-02, -6.4816e-02],\n",
      "         [ 2.7304e-02,  2.6481e-02,  3.6434e-02],\n",
      "         [-3.3690e-02, -2.9842e-02,  2.7131e-02],\n",
      "         [ 2.2330e-02, -1.2590e-02,  4.5109e-02],\n",
      "         [-7.1153e-02, -5.9837e-02, -5.9937e-02],\n",
      "         [-1.8314e-02, -2.7250e-02,  2.0320e-02],\n",
      "         [ 2.4605e-02,  3.2829e-02, -3.0668e-02],\n",
      "         [ 6.0226e-02, -2.0235e-02, -7.0951e-02],\n",
      "         [ 1.0544e-02, -6.6175e-02,  3.6845e-02],\n",
      "         [ 5.4311e-02,  3.8775e-03,  4.6939e-02],\n",
      "         [ 2.8867e-02,  3.5278e-02, -4.6136e-02],\n",
      "         [ 6.2828e-03,  3.5010e-02, -8.8363e-03],\n",
      "         [ 6.4360e-02,  1.1452e-03, -4.1450e-02],\n",
      "         [-2.4523e-02,  1.4925e-02,  7.1596e-02],\n",
      "         [-6.7818e-02,  6.4852e-02, -6.6482e-02],\n",
      "         [ 1.0970e-02,  6.0072e-02,  3.9979e-02],\n",
      "         [-9.0974e-03, -6.2366e-02, -1.9019e-02],\n",
      "         [-3.2073e-02, -1.6018e-02, -2.9303e-02],\n",
      "         [ 3.5799e-02,  5.9407e-02,  2.9468e-02],\n",
      "         [ 4.6850e-02,  2.4632e-02,  1.1860e-03],\n",
      "         [-4.0434e-03, -2.4970e-02,  5.7025e-02],\n",
      "         [-1.1407e-02, -2.0015e-02, -4.5181e-02],\n",
      "         [ 6.9735e-02,  1.0972e-02,  6.6968e-02],\n",
      "         [ 4.1138e-02,  4.2225e-02, -2.2034e-02],\n",
      "         [ 3.5490e-02, -5.6307e-02, -4.9739e-03],\n",
      "         [-2.9868e-02,  5.1803e-02, -2.3022e-02],\n",
      "         [-2.6485e-02, -4.4044e-03,  3.0621e-02],\n",
      "         [-8.0180e-03,  2.4493e-02, -6.1866e-02],\n",
      "         [-2.9554e-02, -6.0273e-02, -6.3611e-02]],\n",
      "\n",
      "        [[-5.5839e-02, -3.9363e-02,  4.4706e-02],\n",
      "         [ 4.8467e-02,  1.0182e-02, -6.9084e-02],\n",
      "         [-6.0269e-03, -5.5396e-03, -9.7606e-03],\n",
      "         [-6.7751e-02,  1.5152e-02,  4.0959e-02],\n",
      "         [-4.9737e-02, -3.3041e-02, -4.3794e-02],\n",
      "         [-1.2105e-02,  4.1792e-02, -2.5232e-02],\n",
      "         [ 2.5401e-02, -1.0185e-02, -3.9863e-02],\n",
      "         [ 7.0167e-02, -2.5809e-02,  6.1733e-02],\n",
      "         [-5.5945e-02,  6.7612e-02,  4.0651e-02],\n",
      "         [-5.5122e-03,  6.6435e-02,  3.3574e-02],\n",
      "         [ 3.4384e-02, -3.2331e-02, -5.4205e-02],\n",
      "         [ 5.4019e-02,  4.5369e-02,  3.8815e-02],\n",
      "         [ 3.4867e-02,  4.5361e-02, -5.5311e-02],\n",
      "         [-4.8660e-02,  2.0348e-03, -3.1498e-02],\n",
      "         [ 5.4128e-02, -9.6788e-03, -3.2458e-02],\n",
      "         [ 1.6493e-02,  3.4439e-02, -2.8671e-02],\n",
      "         [ 2.6756e-02, -7.0555e-02, -2.0844e-02],\n",
      "         [ 7.6924e-03,  1.8839e-02, -3.4801e-03],\n",
      "         [ 3.7657e-02,  6.1663e-02, -1.9457e-02],\n",
      "         [-4.9172e-02, -6.7000e-02, -7.9407e-03],\n",
      "         [ 3.5051e-02,  4.0612e-02, -6.8349e-02],\n",
      "         [ 8.5622e-04,  1.4221e-02, -1.1766e-02],\n",
      "         [-5.2669e-02, -6.2842e-02, -7.0663e-02],\n",
      "         [-5.2358e-02,  6.0861e-02, -4.7775e-02],\n",
      "         [ 3.3864e-02,  6.8989e-02, -6.0972e-02],\n",
      "         [-4.3514e-02,  2.3675e-02,  2.1856e-02],\n",
      "         [ 1.0357e-02,  2.2877e-02, -4.2801e-02],\n",
      "         [ 3.3102e-03,  2.9699e-02, -2.5283e-02],\n",
      "         [-9.8899e-03,  6.0948e-02,  4.2573e-04],\n",
      "         [-1.6584e-02, -6.1510e-02,  7.0195e-02],\n",
      "         [ 2.2649e-02,  2.0264e-02,  6.9219e-02],\n",
      "         [ 4.2384e-02,  3.6004e-02,  4.6979e-02],\n",
      "         [ 2.0181e-02,  6.4480e-02,  5.7523e-02],\n",
      "         [-1.2129e-02, -6.4996e-02,  4.8415e-02],\n",
      "         [-1.5350e-02, -2.7953e-02, -1.1010e-02],\n",
      "         [ 6.8251e-02, -3.9615e-02, -5.0931e-02],\n",
      "         [-4.6456e-02,  3.4434e-02, -2.2209e-02],\n",
      "         [-2.6087e-02,  7.0206e-02,  6.5263e-02],\n",
      "         [ 1.3526e-02, -3.6083e-02,  2.0665e-02],\n",
      "         [ 2.2168e-02, -1.9566e-02,  2.6382e-03],\n",
      "         [ 4.7016e-02,  3.3020e-03,  6.0073e-02],\n",
      "         [-4.9679e-02,  4.3714e-02,  5.5470e-02],\n",
      "         [-3.8313e-02, -5.7848e-03,  5.3983e-02],\n",
      "         [ 4.6242e-02, -2.7316e-02, -1.3653e-02],\n",
      "         [ 3.3294e-02, -1.3559e-02, -3.8369e-02],\n",
      "         [-6.9687e-03,  4.5402e-02, -9.7345e-03],\n",
      "         [ 5.6792e-02, -6.5666e-02,  4.1440e-02],\n",
      "         [ 4.7131e-02, -3.5072e-02,  6.3122e-02],\n",
      "         [-6.3390e-03,  3.0812e-02, -7.7338e-03],\n",
      "         [ 7.1807e-03,  3.6500e-02,  2.2977e-02],\n",
      "         [ 5.8081e-02,  5.3218e-02,  1.5137e-02],\n",
      "         [-5.0277e-03, -2.4608e-02, -2.7887e-02],\n",
      "         [ 5.8236e-03, -4.6557e-02,  6.5537e-02],\n",
      "         [-1.6358e-02, -5.6792e-02, -3.3186e-02],\n",
      "         [-6.7524e-02,  2.7796e-02, -2.2431e-03],\n",
      "         [ 2.4566e-02,  3.6971e-02, -3.2196e-03],\n",
      "         [ 1.9437e-02,  6.5998e-02,  5.8279e-02],\n",
      "         [-1.5580e-02,  1.5280e-02, -6.4622e-03],\n",
      "         [-6.3670e-02, -6.1581e-02,  1.5743e-02],\n",
      "         [ 5.5452e-02,  7.1046e-03,  6.3000e-03],\n",
      "         [ 5.0062e-02, -5.7877e-02,  1.1227e-02],\n",
      "         [ 6.2093e-02,  2.5028e-02, -2.6686e-02],\n",
      "         [ 5.4954e-02,  5.8624e-02,  5.7703e-03],\n",
      "         [ 3.9731e-02, -5.5190e-02, -5.0842e-02]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.0.bias | Size: torch.Size([64]) | Values : tensor([0.0595, 0.0527], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.1.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.1.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv3.0.weight | Size: torch.Size([64, 64, 3]) | Values : tensor([[[ 1.0113e-02, -3.5013e-02, -6.1742e-02],\n",
      "         [ 4.1090e-02,  4.2119e-02,  1.0674e-02],\n",
      "         [ 6.6783e-02,  1.7421e-02, -3.9771e-02],\n",
      "         [ 2.7430e-02,  2.7173e-02,  2.1585e-02],\n",
      "         [-8.1424e-03, -6.3630e-02, -6.1306e-02],\n",
      "         [ 3.5574e-02,  6.8833e-02,  5.5161e-02],\n",
      "         [ 2.0969e-02,  1.5201e-02, -5.3847e-02],\n",
      "         [-1.6263e-02,  8.5385e-03,  4.3958e-03],\n",
      "         [-4.4776e-02,  5.2165e-02,  1.2672e-02],\n",
      "         [ 7.0470e-02,  4.0919e-02, -4.5235e-03],\n",
      "         [ 1.0972e-02,  4.8633e-02, -1.2788e-02],\n",
      "         [ 1.3672e-02, -5.1909e-02,  4.0437e-02],\n",
      "         [-3.7847e-02,  2.2480e-02, -1.9593e-02],\n",
      "         [ 5.6450e-02,  3.6675e-02,  4.8704e-02],\n",
      "         [-2.1474e-02,  5.6680e-03,  5.3707e-02],\n",
      "         [-6.3990e-02, -7.1388e-02, -1.5472e-02],\n",
      "         [ 3.2902e-02, -6.9243e-02, -4.1811e-02],\n",
      "         [ 1.4724e-03, -4.4648e-03, -1.1713e-02],\n",
      "         [ 6.9826e-02, -6.6260e-02,  1.5036e-02],\n",
      "         [-4.1584e-03, -6.1173e-02, -5.2774e-03],\n",
      "         [ 4.9212e-02, -6.3168e-02,  2.5004e-02],\n",
      "         [-6.1081e-02,  6.8478e-02,  6.6446e-02],\n",
      "         [ 6.1319e-02,  1.6216e-02, -5.7181e-02],\n",
      "         [ 5.5245e-02, -3.4440e-02,  1.9962e-02],\n",
      "         [ 1.1492e-02, -6.8270e-02, -3.6854e-02],\n",
      "         [ 4.9462e-02, -5.9139e-02,  1.7293e-02],\n",
      "         [ 8.6485e-03,  5.0939e-02,  3.9691e-02],\n",
      "         [ 1.0012e-02,  2.0630e-02,  3.8961e-02],\n",
      "         [-3.0710e-02, -1.5896e-02,  4.8736e-02],\n",
      "         [ 6.2840e-02,  2.7793e-02, -4.3409e-02],\n",
      "         [ 6.8490e-02, -6.1208e-02, -3.4518e-02],\n",
      "         [-4.8583e-02,  6.2736e-02,  4.9129e-02],\n",
      "         [ 6.3177e-02,  5.1419e-02, -3.6530e-02],\n",
      "         [ 3.4653e-02, -6.1746e-02,  5.1681e-02],\n",
      "         [-2.9269e-02,  3.9592e-03,  5.0881e-03],\n",
      "         [-1.4409e-02, -7.3506e-04,  5.2427e-02],\n",
      "         [ 6.0016e-02,  6.6071e-02,  3.3880e-02],\n",
      "         [ 3.2426e-02, -1.6398e-02,  2.1100e-02],\n",
      "         [ 4.1064e-03,  4.3348e-02,  1.3659e-02],\n",
      "         [-7.0143e-02,  4.9141e-02, -2.5612e-03],\n",
      "         [ 5.8879e-02,  8.0537e-04, -3.5893e-02],\n",
      "         [ 5.8684e-02,  2.5855e-02,  9.0021e-03],\n",
      "         [ 7.0718e-03, -1.6420e-02,  6.6079e-02],\n",
      "         [ 3.1259e-02, -5.5125e-02, -3.1684e-02],\n",
      "         [ 5.9438e-02, -5.1336e-02, -4.2209e-02],\n",
      "         [ 5.2570e-02, -1.6044e-02,  1.5620e-02],\n",
      "         [ 1.9124e-02,  6.1445e-02,  4.2281e-02],\n",
      "         [ 6.0634e-02,  1.6218e-02,  4.7427e-02],\n",
      "         [ 4.0767e-02,  4.0694e-02, -1.4365e-02],\n",
      "         [ 1.0041e-02, -1.4331e-03,  2.5688e-02],\n",
      "         [ 4.5723e-02, -7.1520e-02, -1.3749e-02],\n",
      "         [ 2.5578e-02,  5.3354e-02, -3.6335e-02],\n",
      "         [ 6.9919e-02, -4.4431e-02,  4.5769e-05],\n",
      "         [-5.7138e-02, -2.6582e-02, -6.3559e-02],\n",
      "         [ 6.0540e-03,  1.9189e-02, -2.7562e-02],\n",
      "         [-6.2199e-02,  5.5666e-02, -5.3345e-02],\n",
      "         [ 6.7547e-02,  6.1499e-02,  1.3760e-02],\n",
      "         [ 2.0068e-02,  4.2254e-02, -6.0716e-02],\n",
      "         [-6.5301e-02,  2.6324e-02, -6.4928e-03],\n",
      "         [-6.3741e-02, -2.9055e-02, -3.1363e-02],\n",
      "         [-5.7276e-03, -3.9203e-02,  4.0382e-02],\n",
      "         [ 7.1457e-02, -1.4477e-02, -3.4753e-02],\n",
      "         [-4.2044e-02,  5.5285e-03, -7.2896e-03],\n",
      "         [ 1.5231e-02,  4.7225e-02,  1.0137e-02]],\n",
      "\n",
      "        [[-7.2176e-03,  6.7262e-02,  2.5304e-02],\n",
      "         [-3.3603e-02,  8.8313e-03, -2.4936e-02],\n",
      "         [ 1.4797e-03,  1.2347e-02,  4.8144e-02],\n",
      "         [ 4.0288e-02, -4.4274e-02,  2.8175e-02],\n",
      "         [-2.7861e-03,  2.9840e-02, -1.2104e-02],\n",
      "         [ 1.3579e-02, -7.2111e-03, -3.3995e-02],\n",
      "         [ 4.9666e-02, -2.4945e-02,  7.2745e-03],\n",
      "         [-5.4157e-02, -2.4765e-02,  5.3842e-02],\n",
      "         [-3.1137e-02, -2.8796e-02, -2.5252e-02],\n",
      "         [ 5.3504e-02, -3.9307e-02, -3.1958e-03],\n",
      "         [ 2.8024e-02,  3.4264e-02,  4.0113e-02],\n",
      "         [ 4.2450e-02, -4.4580e-02, -5.1866e-02],\n",
      "         [ 5.7890e-03,  6.7586e-02, -3.1562e-02],\n",
      "         [-6.5190e-02,  2.4738e-02,  1.8427e-02],\n",
      "         [-6.8847e-02, -6.9412e-02, -1.5095e-02],\n",
      "         [ 3.2212e-02,  1.9435e-02,  5.8460e-02],\n",
      "         [ 4.0851e-02,  6.8819e-02,  6.5563e-02],\n",
      "         [-4.9595e-02, -3.9001e-02, -9.1956e-03],\n",
      "         [ 2.1163e-02,  2.6539e-02, -6.1200e-02],\n",
      "         [ 4.9724e-02, -3.4567e-02,  2.7261e-02],\n",
      "         [ 6.3327e-02, -2.1826e-02, -3.3070e-02],\n",
      "         [-3.3391e-02,  2.0925e-02, -4.2751e-02],\n",
      "         [ 4.4624e-02,  2.3763e-02, -7.2056e-02],\n",
      "         [-6.9183e-03, -5.4655e-02,  4.7605e-02],\n",
      "         [ 5.7475e-02,  3.8824e-02,  4.1792e-02],\n",
      "         [-3.8343e-02,  3.9464e-02, -3.8256e-02],\n",
      "         [-6.2706e-02, -5.8455e-02,  3.1646e-02],\n",
      "         [-1.5453e-02, -3.2701e-02,  6.0732e-02],\n",
      "         [ 5.8044e-02, -2.8201e-02, -4.4684e-02],\n",
      "         [ 1.6805e-02,  2.8640e-02, -5.8666e-02],\n",
      "         [-5.3356e-02,  5.0810e-02, -1.3849e-03],\n",
      "         [-6.0192e-03,  7.1224e-02,  1.3812e-02],\n",
      "         [-5.7816e-03,  6.3885e-02,  6.1489e-02],\n",
      "         [ 7.0870e-02,  5.0297e-02,  5.4677e-02],\n",
      "         [ 2.2530e-02, -2.1736e-02, -6.1270e-02],\n",
      "         [-2.7850e-02, -3.6264e-02, -3.0156e-02],\n",
      "         [-5.0978e-02, -6.0002e-02, -6.4474e-02],\n",
      "         [-6.5424e-02,  4.1870e-02, -5.7819e-02],\n",
      "         [ 5.3816e-02,  1.1746e-02, -3.2334e-02],\n",
      "         [-3.1534e-02,  2.2013e-02,  4.7876e-03],\n",
      "         [-6.1768e-02, -3.6666e-02,  2.4464e-03],\n",
      "         [-1.1196e-02, -3.6187e-02,  6.2384e-02],\n",
      "         [-6.8199e-02, -2.2246e-04,  5.7858e-02],\n",
      "         [-5.1979e-02,  2.7031e-02,  7.0797e-02],\n",
      "         [-4.9351e-02, -1.1335e-02, -6.8142e-03],\n",
      "         [-5.6553e-02, -2.1180e-02, -2.9698e-02],\n",
      "         [-6.1737e-03, -3.7971e-02, -3.2155e-02],\n",
      "         [-2.8765e-02, -2.2770e-02, -7.0493e-02],\n",
      "         [-6.2073e-02, -4.6648e-03,  2.9249e-02],\n",
      "         [-7.1399e-02,  4.9659e-02, -4.6610e-02],\n",
      "         [ 6.1419e-02, -5.3025e-02,  5.4785e-02],\n",
      "         [-6.0582e-02, -4.4513e-02, -1.1258e-03],\n",
      "         [ 5.4220e-02,  5.8067e-02, -2.0198e-02],\n",
      "         [-6.5318e-02, -2.4284e-02,  3.4313e-03],\n",
      "         [-6.3406e-02, -3.5986e-02,  1.2580e-02],\n",
      "         [ 3.0497e-02, -3.5116e-02,  2.8646e-02],\n",
      "         [ 5.8787e-02,  4.4011e-02,  6.7312e-03],\n",
      "         [-6.9905e-02,  3.1861e-02,  3.2228e-02],\n",
      "         [ 1.0601e-02, -5.6339e-02,  5.1339e-02],\n",
      "         [ 1.6542e-02, -4.4015e-02, -2.5783e-03],\n",
      "         [ 6.3703e-02, -2.9045e-02,  5.6636e-02],\n",
      "         [ 5.6361e-02,  2.4841e-03,  5.5614e-02],\n",
      "         [ 2.9454e-03,  3.3915e-02,  4.2046e-03],\n",
      "         [-4.1370e-02,  5.6762e-02, -1.2577e-02]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv3.0.bias | Size: torch.Size([64]) | Values : tensor([-0.0713, -0.0582], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv3.1.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv3.1.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm1.weight_ih_l0 | Size: torch.Size([256, 64]) | Values : tensor([[ 0.0499, -0.0543, -0.1185, -0.0102, -0.0023,  0.0772,  0.0753, -0.0083,\n",
      "         -0.0775,  0.0449, -0.0695,  0.0343,  0.0949,  0.0623,  0.0020,  0.0451,\n",
      "         -0.0258, -0.0500, -0.0856, -0.1171,  0.0717, -0.0553,  0.1026,  0.0734,\n",
      "         -0.0617, -0.0107, -0.1142,  0.0235,  0.0767, -0.0166, -0.0979, -0.0204,\n",
      "         -0.0944,  0.0179, -0.0581, -0.1091, -0.0941,  0.1003, -0.0312, -0.0663,\n",
      "         -0.0090,  0.0732, -0.0030, -0.0599,  0.0925,  0.1219,  0.0237, -0.0815,\n",
      "          0.0807, -0.0702,  0.0843, -0.0157, -0.0099, -0.0199, -0.1030, -0.0972,\n",
      "         -0.0520, -0.1021, -0.0276, -0.0787,  0.0477,  0.0492,  0.0413, -0.0022],\n",
      "        [-0.0770, -0.0011,  0.0844, -0.0999,  0.1239, -0.0103, -0.1189,  0.0915,\n",
      "         -0.0310, -0.0076,  0.0210, -0.0196, -0.0112, -0.0562, -0.0208,  0.0118,\n",
      "         -0.0869,  0.0661, -0.0817, -0.0467, -0.0466,  0.0606,  0.0366, -0.0786,\n",
      "          0.0845,  0.0862,  0.0960,  0.1055, -0.0640,  0.0486, -0.0193,  0.0572,\n",
      "         -0.1172,  0.0191,  0.1229, -0.1063, -0.0804, -0.0534,  0.0276, -0.0021,\n",
      "         -0.0923, -0.0744,  0.0851,  0.0216,  0.0443,  0.0438,  0.0368,  0.0516,\n",
      "         -0.0384,  0.0354,  0.0190, -0.0986,  0.0102, -0.1123,  0.1166, -0.0972,\n",
      "         -0.1034, -0.0803, -0.0460, -0.0599, -0.0425, -0.0086, -0.0732,  0.0794]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm1.weight_hh_l0 | Size: torch.Size([256, 64]) | Values : tensor([[-0.0785,  0.1021, -0.1168, -0.0767,  0.0598, -0.0228, -0.0093,  0.0857,\n",
      "         -0.0772, -0.0571,  0.0756,  0.0665,  0.0038,  0.0783,  0.0342,  0.1200,\n",
      "         -0.0840, -0.1009,  0.0685,  0.1151, -0.0601,  0.0513,  0.0713,  0.0027,\n",
      "          0.0967,  0.0611, -0.0825, -0.1225,  0.1142,  0.0359,  0.0565, -0.1019,\n",
      "          0.0184,  0.0052,  0.1015,  0.0206,  0.0431,  0.1052,  0.0682, -0.0082,\n",
      "         -0.0373,  0.0271,  0.0194, -0.0776,  0.0195, -0.0798, -0.0694, -0.1187,\n",
      "          0.0760,  0.1208,  0.0313,  0.0774,  0.0233,  0.0122, -0.0588,  0.0575,\n",
      "         -0.0747, -0.0876,  0.1152, -0.0003,  0.0066, -0.0037,  0.0763, -0.0894],\n",
      "        [-0.0842,  0.0062, -0.0028,  0.0695,  0.0049, -0.0694, -0.1051,  0.0635,\n",
      "         -0.0096, -0.0315,  0.0701, -0.0648,  0.1025, -0.0809, -0.0043,  0.0068,\n",
      "         -0.0451,  0.0271,  0.0280, -0.1107,  0.0666, -0.1077, -0.1064,  0.0196,\n",
      "          0.0168, -0.0256,  0.1128, -0.0080,  0.0959,  0.1075,  0.1221,  0.0113,\n",
      "         -0.1004,  0.0788, -0.0353,  0.0146,  0.0798, -0.1159,  0.0660,  0.0307,\n",
      "          0.0105,  0.0459,  0.0729,  0.0538, -0.1146, -0.0488,  0.1145, -0.1110,\n",
      "         -0.0202,  0.0738,  0.0253, -0.0016,  0.1171, -0.0118, -0.0046, -0.0200,\n",
      "         -0.0670, -0.0071,  0.0698, -0.0921, -0.0022, -0.0945, -0.1250,  0.0204]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm1.bias_ih_l0 | Size: torch.Size([256]) | Values : tensor([-0.0649,  0.1069], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm1.bias_hh_l0 | Size: torch.Size([256]) | Values : tensor([ 0.0151, -0.0073], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm2.weight_ih_l0 | Size: torch.Size([256, 64]) | Values : tensor([[ 0.1103,  0.0719,  0.0932,  0.1137, -0.1089, -0.1148, -0.0588,  0.0299,\n",
      "         -0.0975, -0.0512,  0.0252, -0.0589, -0.0398,  0.1059,  0.1092,  0.1186,\n",
      "         -0.1095, -0.0962, -0.0240,  0.0444, -0.1015, -0.0698, -0.0602,  0.0632,\n",
      "          0.0762,  0.0482, -0.1221, -0.1240,  0.0777,  0.0589,  0.0666,  0.0349,\n",
      "         -0.0666, -0.0623,  0.0792, -0.0241, -0.0002, -0.0459, -0.0813, -0.1161,\n",
      "          0.0417,  0.0517,  0.0293, -0.0466, -0.0328,  0.1035, -0.0352,  0.0929,\n",
      "         -0.0291, -0.0292, -0.1031, -0.1173,  0.0586, -0.1222,  0.1002,  0.0323,\n",
      "         -0.0586, -0.1130, -0.1068, -0.0669,  0.0238,  0.0585, -0.0843,  0.0534],\n",
      "        [ 0.1014, -0.0011, -0.0041, -0.0129,  0.0954,  0.0231, -0.1168,  0.0755,\n",
      "          0.0216, -0.0940, -0.0681, -0.1153,  0.0820, -0.0751, -0.0361, -0.0766,\n",
      "          0.0457,  0.0449, -0.0319,  0.0322, -0.0498, -0.1021, -0.0077,  0.1222,\n",
      "          0.0466,  0.0577, -0.0305,  0.0007,  0.0950,  0.0143,  0.1242, -0.0855,\n",
      "         -0.0078,  0.0065, -0.0944,  0.0082,  0.0392,  0.1053, -0.1112, -0.0384,\n",
      "          0.0162, -0.0122, -0.0103,  0.0048,  0.0381, -0.1060,  0.0478,  0.1042,\n",
      "          0.0337, -0.1233, -0.1240, -0.0890,  0.0180, -0.1090,  0.0706, -0.1019,\n",
      "         -0.0818, -0.0893, -0.0703, -0.1040, -0.0525,  0.0921, -0.0521,  0.0161]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm2.weight_hh_l0 | Size: torch.Size([256, 64]) | Values : tensor([[ 0.1209, -0.0969, -0.0023, -0.1202,  0.1079, -0.0067, -0.1174,  0.0761,\n",
      "          0.1118,  0.0862,  0.0342,  0.0314,  0.0694, -0.0097,  0.1043, -0.0989,\n",
      "         -0.0866,  0.0205, -0.0195,  0.1077, -0.0788,  0.0336,  0.0907, -0.0923,\n",
      "          0.0634,  0.0319,  0.0880,  0.1246,  0.0098, -0.0873, -0.0554,  0.0027,\n",
      "         -0.1139, -0.0704,  0.1184,  0.1136, -0.0869,  0.0254,  0.0743, -0.0590,\n",
      "         -0.0013,  0.0722,  0.0562,  0.1108,  0.0175, -0.0864,  0.0322,  0.0870,\n",
      "          0.0644,  0.0890,  0.0271, -0.0529,  0.1016,  0.0083, -0.0114,  0.0098,\n",
      "         -0.0855, -0.0731,  0.1219,  0.1158,  0.0328, -0.0383, -0.0891,  0.0826],\n",
      "        [-0.0229, -0.0618, -0.0995, -0.0301, -0.1058,  0.0110,  0.0642, -0.1101,\n",
      "         -0.1164,  0.0011,  0.0393,  0.0279, -0.0855, -0.0277, -0.0708, -0.0594,\n",
      "         -0.1122, -0.0410,  0.1114,  0.0160,  0.0668,  0.1087,  0.0899,  0.0058,\n",
      "         -0.0965,  0.0083, -0.1185,  0.0137, -0.0577, -0.0168, -0.0931, -0.0652,\n",
      "         -0.0872,  0.0246, -0.0896, -0.1054, -0.0310, -0.0076, -0.0036, -0.0896,\n",
      "         -0.0266, -0.1211, -0.0234,  0.0935,  0.0483, -0.0062,  0.0058,  0.0775,\n",
      "         -0.0113, -0.1204, -0.0763, -0.0898, -0.0128, -0.0658,  0.0815, -0.0095,\n",
      "         -0.0499,  0.0346, -0.0409,  0.0857,  0.0538, -0.0193,  0.0956, -0.1093]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm2.bias_ih_l0 | Size: torch.Size([256]) | Values : tensor([-0.0600,  0.0595], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm2.bias_hh_l0 | Size: torch.Size([256]) | Values : tensor([-0.1079,  0.0185], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc.weight | Size: torch.Size([2, 64]) | Values : tensor([[ 0.0209, -0.0689, -0.0755,  0.0458,  0.0111, -0.1150, -0.0658,  0.0925,\n",
      "          0.1028, -0.1077,  0.1083, -0.0851,  0.0246,  0.0372, -0.0799,  0.0770,\n",
      "         -0.0760, -0.1031, -0.0518, -0.1141,  0.1168,  0.0210,  0.1022,  0.0976,\n",
      "         -0.0143,  0.0259,  0.0270, -0.0130,  0.0533,  0.0109, -0.1145, -0.0383,\n",
      "         -0.0844, -0.0901, -0.0669, -0.0907, -0.0858,  0.1075, -0.0195, -0.0779,\n",
      "         -0.0077, -0.1157,  0.0566, -0.1085,  0.1068,  0.0916,  0.0321,  0.0608,\n",
      "         -0.0384,  0.0915,  0.0076, -0.0120, -0.0876, -0.0859,  0.1117,  0.0468,\n",
      "          0.0276, -0.0421,  0.0667, -0.0738, -0.1145,  0.0630, -0.0953, -0.0373],\n",
      "        [-0.0147, -0.1104,  0.0219,  0.0131, -0.0012, -0.0896,  0.0458, -0.0779,\n",
      "          0.0155, -0.0504,  0.0500,  0.1189,  0.0262,  0.0444, -0.0712, -0.0376,\n",
      "          0.0080,  0.0604, -0.0608,  0.0998,  0.0908, -0.0648, -0.0833,  0.0400,\n",
      "         -0.0554, -0.1066, -0.0855, -0.0292,  0.0585, -0.0480,  0.0649,  0.0990,\n",
      "         -0.0598, -0.0860, -0.0297,  0.0972, -0.1159,  0.0186,  0.0010, -0.0948,\n",
      "         -0.0377, -0.0051,  0.1014,  0.0968, -0.0130, -0.0100,  0.0377, -0.0615,\n",
      "          0.1072, -0.1176,  0.0683, -0.0166,  0.0006, -0.0566, -0.0232, -0.0533,\n",
      "         -0.1032, -0.0842, -0.1101,  0.1059,  0.0334,  0.0697, -0.0824,  0.0361]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc.bias | Size: torch.Size([2]) | Values : tensor([0.0417, 0.1162], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create an instance of the model\n",
    "model_ConvLSTM = ConvLSTM()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_ConvLSTM.parameters(), lr=learning_rate)\n",
    "# Initialize the scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=patience, verbose=True)\n",
    "print(f\"Model structure: {model_ConvLSTM}\\n\\n\")\n",
    "for name, param in model_ConvLSTM.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "loss: 1.134259  [   64/23232]\n",
      "loss: 0.382163  [ 6464/23232]\n",
      "loss: 0.358830  [12864/23232]\n",
      "loss: 0.114418  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.058425 \n",
      "\n",
      "Epoch 1:\n",
      "loss: 0.370029  [   64/23232]\n",
      "loss: 0.525420  [ 6464/23232]\n",
      "loss: 0.049795  [12864/23232]\n",
      "loss: 0.075194  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.050454 \n",
      "\n",
      "Epoch 2:\n",
      "loss: 0.205643  [   64/23232]\n",
      "loss: 0.267904  [ 6464/23232]\n",
      "loss: 0.102905  [12864/23232]\n",
      "loss: 0.385321  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.050829 \n",
      "\n",
      "Epoch 3:\n",
      "loss: 0.164040  [   64/23232]\n",
      "loss: 0.087281  [ 6464/23232]\n",
      "loss: 0.049689  [12864/23232]\n",
      "loss: 0.098493  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.044533 \n",
      "\n",
      "Epoch 4:\n",
      "loss: 0.185709  [   64/23232]\n",
      "loss: 0.007344  [ 6464/23232]\n",
      "loss: 0.174217  [12864/23232]\n",
      "loss: 0.169936  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.050823 \n",
      "\n",
      "Epoch 5:\n",
      "loss: 0.051107  [   64/23232]\n",
      "loss: 0.131224  [ 6464/23232]\n",
      "loss: 0.066873  [12864/23232]\n",
      "loss: 0.087266  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.047644 \n",
      "\n",
      "Epoch 6:\n",
      "loss: 0.120837  [   64/23232]\n",
      "loss: 0.136391  [ 6464/23232]\n",
      "loss: 0.512601  [12864/23232]\n",
      "loss: 0.086098  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.041863 \n",
      "\n",
      "Epoch 7:\n",
      "loss: 0.020371  [   64/23232]\n",
      "loss: 0.147740  [ 6464/23232]\n",
      "loss: 0.075175  [12864/23232]\n",
      "loss: 0.041075  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.046356 \n",
      "\n",
      "Epoch 8:\n",
      "loss: 0.025536  [   64/23232]\n",
      "loss: 0.065217  [ 6464/23232]\n",
      "loss: 0.039331  [12864/23232]\n",
      "loss: 0.343130  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.044436 \n",
      "\n",
      "Epoch 9:\n",
      "loss: 0.249572  [   64/23232]\n",
      "loss: 0.087303  [ 6464/23232]\n",
      "loss: 0.044493  [12864/23232]\n",
      "loss: 0.054194  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.033948 \n",
      "\n",
      "Epoch 10:\n",
      "loss: 0.017392  [   64/23232]\n",
      "loss: 0.049846  [ 6464/23232]\n",
      "loss: 0.052105  [12864/23232]\n",
      "loss: 0.039214  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.034568 \n",
      "\n",
      "Epoch 11:\n",
      "loss: 0.050028  [   64/23232]\n",
      "loss: 0.072205  [ 6464/23232]\n",
      "loss: 0.063887  [12864/23232]\n",
      "loss: 0.161808  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.034724 \n",
      "\n",
      "Epoch 12:\n",
      "loss: 0.027263  [   64/23232]\n",
      "loss: 0.030714  [ 6464/23232]\n",
      "loss: 0.052380  [12864/23232]\n",
      "loss: 0.023923  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.032090 \n",
      "\n",
      "Epoch 13:\n",
      "loss: 0.093881  [   64/23232]\n",
      "loss: 0.004310  [ 6464/23232]\n",
      "loss: 0.004182  [12864/23232]\n",
      "loss: 0.057045  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.033807 \n",
      "\n",
      "Epoch 14:\n",
      "loss: 0.048632  [   64/23232]\n",
      "loss: 0.011651  [ 6464/23232]\n",
      "loss: 0.597089  [12864/23232]\n",
      "loss: 0.034786  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.032983 \n",
      "\n",
      "Epoch 15:\n",
      "loss: 0.072160  [   64/23232]\n",
      "loss: 0.044552  [ 6464/23232]\n",
      "loss: 0.010943  [12864/23232]\n",
      "loss: 0.002420  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.033558 \n",
      "\n",
      "Epoch 16:\n",
      "loss: 0.043993  [   64/23232]\n",
      "loss: 0.003917  [ 6464/23232]\n",
      "loss: 0.090960  [12864/23232]\n",
      "loss: 0.024416  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.7%, Avg loss: 0.041016 \n",
      "\n",
      "Epoch 17:\n",
      "loss: 0.009949  [   64/23232]\n",
      "loss: 0.012986  [ 6464/23232]\n",
      "loss: 0.010205  [12864/23232]\n",
      "loss: 0.022672  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.029813 \n",
      "\n",
      "Epoch 18:\n",
      "loss: 0.120015  [   64/23232]\n",
      "loss: 0.017633  [ 6464/23232]\n",
      "loss: 0.026220  [12864/23232]\n",
      "loss: 0.011505  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.034962 \n",
      "\n",
      "Epoch 19:\n",
      "loss: 0.071184  [   64/23232]\n",
      "loss: 0.621596  [ 6464/23232]\n",
      "loss: 0.170699  [12864/23232]\n",
      "loss: 0.049800  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.028849 \n",
      "\n",
      "Epoch 20:\n",
      "loss: 0.009223  [   64/23232]\n",
      "loss: 0.090065  [ 6464/23232]\n",
      "loss: 0.041042  [12864/23232]\n",
      "loss: 0.003608  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.031575 \n",
      "\n",
      "Epoch 21:\n",
      "loss: 0.037553  [   64/23232]\n",
      "loss: 0.037063  [ 6464/23232]\n",
      "loss: 0.019605  [12864/23232]\n",
      "loss: 0.063538  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.031192 \n",
      "\n",
      "Epoch 22:\n",
      "loss: 0.042130  [   64/23232]\n",
      "loss: 0.021817  [ 6464/23232]\n",
      "loss: 0.010098  [12864/23232]\n",
      "loss: 0.159600  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.025521 \n",
      "\n",
      "Epoch 23:\n",
      "loss: 0.021947  [   64/23232]\n",
      "loss: 0.002900  [ 6464/23232]\n",
      "loss: 0.003448  [12864/23232]\n",
      "loss: 0.139754  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.025584 \n",
      "\n",
      "Epoch 24:\n",
      "loss: 0.003544  [   64/23232]\n",
      "loss: 0.012294  [ 6464/23232]\n",
      "loss: 0.045814  [12864/23232]\n",
      "loss: 0.316584  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.031282 \n",
      "\n",
      "Epoch 25:\n",
      "loss: 0.044960  [   64/23232]\n",
      "loss: 0.001093  [ 6464/23232]\n",
      "loss: 0.010256  [12864/23232]\n",
      "loss: 0.024623  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.024476 \n",
      "\n",
      "Epoch 26:\n",
      "loss: 0.141863  [   64/23232]\n",
      "loss: 0.000861  [ 6464/23232]\n",
      "loss: 0.002889  [12864/23232]\n",
      "loss: 0.004541  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.022283 \n",
      "\n",
      "Epoch 27:\n",
      "loss: 0.095683  [   64/23232]\n",
      "loss: 0.305635  [ 6464/23232]\n",
      "loss: 0.024087  [12864/23232]\n",
      "loss: 0.008071  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.031263 \n",
      "\n",
      "Epoch 28:\n",
      "loss: 0.062809  [   64/23232]\n",
      "loss: 0.013821  [ 6464/23232]\n",
      "loss: 0.001297  [12864/23232]\n",
      "loss: 0.048676  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.031901 \n",
      "\n",
      "Epoch 29:\n",
      "loss: 0.034442  [   64/23232]\n",
      "loss: 0.008865  [ 6464/23232]\n",
      "loss: 0.011187  [12864/23232]\n",
      "loss: 0.021162  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 99.5%, Avg loss: 0.020366 \n",
      "\n",
      "Epoch 30:\n",
      "loss: 0.002672  [   64/23232]\n",
      "loss: 0.237703  [ 6464/23232]\n",
      "loss: 0.023824  [12864/23232]\n",
      "loss: 0.007070  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.029988 \n",
      "\n",
      "Epoch 31:\n",
      "loss: 0.109201  [   64/23232]\n",
      "loss: 0.140658  [ 6464/23232]\n",
      "loss: 0.017809  [12864/23232]\n",
      "loss: 0.105361  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 99.2%, Avg loss: 0.030719 \n",
      "\n",
      "Epoch 32:\n",
      "loss: 0.025166  [   64/23232]\n",
      "loss: 0.015476  [ 6464/23232]\n",
      "loss: 0.008849  [12864/23232]\n",
      "loss: 0.013396  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.017602 \n",
      "\n",
      "Epoch 33:\n",
      "loss: 0.014246  [   64/23232]\n",
      "loss: 0.033404  [ 6464/23232]\n",
      "loss: 0.003095  [12864/23232]\n",
      "loss: 0.032654  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.025961 \n",
      "\n",
      "Epoch 34:\n",
      "loss: 0.101383  [   64/23232]\n",
      "loss: 0.075126  [ 6464/23232]\n",
      "loss: 0.000919  [12864/23232]\n",
      "loss: 0.100014  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.023514 \n",
      "\n",
      "Epoch 35:\n",
      "loss: 0.008220  [   64/23232]\n",
      "loss: 0.011333  [ 6464/23232]\n",
      "loss: 0.019126  [12864/23232]\n",
      "loss: 0.039883  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 99.3%, Avg loss: 0.022362 \n",
      "\n",
      "Epoch 36:\n",
      "loss: 0.107386  [   64/23232]\n",
      "loss: 0.028435  [ 6464/23232]\n",
      "loss: 0.015752  [12864/23232]\n",
      "loss: 0.062657  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 99.6%, Avg loss: 0.021123 \n",
      "\n",
      "Epoch 37:\n",
      "loss: 0.006467  [   64/23232]\n",
      "loss: 0.226829  [ 6464/23232]\n",
      "loss: 0.005593  [12864/23232]\n",
      "loss: 0.066225  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 99.4%, Avg loss: 0.022884 \n",
      "\n",
      "Early stopping due to no improvement in validation loss.\n"
     ]
    }
   ],
   "source": [
    "train(train_dataloader, model_ConvLSTM, loss_fn, optimizer,val_dataloader, \n",
    "           patience=patience, scheduler=scheduler, epochs=epochs, device=device, B_size=B_size, A_size=A_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 93.1%, Avg loss: 0.318213 \n",
      "\n",
      " Label 0\n",
      "    accuracy\t0.931\n",
      " specificity\t0.900\n",
      " sensitivity\t0.964\n",
      " Label 1\n",
      "    accuracy\t0.931\n",
      " specificity\t0.964\n",
      " sensitivity\t0.900\n",
      "[[27  1]\n",
      " [ 3 27]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# final test\n",
    "test(test_dataloader, model_ConvLSTM, loss_fn, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=16, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding='same')\n",
    "        self.bn2 = nn.BatchNorm1d(16)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=64, kernel_size=1)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.convr = nn.Conv1d(in_channels=in_channels, out_channels=64, kernel_size=1)\n",
    "    def forward(self, input):\n",
    "        residual = self.convr(input)\n",
    "        x = self.conv1(input)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x += residual\n",
    "        x = self.relu3(x)\n",
    "        return x\n",
    "\n",
    "class IdentityBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(IdentityBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=16, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding='same')\n",
    "        self.bn2 = nn.BatchNorm1d(16)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=64, kernel_size=1)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "    def forward(self, input):\n",
    "        \n",
    "        residual = input\n",
    "        x = self.conv1(input)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x += residual\n",
    "        x = self.relu3(x)\n",
    "        return x\n",
    "\n",
    "class ResNet24(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet24, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=9, out_channels=64, kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.convblk1 = ConvBlock(64)\n",
    "        self.convblk2 = ConvBlock(64)\n",
    "        self.identityblk1 = IdentityBlock(64)\n",
    "        self.convblk3 = ConvBlock(64)\n",
    "        self.identityblk2 = IdentityBlock(64)\n",
    "        self.convblk4 = ConvBlock(64)\n",
    "        self.identityblk3 = IdentityBlock(64)\n",
    "        \n",
    "        self.pool2 = nn.AvgPool1d(2)\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.Flatten(),\n",
    "                                nn.Linear(in_features=704, out_features=2),\n",
    "        #                        nn.Softmax()\n",
    "                                )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)  # Transpose to have the correct dimensions for Conv1d (batch, channels, length)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.convblk1(x)\n",
    "        x = self.convblk2(x)\n",
    "        x = self.identityblk1(x)\n",
    "        x = self.convblk3(x)\n",
    "        x = self.identityblk2(x)\n",
    "        x = self.convblk4(x)\n",
    "        x = self.identityblk3(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: ResNet24(\n",
      "  (conv1): Conv1d(9, 64, kernel_size=(3,), stride=(1,))\n",
      "  (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (convblk1): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (convblk2): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (identityblk1): IdentityBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "  )\n",
      "  (convblk3): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (identityblk2): IdentityBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "  )\n",
      "  (convblk4): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (identityblk3): IdentityBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "  )\n",
      "  (pool2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
      "  (fc): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=704, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: conv1.weight | Size: torch.Size([64, 9, 3]) | Values : tensor([[[-0.1695,  0.0337,  0.1520],\n",
      "         [-0.1041, -0.0579,  0.0481],\n",
      "         [-0.0633, -0.0935, -0.1600],\n",
      "         [ 0.1717,  0.0760, -0.1482],\n",
      "         [ 0.0415,  0.0494, -0.1520],\n",
      "         [-0.1039,  0.1238,  0.0270],\n",
      "         [ 0.1687, -0.0117, -0.0240],\n",
      "         [ 0.1202,  0.0476,  0.1602],\n",
      "         [-0.1897, -0.0849, -0.0461]],\n",
      "\n",
      "        [[-0.0189, -0.1200,  0.1085],\n",
      "         [ 0.0626, -0.1101,  0.1653],\n",
      "         [ 0.0423,  0.1386,  0.1639],\n",
      "         [ 0.1303,  0.1547,  0.1670],\n",
      "         [ 0.1226,  0.1811, -0.1053],\n",
      "         [-0.1360, -0.1167,  0.0615],\n",
      "         [-0.1412,  0.1701,  0.1393],\n",
      "         [ 0.1744, -0.0254,  0.1475],\n",
      "         [-0.0538,  0.0219, -0.0486]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.bias | Size: torch.Size([64]) | Values : tensor([-0.0516, -0.0909], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.weight | Size: torch.Size([64, 64, 3]) | Values : tensor([[[ 5.8236e-02, -1.6376e-03, -1.4966e-02],\n",
      "         [-6.6488e-02,  1.5004e-02,  7.0886e-02],\n",
      "         [ 6.5844e-02, -1.1846e-02,  6.2034e-02],\n",
      "         [-3.9634e-04,  5.0974e-02,  8.7075e-03],\n",
      "         [-1.2821e-02, -5.8398e-02,  6.6527e-02],\n",
      "         [-5.5108e-02,  7.2076e-02, -6.5010e-02],\n",
      "         [-1.6710e-02, -1.6105e-02, -4.5792e-02],\n",
      "         [ 9.6592e-03, -2.9588e-02,  3.9136e-02],\n",
      "         [-5.6686e-02, -4.0162e-02,  7.0506e-02],\n",
      "         [ 3.8797e-02,  2.4314e-02,  3.7652e-02],\n",
      "         [ 3.1045e-02, -4.3678e-02,  2.5358e-02],\n",
      "         [ 4.6747e-02, -4.8228e-02, -5.1160e-02],\n",
      "         [ 2.1166e-02,  6.9167e-03,  4.2813e-02],\n",
      "         [ 2.8269e-02, -2.3786e-02, -3.5465e-02],\n",
      "         [ 3.5649e-02, -2.1025e-02,  4.3205e-02],\n",
      "         [ 1.1964e-02,  1.3579e-02, -4.3282e-02],\n",
      "         [ 2.2119e-02, -2.9707e-03, -3.9206e-02],\n",
      "         [-7.0769e-02, -2.9923e-03,  2.5504e-02],\n",
      "         [ 4.8789e-02, -6.5656e-02,  9.8332e-03],\n",
      "         [-7.0892e-02,  1.8457e-02,  3.5692e-02],\n",
      "         [ 2.4211e-02,  6.2563e-02, -1.2474e-02],\n",
      "         [-3.6908e-03,  5.9548e-02, -3.5487e-02],\n",
      "         [-5.4191e-02, -3.3837e-02,  2.7945e-02],\n",
      "         [-5.7832e-02, -5.6876e-02,  5.7407e-02],\n",
      "         [-6.6252e-02,  1.8073e-03,  4.1001e-03],\n",
      "         [ 1.4773e-03,  4.2135e-02, -3.9077e-02],\n",
      "         [ 6.2143e-03, -4.6527e-02, -1.7472e-02],\n",
      "         [ 4.1509e-02,  5.6668e-02, -2.9737e-02],\n",
      "         [ 1.7845e-02, -7.0466e-02,  4.8389e-02],\n",
      "         [-3.3327e-02,  2.1595e-02,  6.4117e-02],\n",
      "         [ 1.9351e-02, -4.0649e-02, -3.5161e-02],\n",
      "         [-4.3426e-02, -1.0528e-02,  5.3867e-03],\n",
      "         [-1.9317e-02,  2.3307e-02, -1.0072e-02],\n",
      "         [-4.0493e-02,  9.5273e-03, -1.4698e-02],\n",
      "         [ 6.8375e-02, -6.5737e-02, -2.1825e-02],\n",
      "         [-1.3718e-02,  4.0416e-03, -6.3131e-02],\n",
      "         [-2.9209e-02, -3.2900e-03,  3.9459e-02],\n",
      "         [ 1.1453e-02, -9.6071e-03,  3.5833e-02],\n",
      "         [-1.9289e-02, -7.1376e-02, -5.5212e-02],\n",
      "         [-5.5060e-02,  2.7734e-02,  3.0243e-02],\n",
      "         [ 2.2818e-02, -4.7911e-02, -1.9235e-03],\n",
      "         [ 6.8841e-02, -5.6276e-02,  2.6016e-02],\n",
      "         [-3.1499e-02, -2.2922e-02,  3.6739e-02],\n",
      "         [-4.0942e-02,  2.4659e-02, -4.9518e-02],\n",
      "         [-5.2149e-02,  1.9130e-02,  5.8257e-02],\n",
      "         [ 6.7203e-02,  2.6818e-02, -2.2666e-02],\n",
      "         [-3.1019e-02, -5.9226e-02, -4.9976e-02],\n",
      "         [ 3.7570e-02,  1.1666e-02, -1.2866e-02],\n",
      "         [ 3.2125e-02, -3.4384e-02,  6.1812e-02],\n",
      "         [-6.6264e-02,  2.8873e-04, -1.8016e-02],\n",
      "         [ 4.8358e-02,  1.7760e-02,  5.0730e-02],\n",
      "         [-5.7047e-02,  3.6867e-02, -5.7088e-02],\n",
      "         [ 4.1995e-02, -2.5358e-02, -3.1387e-02],\n",
      "         [ 5.5184e-02,  2.6722e-02,  1.6727e-02],\n",
      "         [ 7.1989e-02,  2.5760e-02,  4.2279e-02],\n",
      "         [-4.8397e-02, -8.3545e-03, -2.4296e-02],\n",
      "         [-3.6662e-02,  5.5313e-02,  9.7882e-03],\n",
      "         [-5.4558e-02,  4.3636e-02,  3.6351e-02],\n",
      "         [ 2.6740e-02, -8.6914e-03,  8.9780e-03],\n",
      "         [-2.7039e-02,  5.1129e-02,  9.4605e-03],\n",
      "         [ 6.7796e-02,  4.5211e-02, -1.0427e-02],\n",
      "         [-2.6169e-02,  6.9978e-02,  4.2807e-02],\n",
      "         [-5.6295e-02, -6.1170e-02, -1.7633e-02],\n",
      "         [-3.8625e-02,  1.4874e-02, -1.7354e-02]],\n",
      "\n",
      "        [[ 4.5283e-02, -3.3417e-02,  6.4368e-02],\n",
      "         [ 4.9745e-02, -1.7085e-02, -5.2789e-03],\n",
      "         [-6.0236e-02,  2.6137e-02, -3.7645e-02],\n",
      "         [-3.1317e-02,  7.3056e-03,  6.9885e-02],\n",
      "         [ 2.3713e-02,  3.6700e-02, -4.4417e-02],\n",
      "         [-4.1708e-02,  3.1114e-02, -5.0292e-02],\n",
      "         [-5.4986e-02,  1.9687e-02, -3.0013e-02],\n",
      "         [-2.6343e-02,  6.6803e-02, -1.7438e-02],\n",
      "         [ 4.5394e-02,  5.2582e-02,  4.3028e-02],\n",
      "         [-3.6589e-03,  6.3466e-02, -3.4530e-02],\n",
      "         [-3.9745e-02, -2.0770e-02,  4.2812e-02],\n",
      "         [ 1.1375e-02, -2.1836e-02, -8.2311e-03],\n",
      "         [ 6.6598e-02,  3.0791e-02,  2.3384e-02],\n",
      "         [ 7.9215e-03,  4.5027e-02, -3.6059e-02],\n",
      "         [ 3.9307e-02,  4.0432e-02,  2.5533e-02],\n",
      "         [ 5.2206e-02, -6.6689e-02,  6.1622e-02],\n",
      "         [-1.3878e-02,  6.4580e-02,  6.7177e-02],\n",
      "         [ 5.0884e-02,  1.7751e-02,  1.1966e-03],\n",
      "         [ 3.4019e-02,  2.9875e-02,  4.2942e-02],\n",
      "         [-4.3965e-02, -3.9265e-02, -6.7044e-02],\n",
      "         [ 1.5142e-02,  3.1907e-02, -4.5404e-02],\n",
      "         [ 3.1427e-05, -5.1379e-02, -6.5477e-02],\n",
      "         [-1.8279e-03,  4.6101e-02, -6.5586e-02],\n",
      "         [-4.1496e-02, -4.4005e-02, -4.4878e-02],\n",
      "         [ 9.8146e-04, -6.8242e-02,  1.4310e-02],\n",
      "         [ 1.6565e-02,  5.7417e-02,  6.7760e-02],\n",
      "         [ 6.7874e-02,  6.0479e-02,  5.2661e-03],\n",
      "         [-5.5450e-02, -6.7923e-02,  5.9375e-02],\n",
      "         [ 5.2976e-02, -4.3248e-02, -2.2535e-02],\n",
      "         [-2.5294e-02,  6.7716e-02, -5.7195e-02],\n",
      "         [-1.1761e-02, -3.0452e-02, -6.8832e-02],\n",
      "         [-6.7255e-02, -4.1112e-02, -4.5145e-02],\n",
      "         [-6.7167e-02, -4.5031e-03,  5.6491e-02],\n",
      "         [ 6.4473e-02, -2.9688e-02, -4.0258e-03],\n",
      "         [ 1.3135e-05,  4.7200e-02,  3.0429e-02],\n",
      "         [-9.1017e-03,  6.8884e-02, -5.4600e-02],\n",
      "         [ 3.6805e-02, -6.2798e-02, -5.2099e-02],\n",
      "         [-2.6920e-02, -6.2452e-02,  7.0535e-02],\n",
      "         [-6.0951e-02,  3.0773e-02,  8.0438e-03],\n",
      "         [-1.4836e-02,  3.9217e-02, -6.9888e-02],\n",
      "         [ 3.2815e-02,  7.9092e-03,  3.7355e-02],\n",
      "         [ 6.4276e-02,  2.4867e-03,  6.2720e-02],\n",
      "         [ 3.8733e-02, -2.0786e-02,  6.8245e-02],\n",
      "         [-1.3305e-02, -1.9075e-03, -1.0252e-02],\n",
      "         [-4.2628e-02,  7.7430e-03, -2.2145e-02],\n",
      "         [ 4.5057e-02,  3.5908e-02, -2.1538e-02],\n",
      "         [-6.3283e-02, -5.2625e-03, -2.1160e-02],\n",
      "         [ 4.5552e-02,  5.5098e-02,  3.8677e-02],\n",
      "         [-1.6617e-02, -4.4463e-03,  1.2529e-03],\n",
      "         [-1.0060e-02, -5.2382e-02, -3.9603e-02],\n",
      "         [-5.3691e-02, -1.7842e-04, -5.2013e-02],\n",
      "         [-5.8054e-02, -4.3409e-02,  1.0626e-02],\n",
      "         [ 7.7723e-03, -4.5688e-02,  2.6251e-02],\n",
      "         [ 6.8672e-03, -5.4355e-02, -6.3658e-02],\n",
      "         [ 3.4103e-02, -1.8182e-02, -3.5587e-02],\n",
      "         [-6.8431e-02,  1.6992e-02,  4.4151e-02],\n",
      "         [ 3.6740e-02,  1.6688e-02, -1.2244e-02],\n",
      "         [-3.8138e-02,  2.6103e-02,  4.4678e-02],\n",
      "         [ 5.2866e-02, -6.7691e-02,  3.9888e-02],\n",
      "         [ 2.9227e-02, -1.2840e-02, -3.1777e-02],\n",
      "         [-6.0025e-02,  5.6086e-02, -6.4481e-02],\n",
      "         [-6.8892e-02,  4.1045e-03,  3.8046e-02],\n",
      "         [-3.1600e-03,  4.0529e-02, -5.5194e-02],\n",
      "         [-5.1844e-02, -3.6533e-02, -6.0756e-02]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.bias | Size: torch.Size([64]) | Values : tensor([ 0.0601, -0.0003], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[-0.0880],\n",
      "         [-0.0952],\n",
      "         [-0.0274],\n",
      "         [ 0.1099],\n",
      "         [-0.0077],\n",
      "         [-0.1213],\n",
      "         [ 0.0932],\n",
      "         [-0.0040],\n",
      "         [ 0.1095],\n",
      "         [-0.1227],\n",
      "         [-0.0411],\n",
      "         [ 0.0980],\n",
      "         [-0.0856],\n",
      "         [ 0.0553],\n",
      "         [-0.0826],\n",
      "         [ 0.1185],\n",
      "         [-0.1104],\n",
      "         [-0.0290],\n",
      "         [ 0.0297],\n",
      "         [ 0.0450],\n",
      "         [ 0.0263],\n",
      "         [-0.0033],\n",
      "         [-0.0697],\n",
      "         [-0.0388],\n",
      "         [ 0.0991],\n",
      "         [ 0.1089],\n",
      "         [-0.0347],\n",
      "         [-0.0959],\n",
      "         [ 0.0510],\n",
      "         [-0.1085],\n",
      "         [ 0.0741],\n",
      "         [-0.0567],\n",
      "         [ 0.0390],\n",
      "         [ 0.0987],\n",
      "         [ 0.1120],\n",
      "         [ 0.0788],\n",
      "         [ 0.1161],\n",
      "         [ 0.0749],\n",
      "         [-0.0290],\n",
      "         [ 0.0153],\n",
      "         [-0.0024],\n",
      "         [-0.0222],\n",
      "         [ 0.0756],\n",
      "         [ 0.0498],\n",
      "         [-0.0833],\n",
      "         [-0.0498],\n",
      "         [ 0.0431],\n",
      "         [-0.0259],\n",
      "         [-0.0474],\n",
      "         [-0.0647],\n",
      "         [ 0.0016],\n",
      "         [ 0.1128],\n",
      "         [-0.0340],\n",
      "         [ 0.0896],\n",
      "         [ 0.0373],\n",
      "         [ 0.0402],\n",
      "         [ 0.1237],\n",
      "         [ 0.1039],\n",
      "         [ 0.0566],\n",
      "         [ 0.0553],\n",
      "         [ 0.0375],\n",
      "         [-0.0672],\n",
      "         [-0.0864],\n",
      "         [-0.0113]],\n",
      "\n",
      "        [[-0.1014],\n",
      "         [-0.0087],\n",
      "         [-0.0088],\n",
      "         [-0.0907],\n",
      "         [-0.0424],\n",
      "         [-0.0984],\n",
      "         [-0.0622],\n",
      "         [-0.1095],\n",
      "         [-0.0702],\n",
      "         [-0.0120],\n",
      "         [-0.0294],\n",
      "         [ 0.0750],\n",
      "         [ 0.0975],\n",
      "         [-0.1204],\n",
      "         [-0.0045],\n",
      "         [-0.1225],\n",
      "         [ 0.0737],\n",
      "         [ 0.0626],\n",
      "         [ 0.1238],\n",
      "         [ 0.0290],\n",
      "         [ 0.0549],\n",
      "         [-0.1216],\n",
      "         [ 0.0280],\n",
      "         [-0.1071],\n",
      "         [-0.1117],\n",
      "         [-0.0820],\n",
      "         [-0.1223],\n",
      "         [-0.0158],\n",
      "         [-0.0437],\n",
      "         [-0.0752],\n",
      "         [ 0.0087],\n",
      "         [ 0.0581],\n",
      "         [-0.0288],\n",
      "         [-0.0256],\n",
      "         [ 0.0714],\n",
      "         [ 0.0449],\n",
      "         [-0.0796],\n",
      "         [ 0.0179],\n",
      "         [ 0.0756],\n",
      "         [ 0.0689],\n",
      "         [-0.0948],\n",
      "         [-0.0651],\n",
      "         [ 0.0333],\n",
      "         [ 0.0199],\n",
      "         [ 0.0428],\n",
      "         [-0.0721],\n",
      "         [-0.0231],\n",
      "         [ 0.0694],\n",
      "         [-0.0437],\n",
      "         [-0.0389],\n",
      "         [-0.0788],\n",
      "         [-0.0876],\n",
      "         [ 0.0397],\n",
      "         [-0.0382],\n",
      "         [-0.1020],\n",
      "         [-0.0651],\n",
      "         [ 0.1117],\n",
      "         [ 0.0542],\n",
      "         [-0.1106],\n",
      "         [ 0.0059],\n",
      "         [-0.0687],\n",
      "         [-0.0402],\n",
      "         [-0.1051],\n",
      "         [ 0.0673]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv1.bias | Size: torch.Size([16]) | Values : tensor([ 0.0101, -0.0855], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[-0.0821, -0.0713, -0.1215],\n",
      "         [-0.0753, -0.1110, -0.0754],\n",
      "         [-0.0182,  0.0136, -0.0269],\n",
      "         [-0.0224, -0.1186, -0.0752],\n",
      "         [-0.1156, -0.1215, -0.0418],\n",
      "         [ 0.1101,  0.0804, -0.1240],\n",
      "         [-0.0899, -0.0582,  0.1230],\n",
      "         [ 0.1348, -0.0745, -0.0997],\n",
      "         [ 0.0810,  0.0062, -0.0952],\n",
      "         [ 0.1289, -0.0835,  0.1050],\n",
      "         [ 0.0740, -0.0867, -0.0165],\n",
      "         [-0.1002, -0.0252, -0.0844],\n",
      "         [ 0.0724, -0.0289, -0.0681],\n",
      "         [-0.1317, -0.1008, -0.1065],\n",
      "         [-0.0950, -0.0092,  0.0633],\n",
      "         [ 0.0596, -0.0582,  0.0014]],\n",
      "\n",
      "        [[-0.0016,  0.0059, -0.1118],\n",
      "         [-0.0265,  0.1399, -0.0680],\n",
      "         [ 0.0494,  0.0727, -0.1205],\n",
      "         [ 0.1188, -0.0581,  0.1071],\n",
      "         [-0.1388,  0.0779,  0.1320],\n",
      "         [ 0.1017,  0.0604, -0.0634],\n",
      "         [-0.0474, -0.0933, -0.0318],\n",
      "         [-0.1269,  0.0205, -0.0053],\n",
      "         [ 0.0776, -0.1146, -0.0746],\n",
      "         [ 0.0424, -0.1249,  0.0516],\n",
      "         [ 0.0347,  0.0649, -0.1215],\n",
      "         [-0.0680, -0.0965,  0.0855],\n",
      "         [-0.0860,  0.1169, -0.1235],\n",
      "         [-0.0294, -0.0794,  0.0468],\n",
      "         [ 0.1285, -0.0840, -0.0719],\n",
      "         [-0.0640, -0.0807, -0.0516]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv2.bias | Size: torch.Size([16]) | Values : tensor([-0.1237, -0.0272], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[-0.2193],\n",
      "         [-0.2304],\n",
      "         [-0.1540],\n",
      "         [ 0.1534],\n",
      "         [ 0.1704],\n",
      "         [ 0.1228],\n",
      "         [-0.1782],\n",
      "         [-0.0788],\n",
      "         [-0.1903],\n",
      "         [-0.1147],\n",
      "         [ 0.1227],\n",
      "         [ 0.1118],\n",
      "         [ 0.1772],\n",
      "         [-0.0811],\n",
      "         [-0.0926],\n",
      "         [-0.2254]],\n",
      "\n",
      "        [[ 0.0428],\n",
      "         [ 0.2240],\n",
      "         [ 0.1181],\n",
      "         [-0.0207],\n",
      "         [-0.2313],\n",
      "         [ 0.0307],\n",
      "         [-0.0011],\n",
      "         [ 0.1362],\n",
      "         [-0.1484],\n",
      "         [-0.0888],\n",
      "         [-0.1722],\n",
      "         [-0.0796],\n",
      "         [-0.1979],\n",
      "         [-0.1170],\n",
      "         [-0.0877],\n",
      "         [-0.1874]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv3.bias | Size: torch.Size([64]) | Values : tensor([ 0.2267, -0.0939], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[-0.0818],\n",
      "         [ 0.0684],\n",
      "         [ 0.0516],\n",
      "         [-0.0716],\n",
      "         [-0.0599],\n",
      "         [-0.0076],\n",
      "         [-0.1115],\n",
      "         [-0.0812],\n",
      "         [-0.1104],\n",
      "         [-0.0813],\n",
      "         [-0.1063],\n",
      "         [-0.0673],\n",
      "         [-0.0147],\n",
      "         [ 0.0647],\n",
      "         [ 0.0693],\n",
      "         [ 0.0462],\n",
      "         [ 0.0295],\n",
      "         [-0.1205],\n",
      "         [-0.1071],\n",
      "         [-0.0017],\n",
      "         [ 0.0149],\n",
      "         [ 0.0867],\n",
      "         [-0.0194],\n",
      "         [-0.1160],\n",
      "         [ 0.0689],\n",
      "         [-0.1046],\n",
      "         [-0.0126],\n",
      "         [-0.0243],\n",
      "         [-0.0726],\n",
      "         [-0.1182],\n",
      "         [ 0.0110],\n",
      "         [-0.0283],\n",
      "         [-0.0470],\n",
      "         [ 0.0599],\n",
      "         [ 0.1184],\n",
      "         [-0.1062],\n",
      "         [-0.0356],\n",
      "         [-0.1219],\n",
      "         [-0.1088],\n",
      "         [-0.1201],\n",
      "         [ 0.0307],\n",
      "         [ 0.0028],\n",
      "         [-0.0060],\n",
      "         [ 0.0928],\n",
      "         [-0.1212],\n",
      "         [ 0.1157],\n",
      "         [ 0.1248],\n",
      "         [ 0.0770],\n",
      "         [-0.0584],\n",
      "         [ 0.0156],\n",
      "         [-0.1086],\n",
      "         [ 0.0352],\n",
      "         [-0.0460],\n",
      "         [-0.1055],\n",
      "         [-0.1022],\n",
      "         [ 0.0499],\n",
      "         [-0.0680],\n",
      "         [-0.0170],\n",
      "         [-0.0908],\n",
      "         [ 0.0972],\n",
      "         [-0.0481],\n",
      "         [-0.1226],\n",
      "         [-0.0112],\n",
      "         [-0.1096]],\n",
      "\n",
      "        [[ 0.0043],\n",
      "         [-0.0286],\n",
      "         [-0.1200],\n",
      "         [-0.1197],\n",
      "         [-0.1061],\n",
      "         [-0.0256],\n",
      "         [-0.0557],\n",
      "         [ 0.0355],\n",
      "         [-0.1022],\n",
      "         [ 0.0095],\n",
      "         [ 0.1066],\n",
      "         [ 0.0421],\n",
      "         [ 0.0457],\n",
      "         [-0.0743],\n",
      "         [ 0.0985],\n",
      "         [ 0.0803],\n",
      "         [ 0.0790],\n",
      "         [-0.0724],\n",
      "         [-0.0356],\n",
      "         [-0.1068],\n",
      "         [-0.0094],\n",
      "         [ 0.0172],\n",
      "         [-0.0492],\n",
      "         [-0.0927],\n",
      "         [-0.0680],\n",
      "         [ 0.0546],\n",
      "         [ 0.1046],\n",
      "         [-0.0893],\n",
      "         [-0.0939],\n",
      "         [ 0.1194],\n",
      "         [-0.0638],\n",
      "         [-0.0866],\n",
      "         [-0.1121],\n",
      "         [ 0.1161],\n",
      "         [-0.1070],\n",
      "         [ 0.0819],\n",
      "         [ 0.0286],\n",
      "         [-0.0332],\n",
      "         [-0.0319],\n",
      "         [ 0.0781],\n",
      "         [-0.0971],\n",
      "         [ 0.0393],\n",
      "         [ 0.0376],\n",
      "         [-0.1031],\n",
      "         [-0.0244],\n",
      "         [-0.0932],\n",
      "         [-0.0848],\n",
      "         [-0.1112],\n",
      "         [-0.0189],\n",
      "         [ 0.0094],\n",
      "         [-0.0327],\n",
      "         [ 0.0259],\n",
      "         [-0.0420],\n",
      "         [ 0.0496],\n",
      "         [ 0.0063],\n",
      "         [-0.0177],\n",
      "         [-0.0115],\n",
      "         [ 0.1224],\n",
      "         [-0.0102],\n",
      "         [ 0.1183],\n",
      "         [ 0.0847],\n",
      "         [-0.1043],\n",
      "         [ 0.1105],\n",
      "         [-0.0294]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.convr.bias | Size: torch.Size([64]) | Values : tensor([-0.0752,  0.1082], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[-0.0864],\n",
      "         [-0.0869],\n",
      "         [-0.0485],\n",
      "         [-0.0687],\n",
      "         [-0.1186],\n",
      "         [ 0.0175],\n",
      "         [-0.0893],\n",
      "         [ 0.0283],\n",
      "         [ 0.1137],\n",
      "         [-0.0188],\n",
      "         [ 0.0714],\n",
      "         [ 0.1105],\n",
      "         [-0.0155],\n",
      "         [-0.0953],\n",
      "         [ 0.1190],\n",
      "         [ 0.1192],\n",
      "         [-0.1230],\n",
      "         [ 0.0857],\n",
      "         [-0.1047],\n",
      "         [-0.1199],\n",
      "         [-0.0789],\n",
      "         [ 0.0730],\n",
      "         [-0.0702],\n",
      "         [-0.0029],\n",
      "         [ 0.0864],\n",
      "         [-0.0164],\n",
      "         [ 0.0417],\n",
      "         [ 0.0982],\n",
      "         [-0.0590],\n",
      "         [ 0.0328],\n",
      "         [ 0.0495],\n",
      "         [ 0.0555],\n",
      "         [-0.0011],\n",
      "         [ 0.0904],\n",
      "         [ 0.0107],\n",
      "         [-0.0262],\n",
      "         [ 0.1240],\n",
      "         [ 0.0814],\n",
      "         [-0.0634],\n",
      "         [-0.0512],\n",
      "         [ 0.0785],\n",
      "         [ 0.0651],\n",
      "         [ 0.0566],\n",
      "         [-0.1207],\n",
      "         [ 0.0863],\n",
      "         [ 0.1034],\n",
      "         [ 0.1231],\n",
      "         [-0.0623],\n",
      "         [-0.1182],\n",
      "         [-0.0204],\n",
      "         [-0.0110],\n",
      "         [-0.0367],\n",
      "         [-0.0823],\n",
      "         [-0.0400],\n",
      "         [ 0.0791],\n",
      "         [ 0.1185],\n",
      "         [-0.0865],\n",
      "         [ 0.1005],\n",
      "         [ 0.0911],\n",
      "         [ 0.1026],\n",
      "         [-0.0759],\n",
      "         [ 0.1214],\n",
      "         [-0.0429],\n",
      "         [ 0.1143]],\n",
      "\n",
      "        [[-0.0546],\n",
      "         [ 0.1168],\n",
      "         [ 0.1221],\n",
      "         [ 0.0083],\n",
      "         [-0.0578],\n",
      "         [ 0.0467],\n",
      "         [ 0.0884],\n",
      "         [ 0.1146],\n",
      "         [-0.1023],\n",
      "         [ 0.0715],\n",
      "         [ 0.1068],\n",
      "         [-0.0437],\n",
      "         [-0.0693],\n",
      "         [-0.0098],\n",
      "         [ 0.0796],\n",
      "         [-0.0088],\n",
      "         [ 0.0426],\n",
      "         [-0.1050],\n",
      "         [-0.0905],\n",
      "         [ 0.0218],\n",
      "         [ 0.0407],\n",
      "         [-0.1044],\n",
      "         [-0.0826],\n",
      "         [-0.0833],\n",
      "         [ 0.1050],\n",
      "         [-0.1033],\n",
      "         [-0.0074],\n",
      "         [-0.0341],\n",
      "         [-0.0514],\n",
      "         [ 0.0168],\n",
      "         [ 0.0644],\n",
      "         [-0.0695],\n",
      "         [-0.1169],\n",
      "         [-0.1236],\n",
      "         [-0.1072],\n",
      "         [-0.0938],\n",
      "         [ 0.0223],\n",
      "         [-0.1051],\n",
      "         [ 0.0807],\n",
      "         [-0.0013],\n",
      "         [-0.1023],\n",
      "         [-0.0949],\n",
      "         [ 0.0621],\n",
      "         [-0.1139],\n",
      "         [ 0.0883],\n",
      "         [-0.1099],\n",
      "         [-0.1019],\n",
      "         [ 0.0457],\n",
      "         [-0.0927],\n",
      "         [ 0.0233],\n",
      "         [ 0.0067],\n",
      "         [-0.0497],\n",
      "         [ 0.0365],\n",
      "         [-0.0643],\n",
      "         [-0.1163],\n",
      "         [ 0.1243],\n",
      "         [-0.0527],\n",
      "         [ 0.0048],\n",
      "         [-0.1201],\n",
      "         [-0.0283],\n",
      "         [ 0.0187],\n",
      "         [ 0.0502],\n",
      "         [ 0.0010],\n",
      "         [ 0.0131]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv1.bias | Size: torch.Size([16]) | Values : tensor([-0.1186, -0.1064], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[ 0.0560,  0.0707,  0.0883],\n",
      "         [-0.1074, -0.1205, -0.0904],\n",
      "         [ 0.0930,  0.1193, -0.1443],\n",
      "         [ 0.0083, -0.0167, -0.0156],\n",
      "         [ 0.0980, -0.0311, -0.0409],\n",
      "         [ 0.0179,  0.0535, -0.0663],\n",
      "         [-0.0979, -0.0200, -0.0123],\n",
      "         [-0.0556, -0.0023,  0.0488],\n",
      "         [ 0.0836,  0.1081,  0.0640],\n",
      "         [-0.1359, -0.0758,  0.0135],\n",
      "         [-0.0606, -0.0452, -0.0460],\n",
      "         [ 0.0903,  0.1294, -0.0122],\n",
      "         [-0.0017,  0.0244, -0.0700],\n",
      "         [-0.0226,  0.1300, -0.0088],\n",
      "         [-0.0367,  0.0005,  0.0054],\n",
      "         [-0.0219,  0.0805,  0.0162]],\n",
      "\n",
      "        [[-0.0392,  0.1442,  0.0642],\n",
      "         [ 0.0348, -0.1378,  0.0619],\n",
      "         [-0.1033,  0.1083, -0.1189],\n",
      "         [-0.0578,  0.0949, -0.0459],\n",
      "         [ 0.0189,  0.0034, -0.1192],\n",
      "         [ 0.1024, -0.0065,  0.0488],\n",
      "         [ 0.1052, -0.0313, -0.0375],\n",
      "         [-0.1009, -0.0788,  0.0976],\n",
      "         [-0.0436, -0.1369,  0.1180],\n",
      "         [-0.1361, -0.0497, -0.1391],\n",
      "         [-0.0786,  0.0383, -0.1030],\n",
      "         [ 0.0784,  0.1136,  0.0649],\n",
      "         [ 0.1009, -0.1083, -0.0726],\n",
      "         [-0.1189, -0.0189, -0.0248],\n",
      "         [ 0.1311, -0.1095, -0.0418],\n",
      "         [-0.0155,  0.0908,  0.0551]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv2.bias | Size: torch.Size([16]) | Values : tensor([-0.0933, -0.0669], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[ 0.0882],\n",
      "         [ 0.0937],\n",
      "         [-0.1774],\n",
      "         [-0.0214],\n",
      "         [ 0.0790],\n",
      "         [ 0.2058],\n",
      "         [ 0.0347],\n",
      "         [ 0.1253],\n",
      "         [-0.1710],\n",
      "         [ 0.1590],\n",
      "         [-0.0621],\n",
      "         [-0.1800],\n",
      "         [-0.0734],\n",
      "         [ 0.1742],\n",
      "         [ 0.1293],\n",
      "         [-0.0709]],\n",
      "\n",
      "        [[-0.1753],\n",
      "         [ 0.0903],\n",
      "         [-0.1331],\n",
      "         [-0.1961],\n",
      "         [ 0.2181],\n",
      "         [-0.0034],\n",
      "         [ 0.2101],\n",
      "         [ 0.1326],\n",
      "         [ 0.1311],\n",
      "         [-0.2369],\n",
      "         [ 0.2113],\n",
      "         [ 0.1669],\n",
      "         [ 0.0015],\n",
      "         [-0.0639],\n",
      "         [-0.0814],\n",
      "         [ 0.0104]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv3.bias | Size: torch.Size([64]) | Values : tensor([-0.1179, -0.2396], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[ 0.0319],\n",
      "         [-0.1209],\n",
      "         [ 0.0691],\n",
      "         [ 0.0462],\n",
      "         [-0.0090],\n",
      "         [-0.0408],\n",
      "         [ 0.1168],\n",
      "         [ 0.0392],\n",
      "         [-0.0268],\n",
      "         [-0.1075],\n",
      "         [-0.0364],\n",
      "         [ 0.0619],\n",
      "         [ 0.0585],\n",
      "         [ 0.0775],\n",
      "         [-0.0918],\n",
      "         [ 0.0599],\n",
      "         [-0.0503],\n",
      "         [-0.0882],\n",
      "         [ 0.0355],\n",
      "         [-0.0332],\n",
      "         [ 0.1031],\n",
      "         [-0.0084],\n",
      "         [ 0.1052],\n",
      "         [-0.1150],\n",
      "         [ 0.0961],\n",
      "         [-0.1097],\n",
      "         [-0.1038],\n",
      "         [ 0.0698],\n",
      "         [ 0.0735],\n",
      "         [-0.0756],\n",
      "         [ 0.0028],\n",
      "         [-0.0881],\n",
      "         [-0.0491],\n",
      "         [-0.0642],\n",
      "         [ 0.1049],\n",
      "         [-0.1197],\n",
      "         [-0.0468],\n",
      "         [-0.0140],\n",
      "         [ 0.0224],\n",
      "         [ 0.1068],\n",
      "         [ 0.1115],\n",
      "         [ 0.1166],\n",
      "         [-0.0094],\n",
      "         [-0.0527],\n",
      "         [-0.0978],\n",
      "         [-0.0037],\n",
      "         [-0.1205],\n",
      "         [-0.0709],\n",
      "         [ 0.0986],\n",
      "         [ 0.1172],\n",
      "         [ 0.0716],\n",
      "         [ 0.1058],\n",
      "         [ 0.0838],\n",
      "         [-0.0174],\n",
      "         [-0.0533],\n",
      "         [-0.0406],\n",
      "         [ 0.0194],\n",
      "         [-0.0452],\n",
      "         [-0.0884],\n",
      "         [-0.1210],\n",
      "         [-0.1189],\n",
      "         [ 0.1133],\n",
      "         [ 0.0169],\n",
      "         [-0.0591]],\n",
      "\n",
      "        [[ 0.0169],\n",
      "         [ 0.1102],\n",
      "         [-0.0820],\n",
      "         [ 0.0138],\n",
      "         [-0.0531],\n",
      "         [-0.0197],\n",
      "         [-0.0589],\n",
      "         [-0.0497],\n",
      "         [-0.0298],\n",
      "         [-0.0448],\n",
      "         [-0.0509],\n",
      "         [ 0.0828],\n",
      "         [-0.0180],\n",
      "         [-0.1127],\n",
      "         [-0.1213],\n",
      "         [-0.0806],\n",
      "         [ 0.0855],\n",
      "         [-0.1149],\n",
      "         [-0.0489],\n",
      "         [ 0.0851],\n",
      "         [ 0.0808],\n",
      "         [ 0.0351],\n",
      "         [ 0.0198],\n",
      "         [ 0.0915],\n",
      "         [-0.0575],\n",
      "         [ 0.0081],\n",
      "         [-0.0612],\n",
      "         [ 0.1143],\n",
      "         [ 0.1144],\n",
      "         [-0.0452],\n",
      "         [ 0.0484],\n",
      "         [-0.0305],\n",
      "         [-0.0199],\n",
      "         [ 0.0144],\n",
      "         [ 0.0426],\n",
      "         [-0.0469],\n",
      "         [ 0.0036],\n",
      "         [-0.1145],\n",
      "         [-0.0335],\n",
      "         [ 0.0114],\n",
      "         [-0.0933],\n",
      "         [ 0.0086],\n",
      "         [ 0.0795],\n",
      "         [ 0.0982],\n",
      "         [ 0.0782],\n",
      "         [ 0.0849],\n",
      "         [-0.0627],\n",
      "         [ 0.0882],\n",
      "         [ 0.0707],\n",
      "         [-0.0032],\n",
      "         [-0.1109],\n",
      "         [-0.0607],\n",
      "         [-0.1174],\n",
      "         [-0.0297],\n",
      "         [ 0.0113],\n",
      "         [ 0.0671],\n",
      "         [ 0.0116],\n",
      "         [ 0.1001],\n",
      "         [ 0.0631],\n",
      "         [-0.1176],\n",
      "         [ 0.0327],\n",
      "         [-0.0400],\n",
      "         [-0.0699],\n",
      "         [ 0.0881]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.convr.bias | Size: torch.Size([64]) | Values : tensor([0.0672, 0.0658], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[-0.0132],\n",
      "         [-0.0194],\n",
      "         [ 0.1097],\n",
      "         [ 0.0765],\n",
      "         [ 0.0280],\n",
      "         [-0.0116],\n",
      "         [ 0.0656],\n",
      "         [ 0.0887],\n",
      "         [-0.0797],\n",
      "         [ 0.0523],\n",
      "         [-0.0351],\n",
      "         [-0.1172],\n",
      "         [-0.0888],\n",
      "         [ 0.0117],\n",
      "         [ 0.0005],\n",
      "         [ 0.1009],\n",
      "         [-0.1128],\n",
      "         [-0.0237],\n",
      "         [ 0.0433],\n",
      "         [-0.1239],\n",
      "         [-0.1198],\n",
      "         [-0.0526],\n",
      "         [ 0.1108],\n",
      "         [-0.0219],\n",
      "         [ 0.0221],\n",
      "         [ 0.0025],\n",
      "         [-0.0572],\n",
      "         [-0.0004],\n",
      "         [-0.1150],\n",
      "         [ 0.0701],\n",
      "         [-0.0550],\n",
      "         [ 0.1104],\n",
      "         [ 0.0481],\n",
      "         [-0.0089],\n",
      "         [-0.0974],\n",
      "         [ 0.1132],\n",
      "         [ 0.1220],\n",
      "         [-0.0062],\n",
      "         [-0.0743],\n",
      "         [ 0.0127],\n",
      "         [-0.0267],\n",
      "         [ 0.1107],\n",
      "         [ 0.0390],\n",
      "         [ 0.0738],\n",
      "         [ 0.0441],\n",
      "         [ 0.0739],\n",
      "         [-0.0350],\n",
      "         [ 0.0316],\n",
      "         [ 0.0358],\n",
      "         [-0.0277],\n",
      "         [-0.1226],\n",
      "         [-0.0282],\n",
      "         [ 0.1220],\n",
      "         [ 0.1134],\n",
      "         [-0.0302],\n",
      "         [ 0.0589],\n",
      "         [-0.0836],\n",
      "         [ 0.0617],\n",
      "         [ 0.0498],\n",
      "         [ 0.0878],\n",
      "         [-0.0838],\n",
      "         [ 0.0432],\n",
      "         [-0.0182],\n",
      "         [-0.0646]],\n",
      "\n",
      "        [[-0.0715],\n",
      "         [ 0.0537],\n",
      "         [ 0.0839],\n",
      "         [ 0.0996],\n",
      "         [-0.0547],\n",
      "         [ 0.0932],\n",
      "         [-0.0010],\n",
      "         [ 0.0636],\n",
      "         [ 0.1101],\n",
      "         [-0.0817],\n",
      "         [-0.1007],\n",
      "         [ 0.0794],\n",
      "         [ 0.0574],\n",
      "         [ 0.0615],\n",
      "         [ 0.0223],\n",
      "         [ 0.0630],\n",
      "         [ 0.0577],\n",
      "         [ 0.0159],\n",
      "         [-0.1082],\n",
      "         [ 0.0730],\n",
      "         [-0.0010],\n",
      "         [-0.0727],\n",
      "         [-0.0989],\n",
      "         [-0.0207],\n",
      "         [ 0.1176],\n",
      "         [-0.0692],\n",
      "         [ 0.1223],\n",
      "         [-0.0085],\n",
      "         [-0.0307],\n",
      "         [-0.0218],\n",
      "         [-0.0899],\n",
      "         [-0.0134],\n",
      "         [ 0.0254],\n",
      "         [ 0.0806],\n",
      "         [ 0.1243],\n",
      "         [ 0.0677],\n",
      "         [ 0.0696],\n",
      "         [ 0.0907],\n",
      "         [-0.0256],\n",
      "         [-0.0468],\n",
      "         [-0.0570],\n",
      "         [-0.0485],\n",
      "         [-0.0924],\n",
      "         [ 0.0271],\n",
      "         [ 0.0820],\n",
      "         [ 0.0887],\n",
      "         [ 0.0072],\n",
      "         [-0.0043],\n",
      "         [-0.1237],\n",
      "         [-0.1175],\n",
      "         [ 0.0723],\n",
      "         [ 0.0028],\n",
      "         [ 0.1245],\n",
      "         [-0.0319],\n",
      "         [-0.1022],\n",
      "         [ 0.0104],\n",
      "         [ 0.0307],\n",
      "         [-0.0162],\n",
      "         [-0.0488],\n",
      "         [-0.0904],\n",
      "         [-0.1153],\n",
      "         [-0.0338],\n",
      "         [-0.0514],\n",
      "         [-0.0816]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.conv1.bias | Size: torch.Size([16]) | Values : tensor([0.0192, 0.0856], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[-0.1173, -0.0095,  0.0778],\n",
      "         [ 0.0961,  0.0761, -0.1308],\n",
      "         [-0.0110,  0.1210, -0.1384],\n",
      "         [-0.1171, -0.0170, -0.1426],\n",
      "         [ 0.0207, -0.0149,  0.0081],\n",
      "         [-0.0780,  0.0121,  0.0433],\n",
      "         [-0.0398,  0.0761, -0.0607],\n",
      "         [-0.0480,  0.0441, -0.0102],\n",
      "         [-0.0143,  0.0206, -0.0809],\n",
      "         [ 0.0313, -0.0540, -0.0148],\n",
      "         [ 0.0944,  0.0546,  0.0409],\n",
      "         [ 0.0435, -0.0808, -0.0266],\n",
      "         [ 0.0309, -0.0064, -0.0528],\n",
      "         [ 0.0181, -0.0328,  0.0875],\n",
      "         [ 0.1121, -0.0601, -0.1424],\n",
      "         [-0.0486,  0.0153, -0.1059]],\n",
      "\n",
      "        [[-0.0363, -0.1085, -0.1403],\n",
      "         [ 0.1421,  0.0436, -0.1041],\n",
      "         [-0.0592, -0.0657, -0.1307],\n",
      "         [ 0.1164,  0.1317,  0.1351],\n",
      "         [-0.1170, -0.0984, -0.0286],\n",
      "         [-0.1230,  0.0443,  0.1001],\n",
      "         [ 0.1245,  0.1043,  0.0345],\n",
      "         [ 0.0673, -0.0049, -0.0746],\n",
      "         [-0.1387,  0.0399,  0.0904],\n",
      "         [-0.1226,  0.0923,  0.1011],\n",
      "         [ 0.0436, -0.0849,  0.0017],\n",
      "         [-0.0988,  0.0277, -0.0689],\n",
      "         [ 0.0103, -0.0941, -0.0599],\n",
      "         [ 0.0190, -0.0048,  0.1248],\n",
      "         [ 0.1034,  0.0995, -0.0085],\n",
      "         [ 0.0370, -0.0187, -0.0003]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.conv2.bias | Size: torch.Size([16]) | Values : tensor([-0.0320,  0.0744], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[ 0.1917],\n",
      "         [-0.0532],\n",
      "         [-0.0378],\n",
      "         [ 0.0129],\n",
      "         [ 0.0879],\n",
      "         [-0.2283],\n",
      "         [-0.0208],\n",
      "         [ 0.1772],\n",
      "         [ 0.1948],\n",
      "         [ 0.2113],\n",
      "         [-0.0872],\n",
      "         [-0.1817],\n",
      "         [-0.1324],\n",
      "         [ 0.0603],\n",
      "         [ 0.0058],\n",
      "         [ 0.1020]],\n",
      "\n",
      "        [[-0.1004],\n",
      "         [-0.1735],\n",
      "         [-0.1606],\n",
      "         [ 0.1768],\n",
      "         [ 0.1007],\n",
      "         [ 0.2234],\n",
      "         [ 0.0811],\n",
      "         [-0.0778],\n",
      "         [ 0.1897],\n",
      "         [ 0.2378],\n",
      "         [ 0.0145],\n",
      "         [-0.2398],\n",
      "         [-0.0528],\n",
      "         [-0.0895],\n",
      "         [ 0.0192],\n",
      "         [-0.0970]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.conv3.bias | Size: torch.Size([64]) | Values : tensor([0.1177, 0.1279], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[ 0.0829],\n",
      "         [-0.0893],\n",
      "         [ 0.0180],\n",
      "         [ 0.0541],\n",
      "         [ 0.0613],\n",
      "         [ 0.0545],\n",
      "         [ 0.0354],\n",
      "         [-0.0388],\n",
      "         [-0.0213],\n",
      "         [-0.0129],\n",
      "         [-0.1167],\n",
      "         [-0.0558],\n",
      "         [-0.1193],\n",
      "         [-0.0709],\n",
      "         [ 0.0521],\n",
      "         [-0.0987],\n",
      "         [-0.1061],\n",
      "         [ 0.0752],\n",
      "         [-0.0467],\n",
      "         [ 0.0351],\n",
      "         [ 0.0040],\n",
      "         [ 0.0633],\n",
      "         [-0.1194],\n",
      "         [ 0.0094],\n",
      "         [ 0.0576],\n",
      "         [ 0.0997],\n",
      "         [-0.0241],\n",
      "         [ 0.1086],\n",
      "         [ 0.0709],\n",
      "         [ 0.0761],\n",
      "         [-0.0907],\n",
      "         [-0.0659],\n",
      "         [-0.0992],\n",
      "         [ 0.1142],\n",
      "         [ 0.0713],\n",
      "         [-0.0178],\n",
      "         [ 0.0060],\n",
      "         [ 0.0338],\n",
      "         [-0.0334],\n",
      "         [-0.0480],\n",
      "         [-0.0312],\n",
      "         [ 0.0181],\n",
      "         [ 0.0576],\n",
      "         [ 0.0700],\n",
      "         [ 0.0635],\n",
      "         [-0.0157],\n",
      "         [-0.0686],\n",
      "         [-0.0523],\n",
      "         [ 0.0899],\n",
      "         [-0.0074],\n",
      "         [-0.0241],\n",
      "         [-0.0869],\n",
      "         [ 0.0643],\n",
      "         [ 0.1171],\n",
      "         [ 0.0605],\n",
      "         [-0.0111],\n",
      "         [-0.0928],\n",
      "         [-0.0344],\n",
      "         [ 0.0411],\n",
      "         [-0.0130],\n",
      "         [ 0.1212],\n",
      "         [-0.0107],\n",
      "         [-0.0044],\n",
      "         [ 0.1195]],\n",
      "\n",
      "        [[ 0.0977],\n",
      "         [ 0.0274],\n",
      "         [-0.0868],\n",
      "         [-0.0602],\n",
      "         [ 0.1193],\n",
      "         [ 0.0598],\n",
      "         [-0.0259],\n",
      "         [ 0.1181],\n",
      "         [ 0.0151],\n",
      "         [ 0.0138],\n",
      "         [ 0.1060],\n",
      "         [ 0.1024],\n",
      "         [-0.0290],\n",
      "         [-0.0388],\n",
      "         [-0.1157],\n",
      "         [ 0.0693],\n",
      "         [-0.0487],\n",
      "         [-0.0693],\n",
      "         [ 0.1121],\n",
      "         [ 0.0107],\n",
      "         [ 0.0691],\n",
      "         [ 0.1188],\n",
      "         [ 0.0003],\n",
      "         [-0.1170],\n",
      "         [ 0.0614],\n",
      "         [ 0.0151],\n",
      "         [-0.0774],\n",
      "         [-0.0834],\n",
      "         [ 0.0098],\n",
      "         [ 0.1056],\n",
      "         [ 0.0679],\n",
      "         [-0.0802],\n",
      "         [-0.0571],\n",
      "         [-0.0595],\n",
      "         [ 0.0258],\n",
      "         [ 0.0672],\n",
      "         [-0.0260],\n",
      "         [ 0.0965],\n",
      "         [ 0.0046],\n",
      "         [ 0.1048],\n",
      "         [-0.0795],\n",
      "         [ 0.0276],\n",
      "         [ 0.0319],\n",
      "         [-0.0630],\n",
      "         [-0.1040],\n",
      "         [-0.0596],\n",
      "         [-0.0721],\n",
      "         [-0.0076],\n",
      "         [ 0.0191],\n",
      "         [ 0.0249],\n",
      "         [-0.1004],\n",
      "         [ 0.1017],\n",
      "         [-0.1053],\n",
      "         [-0.0927],\n",
      "         [ 0.0036],\n",
      "         [-0.0539],\n",
      "         [-0.0043],\n",
      "         [-0.0005],\n",
      "         [ 0.1235],\n",
      "         [-0.0523],\n",
      "         [ 0.0415],\n",
      "         [-0.0845],\n",
      "         [-0.0955],\n",
      "         [ 0.0582]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv1.bias | Size: torch.Size([16]) | Values : tensor([ 0.1147, -0.0614], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[ 0.1024,  0.0047, -0.0879],\n",
      "         [ 0.1045,  0.1106,  0.0338],\n",
      "         [-0.1420,  0.0718,  0.0524],\n",
      "         [ 0.1020,  0.0250, -0.1207],\n",
      "         [ 0.0004,  0.1334,  0.0940],\n",
      "         [-0.0635,  0.0958, -0.0241],\n",
      "         [-0.0566,  0.0058, -0.1255],\n",
      "         [-0.0269, -0.1357, -0.1132],\n",
      "         [ 0.0477, -0.1274, -0.0317],\n",
      "         [-0.0886,  0.0318, -0.1357],\n",
      "         [-0.1121, -0.0135,  0.0414],\n",
      "         [-0.1381, -0.0062, -0.0058],\n",
      "         [ 0.0772, -0.0495, -0.1178],\n",
      "         [-0.0824,  0.0625,  0.0393],\n",
      "         [-0.1243, -0.0245,  0.1352],\n",
      "         [-0.0004, -0.1405,  0.0008]],\n",
      "\n",
      "        [[ 0.0569,  0.1206, -0.0346],\n",
      "         [ 0.1190, -0.0336, -0.1170],\n",
      "         [-0.1204, -0.1359,  0.0225],\n",
      "         [-0.0127, -0.0690, -0.1003],\n",
      "         [-0.1277, -0.0350, -0.0973],\n",
      "         [-0.0074,  0.1049,  0.0828],\n",
      "         [-0.1328, -0.0365, -0.1438],\n",
      "         [ 0.0938, -0.1150,  0.0682],\n",
      "         [ 0.1017,  0.0815,  0.0483],\n",
      "         [-0.0890,  0.0785, -0.0086],\n",
      "         [-0.1130,  0.0329,  0.0241],\n",
      "         [-0.1074,  0.0631,  0.0569],\n",
      "         [-0.0867,  0.0500,  0.1314],\n",
      "         [ 0.0815,  0.0681,  0.0660],\n",
      "         [ 0.0558,  0.0628,  0.0918],\n",
      "         [ 0.0737,  0.0810, -0.0413]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv2.bias | Size: torch.Size([16]) | Values : tensor([-7.4074e-05, -2.8947e-02], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[-0.0734],\n",
      "         [-0.2379],\n",
      "         [ 0.2361],\n",
      "         [ 0.0711],\n",
      "         [ 0.1939],\n",
      "         [ 0.2399],\n",
      "         [ 0.0705],\n",
      "         [ 0.1971],\n",
      "         [-0.1319],\n",
      "         [-0.2084],\n",
      "         [ 0.1880],\n",
      "         [-0.0354],\n",
      "         [-0.2490],\n",
      "         [ 0.0080],\n",
      "         [ 0.1297],\n",
      "         [ 0.1883]],\n",
      "\n",
      "        [[-0.1120],\n",
      "         [ 0.2254],\n",
      "         [-0.2493],\n",
      "         [-0.0716],\n",
      "         [ 0.1333],\n",
      "         [-0.1103],\n",
      "         [-0.0041],\n",
      "         [-0.1701],\n",
      "         [-0.1817],\n",
      "         [ 0.0619],\n",
      "         [-0.0601],\n",
      "         [-0.2450],\n",
      "         [-0.0349],\n",
      "         [ 0.1105],\n",
      "         [-0.0751],\n",
      "         [-0.0889]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv3.bias | Size: torch.Size([64]) | Values : tensor([-0.0059,  0.1147], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[-0.0545],\n",
      "         [-0.0201],\n",
      "         [ 0.0651],\n",
      "         [-0.1084],\n",
      "         [ 0.1085],\n",
      "         [ 0.0137],\n",
      "         [ 0.0924],\n",
      "         [-0.1179],\n",
      "         [ 0.0860],\n",
      "         [ 0.0816],\n",
      "         [-0.1208],\n",
      "         [ 0.0487],\n",
      "         [-0.0475],\n",
      "         [ 0.0853],\n",
      "         [ 0.1088],\n",
      "         [-0.0287],\n",
      "         [-0.0577],\n",
      "         [-0.0109],\n",
      "         [-0.0814],\n",
      "         [-0.1152],\n",
      "         [-0.0613],\n",
      "         [-0.1180],\n",
      "         [ 0.0517],\n",
      "         [-0.0970],\n",
      "         [-0.1091],\n",
      "         [-0.0111],\n",
      "         [ 0.0104],\n",
      "         [ 0.0210],\n",
      "         [ 0.1176],\n",
      "         [ 0.0483],\n",
      "         [-0.0132],\n",
      "         [-0.1191],\n",
      "         [ 0.0836],\n",
      "         [-0.0724],\n",
      "         [-0.0523],\n",
      "         [ 0.0401],\n",
      "         [-0.0554],\n",
      "         [-0.0798],\n",
      "         [-0.1130],\n",
      "         [-0.0689],\n",
      "         [ 0.0127],\n",
      "         [ 0.0083],\n",
      "         [ 0.0292],\n",
      "         [ 0.0178],\n",
      "         [-0.0710],\n",
      "         [ 0.0988],\n",
      "         [ 0.0285],\n",
      "         [-0.0756],\n",
      "         [-0.1046],\n",
      "         [ 0.0434],\n",
      "         [-0.0597],\n",
      "         [-0.0766],\n",
      "         [ 0.1249],\n",
      "         [ 0.1120],\n",
      "         [ 0.0588],\n",
      "         [-0.0910],\n",
      "         [ 0.1079],\n",
      "         [-0.0429],\n",
      "         [ 0.0431],\n",
      "         [ 0.0537],\n",
      "         [ 0.0094],\n",
      "         [ 0.0485],\n",
      "         [-0.0335],\n",
      "         [ 0.0729]],\n",
      "\n",
      "        [[-0.1248],\n",
      "         [ 0.1206],\n",
      "         [-0.0714],\n",
      "         [ 0.0913],\n",
      "         [ 0.1206],\n",
      "         [-0.1204],\n",
      "         [-0.1218],\n",
      "         [ 0.0120],\n",
      "         [ 0.0155],\n",
      "         [-0.1003],\n",
      "         [-0.0528],\n",
      "         [-0.0316],\n",
      "         [-0.0009],\n",
      "         [-0.0415],\n",
      "         [-0.0703],\n",
      "         [-0.0917],\n",
      "         [ 0.1083],\n",
      "         [-0.0364],\n",
      "         [ 0.0787],\n",
      "         [-0.0785],\n",
      "         [ 0.0045],\n",
      "         [-0.0716],\n",
      "         [-0.0732],\n",
      "         [ 0.0482],\n",
      "         [ 0.0737],\n",
      "         [-0.0349],\n",
      "         [ 0.0802],\n",
      "         [ 0.0444],\n",
      "         [ 0.0152],\n",
      "         [ 0.0046],\n",
      "         [-0.1134],\n",
      "         [-0.0321],\n",
      "         [-0.0299],\n",
      "         [ 0.0745],\n",
      "         [-0.0565],\n",
      "         [-0.1041],\n",
      "         [ 0.0156],\n",
      "         [-0.0428],\n",
      "         [-0.1012],\n",
      "         [-0.0591],\n",
      "         [-0.0418],\n",
      "         [-0.0891],\n",
      "         [ 0.0962],\n",
      "         [-0.1115],\n",
      "         [ 0.0045],\n",
      "         [-0.0573],\n",
      "         [ 0.0125],\n",
      "         [-0.0868],\n",
      "         [-0.0400],\n",
      "         [ 0.0428],\n",
      "         [ 0.0820],\n",
      "         [ 0.0131],\n",
      "         [ 0.0750],\n",
      "         [ 0.0974],\n",
      "         [-0.1040],\n",
      "         [ 0.0785],\n",
      "         [-0.0998],\n",
      "         [-0.0552],\n",
      "         [-0.0038],\n",
      "         [-0.0214],\n",
      "         [ 0.0192],\n",
      "         [ 0.0963],\n",
      "         [-0.0976],\n",
      "         [-0.0010]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.convr.bias | Size: torch.Size([64]) | Values : tensor([-0.0741,  0.0013], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[ 0.1016],\n",
      "         [-0.1232],\n",
      "         [-0.0427],\n",
      "         [-0.0024],\n",
      "         [ 0.0080],\n",
      "         [-0.0711],\n",
      "         [ 0.1115],\n",
      "         [ 0.1229],\n",
      "         [ 0.0005],\n",
      "         [-0.1146],\n",
      "         [ 0.0766],\n",
      "         [ 0.0442],\n",
      "         [-0.0093],\n",
      "         [-0.0750],\n",
      "         [-0.1105],\n",
      "         [-0.0183],\n",
      "         [-0.0499],\n",
      "         [ 0.0404],\n",
      "         [-0.0031],\n",
      "         [-0.0709],\n",
      "         [ 0.0631],\n",
      "         [ 0.0354],\n",
      "         [ 0.0605],\n",
      "         [-0.0436],\n",
      "         [-0.1108],\n",
      "         [ 0.1143],\n",
      "         [ 0.1234],\n",
      "         [-0.0174],\n",
      "         [ 0.0513],\n",
      "         [ 0.0774],\n",
      "         [ 0.1204],\n",
      "         [-0.0560],\n",
      "         [ 0.0443],\n",
      "         [-0.0316],\n",
      "         [ 0.1002],\n",
      "         [-0.1159],\n",
      "         [ 0.0585],\n",
      "         [ 0.0254],\n",
      "         [ 0.1085],\n",
      "         [ 0.0870],\n",
      "         [ 0.0400],\n",
      "         [-0.0876],\n",
      "         [ 0.0443],\n",
      "         [ 0.1076],\n",
      "         [ 0.0213],\n",
      "         [-0.0147],\n",
      "         [ 0.0806],\n",
      "         [-0.0052],\n",
      "         [ 0.0125],\n",
      "         [-0.0548],\n",
      "         [-0.0126],\n",
      "         [ 0.0142],\n",
      "         [-0.0451],\n",
      "         [ 0.0628],\n",
      "         [ 0.0540],\n",
      "         [-0.0750],\n",
      "         [ 0.1141],\n",
      "         [ 0.1080],\n",
      "         [-0.0765],\n",
      "         [-0.1063],\n",
      "         [ 0.0807],\n",
      "         [ 0.0297],\n",
      "         [ 0.1179],\n",
      "         [ 0.0772]],\n",
      "\n",
      "        [[ 0.0136],\n",
      "         [ 0.0734],\n",
      "         [-0.0092],\n",
      "         [ 0.0198],\n",
      "         [-0.0591],\n",
      "         [-0.0945],\n",
      "         [ 0.0600],\n",
      "         [-0.0553],\n",
      "         [-0.0877],\n",
      "         [-0.0228],\n",
      "         [-0.0183],\n",
      "         [-0.0520],\n",
      "         [-0.0569],\n",
      "         [ 0.0931],\n",
      "         [ 0.0748],\n",
      "         [-0.0490],\n",
      "         [ 0.0713],\n",
      "         [-0.1060],\n",
      "         [-0.0832],\n",
      "         [-0.0846],\n",
      "         [ 0.0412],\n",
      "         [-0.0925],\n",
      "         [-0.0648],\n",
      "         [-0.1005],\n",
      "         [-0.1040],\n",
      "         [ 0.0007],\n",
      "         [ 0.0569],\n",
      "         [ 0.1102],\n",
      "         [-0.1057],\n",
      "         [-0.0097],\n",
      "         [ 0.1094],\n",
      "         [ 0.0448],\n",
      "         [ 0.0753],\n",
      "         [ 0.0286],\n",
      "         [-0.0006],\n",
      "         [ 0.0449],\n",
      "         [-0.0769],\n",
      "         [-0.0904],\n",
      "         [-0.0692],\n",
      "         [-0.0812],\n",
      "         [ 0.0583],\n",
      "         [ 0.0028],\n",
      "         [-0.1087],\n",
      "         [ 0.0247],\n",
      "         [-0.0103],\n",
      "         [ 0.0633],\n",
      "         [ 0.1105],\n",
      "         [ 0.0326],\n",
      "         [-0.1158],\n",
      "         [-0.0144],\n",
      "         [ 0.0053],\n",
      "         [-0.0620],\n",
      "         [ 0.0934],\n",
      "         [-0.0860],\n",
      "         [-0.0799],\n",
      "         [ 0.1076],\n",
      "         [-0.1033],\n",
      "         [-0.0075],\n",
      "         [ 0.1113],\n",
      "         [-0.0417],\n",
      "         [ 0.0563],\n",
      "         [ 0.0880],\n",
      "         [ 0.1204],\n",
      "         [-0.0278]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.conv1.bias | Size: torch.Size([16]) | Values : tensor([0.0472, 0.1181], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[-0.0670,  0.1337, -0.1186],\n",
      "         [-0.0201,  0.0969, -0.1217],\n",
      "         [-0.0101,  0.0215,  0.0915],\n",
      "         [-0.0966,  0.1127, -0.0979],\n",
      "         [ 0.0583, -0.0028, -0.1057],\n",
      "         [-0.0583, -0.0597, -0.0230],\n",
      "         [-0.0767,  0.1190,  0.0902],\n",
      "         [ 0.0934, -0.1404, -0.1190],\n",
      "         [ 0.0529, -0.0062, -0.0627],\n",
      "         [-0.0067, -0.1330,  0.0057],\n",
      "         [-0.1181,  0.1372, -0.0246],\n",
      "         [ 0.0716, -0.1234, -0.1332],\n",
      "         [ 0.0970, -0.1433, -0.0229],\n",
      "         [ 0.1261,  0.0149, -0.0496],\n",
      "         [-0.0245,  0.0023,  0.0444],\n",
      "         [-0.1345, -0.1063, -0.1258]],\n",
      "\n",
      "        [[ 0.0281, -0.0481,  0.0358],\n",
      "         [ 0.0359,  0.0336, -0.1259],\n",
      "         [-0.0529, -0.0441,  0.1055],\n",
      "         [-0.0085, -0.1002,  0.1216],\n",
      "         [ 0.0294, -0.1202,  0.0546],\n",
      "         [ 0.0151, -0.0989, -0.1032],\n",
      "         [-0.0522,  0.0983,  0.0194],\n",
      "         [-0.0732, -0.1118,  0.1028],\n",
      "         [ 0.0392,  0.0286, -0.0936],\n",
      "         [-0.0196,  0.1352,  0.1188],\n",
      "         [-0.0424,  0.0468, -0.0307],\n",
      "         [ 0.0974, -0.0569, -0.0398],\n",
      "         [ 0.1017, -0.1313,  0.0213],\n",
      "         [ 0.0897,  0.0518, -0.1384],\n",
      "         [-0.1091, -0.1437, -0.1226],\n",
      "         [ 0.0139, -0.0723,  0.0894]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.conv2.bias | Size: torch.Size([16]) | Values : tensor([-0.0657,  0.1116], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[-0.1725],\n",
      "         [-0.2469],\n",
      "         [-0.2475],\n",
      "         [ 0.2329],\n",
      "         [ 0.0885],\n",
      "         [-0.2237],\n",
      "         [-0.2248],\n",
      "         [ 0.0826],\n",
      "         [-0.0962],\n",
      "         [-0.1861],\n",
      "         [-0.0547],\n",
      "         [-0.1655],\n",
      "         [ 0.1980],\n",
      "         [ 0.0286],\n",
      "         [ 0.2166],\n",
      "         [ 0.1512]],\n",
      "\n",
      "        [[ 0.2142],\n",
      "         [-0.0722],\n",
      "         [-0.0286],\n",
      "         [-0.0587],\n",
      "         [-0.0473],\n",
      "         [-0.0748],\n",
      "         [ 0.0796],\n",
      "         [ 0.0960],\n",
      "         [ 0.0003],\n",
      "         [-0.1641],\n",
      "         [-0.1844],\n",
      "         [-0.1006],\n",
      "         [-0.0219],\n",
      "         [ 0.1126],\n",
      "         [ 0.1781],\n",
      "         [ 0.0178]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.conv3.bias | Size: torch.Size([64]) | Values : tensor([ 0.0238, -0.1841], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[ 0.0578],\n",
      "         [-0.1153],\n",
      "         [ 0.0062],\n",
      "         [-0.1025],\n",
      "         [-0.0527],\n",
      "         [ 0.0927],\n",
      "         [ 0.0456],\n",
      "         [ 0.1051],\n",
      "         [-0.0744],\n",
      "         [ 0.1227],\n",
      "         [-0.0406],\n",
      "         [ 0.0114],\n",
      "         [ 0.0975],\n",
      "         [-0.0662],\n",
      "         [ 0.0012],\n",
      "         [-0.0563],\n",
      "         [-0.0382],\n",
      "         [ 0.0429],\n",
      "         [-0.0971],\n",
      "         [ 0.0653],\n",
      "         [-0.0610],\n",
      "         [ 0.1089],\n",
      "         [-0.1177],\n",
      "         [ 0.0735],\n",
      "         [ 0.0052],\n",
      "         [-0.0165],\n",
      "         [ 0.0033],\n",
      "         [-0.0391],\n",
      "         [-0.0434],\n",
      "         [-0.0040],\n",
      "         [ 0.0183],\n",
      "         [ 0.0115],\n",
      "         [ 0.0009],\n",
      "         [ 0.0708],\n",
      "         [ 0.0095],\n",
      "         [-0.0320],\n",
      "         [ 0.0258],\n",
      "         [ 0.0767],\n",
      "         [ 0.0001],\n",
      "         [ 0.1233],\n",
      "         [ 0.0608],\n",
      "         [-0.1248],\n",
      "         [-0.0600],\n",
      "         [-0.1026],\n",
      "         [-0.0995],\n",
      "         [-0.1132],\n",
      "         [-0.0314],\n",
      "         [-0.0669],\n",
      "         [ 0.0091],\n",
      "         [ 0.0993],\n",
      "         [ 0.0544],\n",
      "         [ 0.0793],\n",
      "         [-0.0038],\n",
      "         [ 0.1066],\n",
      "         [ 0.0061],\n",
      "         [-0.0341],\n",
      "         [-0.0564],\n",
      "         [-0.0130],\n",
      "         [-0.0446],\n",
      "         [-0.0895],\n",
      "         [-0.0232],\n",
      "         [-0.0705],\n",
      "         [-0.0498],\n",
      "         [-0.0475]],\n",
      "\n",
      "        [[ 0.0863],\n",
      "         [-0.0932],\n",
      "         [ 0.1036],\n",
      "         [ 0.0173],\n",
      "         [-0.0499],\n",
      "         [ 0.0367],\n",
      "         [ 0.1204],\n",
      "         [-0.0573],\n",
      "         [ 0.0651],\n",
      "         [-0.0245],\n",
      "         [ 0.0401],\n",
      "         [ 0.0489],\n",
      "         [-0.0359],\n",
      "         [ 0.0328],\n",
      "         [-0.0562],\n",
      "         [ 0.0335],\n",
      "         [-0.0170],\n",
      "         [-0.0005],\n",
      "         [-0.0889],\n",
      "         [ 0.0389],\n",
      "         [-0.0667],\n",
      "         [ 0.1058],\n",
      "         [-0.0110],\n",
      "         [-0.0586],\n",
      "         [-0.1078],\n",
      "         [ 0.0665],\n",
      "         [-0.1108],\n",
      "         [ 0.0586],\n",
      "         [-0.1140],\n",
      "         [ 0.1114],\n",
      "         [-0.0518],\n",
      "         [-0.0677],\n",
      "         [-0.1196],\n",
      "         [-0.0087],\n",
      "         [ 0.0310],\n",
      "         [ 0.0194],\n",
      "         [ 0.0210],\n",
      "         [-0.0750],\n",
      "         [ 0.0879],\n",
      "         [ 0.1025],\n",
      "         [ 0.0478],\n",
      "         [-0.0979],\n",
      "         [ 0.0388],\n",
      "         [ 0.0039],\n",
      "         [-0.0189],\n",
      "         [ 0.0635],\n",
      "         [-0.1173],\n",
      "         [-0.0887],\n",
      "         [ 0.1120],\n",
      "         [ 0.0080],\n",
      "         [ 0.1179],\n",
      "         [ 0.1166],\n",
      "         [ 0.0422],\n",
      "         [-0.1192],\n",
      "         [-0.0141],\n",
      "         [-0.0364],\n",
      "         [-0.0843],\n",
      "         [-0.0237],\n",
      "         [ 0.0935],\n",
      "         [-0.0816],\n",
      "         [ 0.0368],\n",
      "         [-0.0979],\n",
      "         [-0.0301],\n",
      "         [-0.0799]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv1.bias | Size: torch.Size([16]) | Values : tensor([ 0.0566, -0.1239], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[-0.0215, -0.1247,  0.1145],\n",
      "         [ 0.0355,  0.0954,  0.1160],\n",
      "         [ 0.0778, -0.0290, -0.0827],\n",
      "         [ 0.1140,  0.0417,  0.1250],\n",
      "         [ 0.0631,  0.1112, -0.0668],\n",
      "         [ 0.0157, -0.0024, -0.0212],\n",
      "         [ 0.0167,  0.0799, -0.0377],\n",
      "         [ 0.0409,  0.0578, -0.0869],\n",
      "         [ 0.0218,  0.1050,  0.0796],\n",
      "         [-0.0935,  0.0828,  0.0977],\n",
      "         [-0.0510, -0.0141, -0.1195],\n",
      "         [-0.1072,  0.0420,  0.0553],\n",
      "         [-0.0202, -0.1230,  0.0263],\n",
      "         [-0.1050,  0.1074,  0.0392],\n",
      "         [-0.0372, -0.1292,  0.0240],\n",
      "         [ 0.1046,  0.1036,  0.0244]],\n",
      "\n",
      "        [[ 0.1177,  0.0314, -0.0018],\n",
      "         [ 0.0017,  0.0332, -0.1111],\n",
      "         [ 0.0614, -0.0517, -0.0286],\n",
      "         [ 0.1294,  0.1007, -0.0079],\n",
      "         [-0.0453, -0.0137, -0.0521],\n",
      "         [ 0.0453, -0.0213, -0.0588],\n",
      "         [-0.0207, -0.1096, -0.0141],\n",
      "         [-0.1436,  0.1298,  0.0876],\n",
      "         [ 0.1280, -0.1204,  0.0128],\n",
      "         [ 0.1324,  0.0350,  0.1232],\n",
      "         [-0.1122, -0.0671,  0.0920],\n",
      "         [ 0.1327, -0.1384, -0.0272],\n",
      "         [-0.1174,  0.0093,  0.1330],\n",
      "         [-0.0389, -0.1416, -0.0293],\n",
      "         [ 0.0994, -0.1011,  0.0588],\n",
      "         [-0.0275,  0.1051, -0.0814]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv2.bias | Size: torch.Size([16]) | Values : tensor([ 0.0149, -0.1067], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[ 0.0329],\n",
      "         [ 0.0497],\n",
      "         [ 0.1597],\n",
      "         [-0.1582],\n",
      "         [ 0.0684],\n",
      "         [ 0.0496],\n",
      "         [ 0.1039],\n",
      "         [ 0.1088],\n",
      "         [ 0.1312],\n",
      "         [ 0.1928],\n",
      "         [-0.1223],\n",
      "         [ 0.0395],\n",
      "         [ 0.0711],\n",
      "         [ 0.1459],\n",
      "         [-0.1333],\n",
      "         [-0.1420]],\n",
      "\n",
      "        [[-0.0917],\n",
      "         [ 0.1565],\n",
      "         [ 0.0247],\n",
      "         [-0.1898],\n",
      "         [ 0.1082],\n",
      "         [-0.2442],\n",
      "         [-0.2491],\n",
      "         [ 0.0681],\n",
      "         [ 0.1404],\n",
      "         [-0.1833],\n",
      "         [-0.2193],\n",
      "         [ 0.0560],\n",
      "         [-0.1354],\n",
      "         [-0.2469],\n",
      "         [ 0.1895],\n",
      "         [-0.0892]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv3.bias | Size: torch.Size([64]) | Values : tensor([ 0.0549, -0.1701], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[ 1.7076e-02],\n",
      "         [-6.5101e-02],\n",
      "         [-5.5582e-02],\n",
      "         [-9.1460e-02],\n",
      "         [-1.5669e-03],\n",
      "         [ 7.6294e-02],\n",
      "         [-6.5255e-02],\n",
      "         [-8.4441e-02],\n",
      "         [ 1.2088e-02],\n",
      "         [-3.4304e-02],\n",
      "         [-7.0698e-02],\n",
      "         [ 9.5180e-02],\n",
      "         [-7.1753e-03],\n",
      "         [-5.6053e-02],\n",
      "         [-1.0719e-01],\n",
      "         [-5.9480e-02],\n",
      "         [-9.5415e-02],\n",
      "         [-6.3546e-02],\n",
      "         [-1.1380e-01],\n",
      "         [ 4.5468e-02],\n",
      "         [ 2.1260e-02],\n",
      "         [ 9.7526e-02],\n",
      "         [ 5.5732e-02],\n",
      "         [-1.0943e-01],\n",
      "         [ 3.2806e-02],\n",
      "         [ 6.8555e-02],\n",
      "         [-9.3324e-02],\n",
      "         [-1.4214e-02],\n",
      "         [-1.1202e-01],\n",
      "         [-4.7305e-02],\n",
      "         [-9.6734e-02],\n",
      "         [ 5.7568e-02],\n",
      "         [-1.1328e-01],\n",
      "         [-7.4655e-05],\n",
      "         [ 8.2959e-03],\n",
      "         [-3.8773e-02],\n",
      "         [ 2.7514e-02],\n",
      "         [ 8.0512e-02],\n",
      "         [ 3.6045e-02],\n",
      "         [-6.9152e-04],\n",
      "         [-5.7795e-02],\n",
      "         [ 7.4054e-02],\n",
      "         [-7.8855e-02],\n",
      "         [ 8.6751e-02],\n",
      "         [-6.6084e-03],\n",
      "         [ 9.8751e-02],\n",
      "         [ 9.0112e-02],\n",
      "         [-1.8816e-02],\n",
      "         [ 1.2301e-01],\n",
      "         [-1.0730e-01],\n",
      "         [-8.0373e-02],\n",
      "         [ 7.7348e-02],\n",
      "         [ 3.2752e-02],\n",
      "         [-1.2075e-01],\n",
      "         [ 9.9036e-02],\n",
      "         [ 9.0928e-02],\n",
      "         [ 2.0572e-02],\n",
      "         [-6.9341e-02],\n",
      "         [-1.1083e-01],\n",
      "         [ 9.4848e-02],\n",
      "         [-9.0764e-02],\n",
      "         [ 1.1694e-01],\n",
      "         [-1.0763e-01],\n",
      "         [-1.2330e-01]],\n",
      "\n",
      "        [[-6.5765e-02],\n",
      "         [ 6.5706e-02],\n",
      "         [-1.0217e-01],\n",
      "         [ 9.8185e-02],\n",
      "         [-4.7676e-02],\n",
      "         [-1.4671e-02],\n",
      "         [ 2.5562e-02],\n",
      "         [-3.5200e-02],\n",
      "         [-5.8357e-02],\n",
      "         [ 1.1355e-01],\n",
      "         [ 1.1269e-01],\n",
      "         [ 4.4659e-02],\n",
      "         [-5.7292e-02],\n",
      "         [ 3.6444e-02],\n",
      "         [-1.1447e-02],\n",
      "         [-5.0335e-02],\n",
      "         [-1.0318e-01],\n",
      "         [-4.6921e-02],\n",
      "         [-1.0811e-01],\n",
      "         [ 1.9802e-03],\n",
      "         [ 9.5286e-02],\n",
      "         [ 1.4319e-03],\n",
      "         [-6.0437e-02],\n",
      "         [ 1.4709e-02],\n",
      "         [ 1.1311e-01],\n",
      "         [-8.4426e-02],\n",
      "         [ 9.9518e-02],\n",
      "         [-1.0542e-01],\n",
      "         [-1.2950e-02],\n",
      "         [-1.1754e-01],\n",
      "         [ 5.8673e-02],\n",
      "         [ 7.0773e-02],\n",
      "         [-1.2405e-01],\n",
      "         [-7.1242e-02],\n",
      "         [-7.8347e-02],\n",
      "         [-7.8302e-03],\n",
      "         [ 1.0942e-01],\n",
      "         [ 5.5893e-02],\n",
      "         [ 8.6767e-02],\n",
      "         [-9.5548e-02],\n",
      "         [ 8.8411e-02],\n",
      "         [-8.1713e-02],\n",
      "         [-1.0719e-01],\n",
      "         [ 2.5870e-03],\n",
      "         [-6.9063e-02],\n",
      "         [ 6.2224e-02],\n",
      "         [ 3.9814e-03],\n",
      "         [-9.0941e-02],\n",
      "         [ 2.7199e-02],\n",
      "         [ 7.2406e-02],\n",
      "         [-9.1160e-02],\n",
      "         [-2.1483e-02],\n",
      "         [-1.0784e-01],\n",
      "         [-3.5712e-02],\n",
      "         [ 8.3701e-02],\n",
      "         [ 3.3729e-02],\n",
      "         [-7.7713e-02],\n",
      "         [-1.2368e-01],\n",
      "         [ 6.9181e-02],\n",
      "         [-3.8416e-02],\n",
      "         [-8.8988e-02],\n",
      "         [ 1.0227e-02],\n",
      "         [ 1.1036e-01],\n",
      "         [ 1.2110e-01]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.convr.bias | Size: torch.Size([64]) | Values : tensor([ 0.0557, -0.1094], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[ 0.0084],\n",
      "         [ 0.1056],\n",
      "         [ 0.0531],\n",
      "         [ 0.0727],\n",
      "         [-0.0410],\n",
      "         [ 0.0753],\n",
      "         [-0.0265],\n",
      "         [-0.0551],\n",
      "         [ 0.1089],\n",
      "         [-0.0556],\n",
      "         [ 0.0874],\n",
      "         [ 0.0466],\n",
      "         [-0.0345],\n",
      "         [ 0.0465],\n",
      "         [ 0.1120],\n",
      "         [-0.0313],\n",
      "         [-0.1098],\n",
      "         [ 0.0650],\n",
      "         [ 0.0594],\n",
      "         [ 0.0668],\n",
      "         [ 0.0081],\n",
      "         [-0.0665],\n",
      "         [ 0.0235],\n",
      "         [-0.0904],\n",
      "         [-0.1007],\n",
      "         [ 0.0457],\n",
      "         [-0.0603],\n",
      "         [ 0.0262],\n",
      "         [-0.0490],\n",
      "         [-0.1145],\n",
      "         [-0.1055],\n",
      "         [ 0.0216],\n",
      "         [ 0.0490],\n",
      "         [ 0.0699],\n",
      "         [ 0.1182],\n",
      "         [-0.0562],\n",
      "         [-0.0911],\n",
      "         [-0.0379],\n",
      "         [ 0.0084],\n",
      "         [ 0.0947],\n",
      "         [ 0.0174],\n",
      "         [ 0.0064],\n",
      "         [ 0.0418],\n",
      "         [-0.0116],\n",
      "         [ 0.0276],\n",
      "         [ 0.0515],\n",
      "         [-0.0096],\n",
      "         [ 0.0834],\n",
      "         [ 0.1017],\n",
      "         [-0.0850],\n",
      "         [-0.1047],\n",
      "         [ 0.0510],\n",
      "         [ 0.0002],\n",
      "         [ 0.0544],\n",
      "         [ 0.0084],\n",
      "         [ 0.0067],\n",
      "         [-0.0961],\n",
      "         [-0.0048],\n",
      "         [ 0.0640],\n",
      "         [-0.0028],\n",
      "         [ 0.1129],\n",
      "         [ 0.1066],\n",
      "         [ 0.1033],\n",
      "         [ 0.0305]],\n",
      "\n",
      "        [[ 0.0330],\n",
      "         [-0.0908],\n",
      "         [-0.0179],\n",
      "         [ 0.0036],\n",
      "         [ 0.0943],\n",
      "         [ 0.0986],\n",
      "         [-0.0752],\n",
      "         [ 0.1154],\n",
      "         [ 0.1085],\n",
      "         [ 0.1069],\n",
      "         [ 0.0659],\n",
      "         [ 0.0096],\n",
      "         [ 0.0686],\n",
      "         [-0.0166],\n",
      "         [ 0.0436],\n",
      "         [ 0.0758],\n",
      "         [ 0.0819],\n",
      "         [-0.0419],\n",
      "         [ 0.0654],\n",
      "         [-0.0849],\n",
      "         [-0.0118],\n",
      "         [ 0.0778],\n",
      "         [-0.0381],\n",
      "         [ 0.1219],\n",
      "         [-0.0740],\n",
      "         [-0.0438],\n",
      "         [ 0.0220],\n",
      "         [-0.0184],\n",
      "         [-0.0046],\n",
      "         [ 0.0048],\n",
      "         [-0.0772],\n",
      "         [ 0.0528],\n",
      "         [ 0.0037],\n",
      "         [ 0.0761],\n",
      "         [-0.0018],\n",
      "         [-0.0699],\n",
      "         [-0.1180],\n",
      "         [ 0.0706],\n",
      "         [ 0.1187],\n",
      "         [ 0.0923],\n",
      "         [-0.0081],\n",
      "         [-0.0618],\n",
      "         [-0.0170],\n",
      "         [-0.0776],\n",
      "         [-0.0349],\n",
      "         [-0.0147],\n",
      "         [ 0.0227],\n",
      "         [-0.0989],\n",
      "         [-0.0098],\n",
      "         [ 0.1190],\n",
      "         [ 0.0954],\n",
      "         [-0.1195],\n",
      "         [ 0.0825],\n",
      "         [-0.0045],\n",
      "         [-0.1072],\n",
      "         [ 0.1077],\n",
      "         [ 0.0852],\n",
      "         [ 0.0607],\n",
      "         [ 0.0468],\n",
      "         [-0.1123],\n",
      "         [ 0.1209],\n",
      "         [-0.0653],\n",
      "         [-0.0841],\n",
      "         [ 0.1104]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.conv1.bias | Size: torch.Size([16]) | Values : tensor([0.0700, 0.0570], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[-0.0880,  0.1153, -0.0473],\n",
      "         [ 0.0481,  0.0516,  0.1238],\n",
      "         [ 0.0879, -0.1272, -0.0669],\n",
      "         [ 0.0963, -0.0013,  0.1163],\n",
      "         [ 0.0871,  0.0615, -0.1125],\n",
      "         [-0.0618, -0.1373,  0.1248],\n",
      "         [-0.0059, -0.1213,  0.0922],\n",
      "         [-0.1225,  0.0839,  0.0958],\n",
      "         [-0.0667, -0.1422, -0.0273],\n",
      "         [-0.0306, -0.0281,  0.0365],\n",
      "         [ 0.0083,  0.0112, -0.1199],\n",
      "         [ 0.0769, -0.1330,  0.1241],\n",
      "         [ 0.1310, -0.0614,  0.1165],\n",
      "         [ 0.0998, -0.1294,  0.0234],\n",
      "         [ 0.0419, -0.1135,  0.0070],\n",
      "         [-0.1046, -0.1422,  0.0521]],\n",
      "\n",
      "        [[ 0.0065, -0.0818,  0.1423],\n",
      "         [ 0.0935,  0.0072, -0.1108],\n",
      "         [ 0.1031, -0.0972, -0.0897],\n",
      "         [ 0.0268,  0.1259,  0.0549],\n",
      "         [-0.0089,  0.0093,  0.1228],\n",
      "         [ 0.0173,  0.0090, -0.1289],\n",
      "         [ 0.1163,  0.0424,  0.1060],\n",
      "         [ 0.0348,  0.0810,  0.0679],\n",
      "         [ 0.1069,  0.1300, -0.0407],\n",
      "         [ 0.1166, -0.0038, -0.0078],\n",
      "         [ 0.0996, -0.1287,  0.0786],\n",
      "         [-0.1035,  0.0474, -0.1216],\n",
      "         [-0.0706,  0.1132, -0.0383],\n",
      "         [ 0.0603, -0.1082,  0.1350],\n",
      "         [-0.0394, -0.0565, -0.1166],\n",
      "         [-0.0190,  0.0271, -0.0388]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.conv2.bias | Size: torch.Size([16]) | Values : tensor([ 0.0759, -0.0660], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[ 0.1320],\n",
      "         [-0.2396],\n",
      "         [-0.0797],\n",
      "         [-0.2154],\n",
      "         [-0.1412],\n",
      "         [-0.2160],\n",
      "         [ 0.1313],\n",
      "         [ 0.0511],\n",
      "         [-0.1572],\n",
      "         [-0.2306],\n",
      "         [ 0.1825],\n",
      "         [-0.1343],\n",
      "         [-0.0490],\n",
      "         [-0.2369],\n",
      "         [ 0.2266],\n",
      "         [ 0.1008]],\n",
      "\n",
      "        [[ 0.2311],\n",
      "         [-0.1007],\n",
      "         [-0.1302],\n",
      "         [-0.2024],\n",
      "         [-0.0746],\n",
      "         [-0.2450],\n",
      "         [-0.1539],\n",
      "         [ 0.0174],\n",
      "         [-0.0127],\n",
      "         [-0.1006],\n",
      "         [-0.0413],\n",
      "         [-0.2454],\n",
      "         [ 0.1390],\n",
      "         [ 0.0885],\n",
      "         [ 0.1234],\n",
      "         [-0.2030]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.conv3.bias | Size: torch.Size([64]) | Values : tensor([0.2161, 0.0379], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc.1.weight | Size: torch.Size([2, 704]) | Values : tensor([[-0.0046, -0.0267,  0.0124,  ...,  0.0165,  0.0031,  0.0288],\n",
      "        [ 0.0363, -0.0280, -0.0144,  ..., -0.0123, -0.0231,  0.0228]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc.1.bias | Size: torch.Size([2]) | Values : tensor([0.0001, 0.0291], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from models.ResNet24 import ResNet24\n",
    "\n",
    "# Create an instance of the model\n",
    "model_resnet = ResNet24().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_resnet.parameters(), lr=learning_rate)\n",
    "# Initialize the scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=patience, verbose=True)\n",
    "print(f\"Model structure: {model_resnet}\\n\\n\")\n",
    "for name, param in model_resnet.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "loss: 1.096105  [   64/23232]\n",
      "loss: 0.010406  [ 6464/23232]\n",
      "loss: 0.106687  [12864/23232]\n",
      "loss: 0.096606  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.066864 \n",
      "\n",
      "Epoch 1:\n",
      "loss: 0.070460  [   64/23232]\n",
      "loss: 0.045280  [ 6464/23232]\n",
      "loss: 0.040948  [12864/23232]\n",
      "loss: 0.272570  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.076399 \n",
      "\n",
      "Epoch 2:\n",
      "loss: 0.254746  [   64/23232]\n",
      "loss: 0.027418  [ 6464/23232]\n",
      "loss: 0.155882  [12864/23232]\n",
      "loss: 0.209149  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.049656 \n",
      "\n",
      "Epoch 3:\n",
      "loss: 0.080304  [   64/23232]\n",
      "loss: 0.047344  [ 6464/23232]\n",
      "loss: 0.297360  [12864/23232]\n",
      "loss: 0.093212  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.047004 \n",
      "\n",
      "Epoch 4:\n",
      "loss: 0.012315  [   64/23232]\n",
      "loss: 0.307595  [ 6464/23232]\n",
      "loss: 0.060982  [12864/23232]\n",
      "loss: 0.008558  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.048525 \n",
      "\n",
      "Epoch 5:\n",
      "loss: 0.324041  [   64/23232]\n",
      "loss: 0.031715  [ 6464/23232]\n",
      "loss: 0.074121  [12864/23232]\n",
      "loss: 0.080976  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.044396 \n",
      "\n",
      "Epoch 6:\n",
      "loss: 0.139942  [   64/23232]\n",
      "loss: 0.130357  [ 6464/23232]\n",
      "loss: 0.039882  [12864/23232]\n",
      "loss: 0.022895  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.046039 \n",
      "\n",
      "Epoch 7:\n",
      "loss: 0.136873  [   64/23232]\n",
      "loss: 0.055453  [ 6464/23232]\n",
      "loss: 0.090142  [12864/23232]\n",
      "loss: 0.068460  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.045928 \n",
      "\n",
      "Epoch 8:\n",
      "loss: 0.165780  [   64/23232]\n",
      "loss: 0.165748  [ 6464/23232]\n",
      "loss: 0.053255  [12864/23232]\n",
      "loss: 0.089157  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.038986 \n",
      "\n",
      "Epoch 9:\n",
      "loss: 0.093964  [   64/23232]\n",
      "loss: 0.020795  [ 6464/23232]\n",
      "loss: 0.095515  [12864/23232]\n",
      "loss: 0.076339  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 96.9%, Avg loss: 0.085612 \n",
      "\n",
      "Epoch 10:\n",
      "loss: 0.358486  [   64/23232]\n",
      "loss: 0.208118  [ 6464/23232]\n",
      "loss: 0.081895  [12864/23232]\n",
      "loss: 0.129129  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.043638 \n",
      "\n",
      "Epoch 11:\n",
      "loss: 0.110231  [   64/23232]\n",
      "loss: 0.127025  [ 6464/23232]\n",
      "loss: 0.080742  [12864/23232]\n",
      "loss: 0.508783  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.035785 \n",
      "\n",
      "Epoch 12:\n",
      "loss: 0.105752  [   64/23232]\n",
      "loss: 0.016003  [ 6464/23232]\n",
      "loss: 0.307719  [12864/23232]\n",
      "loss: 0.719452  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.037344 \n",
      "\n",
      "Epoch 13:\n",
      "loss: 0.038284  [   64/23232]\n",
      "loss: 0.007103  [ 6464/23232]\n",
      "loss: 0.044270  [12864/23232]\n",
      "loss: 0.190721  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.051724 \n",
      "\n",
      "Epoch 14:\n",
      "loss: 0.017839  [   64/23232]\n",
      "loss: 0.006903  [ 6464/23232]\n",
      "loss: 0.055171  [12864/23232]\n",
      "loss: 0.047494  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.032198 \n",
      "\n",
      "Epoch 15:\n",
      "loss: 0.037046  [   64/23232]\n",
      "loss: 0.147594  [ 6464/23232]\n",
      "loss: 0.136874  [12864/23232]\n",
      "loss: 0.351767  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.044766 \n",
      "\n",
      "Epoch 16:\n",
      "loss: 0.066210  [   64/23232]\n",
      "loss: 0.034224  [ 6464/23232]\n",
      "loss: 0.368748  [12864/23232]\n",
      "loss: 0.011717  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.045140 \n",
      "\n",
      "Epoch 17:\n",
      "loss: 0.197630  [   64/23232]\n",
      "loss: 0.111828  [ 6464/23232]\n",
      "loss: 0.013139  [12864/23232]\n",
      "loss: 0.035283  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.029371 \n",
      "\n",
      "Epoch 18:\n",
      "loss: 0.024799  [   64/23232]\n",
      "loss: 0.018704  [ 6464/23232]\n",
      "loss: 0.090411  [12864/23232]\n",
      "loss: 0.132654  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.038588 \n",
      "\n",
      "Epoch 19:\n",
      "loss: 0.005576  [   64/23232]\n",
      "loss: 0.347827  [ 6464/23232]\n",
      "loss: 0.058003  [12864/23232]\n",
      "loss: 0.114396  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.033292 \n",
      "\n",
      "Epoch 20:\n",
      "loss: 0.006003  [   64/23232]\n",
      "loss: 0.362913  [ 6464/23232]\n",
      "loss: 0.192421  [12864/23232]\n",
      "loss: 0.044725  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.032413 \n",
      "\n",
      "Epoch 21:\n",
      "loss: 0.037551  [   64/23232]\n",
      "loss: 0.070332  [ 6464/23232]\n",
      "loss: 0.038479  [12864/23232]\n",
      "loss: 0.146908  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.037942 \n",
      "\n",
      "Epoch 22:\n",
      "loss: 0.061124  [   64/23232]\n",
      "loss: 0.144319  [ 6464/23232]\n",
      "loss: 0.003541  [12864/23232]\n",
      "loss: 0.018403  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 99.0%, Avg loss: 0.033922 \n",
      "\n",
      "Early stopping due to no improvement in validation loss.\n"
     ]
    }
   ],
   "source": [
    "train(train_dataloader, model_resnet, loss_fn, optimizer,val_dataloader, \n",
    "        patience=patience, scheduler=scheduler, device=device, epochs=epochs, B_size=B_size, A_size=A_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.564428 \n",
      "\n",
      " Label 0\n",
      "    accuracy\t0.793\n",
      " specificity\t0.633\n",
      " sensitivity\t0.964\n",
      " Label 1\n",
      "    accuracy\t0.793\n",
      " specificity\t0.964\n",
      " sensitivity\t0.633\n",
      "[[27  1]\n",
      " [11 19]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# final test\n",
    "test(test_dataloader, model_resnet, loss_fn, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TinyFallNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=16, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding='same')\n",
    "        self.bn2 = nn.BatchNorm1d(16)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=64, kernel_size=1)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.convr = nn.Conv1d(in_channels=in_channels, out_channels=64, kernel_size=1)\n",
    "    def forward(self, input):\n",
    "        residual = self.convr(input)\n",
    "        x = self.conv1(input)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x += residual\n",
    "        x = self.relu3(x)\n",
    "        return x\n",
    "\n",
    "class TinyFallNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TinyFallNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=9, out_channels=64, kernel_size=3)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.convblk1 = ConvBlock(64)\n",
    "        self.convblk2 = ConvBlock(64)\n",
    "        self.convblk3 = ConvBlock(64)\n",
    "        self.convblk4 = ConvBlock(64)\n",
    "        \n",
    "        self.pool2 = nn.AvgPool1d(2)\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.Flatten(),\n",
    "                                nn.Linear(in_features=768, out_features=2),\n",
    "                                nn.Softmax())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)  # Transpose to have the correct dimensions for Conv1d (batch, channels, length)\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.convblk1(x)\n",
    "        x = self.convblk2(x)\n",
    "        x = self.convblk3(x)\n",
    "        x = self.convblk4(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: TinyFallNet(\n",
      "  (conv1): Conv1d(9, 64, kernel_size=(3,), stride=(1,))\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (convblk1): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (convblk2): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (convblk3): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (convblk4): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (pool2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
      "  (fc): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=768, out_features=2, bias=True)\n",
      "    (2): Softmax(dim=None)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: conv1.weight | Size: torch.Size([64, 9, 3]) | Values : tensor([[[ 0.1707,  0.1909, -0.1819],\n",
      "         [-0.1509, -0.0172, -0.0054],\n",
      "         [ 0.0201, -0.0625,  0.1875],\n",
      "         [ 0.0921,  0.0577, -0.1649],\n",
      "         [ 0.1108, -0.0679,  0.1841],\n",
      "         [-0.1487,  0.1183,  0.0439],\n",
      "         [-0.1134,  0.1050, -0.0172],\n",
      "         [-0.0411, -0.1415,  0.1669],\n",
      "         [ 0.0066, -0.1593, -0.0248]],\n",
      "\n",
      "        [[ 0.0031, -0.1270,  0.0543],\n",
      "         [-0.0451, -0.0734, -0.0672],\n",
      "         [ 0.0110, -0.1800,  0.1265],\n",
      "         [ 0.0282,  0.1774, -0.0625],\n",
      "         [-0.1029,  0.0655,  0.1388],\n",
      "         [-0.1187,  0.0612, -0.0328],\n",
      "         [-0.0155,  0.1794, -0.0875],\n",
      "         [ 0.1095,  0.0275, -0.0173],\n",
      "         [-0.1274,  0.1052,  0.1348]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.bias | Size: torch.Size([64]) | Values : tensor([-0.0987, -0.1815], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[-0.0644],\n",
      "         [-0.1074],\n",
      "         [-0.0250],\n",
      "         [-0.1088],\n",
      "         [ 0.0046],\n",
      "         [-0.0266],\n",
      "         [ 0.0935],\n",
      "         [ 0.0508],\n",
      "         [ 0.0139],\n",
      "         [ 0.1062],\n",
      "         [ 0.0837],\n",
      "         [ 0.1050],\n",
      "         [ 0.0686],\n",
      "         [ 0.1217],\n",
      "         [ 0.0603],\n",
      "         [-0.0124],\n",
      "         [ 0.0702],\n",
      "         [ 0.0541],\n",
      "         [-0.0371],\n",
      "         [ 0.0697],\n",
      "         [ 0.0194],\n",
      "         [-0.0676],\n",
      "         [-0.0151],\n",
      "         [ 0.0484],\n",
      "         [ 0.0608],\n",
      "         [-0.0450],\n",
      "         [-0.0718],\n",
      "         [-0.0726],\n",
      "         [-0.0620],\n",
      "         [-0.0859],\n",
      "         [-0.1146],\n",
      "         [-0.1073],\n",
      "         [-0.0967],\n",
      "         [ 0.0928],\n",
      "         [ 0.0975],\n",
      "         [-0.0926],\n",
      "         [-0.1219],\n",
      "         [-0.0435],\n",
      "         [ 0.0634],\n",
      "         [-0.0560],\n",
      "         [-0.0962],\n",
      "         [-0.0783],\n",
      "         [ 0.1185],\n",
      "         [-0.0029],\n",
      "         [-0.0780],\n",
      "         [ 0.0510],\n",
      "         [ 0.0449],\n",
      "         [-0.1193],\n",
      "         [-0.0567],\n",
      "         [-0.1178],\n",
      "         [-0.0484],\n",
      "         [-0.1060],\n",
      "         [-0.0036],\n",
      "         [ 0.0402],\n",
      "         [-0.1055],\n",
      "         [ 0.0926],\n",
      "         [ 0.0871],\n",
      "         [-0.0140],\n",
      "         [ 0.0323],\n",
      "         [-0.0669],\n",
      "         [-0.1121],\n",
      "         [-0.1020],\n",
      "         [-0.0981],\n",
      "         [ 0.0530]],\n",
      "\n",
      "        [[ 0.0677],\n",
      "         [-0.0294],\n",
      "         [ 0.0601],\n",
      "         [-0.0515],\n",
      "         [-0.1234],\n",
      "         [ 0.1066],\n",
      "         [ 0.0949],\n",
      "         [ 0.0240],\n",
      "         [ 0.0245],\n",
      "         [ 0.0460],\n",
      "         [-0.0181],\n",
      "         [-0.0688],\n",
      "         [ 0.0367],\n",
      "         [-0.0371],\n",
      "         [-0.0009],\n",
      "         [ 0.0903],\n",
      "         [ 0.0754],\n",
      "         [ 0.0823],\n",
      "         [ 0.1208],\n",
      "         [-0.0286],\n",
      "         [ 0.0958],\n",
      "         [ 0.0212],\n",
      "         [ 0.0094],\n",
      "         [-0.0152],\n",
      "         [ 0.0058],\n",
      "         [ 0.0789],\n",
      "         [ 0.0190],\n",
      "         [ 0.1131],\n",
      "         [ 0.0615],\n",
      "         [-0.0178],\n",
      "         [ 0.0762],\n",
      "         [ 0.0463],\n",
      "         [-0.0757],\n",
      "         [-0.0972],\n",
      "         [-0.0333],\n",
      "         [ 0.1019],\n",
      "         [ 0.0418],\n",
      "         [-0.0600],\n",
      "         [ 0.0626],\n",
      "         [ 0.0438],\n",
      "         [ 0.1052],\n",
      "         [ 0.0653],\n",
      "         [-0.1240],\n",
      "         [-0.0495],\n",
      "         [ 0.0181],\n",
      "         [-0.0599],\n",
      "         [ 0.1098],\n",
      "         [ 0.0410],\n",
      "         [-0.0574],\n",
      "         [ 0.1185],\n",
      "         [-0.0872],\n",
      "         [-0.0301],\n",
      "         [-0.0899],\n",
      "         [-0.0769],\n",
      "         [ 0.0913],\n",
      "         [ 0.1212],\n",
      "         [ 0.0213],\n",
      "         [-0.0780],\n",
      "         [ 0.0742],\n",
      "         [-0.0611],\n",
      "         [-0.0708],\n",
      "         [ 0.1130],\n",
      "         [-0.0722],\n",
      "         [-0.0117]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv1.bias | Size: torch.Size([16]) | Values : tensor([0.0644, 0.1210], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[ 0.0446,  0.0761, -0.0259],\n",
      "         [-0.1184, -0.0702,  0.1218],\n",
      "         [-0.0184,  0.0372, -0.0346],\n",
      "         [ 0.0187,  0.0555,  0.0129],\n",
      "         [ 0.0581, -0.1006, -0.0175],\n",
      "         [-0.0849, -0.1043, -0.0125],\n",
      "         [-0.1125,  0.0198, -0.0071],\n",
      "         [-0.1254,  0.0856, -0.0894],\n",
      "         [ 0.0033,  0.0870,  0.0898],\n",
      "         [-0.0653, -0.1379, -0.0072],\n",
      "         [-0.0960, -0.0394,  0.1413],\n",
      "         [ 0.0752,  0.0399,  0.0937],\n",
      "         [ 0.0991, -0.1285, -0.0800],\n",
      "         [-0.1116,  0.0702,  0.1031],\n",
      "         [ 0.0849,  0.0624,  0.0274],\n",
      "         [-0.0535, -0.1350,  0.0031]],\n",
      "\n",
      "        [[-0.1292,  0.1031,  0.0750],\n",
      "         [-0.0050,  0.0756,  0.0476],\n",
      "         [-0.0362, -0.0199, -0.1277],\n",
      "         [-0.0481,  0.0584,  0.0032],\n",
      "         [ 0.0720, -0.0890,  0.1417],\n",
      "         [ 0.0512, -0.0616,  0.1379],\n",
      "         [ 0.0468,  0.0551, -0.0916],\n",
      "         [-0.0933, -0.0698,  0.0709],\n",
      "         [ 0.0198,  0.0696,  0.1293],\n",
      "         [ 0.1010, -0.0825,  0.1345],\n",
      "         [-0.0371,  0.0707,  0.0463],\n",
      "         [ 0.1422,  0.0703, -0.0357],\n",
      "         [ 0.0732,  0.1276,  0.0361],\n",
      "         [ 0.0020, -0.1238, -0.0328],\n",
      "         [-0.1002,  0.0783,  0.0148],\n",
      "         [ 0.1020,  0.0186,  0.1435]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv2.bias | Size: torch.Size([16]) | Values : tensor([ 0.0755, -0.1415], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[ 0.1890],\n",
      "         [-0.0242],\n",
      "         [ 0.0715],\n",
      "         [-0.1681],\n",
      "         [-0.2274],\n",
      "         [ 0.2389],\n",
      "         [ 0.1715],\n",
      "         [ 0.0367],\n",
      "         [-0.2262],\n",
      "         [ 0.2048],\n",
      "         [ 0.1324],\n",
      "         [-0.1536],\n",
      "         [ 0.0967],\n",
      "         [ 0.0792],\n",
      "         [ 0.1717],\n",
      "         [ 0.0433]],\n",
      "\n",
      "        [[-0.0634],\n",
      "         [-0.1794],\n",
      "         [-0.1208],\n",
      "         [ 0.0420],\n",
      "         [-0.1926],\n",
      "         [-0.1667],\n",
      "         [ 0.1484],\n",
      "         [-0.2120],\n",
      "         [-0.1162],\n",
      "         [-0.0767],\n",
      "         [ 0.1634],\n",
      "         [ 0.1812],\n",
      "         [-0.2070],\n",
      "         [ 0.2336],\n",
      "         [-0.0852],\n",
      "         [ 0.0307]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv3.bias | Size: torch.Size([64]) | Values : tensor([ 0.0186, -0.0507], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[ 0.0149],\n",
      "         [-0.0123],\n",
      "         [-0.0091],\n",
      "         [-0.0139],\n",
      "         [ 0.0480],\n",
      "         [ 0.1097],\n",
      "         [ 0.0124],\n",
      "         [-0.1050],\n",
      "         [ 0.1012],\n",
      "         [-0.0084],\n",
      "         [-0.1212],\n",
      "         [-0.0011],\n",
      "         [ 0.1033],\n",
      "         [-0.0603],\n",
      "         [-0.0577],\n",
      "         [ 0.0953],\n",
      "         [-0.0218],\n",
      "         [-0.0294],\n",
      "         [ 0.0054],\n",
      "         [-0.0419],\n",
      "         [-0.0266],\n",
      "         [-0.0920],\n",
      "         [-0.0370],\n",
      "         [ 0.0673],\n",
      "         [-0.0648],\n",
      "         [-0.1068],\n",
      "         [ 0.0375],\n",
      "         [ 0.1226],\n",
      "         [ 0.0767],\n",
      "         [ 0.0750],\n",
      "         [-0.0900],\n",
      "         [-0.0615],\n",
      "         [ 0.0224],\n",
      "         [ 0.0027],\n",
      "         [-0.1157],\n",
      "         [-0.0500],\n",
      "         [-0.0365],\n",
      "         [-0.0099],\n",
      "         [-0.0955],\n",
      "         [-0.0697],\n",
      "         [-0.1042],\n",
      "         [-0.0561],\n",
      "         [ 0.0854],\n",
      "         [ 0.0036],\n",
      "         [ 0.0076],\n",
      "         [ 0.0652],\n",
      "         [-0.0779],\n",
      "         [ 0.0433],\n",
      "         [ 0.1165],\n",
      "         [-0.0974],\n",
      "         [ 0.0425],\n",
      "         [-0.1002],\n",
      "         [ 0.0679],\n",
      "         [-0.0989],\n",
      "         [ 0.0641],\n",
      "         [-0.0490],\n",
      "         [ 0.0902],\n",
      "         [-0.0158],\n",
      "         [ 0.0008],\n",
      "         [ 0.0489],\n",
      "         [-0.0691],\n",
      "         [ 0.0763],\n",
      "         [-0.0523],\n",
      "         [-0.0266]],\n",
      "\n",
      "        [[ 0.1203],\n",
      "         [ 0.0667],\n",
      "         [ 0.0892],\n",
      "         [ 0.0857],\n",
      "         [-0.0609],\n",
      "         [ 0.0332],\n",
      "         [-0.0900],\n",
      "         [ 0.0206],\n",
      "         [ 0.0719],\n",
      "         [-0.1239],\n",
      "         [-0.1135],\n",
      "         [ 0.0789],\n",
      "         [ 0.1044],\n",
      "         [-0.1069],\n",
      "         [ 0.1119],\n",
      "         [ 0.0204],\n",
      "         [ 0.0548],\n",
      "         [-0.1245],\n",
      "         [-0.0476],\n",
      "         [-0.0128],\n",
      "         [-0.0451],\n",
      "         [-0.1099],\n",
      "         [-0.0250],\n",
      "         [-0.0251],\n",
      "         [-0.0266],\n",
      "         [-0.0798],\n",
      "         [-0.0405],\n",
      "         [-0.0211],\n",
      "         [ 0.0419],\n",
      "         [ 0.0154],\n",
      "         [-0.0287],\n",
      "         [ 0.0561],\n",
      "         [ 0.0513],\n",
      "         [-0.0897],\n",
      "         [-0.0134],\n",
      "         [-0.0205],\n",
      "         [-0.0572],\n",
      "         [ 0.1197],\n",
      "         [-0.0907],\n",
      "         [-0.0679],\n",
      "         [ 0.0153],\n",
      "         [-0.1073],\n",
      "         [-0.0287],\n",
      "         [ 0.0258],\n",
      "         [-0.0142],\n",
      "         [-0.0901],\n",
      "         [ 0.1063],\n",
      "         [-0.0660],\n",
      "         [ 0.0033],\n",
      "         [-0.0778],\n",
      "         [-0.0266],\n",
      "         [ 0.0100],\n",
      "         [ 0.0690],\n",
      "         [-0.0973],\n",
      "         [-0.0833],\n",
      "         [ 0.0684],\n",
      "         [ 0.0051],\n",
      "         [-0.0464],\n",
      "         [ 0.0192],\n",
      "         [-0.1100],\n",
      "         [-0.0480],\n",
      "         [ 0.0302],\n",
      "         [ 0.0802],\n",
      "         [-0.1239]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.convr.bias | Size: torch.Size([64]) | Values : tensor([0.0681, 0.0333], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[ 0.1039],\n",
      "         [-0.0893],\n",
      "         [ 0.1044],\n",
      "         [ 0.0154],\n",
      "         [ 0.1117],\n",
      "         [-0.0932],\n",
      "         [ 0.0184],\n",
      "         [-0.0418],\n",
      "         [-0.0785],\n",
      "         [-0.1110],\n",
      "         [-0.0915],\n",
      "         [ 0.0379],\n",
      "         [-0.0641],\n",
      "         [ 0.0504],\n",
      "         [ 0.0657],\n",
      "         [ 0.0988],\n",
      "         [-0.1101],\n",
      "         [ 0.1126],\n",
      "         [-0.0993],\n",
      "         [ 0.0692],\n",
      "         [-0.0921],\n",
      "         [ 0.0310],\n",
      "         [-0.0278],\n",
      "         [-0.0617],\n",
      "         [ 0.0086],\n",
      "         [ 0.0219],\n",
      "         [ 0.0617],\n",
      "         [ 0.1216],\n",
      "         [ 0.0623],\n",
      "         [-0.1202],\n",
      "         [ 0.0098],\n",
      "         [ 0.0325],\n",
      "         [-0.1018],\n",
      "         [ 0.0322],\n",
      "         [-0.0138],\n",
      "         [-0.0127],\n",
      "         [-0.0548],\n",
      "         [-0.0765],\n",
      "         [-0.0951],\n",
      "         [ 0.0029],\n",
      "         [-0.0773],\n",
      "         [-0.1164],\n",
      "         [-0.1053],\n",
      "         [-0.1047],\n",
      "         [ 0.0831],\n",
      "         [-0.0638],\n",
      "         [ 0.0839],\n",
      "         [ 0.0540],\n",
      "         [ 0.0843],\n",
      "         [ 0.0954],\n",
      "         [-0.0449],\n",
      "         [-0.1090],\n",
      "         [ 0.1025],\n",
      "         [ 0.0051],\n",
      "         [ 0.0606],\n",
      "         [-0.0722],\n",
      "         [-0.1091],\n",
      "         [-0.1035],\n",
      "         [-0.0907],\n",
      "         [-0.0104],\n",
      "         [ 0.0170],\n",
      "         [-0.0097],\n",
      "         [-0.1238],\n",
      "         [-0.0970]],\n",
      "\n",
      "        [[ 0.0163],\n",
      "         [-0.0768],\n",
      "         [-0.0681],\n",
      "         [-0.0198],\n",
      "         [-0.1016],\n",
      "         [-0.1113],\n",
      "         [-0.0792],\n",
      "         [ 0.0478],\n",
      "         [ 0.0443],\n",
      "         [-0.1074],\n",
      "         [ 0.0126],\n",
      "         [ 0.0726],\n",
      "         [ 0.0064],\n",
      "         [ 0.0830],\n",
      "         [-0.0696],\n",
      "         [-0.1161],\n",
      "         [ 0.1143],\n",
      "         [-0.1012],\n",
      "         [ 0.0051],\n",
      "         [-0.0731],\n",
      "         [-0.0372],\n",
      "         [-0.0087],\n",
      "         [ 0.0039],\n",
      "         [ 0.0969],\n",
      "         [ 0.0182],\n",
      "         [-0.0307],\n",
      "         [ 0.0720],\n",
      "         [-0.0393],\n",
      "         [ 0.0356],\n",
      "         [-0.0493],\n",
      "         [ 0.0383],\n",
      "         [-0.0518],\n",
      "         [ 0.1027],\n",
      "         [ 0.0349],\n",
      "         [ 0.0094],\n",
      "         [ 0.0358],\n",
      "         [-0.0549],\n",
      "         [ 0.1017],\n",
      "         [ 0.0771],\n",
      "         [-0.0818],\n",
      "         [-0.0079],\n",
      "         [-0.0139],\n",
      "         [ 0.1076],\n",
      "         [-0.0987],\n",
      "         [ 0.0405],\n",
      "         [-0.0678],\n",
      "         [ 0.0101],\n",
      "         [ 0.1007],\n",
      "         [ 0.0048],\n",
      "         [ 0.0513],\n",
      "         [ 0.0886],\n",
      "         [-0.1205],\n",
      "         [-0.0509],\n",
      "         [-0.0668],\n",
      "         [ 0.1046],\n",
      "         [-0.0434],\n",
      "         [ 0.0911],\n",
      "         [-0.0351],\n",
      "         [-0.0478],\n",
      "         [ 0.0193],\n",
      "         [ 0.1032],\n",
      "         [-0.0169],\n",
      "         [ 0.0836],\n",
      "         [-0.0926]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv1.bias | Size: torch.Size([16]) | Values : tensor([-0.0870, -0.0680], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[ 0.0033,  0.0767,  0.1268],\n",
      "         [-0.0599,  0.0619,  0.0006],\n",
      "         [-0.0491, -0.0863, -0.1120],\n",
      "         [ 0.0113,  0.0893, -0.0650],\n",
      "         [ 0.1089,  0.1058, -0.0283],\n",
      "         [-0.1322, -0.0439, -0.1058],\n",
      "         [ 0.0104, -0.0278,  0.0250],\n",
      "         [-0.0288,  0.0629, -0.0289],\n",
      "         [-0.0616,  0.0765, -0.1184],\n",
      "         [-0.0997,  0.1175, -0.1440],\n",
      "         [ 0.0190, -0.0943, -0.0222],\n",
      "         [ 0.0427,  0.1005,  0.0837],\n",
      "         [-0.1254,  0.0675,  0.0530],\n",
      "         [ 0.1353, -0.1392,  0.0093],\n",
      "         [-0.1071,  0.1411, -0.0783],\n",
      "         [ 0.0185, -0.0768, -0.1154]],\n",
      "\n",
      "        [[-0.0463,  0.0308, -0.1416],\n",
      "         [-0.0876,  0.0505, -0.1341],\n",
      "         [-0.0803,  0.0109, -0.1210],\n",
      "         [ 0.0887, -0.0834,  0.0213],\n",
      "         [ 0.1104, -0.0780, -0.0597],\n",
      "         [-0.0992, -0.0484,  0.1186],\n",
      "         [-0.0301, -0.1004, -0.1176],\n",
      "         [ 0.1419, -0.0751,  0.1156],\n",
      "         [ 0.0705,  0.0489,  0.1136],\n",
      "         [ 0.0245, -0.0798, -0.0728],\n",
      "         [-0.0369,  0.1092, -0.0901],\n",
      "         [ 0.0505,  0.0391, -0.0295],\n",
      "         [ 0.0648,  0.0850, -0.0579],\n",
      "         [-0.0317, -0.0410, -0.1135],\n",
      "         [ 0.1394,  0.1351,  0.1367],\n",
      "         [ 0.0922,  0.1047,  0.1256]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv2.bias | Size: torch.Size([16]) | Values : tensor([-0.0720,  0.0950], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[-0.0889],\n",
      "         [-0.0971],\n",
      "         [ 0.2165],\n",
      "         [-0.0310],\n",
      "         [-0.1308],\n",
      "         [-0.2024],\n",
      "         [-0.1463],\n",
      "         [-0.0327],\n",
      "         [ 0.2438],\n",
      "         [-0.1463],\n",
      "         [ 0.0518],\n",
      "         [-0.0084],\n",
      "         [ 0.1447],\n",
      "         [-0.0809],\n",
      "         [ 0.1241],\n",
      "         [ 0.0213]],\n",
      "\n",
      "        [[ 0.1338],\n",
      "         [ 0.2320],\n",
      "         [-0.1941],\n",
      "         [-0.1539],\n",
      "         [ 0.1518],\n",
      "         [ 0.0564],\n",
      "         [-0.1861],\n",
      "         [-0.1460],\n",
      "         [ 0.0382],\n",
      "         [ 0.1362],\n",
      "         [-0.0063],\n",
      "         [-0.2184],\n",
      "         [ 0.0581],\n",
      "         [ 0.2424],\n",
      "         [-0.0530],\n",
      "         [-0.2267]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv3.bias | Size: torch.Size([64]) | Values : tensor([0.1421, 0.1782], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[-1.1120e-01],\n",
      "         [-5.3292e-02],\n",
      "         [-1.2021e-01],\n",
      "         [-1.1093e-01],\n",
      "         [ 1.1014e-01],\n",
      "         [ 1.2859e-02],\n",
      "         [ 9.7881e-02],\n",
      "         [-5.1007e-02],\n",
      "         [ 1.2125e-01],\n",
      "         [-6.0236e-02],\n",
      "         [-9.1264e-02],\n",
      "         [ 9.5705e-02],\n",
      "         [-6.9156e-02],\n",
      "         [-4.6752e-03],\n",
      "         [-1.3299e-02],\n",
      "         [ 6.4633e-02],\n",
      "         [ 7.2771e-02],\n",
      "         [ 1.4973e-02],\n",
      "         [-1.1192e-01],\n",
      "         [-8.2895e-02],\n",
      "         [-1.1230e-01],\n",
      "         [-4.5795e-02],\n",
      "         [ 9.2147e-02],\n",
      "         [-2.6426e-02],\n",
      "         [ 5.9749e-02],\n",
      "         [ 1.4361e-02],\n",
      "         [ 1.1919e-01],\n",
      "         [-5.1071e-02],\n",
      "         [-3.7305e-02],\n",
      "         [ 6.3831e-02],\n",
      "         [-1.0197e-01],\n",
      "         [-4.9405e-02],\n",
      "         [ 8.1829e-02],\n",
      "         [-3.2750e-02],\n",
      "         [ 5.8749e-02],\n",
      "         [-6.3704e-02],\n",
      "         [-3.7125e-02],\n",
      "         [-4.7611e-02],\n",
      "         [-5.4004e-03],\n",
      "         [ 1.0996e-01],\n",
      "         [-5.9537e-02],\n",
      "         [-1.1795e-01],\n",
      "         [-1.1826e-01],\n",
      "         [-9.4962e-02],\n",
      "         [-1.0907e-01],\n",
      "         [-5.5149e-02],\n",
      "         [ 5.2582e-02],\n",
      "         [ 2.0470e-03],\n",
      "         [ 7.4370e-02],\n",
      "         [-4.4275e-02],\n",
      "         [-1.2025e-02],\n",
      "         [ 4.4345e-02],\n",
      "         [-8.9839e-02],\n",
      "         [-3.1400e-02],\n",
      "         [-7.6070e-05],\n",
      "         [ 1.6925e-02],\n",
      "         [ 6.0121e-02],\n",
      "         [-1.1083e-02],\n",
      "         [ 7.7154e-02],\n",
      "         [ 7.0118e-02],\n",
      "         [-2.8552e-04],\n",
      "         [ 7.3829e-02],\n",
      "         [-8.2728e-02],\n",
      "         [ 1.0865e-01]],\n",
      "\n",
      "        [[ 1.2209e-01],\n",
      "         [-8.2962e-02],\n",
      "         [ 6.2250e-02],\n",
      "         [ 8.7975e-04],\n",
      "         [ 3.8483e-02],\n",
      "         [ 1.1252e-01],\n",
      "         [ 8.6140e-02],\n",
      "         [ 2.1710e-02],\n",
      "         [ 2.3440e-02],\n",
      "         [ 8.1769e-02],\n",
      "         [ 4.2167e-02],\n",
      "         [ 3.5610e-02],\n",
      "         [-6.0301e-02],\n",
      "         [ 5.5738e-02],\n",
      "         [-1.9986e-02],\n",
      "         [-3.6075e-02],\n",
      "         [ 1.2407e-01],\n",
      "         [-8.6022e-02],\n",
      "         [-3.1989e-02],\n",
      "         [ 4.1926e-02],\n",
      "         [ 1.8583e-02],\n",
      "         [-8.9098e-02],\n",
      "         [-6.8164e-02],\n",
      "         [-1.0437e-01],\n",
      "         [ 1.0571e-01],\n",
      "         [-2.4165e-02],\n",
      "         [ 7.5345e-02],\n",
      "         [-2.7485e-03],\n",
      "         [ 7.8067e-02],\n",
      "         [-1.1172e-01],\n",
      "         [-4.4955e-02],\n",
      "         [ 9.3496e-03],\n",
      "         [ 6.7453e-02],\n",
      "         [-1.0910e-01],\n",
      "         [ 4.1958e-02],\n",
      "         [ 1.1611e-01],\n",
      "         [ 1.0405e-01],\n",
      "         [-2.4889e-02],\n",
      "         [-3.4254e-02],\n",
      "         [-1.2358e-01],\n",
      "         [-1.0668e-01],\n",
      "         [-5.2490e-02],\n",
      "         [-1.2233e-01],\n",
      "         [ 4.4765e-02],\n",
      "         [ 2.0842e-03],\n",
      "         [-1.2285e-01],\n",
      "         [-8.5616e-02],\n",
      "         [-2.3186e-02],\n",
      "         [-1.1232e-01],\n",
      "         [-5.4347e-02],\n",
      "         [ 1.6491e-02],\n",
      "         [ 6.9029e-02],\n",
      "         [ 1.5638e-02],\n",
      "         [ 1.0723e-01],\n",
      "         [ 5.7262e-02],\n",
      "         [ 1.4301e-02],\n",
      "         [ 7.3324e-03],\n",
      "         [-8.0076e-02],\n",
      "         [ 1.1029e-01],\n",
      "         [-9.6336e-02],\n",
      "         [-5.3583e-02],\n",
      "         [ 1.2285e-01],\n",
      "         [ 4.5269e-02],\n",
      "         [ 1.3445e-02]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.convr.bias | Size: torch.Size([64]) | Values : tensor([-0.0166, -0.0072], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[ 4.9141e-02],\n",
      "         [-7.6861e-03],\n",
      "         [ 5.9871e-02],\n",
      "         [ 1.8972e-02],\n",
      "         [ 7.8488e-02],\n",
      "         [-1.0870e-01],\n",
      "         [-2.2686e-02],\n",
      "         [-1.7648e-02],\n",
      "         [ 6.0674e-02],\n",
      "         [-2.7494e-03],\n",
      "         [-8.1985e-02],\n",
      "         [ 3.8071e-02],\n",
      "         [ 7.8592e-02],\n",
      "         [ 6.1056e-02],\n",
      "         [-1.0035e-01],\n",
      "         [ 1.0091e-01],\n",
      "         [-1.1407e-01],\n",
      "         [ 3.6327e-02],\n",
      "         [ 6.8754e-02],\n",
      "         [ 4.5971e-02],\n",
      "         [-2.2144e-02],\n",
      "         [ 2.4583e-03],\n",
      "         [-1.8160e-02],\n",
      "         [-2.5918e-02],\n",
      "         [-1.2144e-02],\n",
      "         [ 6.4092e-03],\n",
      "         [-4.6368e-02],\n",
      "         [-3.6415e-02],\n",
      "         [ 1.1699e-01],\n",
      "         [ 2.1731e-02],\n",
      "         [-5.1426e-02],\n",
      "         [-3.2583e-02],\n",
      "         [ 5.1114e-02],\n",
      "         [ 5.8056e-02],\n",
      "         [ 2.5619e-02],\n",
      "         [ 9.0683e-02],\n",
      "         [ 8.7445e-02],\n",
      "         [-4.5273e-02],\n",
      "         [ 1.1649e-01],\n",
      "         [-3.6049e-03],\n",
      "         [ 1.1188e-01],\n",
      "         [ 3.8076e-02],\n",
      "         [ 8.4880e-02],\n",
      "         [-5.7791e-02],\n",
      "         [ 6.8009e-02],\n",
      "         [-1.2670e-02],\n",
      "         [ 2.0393e-02],\n",
      "         [ 5.4537e-02],\n",
      "         [-1.1118e-01],\n",
      "         [ 8.8075e-02],\n",
      "         [ 1.0578e-01],\n",
      "         [-1.1082e-02],\n",
      "         [ 6.5698e-02],\n",
      "         [-4.8634e-02],\n",
      "         [ 6.7771e-02],\n",
      "         [ 1.2693e-02],\n",
      "         [-6.7357e-03],\n",
      "         [-1.1206e-01],\n",
      "         [-7.3737e-02],\n",
      "         [-4.4513e-02],\n",
      "         [ 1.0811e-02],\n",
      "         [ 3.0042e-02],\n",
      "         [ 8.0308e-02],\n",
      "         [-3.4733e-02]],\n",
      "\n",
      "        [[-1.0079e-01],\n",
      "         [ 1.1800e-01],\n",
      "         [ 7.1922e-02],\n",
      "         [-2.9414e-02],\n",
      "         [-5.2815e-02],\n",
      "         [ 9.5566e-02],\n",
      "         [ 1.1678e-01],\n",
      "         [-3.7566e-02],\n",
      "         [-4.5078e-02],\n",
      "         [ 7.5050e-03],\n",
      "         [-6.9007e-02],\n",
      "         [ 1.0950e-01],\n",
      "         [-1.1866e-04],\n",
      "         [-1.4447e-02],\n",
      "         [-1.5298e-02],\n",
      "         [ 1.6537e-02],\n",
      "         [-6.1291e-02],\n",
      "         [ 1.0904e-01],\n",
      "         [-6.3251e-03],\n",
      "         [ 6.7102e-02],\n",
      "         [-1.2157e-01],\n",
      "         [-2.4522e-02],\n",
      "         [-1.0098e-01],\n",
      "         [-6.4246e-02],\n",
      "         [ 7.9526e-02],\n",
      "         [ 5.8053e-02],\n",
      "         [ 3.8652e-02],\n",
      "         [ 1.2055e-01],\n",
      "         [-5.3572e-02],\n",
      "         [ 2.2678e-02],\n",
      "         [ 9.5523e-02],\n",
      "         [ 5.2348e-02],\n",
      "         [-8.1668e-02],\n",
      "         [ 1.0020e-01],\n",
      "         [ 8.0165e-02],\n",
      "         [-1.5924e-02],\n",
      "         [ 9.1830e-02],\n",
      "         [-3.3365e-02],\n",
      "         [-1.1268e-01],\n",
      "         [-7.1592e-02],\n",
      "         [-6.0152e-03],\n",
      "         [-1.4352e-02],\n",
      "         [ 1.2105e-02],\n",
      "         [-5.0424e-04],\n",
      "         [ 1.1614e-01],\n",
      "         [-6.0897e-02],\n",
      "         [ 1.1555e-01],\n",
      "         [ 4.5783e-02],\n",
      "         [-7.8372e-02],\n",
      "         [-7.7486e-02],\n",
      "         [ 3.2869e-02],\n",
      "         [-4.9482e-02],\n",
      "         [ 9.0000e-02],\n",
      "         [-9.9340e-02],\n",
      "         [ 1.2868e-02],\n",
      "         [-1.8177e-02],\n",
      "         [ 4.9634e-02],\n",
      "         [-6.8997e-02],\n",
      "         [-1.4407e-02],\n",
      "         [ 7.3007e-03],\n",
      "         [-6.1150e-02],\n",
      "         [-1.0474e-01],\n",
      "         [-5.3244e-02],\n",
      "         [-7.5507e-02]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv1.bias | Size: torch.Size([16]) | Values : tensor([-0.0242, -0.0731], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[ 0.0107,  0.0071,  0.0757],\n",
      "         [-0.0978,  0.0685, -0.0229],\n",
      "         [ 0.0217, -0.0636, -0.0812],\n",
      "         [-0.0867, -0.0901, -0.1244],\n",
      "         [-0.0700,  0.0482, -0.0437],\n",
      "         [ 0.0236, -0.0880,  0.0432],\n",
      "         [ 0.1389,  0.1340,  0.0775],\n",
      "         [ 0.1420, -0.0061, -0.0650],\n",
      "         [-0.0254,  0.0865,  0.0131],\n",
      "         [-0.1408, -0.1290,  0.0663],\n",
      "         [-0.0428, -0.0917, -0.0433],\n",
      "         [-0.0744,  0.0190,  0.0655],\n",
      "         [ 0.0936, -0.1203,  0.0842],\n",
      "         [ 0.0736,  0.0894, -0.0588],\n",
      "         [-0.1218, -0.0218, -0.0689],\n",
      "         [ 0.1094,  0.0434,  0.0090]],\n",
      "\n",
      "        [[-0.0560, -0.0975, -0.1125],\n",
      "         [-0.0618,  0.0913,  0.0667],\n",
      "         [ 0.0169,  0.1135,  0.1100],\n",
      "         [-0.1159,  0.0342, -0.1402],\n",
      "         [ 0.1438,  0.0117,  0.0578],\n",
      "         [-0.0886, -0.0497, -0.0318],\n",
      "         [-0.0704,  0.0448, -0.1131],\n",
      "         [ 0.0188, -0.0171,  0.0060],\n",
      "         [-0.1059,  0.0419,  0.0872],\n",
      "         [ 0.0433, -0.0476, -0.0948],\n",
      "         [-0.0929,  0.1291, -0.0377],\n",
      "         [ 0.0445, -0.0104, -0.0994],\n",
      "         [-0.1389,  0.1375,  0.0942],\n",
      "         [ 0.0731, -0.0235,  0.0245],\n",
      "         [ 0.1103,  0.0186,  0.1296],\n",
      "         [-0.0039,  0.0561, -0.0301]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv2.bias | Size: torch.Size([16]) | Values : tensor([0.0065, 0.0210], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[-0.1206],\n",
      "         [-0.0230],\n",
      "         [ 0.2057],\n",
      "         [ 0.1987],\n",
      "         [-0.0055],\n",
      "         [-0.0794],\n",
      "         [ 0.2241],\n",
      "         [ 0.2171],\n",
      "         [ 0.1975],\n",
      "         [-0.1737],\n",
      "         [ 0.0718],\n",
      "         [ 0.2113],\n",
      "         [ 0.0211],\n",
      "         [ 0.1153],\n",
      "         [ 0.1585],\n",
      "         [ 0.1170]],\n",
      "\n",
      "        [[ 0.2161],\n",
      "         [ 0.2214],\n",
      "         [-0.0179],\n",
      "         [-0.0155],\n",
      "         [ 0.0215],\n",
      "         [ 0.1461],\n",
      "         [-0.1275],\n",
      "         [ 0.2330],\n",
      "         [-0.0474],\n",
      "         [ 0.1698],\n",
      "         [-0.2024],\n",
      "         [-0.0943],\n",
      "         [ 0.0230],\n",
      "         [-0.1670],\n",
      "         [ 0.2333],\n",
      "         [-0.1602]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv3.bias | Size: torch.Size([64]) | Values : tensor([ 0.1258, -0.0854], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[ 0.0359],\n",
      "         [-0.0424],\n",
      "         [ 0.0781],\n",
      "         [-0.0538],\n",
      "         [-0.0363],\n",
      "         [ 0.0404],\n",
      "         [-0.0423],\n",
      "         [-0.1079],\n",
      "         [ 0.0684],\n",
      "         [ 0.0755],\n",
      "         [ 0.0574],\n",
      "         [ 0.0471],\n",
      "         [-0.0561],\n",
      "         [-0.1206],\n",
      "         [-0.0147],\n",
      "         [-0.0671],\n",
      "         [ 0.0764],\n",
      "         [-0.0177],\n",
      "         [ 0.0545],\n",
      "         [-0.0079],\n",
      "         [-0.0318],\n",
      "         [ 0.0285],\n",
      "         [ 0.0534],\n",
      "         [ 0.0291],\n",
      "         [-0.1021],\n",
      "         [ 0.0319],\n",
      "         [ 0.0753],\n",
      "         [ 0.0512],\n",
      "         [-0.0741],\n",
      "         [ 0.0087],\n",
      "         [-0.0999],\n",
      "         [ 0.1079],\n",
      "         [-0.0653],\n",
      "         [-0.0895],\n",
      "         [ 0.0187],\n",
      "         [-0.0219],\n",
      "         [-0.1221],\n",
      "         [ 0.0243],\n",
      "         [-0.0297],\n",
      "         [ 0.0413],\n",
      "         [ 0.0137],\n",
      "         [ 0.0561],\n",
      "         [-0.0785],\n",
      "         [-0.1243],\n",
      "         [ 0.0818],\n",
      "         [ 0.0559],\n",
      "         [-0.0506],\n",
      "         [-0.0602],\n",
      "         [-0.0139],\n",
      "         [ 0.1191],\n",
      "         [-0.0862],\n",
      "         [-0.0304],\n",
      "         [ 0.0272],\n",
      "         [-0.0180],\n",
      "         [-0.0992],\n",
      "         [ 0.0785],\n",
      "         [ 0.0040],\n",
      "         [-0.0978],\n",
      "         [ 0.0654],\n",
      "         [-0.0546],\n",
      "         [-0.0315],\n",
      "         [-0.0575],\n",
      "         [ 0.0957],\n",
      "         [ 0.0304]],\n",
      "\n",
      "        [[-0.0289],\n",
      "         [ 0.0752],\n",
      "         [-0.0838],\n",
      "         [-0.0535],\n",
      "         [-0.1052],\n",
      "         [ 0.1066],\n",
      "         [ 0.0764],\n",
      "         [-0.0485],\n",
      "         [-0.0633],\n",
      "         [ 0.1006],\n",
      "         [ 0.0575],\n",
      "         [ 0.0987],\n",
      "         [ 0.0310],\n",
      "         [-0.0292],\n",
      "         [-0.0929],\n",
      "         [ 0.1156],\n",
      "         [ 0.0155],\n",
      "         [ 0.0426],\n",
      "         [ 0.0187],\n",
      "         [ 0.0833],\n",
      "         [-0.1143],\n",
      "         [ 0.0439],\n",
      "         [ 0.0746],\n",
      "         [ 0.0288],\n",
      "         [-0.0161],\n",
      "         [ 0.0831],\n",
      "         [ 0.1100],\n",
      "         [-0.1021],\n",
      "         [-0.0734],\n",
      "         [-0.1182],\n",
      "         [ 0.0615],\n",
      "         [ 0.0755],\n",
      "         [-0.0159],\n",
      "         [ 0.0516],\n",
      "         [ 0.0955],\n",
      "         [ 0.0737],\n",
      "         [ 0.0481],\n",
      "         [ 0.0956],\n",
      "         [ 0.1223],\n",
      "         [-0.0463],\n",
      "         [-0.1229],\n",
      "         [ 0.0615],\n",
      "         [-0.0611],\n",
      "         [ 0.1180],\n",
      "         [ 0.0583],\n",
      "         [-0.0181],\n",
      "         [ 0.0378],\n",
      "         [-0.0972],\n",
      "         [-0.0733],\n",
      "         [-0.0215],\n",
      "         [-0.0043],\n",
      "         [ 0.0179],\n",
      "         [ 0.0041],\n",
      "         [ 0.0634],\n",
      "         [-0.0209],\n",
      "         [-0.1160],\n",
      "         [-0.1190],\n",
      "         [ 0.0673],\n",
      "         [ 0.0092],\n",
      "         [ 0.1019],\n",
      "         [-0.0464],\n",
      "         [-0.1175],\n",
      "         [ 0.1074],\n",
      "         [-0.0219]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.convr.bias | Size: torch.Size([64]) | Values : tensor([-0.0812,  0.0958], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[-0.1009],\n",
      "         [-0.0794],\n",
      "         [ 0.0552],\n",
      "         [-0.1086],\n",
      "         [-0.0221],\n",
      "         [-0.0794],\n",
      "         [ 0.0860],\n",
      "         [ 0.1063],\n",
      "         [-0.0365],\n",
      "         [ 0.0407],\n",
      "         [ 0.0354],\n",
      "         [-0.0325],\n",
      "         [-0.0163],\n",
      "         [-0.0911],\n",
      "         [ 0.0055],\n",
      "         [-0.0354],\n",
      "         [ 0.0667],\n",
      "         [-0.0211],\n",
      "         [-0.0631],\n",
      "         [-0.0872],\n",
      "         [ 0.1214],\n",
      "         [-0.0802],\n",
      "         [-0.1076],\n",
      "         [-0.0300],\n",
      "         [ 0.0886],\n",
      "         [ 0.0686],\n",
      "         [-0.0121],\n",
      "         [ 0.1153],\n",
      "         [-0.1055],\n",
      "         [ 0.0397],\n",
      "         [-0.0530],\n",
      "         [ 0.0666],\n",
      "         [ 0.0012],\n",
      "         [-0.0469],\n",
      "         [-0.0209],\n",
      "         [ 0.0503],\n",
      "         [ 0.1217],\n",
      "         [ 0.0172],\n",
      "         [ 0.0182],\n",
      "         [-0.0964],\n",
      "         [-0.1249],\n",
      "         [-0.0524],\n",
      "         [-0.0803],\n",
      "         [-0.1046],\n",
      "         [ 0.0456],\n",
      "         [-0.0645],\n",
      "         [ 0.0928],\n",
      "         [ 0.0605],\n",
      "         [ 0.0774],\n",
      "         [ 0.0983],\n",
      "         [ 0.1184],\n",
      "         [ 0.0729],\n",
      "         [ 0.1217],\n",
      "         [-0.1046],\n",
      "         [ 0.0779],\n",
      "         [ 0.1021],\n",
      "         [-0.0256],\n",
      "         [ 0.0007],\n",
      "         [-0.0079],\n",
      "         [ 0.0206],\n",
      "         [ 0.1157],\n",
      "         [ 0.0250],\n",
      "         [-0.1040],\n",
      "         [-0.1011]],\n",
      "\n",
      "        [[ 0.0997],\n",
      "         [ 0.0610],\n",
      "         [-0.0870],\n",
      "         [-0.1159],\n",
      "         [ 0.1144],\n",
      "         [-0.0983],\n",
      "         [ 0.1186],\n",
      "         [ 0.0845],\n",
      "         [ 0.0738],\n",
      "         [ 0.1125],\n",
      "         [-0.0082],\n",
      "         [-0.0170],\n",
      "         [-0.0226],\n",
      "         [-0.0206],\n",
      "         [ 0.0678],\n",
      "         [ 0.0844],\n",
      "         [-0.0848],\n",
      "         [-0.0142],\n",
      "         [ 0.0522],\n",
      "         [ 0.0272],\n",
      "         [-0.0920],\n",
      "         [-0.0406],\n",
      "         [-0.0967],\n",
      "         [-0.0542],\n",
      "         [-0.0854],\n",
      "         [ 0.0879],\n",
      "         [ 0.0368],\n",
      "         [-0.1156],\n",
      "         [ 0.0406],\n",
      "         [ 0.1094],\n",
      "         [-0.0439],\n",
      "         [-0.0412],\n",
      "         [ 0.0079],\n",
      "         [-0.0626],\n",
      "         [ 0.0006],\n",
      "         [ 0.1121],\n",
      "         [-0.1049],\n",
      "         [ 0.1041],\n",
      "         [ 0.0199],\n",
      "         [ 0.0171],\n",
      "         [-0.0089],\n",
      "         [-0.0790],\n",
      "         [ 0.0572],\n",
      "         [-0.0973],\n",
      "         [ 0.1054],\n",
      "         [ 0.0452],\n",
      "         [-0.0982],\n",
      "         [-0.0405],\n",
      "         [ 0.1060],\n",
      "         [ 0.1072],\n",
      "         [ 0.1245],\n",
      "         [ 0.0117],\n",
      "         [-0.0695],\n",
      "         [-0.0957],\n",
      "         [-0.0229],\n",
      "         [ 0.1101],\n",
      "         [ 0.1222],\n",
      "         [ 0.0056],\n",
      "         [-0.0258],\n",
      "         [-0.0517],\n",
      "         [-0.1129],\n",
      "         [ 0.0782],\n",
      "         [ 0.0040],\n",
      "         [ 0.0485]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv1.bias | Size: torch.Size([16]) | Values : tensor([-0.0391, -0.0301], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[ 0.0387, -0.0768,  0.0346],\n",
      "         [ 0.0042,  0.0120, -0.0983],\n",
      "         [-0.0201, -0.0629,  0.0463],\n",
      "         [ 0.1078, -0.0014,  0.1437],\n",
      "         [-0.0889,  0.0891, -0.0846],\n",
      "         [ 0.0604, -0.0809,  0.0806],\n",
      "         [-0.0604,  0.0299,  0.0997],\n",
      "         [ 0.1391,  0.0829,  0.0152],\n",
      "         [-0.0605,  0.0357,  0.0679],\n",
      "         [-0.1082,  0.1433, -0.0963],\n",
      "         [-0.0065, -0.0357,  0.1124],\n",
      "         [-0.0663,  0.1053,  0.0985],\n",
      "         [ 0.0311, -0.0644,  0.1036],\n",
      "         [-0.0598,  0.0340,  0.1048],\n",
      "         [-0.0649,  0.0793, -0.0624],\n",
      "         [ 0.0958, -0.0322, -0.0751]],\n",
      "\n",
      "        [[-0.0618, -0.0588,  0.1340],\n",
      "         [-0.0427, -0.0409,  0.1435],\n",
      "         [-0.0036, -0.0087,  0.1251],\n",
      "         [-0.0609,  0.0343,  0.0406],\n",
      "         [-0.0434, -0.0877, -0.0078],\n",
      "         [ 0.0610,  0.0009,  0.0303],\n",
      "         [-0.1250, -0.1279,  0.0143],\n",
      "         [-0.0540,  0.0196,  0.0168],\n",
      "         [-0.0413, -0.0912, -0.0641],\n",
      "         [ 0.0246,  0.1129, -0.1222],\n",
      "         [ 0.1410,  0.1270, -0.0401],\n",
      "         [ 0.1277,  0.0800, -0.1062],\n",
      "         [ 0.0885, -0.1125, -0.0417],\n",
      "         [-0.1139, -0.0324, -0.0620],\n",
      "         [ 0.0586, -0.0195,  0.0469],\n",
      "         [-0.1127,  0.1081, -0.1427]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv2.bias | Size: torch.Size([16]) | Values : tensor([-0.1378, -0.0251], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[ 0.1535],\n",
      "         [ 0.1596],\n",
      "         [-0.0475],\n",
      "         [-0.1478],\n",
      "         [-0.0400],\n",
      "         [-0.2082],\n",
      "         [ 0.1941],\n",
      "         [-0.1724],\n",
      "         [-0.1921],\n",
      "         [ 0.1785],\n",
      "         [-0.0736],\n",
      "         [-0.2391],\n",
      "         [-0.1146],\n",
      "         [ 0.0166],\n",
      "         [-0.1357],\n",
      "         [-0.0987]],\n",
      "\n",
      "        [[-0.0421],\n",
      "         [ 0.1914],\n",
      "         [-0.1398],\n",
      "         [-0.2360],\n",
      "         [-0.0557],\n",
      "         [-0.0244],\n",
      "         [-0.1887],\n",
      "         [-0.0506],\n",
      "         [ 0.1557],\n",
      "         [-0.2094],\n",
      "         [-0.1722],\n",
      "         [ 0.2170],\n",
      "         [-0.1320],\n",
      "         [-0.0557],\n",
      "         [ 0.1652],\n",
      "         [-0.0979]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv3.bias | Size: torch.Size([64]) | Values : tensor([0.1638, 0.2255], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[ 1.0726e-01],\n",
      "         [-1.7075e-02],\n",
      "         [ 8.5716e-02],\n",
      "         [-1.0495e-01],\n",
      "         [-1.6246e-02],\n",
      "         [ 9.3644e-02],\n",
      "         [ 7.8387e-02],\n",
      "         [ 8.2179e-02],\n",
      "         [-6.4377e-02],\n",
      "         [ 1.1904e-01],\n",
      "         [-1.8331e-02],\n",
      "         [-8.2251e-02],\n",
      "         [ 3.6533e-02],\n",
      "         [ 4.8086e-02],\n",
      "         [-1.1225e-01],\n",
      "         [-1.8998e-02],\n",
      "         [ 1.8734e-02],\n",
      "         [ 7.5410e-02],\n",
      "         [-8.1981e-02],\n",
      "         [ 1.2145e-01],\n",
      "         [ 9.4863e-02],\n",
      "         [-1.6130e-02],\n",
      "         [ 3.7829e-03],\n",
      "         [-1.1912e-01],\n",
      "         [ 7.8720e-02],\n",
      "         [ 6.6327e-02],\n",
      "         [-1.3510e-02],\n",
      "         [-2.7380e-02],\n",
      "         [-6.3416e-03],\n",
      "         [-1.5384e-02],\n",
      "         [-9.7562e-04],\n",
      "         [-6.6360e-02],\n",
      "         [-6.9233e-02],\n",
      "         [-8.6886e-02],\n",
      "         [ 6.6242e-02],\n",
      "         [ 2.3882e-02],\n",
      "         [-1.2013e-01],\n",
      "         [-6.4344e-02],\n",
      "         [ 8.0233e-03],\n",
      "         [ 6.6761e-02],\n",
      "         [-5.5082e-02],\n",
      "         [ 9.0359e-02],\n",
      "         [-8.8459e-02],\n",
      "         [ 6.6129e-02],\n",
      "         [ 1.9313e-02],\n",
      "         [-8.0573e-02],\n",
      "         [-1.0684e-01],\n",
      "         [-9.6657e-02],\n",
      "         [-7.4525e-02],\n",
      "         [-9.6534e-02],\n",
      "         [ 9.6959e-02],\n",
      "         [ 7.7921e-02],\n",
      "         [-3.9430e-02],\n",
      "         [-7.6827e-02],\n",
      "         [ 9.4059e-02],\n",
      "         [ 1.1554e-04],\n",
      "         [-6.1545e-02],\n",
      "         [-8.4859e-03],\n",
      "         [ 9.8618e-02],\n",
      "         [-1.1764e-01],\n",
      "         [ 4.8209e-02],\n",
      "         [-1.1601e-01],\n",
      "         [ 5.4544e-02],\n",
      "         [-2.3751e-02]],\n",
      "\n",
      "        [[ 7.9167e-02],\n",
      "         [ 7.8986e-02],\n",
      "         [ 6.8725e-02],\n",
      "         [ 1.1902e-01],\n",
      "         [ 1.1088e-01],\n",
      "         [ 6.5177e-02],\n",
      "         [ 8.4762e-02],\n",
      "         [-1.0443e-01],\n",
      "         [-9.3376e-02],\n",
      "         [ 4.5234e-02],\n",
      "         [-8.7960e-03],\n",
      "         [ 9.4849e-02],\n",
      "         [-3.8972e-02],\n",
      "         [-2.2468e-02],\n",
      "         [ 2.0676e-02],\n",
      "         [-3.6870e-02],\n",
      "         [ 1.1581e-01],\n",
      "         [ 2.5101e-02],\n",
      "         [ 9.2279e-02],\n",
      "         [ 4.6178e-02],\n",
      "         [-9.0266e-02],\n",
      "         [-5.6265e-02],\n",
      "         [ 3.7206e-02],\n",
      "         [ 7.9890e-02],\n",
      "         [-6.9750e-02],\n",
      "         [ 2.1752e-02],\n",
      "         [ 4.0677e-02],\n",
      "         [ 4.4517e-02],\n",
      "         [-7.5479e-02],\n",
      "         [ 2.0950e-02],\n",
      "         [ 8.8072e-02],\n",
      "         [-7.4467e-02],\n",
      "         [-9.8029e-02],\n",
      "         [-1.8068e-02],\n",
      "         [ 1.2349e-01],\n",
      "         [-8.8891e-02],\n",
      "         [ 1.0667e-01],\n",
      "         [-8.2722e-02],\n",
      "         [ 8.2491e-02],\n",
      "         [ 1.2396e-01],\n",
      "         [ 1.2491e-01],\n",
      "         [-8.4692e-02],\n",
      "         [-7.8705e-03],\n",
      "         [ 6.1696e-02],\n",
      "         [-9.2025e-04],\n",
      "         [ 1.5687e-02],\n",
      "         [ 7.4725e-02],\n",
      "         [ 3.8812e-02],\n",
      "         [ 6.1119e-02],\n",
      "         [-1.1961e-01],\n",
      "         [ 5.0877e-02],\n",
      "         [ 1.1517e-01],\n",
      "         [ 5.8194e-02],\n",
      "         [ 4.3063e-02],\n",
      "         [ 3.2964e-02],\n",
      "         [-5.6267e-02],\n",
      "         [ 8.6637e-02],\n",
      "         [-1.0377e-01],\n",
      "         [-1.3506e-02],\n",
      "         [-1.1077e-01],\n",
      "         [ 9.9553e-02],\n",
      "         [ 1.1955e-01],\n",
      "         [-3.8775e-02],\n",
      "         [ 9.1105e-02]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.convr.bias | Size: torch.Size([64]) | Values : tensor([-0.0982,  0.0127], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc.1.weight | Size: torch.Size([2, 768]) | Values : tensor([[ 0.0029,  0.0062,  0.0301,  ..., -0.0138,  0.0141,  0.0250],\n",
      "        [ 0.0354,  0.0116, -0.0342,  ...,  0.0135, -0.0284, -0.0254]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc.1.bias | Size: torch.Size([2]) | Values : tensor([ 0.0050, -0.0150], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from models.TinyFallNet import TinyFallNet\n",
    "\n",
    "# Create an instance of the model\n",
    "model_tinyFallNet = TinyFallNet().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_tinyFallNet.parameters(), lr=learning_rate)\n",
    "# Initialize the scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=patience, verbose=True)\n",
    "\n",
    "print(f\"Model structure: {model_tinyFallNet}\\n\\n\")\n",
    "for name, param in model_tinyFallNet.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "loss: 1.259295  [   64/23232]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\python\\lib\\site-packages\\torch\\nn\\modules\\container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.501584  [ 6464/23232]\n",
      "loss: 0.313263  [12864/23232]\n",
      "loss: 0.706318  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.340608 \n",
      "\n",
      "Epoch 1:\n",
      "loss: 0.313266  [   64/23232]\n",
      "loss: 0.313266  [ 6464/23232]\n",
      "loss: 0.706313  [12864/23232]\n",
      "loss: 0.501585  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.340606 \n",
      "\n",
      "Epoch 2:\n",
      "loss: 0.927450  [   64/23232]\n",
      "loss: 0.501584  [ 6464/23232]\n",
      "loss: 0.313263  [12864/23232]\n",
      "loss: 1.164999  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.340606 \n",
      "\n",
      "Epoch 3:\n",
      "loss: 0.313263  [   64/23232]\n",
      "loss: 0.313262  [ 6464/23232]\n",
      "loss: 0.927452  [12864/23232]\n",
      "loss: 0.706312  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.340606 \n",
      "\n",
      "Epoch 4:\n",
      "loss: 0.706312  [   64/23232]\n",
      "loss: 0.927452  [ 6464/23232]\n",
      "loss: 0.501584  [12864/23232]\n",
      "loss: 0.501583  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.340606 \n",
      "\n",
      "Epoch 5:\n",
      "loss: 1.164999  [   64/23232]\n",
      "loss: 0.501584  [ 6464/23232]\n",
      "loss: 0.313262  [12864/23232]\n",
      "loss: 0.706312  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.340606 \n",
      "\n",
      "Epoch 6:\n",
      "loss: 0.706313  [   64/23232]\n",
      "loss: 0.501582  [ 6464/23232]\n",
      "loss: 0.313262  [12864/23232]\n",
      "loss: 0.501582  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.340606 \n",
      "\n",
      "Epoch 00007: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Epoch 7:\n",
      "loss: 0.313262  [   64/23232]\n",
      "loss: 0.706313  [ 6464/23232]\n",
      "loss: 0.501583  [12864/23232]\n",
      "loss: 0.501582  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.340606 \n",
      "\n",
      "Epoch 8:\n",
      "loss: 0.706312  [   64/23232]\n",
      "loss: 0.501583  [ 6464/23232]\n",
      "loss: 0.706313  [12864/23232]\n",
      "loss: 0.706312  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.340606 \n",
      "\n",
      "Epoch 9:\n",
      "loss: 0.501582  [   64/23232]\n",
      "loss: 1.164998  [ 6464/23232]\n",
      "loss: 1.418955  [12864/23232]\n",
      "loss: 0.927451  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.340606 \n",
      "\n",
      "Epoch 10:\n",
      "loss: 0.927451  [   64/23232]\n",
      "loss: 0.706312  [ 6464/23232]\n",
      "loss: 0.706313  [12864/23232]\n",
      "loss: 1.418955  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.340606 \n",
      "\n",
      "Epoch 11:\n",
      "loss: 0.706312  [   64/23232]\n",
      "loss: 0.927451  [ 6464/23232]\n",
      "loss: 0.501583  [12864/23232]\n",
      "loss: 0.927451  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.340606 \n",
      "\n",
      "Epoch 12:\n",
      "loss: 0.313262  [   64/23232]\n",
      "loss: 0.706312  [ 6464/23232]\n",
      "loss: 0.706312  [12864/23232]\n",
      "loss: 0.706312  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.340606 \n",
      "\n",
      "Epoch 00013: reducing learning rate of group 0 to 5.0000e-06.\n",
      "Epoch 13:\n",
      "loss: 0.927451  [   64/23232]\n",
      "loss: 0.927451  [ 6464/23232]\n",
      "loss: 0.501583  [12864/23232]\n",
      "loss: 0.706312  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.340606 \n",
      "\n",
      "Epoch 14:\n",
      "loss: 0.706312  [   64/23232]\n",
      "loss: 0.501583  [ 6464/23232]\n",
      "loss: 0.706312  [12864/23232]\n",
      "loss: 0.313262  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.340606 \n",
      "\n",
      "Epoch 15:\n",
      "loss: 0.706312  [   64/23232]\n",
      "loss: 0.313262  [ 6464/23232]\n",
      "loss: 0.501582  [12864/23232]\n",
      "loss: 0.706312  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.340606 \n",
      "\n",
      "Epoch 16:\n",
      "loss: 0.313262  [   64/23232]\n",
      "loss: 0.313262  [ 6464/23232]\n",
      "loss: 0.501582  [12864/23232]\n",
      "loss: 0.501583  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.340606 \n",
      "\n",
      "Epoch 17:\n",
      "loss: 0.501582  [   64/23232]\n",
      "loss: 1.164998  [ 6464/23232]\n",
      "loss: 0.313262  [12864/23232]\n",
      "loss: 0.927451  [19264/23232]\n",
      "Validation Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.340606 \n",
      "\n",
      "Early stopping due to no improvement in validation loss.\n"
     ]
    }
   ],
   "source": [
    "train(train_dataloader, model_tinyFallNet, loss_fn, optimizer,val_dataloader, \n",
    "        patience=patience, scheduler=scheduler, device=device, epochs=epochs, B_size=B_size, A_size=A_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 48.3%, Avg loss: 0.830503 \n",
      "\n",
      " Label 0\n",
      "    accuracy\t0.483\n",
      " specificity\t0.000\n",
      " sensitivity\t1.000\n",
      " Label 1\n",
      "    accuracy\t0.483\n",
      " specificity\t1.000\n",
      " sensitivity\t0.000\n",
      "[[28  0]\n",
      " [30  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\python\\lib\\site-packages\\torch\\nn\\modules\\container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# final test\n",
    "test(test_dataloader, model_tinyFallNet, loss_fn, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvLSTM\n",
      "Test Error: \n",
      " Accuracy: 93.1%, Avg loss: 0.318213 \n",
      "\n",
      " Label 0\n",
      "    accuracy\t0.931\n",
      " specificity\t0.900\n",
      " sensitivity\t0.964\n",
      " Label 1\n",
      "    accuracy\t0.931\n",
      " specificity\t0.964\n",
      " sensitivity\t0.900\n",
      "[[27  1]\n",
      " [ 3 27]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ConvLSTM\n",
    "print('ConvLSTM')\n",
    "test(test_dataloader, model_ConvLSTM, loss_fn, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet24\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.564428 \n",
      "\n",
      " Label 0\n",
      "    accuracy\t0.793\n",
      " specificity\t0.633\n",
      " sensitivity\t0.964\n",
      " Label 1\n",
      "    accuracy\t0.793\n",
      " specificity\t0.964\n",
      " sensitivity\t0.633\n",
      "[[27  1]\n",
      " [11 19]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ResNet24\n",
    "print('ResNet24')\n",
    "test(test_dataloader, model_resnet, loss_fn, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinyFallNet\n",
      "Test Error: \n",
      " Accuracy: 48.3%, Avg loss: 0.830503 \n",
      "\n",
      " Label 0\n",
      "    accuracy\t0.483\n",
      " specificity\t0.000\n",
      " sensitivity\t1.000\n",
      " Label 1\n",
      "    accuracy\t0.483\n",
      " specificity\t1.000\n",
      " sensitivity\t0.000\n",
      "[[28  0]\n",
      " [30  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\python\\lib\\site-packages\\torch\\nn\\modules\\container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TinyFallNet\n",
    "print('TinyFallNet')\n",
    "test(test_dataloader, model_tinyFallNet, loss_fn, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fall_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
