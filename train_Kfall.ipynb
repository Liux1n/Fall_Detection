{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.signal import resample\n",
    "\n",
    "from data_organizer_Kfall import DataOrganizer\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from utils import train, test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/32 folder...\n",
      "(1212, 9, 50)\n",
      "Processing 2/32 folder...\n",
      "(750, 9, 50)\n",
      "Processing 3/32 folder...\n",
      "(815, 9, 50)\n",
      "Processing 4/32 folder...\n",
      "(765, 9, 50)\n",
      "Processing 5/32 folder...\n",
      "(795, 9, 50)\n",
      "Processing 6/32 folder...\n",
      "(815, 9, 50)\n",
      "Processing 7/32 folder...\n",
      "(710, 9, 50)\n",
      "Processing 8/32 folder...\n",
      "(800, 9, 50)\n",
      "Processing 9/32 folder...\n",
      "(810, 9, 50)\n",
      "Processing 10/32 folder...\n",
      "(810, 9, 50)\n",
      "Processing 11/32 folder...\n",
      "(815, 9, 50)\n",
      "Processing 12/32 folder...\n",
      "(805, 9, 50)\n",
      "Processing 13/32 folder...\n",
      "(800, 9, 50)\n",
      "Processing 14/32 folder...\n",
      "(790, 9, 50)\n",
      "Processing 15/32 folder...\n",
      "(780, 9, 50)\n",
      "Processing 16/32 folder...\n",
      "(815, 9, 50)\n",
      "Processing 17/32 folder...\n",
      "(805, 9, 50)\n",
      "Processing 18/32 folder...\n",
      "(815, 9, 50)\n",
      "Processing 19/32 folder...\n",
      "(765, 9, 50)\n",
      "Processing 20/32 folder...\n",
      "(815, 9, 50)\n",
      "Processing 21/32 folder...\n",
      "(805, 9, 50)\n",
      "Processing 22/32 folder...\n",
      "(785, 9, 50)\n",
      "Processing 23/32 folder...\n",
      "(780, 9, 50)\n",
      "Processing 24/32 folder...\n",
      "(790, 9, 50)\n",
      "Processing 25/32 folder...\n",
      "(805, 9, 50)\n",
      "Processing 26/32 folder...\n",
      "(780, 9, 50)\n",
      "Processing 27/32 folder...\n",
      "(815, 9, 50)\n",
      "Processing 28/32 folder...\n",
      "(810, 9, 50)\n",
      "Processing 29/32 folder...\n",
      "(800, 9, 50)\n",
      "Processing 30/32 folder...\n",
      "(800, 9, 50)\n",
      "Processing 31/32 folder...\n",
      "(740, 9, 50)\n",
      "Processing 32/32 folder...\n",
      "(810, 9, 50)\n"
     ]
    }
   ],
   "source": [
    "# mac\n",
    "#sensor_data_folder = '/Users/liuxinqing/Documents/Kfall/sensor_data'  # Update with the path to sensor data\n",
    "#label_data_folder = '/Users/liuxinqing/Documents/Kfall/label_data'  \n",
    "# windows \n",
    "sensor_data_folder = 'G:\\MLonMCU\\Kfall_dataset\\sensor_data'  # Update with the path to sensor data\n",
    "label_data_folder = 'G:\\MLonMCU\\Kfall_dataset\\label_data' \n",
    "\n",
    "#window_size = 256\n",
    "# Kfall: window_size = 50\n",
    "window_size = 50\n",
    "threshold = 0.1\n",
    "num_window_fall_data = 50\n",
    "num_window_not_fall_data = 5\n",
    "\n",
    "data, label = DataOrganizer(sensor_data_folder, \n",
    "                            label_data_folder, \n",
    "                            window_size, \n",
    "                            threshold, \n",
    "                            num_window_fall_data, \n",
    "                            num_window_not_fall_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_channels:  9\n",
      "data.shape:  (25807, 9, 50)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "in_channels = data.shape[1]\n",
    "print('in_channels: ', in_channels)\n",
    "# the input data should have the shape (batch_size, in_channels, sequence_length)\n",
    "#data = data.reshape(data.shape[0], in_channels, -1)\n",
    "print('data.shape: ', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_size:  25020\n",
      "A_size:  787\n",
      "data.shape:  (25807, 9, 50)\n",
      "(62, 9, 50)\n",
      "X_train_tensor.dtype:  torch.float64\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "label = label.astype(np.int64)\n",
    "# (y == 0).sum()\n",
    "B_size = (label == 0).sum()\n",
    "A_size = (label == 1).sum()\n",
    "print('B_size: ', B_size)\t\n",
    "print('A_size: ', A_size)\n",
    "# transpose the data to (batch_size, in_channels, sequence_length)\n",
    "#data = np.transpose(data, (0, 2, 1))\n",
    "print('data.shape: ', data.shape)\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.05, random_state=42)\n",
    "\n",
    "# Further split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.05, random_state=42)\n",
    "\n",
    "#print(np.unique(y_train)) # [0 1]\n",
    "y_train = y_train.astype(np.int64)\n",
    "y_test = y_test.astype(np.int64)\n",
    "\n",
    "\n",
    "# select the test data that is not zero\n",
    "X_test_true = X_test[y_test != 0]\n",
    "y_test_true = y_test[y_test != 0]\n",
    "# length of the test data\n",
    "test_len = X_test_true.shape[0]\n",
    "X_test_false = X_test[y_test == 0]\n",
    "y_test_false = y_test[y_test == 0]\n",
    "# X_test.shape:  (17, 50, 9)\n",
    "# randomly len number of test data that is zero\n",
    "index = np.random.choice(X_test_false.shape[0], test_len, replace=False)\n",
    "# X_test.shape:  (17, 50, 9)\n",
    "# randomly len number of test data that is zero\n",
    "#index = np.random.choice(X_test_false.shape[0], len, replace=False)\n",
    "\n",
    "\n",
    "X_test_false = X_test[index]\n",
    "y_test_false = y_test[index]\n",
    "\n",
    "# concatenate the true and false test data\n",
    "X_test = np.concatenate((X_test_true, X_test_false), axis=0)\n",
    "y_test = np.concatenate((y_test_true, y_test_false), axis=0)\n",
    "#X_test = X_test[y_test != 0]\n",
    "#y_test = y_test[y_test != 0]\n",
    "print(X_test.shape)\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.from_numpy(X_train)\n",
    "y_train_tensor = torch.from_numpy(y_train)\n",
    "X_val_tensor = torch.from_numpy(X_val)\n",
    "y_val_tensor = torch.from_numpy(y_val)\n",
    "X_test_tensor = torch.from_numpy(X_test)\n",
    "y_test_tensor = torch.from_numpy(y_test)\n",
    "\n",
    "\n",
    "# print datatype of X_train_tensor\n",
    "X_train_tensor = X_train_tensor.double()\n",
    "print('X_train_tensor.dtype: ', X_train_tensor.dtype)\n",
    "X_test = X_train_tensor.double()\n",
    "\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 5e-4\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(nn.Conv1d(in_channels=9, out_channels=64, kernel_size=3, padding=1),\n",
    "                                   nn.BatchNorm1d(64),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool1d(2))\n",
    "        self.conv2 = nn.Sequential(nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "                                   nn.BatchNorm1d(64),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool1d(2))\n",
    "        self.conv3 = nn.Sequential(nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "                                   nn.BatchNorm1d(64),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool1d(2))\n",
    "\n",
    "        # LSTM layers\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size=64, hidden_size=64, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.lstm2 = nn.LSTM(input_size=64, hidden_size=64, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc = nn.Linear(64, 2)  # No need for softmax here when using nn.CrossEntropyLoss\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        # x.shape = (batch_size, channels, sequence_length)\n",
    "        # Prepare for LSTM\n",
    "        # batch_first=True: (batch, sequence_length, channels)\n",
    "\n",
    "\n",
    "        # transpose x to (batch_size, sequence_length, channels)\n",
    "        x = x.transpose(1, 2)\n",
    "        \n",
    "        # LSTM layers\n",
    "        x, _ = self.lstm1(x)  # Only take the output, ignore hidden states\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm2(x)  # Only take the output, ignore hidden states\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        # Take the outputs of the last time step\n",
    "        x = x[:, -1, :]\n",
    "        \n",
    "        # Fully connected layer\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: ConvLSTM(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv1d(9, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (lstm1): LSTM(64, 64, batch_first=True)\n",
      "  (dropout1): Dropout(p=0.5, inplace=False)\n",
      "  (lstm2): LSTM(64, 64, batch_first=True)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "Layer: conv1.0.weight | Size: torch.Size([64, 9, 3]) | Values : tensor([[[-0.1783,  0.1740, -0.0743],\n",
      "         [-0.0050, -0.0139, -0.1338],\n",
      "         [ 0.0745, -0.0925,  0.0293],\n",
      "         [-0.1678,  0.0668,  0.0809],\n",
      "         [ 0.1671,  0.0081, -0.0846],\n",
      "         [-0.0948,  0.1650,  0.0304],\n",
      "         [-0.1293,  0.0804, -0.0539],\n",
      "         [-0.0053,  0.0033, -0.0279],\n",
      "         [-0.0941,  0.1857,  0.0130]],\n",
      "\n",
      "        [[ 0.0234, -0.1724,  0.0580],\n",
      "         [-0.0527,  0.0090, -0.1641],\n",
      "         [-0.1406, -0.1495, -0.1839],\n",
      "         [-0.1816, -0.0234,  0.0539],\n",
      "         [-0.0984, -0.1512,  0.0044],\n",
      "         [-0.0196,  0.1320, -0.1623],\n",
      "         [ 0.0387, -0.1520,  0.0759],\n",
      "         [-0.0938,  0.0748,  0.0740],\n",
      "         [-0.1420,  0.0098, -0.0320]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.0.bias | Size: torch.Size([64]) | Values : tensor([0.0021, 0.1528], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.1.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.1.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.0.weight | Size: torch.Size([64, 64, 3]) | Values : tensor([[[-5.7296e-02, -5.7995e-02, -6.5166e-02],\n",
      "         [ 2.8525e-03,  1.8251e-02, -2.2985e-02],\n",
      "         [-2.4413e-02, -2.9789e-02,  3.8181e-02],\n",
      "         [-5.6835e-02, -2.6173e-02,  2.4986e-02],\n",
      "         [ 1.7903e-03, -3.7771e-02,  5.8337e-02],\n",
      "         [-2.6985e-02, -5.3413e-03,  6.8555e-02],\n",
      "         [-2.9521e-02,  6.4133e-02,  7.0083e-02],\n",
      "         [-1.6049e-03, -3.3578e-02, -2.3602e-02],\n",
      "         [ 7.8227e-03,  1.9755e-02,  1.2706e-02],\n",
      "         [-4.8598e-02, -3.9042e-02, -5.2034e-02],\n",
      "         [-3.7523e-03, -2.5111e-02,  2.8188e-02],\n",
      "         [ 5.3403e-02,  7.0606e-03, -6.0440e-02],\n",
      "         [-1.4699e-02, -6.6892e-02, -6.0392e-02],\n",
      "         [ 4.8078e-02,  5.0343e-02, -6.3678e-02],\n",
      "         [ 5.2686e-02,  1.2029e-02,  2.7647e-03],\n",
      "         [ 2.5698e-02,  3.2500e-02, -4.1002e-02],\n",
      "         [-1.4767e-02,  5.6288e-03, -4.3415e-02],\n",
      "         [ 1.4725e-02,  7.1895e-02, -6.6570e-02],\n",
      "         [ 1.2010e-03,  4.0163e-02, -1.3364e-02],\n",
      "         [ 2.3570e-02, -3.7906e-02,  4.3070e-02],\n",
      "         [ 5.5729e-02, -3.2337e-03, -3.0402e-02],\n",
      "         [ 6.8171e-02, -4.5571e-02, -6.4040e-02],\n",
      "         [ 2.3628e-02,  4.4950e-02, -1.5430e-02],\n",
      "         [ 2.5373e-02,  2.4865e-02, -4.6843e-02],\n",
      "         [ 6.6789e-02, -5.5742e-02,  6.6188e-02],\n",
      "         [ 5.2448e-02,  4.7788e-02, -3.9334e-02],\n",
      "         [-5.0167e-02, -1.3357e-02, -2.3962e-02],\n",
      "         [-5.6877e-02,  5.1200e-02, -5.1130e-02],\n",
      "         [-4.8504e-02,  3.2382e-02, -1.1876e-02],\n",
      "         [ 3.6439e-02,  5.7855e-02, -1.7499e-02],\n",
      "         [-6.8673e-02,  5.3230e-02, -5.4295e-02],\n",
      "         [ 6.5203e-02, -4.7591e-03,  2.3254e-02],\n",
      "         [-4.5890e-02,  2.2419e-02,  3.8063e-02],\n",
      "         [ 8.9568e-03,  3.7140e-02,  4.5621e-02],\n",
      "         [ 5.7379e-02, -1.7397e-02,  5.1699e-03],\n",
      "         [ 3.9924e-03, -5.9076e-02,  2.9672e-02],\n",
      "         [-6.7794e-02, -5.6946e-04,  3.0104e-02],\n",
      "         [ 3.1750e-02, -2.2127e-02, -5.0703e-02],\n",
      "         [-5.0141e-02, -1.1221e-02, -1.2543e-02],\n",
      "         [-5.2591e-02,  4.5352e-02,  3.5514e-02],\n",
      "         [-2.3028e-02, -6.3386e-03,  3.6314e-02],\n",
      "         [-5.2669e-02, -4.7519e-02,  1.4742e-02],\n",
      "         [ 4.1707e-02, -4.3814e-02, -4.8712e-02],\n",
      "         [-4.1300e-02,  6.3008e-02,  1.3253e-02],\n",
      "         [ 5.1077e-02,  3.3956e-02,  6.1773e-02],\n",
      "         [ 2.5431e-02, -4.0575e-02, -5.9507e-02],\n",
      "         [-6.5717e-02,  6.8339e-02, -4.7293e-02],\n",
      "         [-3.6827e-02,  4.0698e-02,  3.4021e-03],\n",
      "         [-2.9224e-02, -5.4661e-02, -6.8637e-02],\n",
      "         [-1.4691e-02,  4.4679e-02,  3.6587e-02],\n",
      "         [-1.6976e-02,  5.6910e-02, -1.5473e-02],\n",
      "         [-3.9192e-02, -1.7821e-02, -2.3544e-02],\n",
      "         [-3.4692e-02, -3.1800e-02, -2.0013e-03],\n",
      "         [-5.9293e-02, -5.6175e-02, -6.7148e-02],\n",
      "         [-1.1345e-02,  6.7608e-02,  7.1750e-02],\n",
      "         [ 6.7755e-02, -4.7707e-02, -4.7541e-02],\n",
      "         [-4.8728e-02,  1.6873e-02,  3.4427e-02],\n",
      "         [ 1.6925e-02,  6.3346e-02, -1.8435e-02],\n",
      "         [-3.3702e-02, -6.4762e-02, -1.7773e-02],\n",
      "         [-4.7328e-02,  6.9465e-02,  6.0949e-02],\n",
      "         [-6.0135e-02,  5.9077e-03, -1.5430e-02],\n",
      "         [-2.9198e-02, -6.2065e-02,  2.5376e-02],\n",
      "         [ 5.7957e-02,  2.0711e-02, -3.2362e-03],\n",
      "         [ 3.7633e-02,  5.8282e-02, -6.9482e-02]],\n",
      "\n",
      "        [[ 2.0512e-02, -1.9788e-02, -4.5689e-03],\n",
      "         [-6.8424e-02,  4.1818e-02, -4.7015e-02],\n",
      "         [-6.1330e-02, -1.2354e-02, -9.1542e-03],\n",
      "         [ 3.1474e-02, -1.3889e-02, -6.6407e-02],\n",
      "         [-6.2469e-02,  1.9076e-02,  3.9827e-02],\n",
      "         [-3.9879e-02,  4.7347e-02, -4.6423e-02],\n",
      "         [ 1.9574e-02, -4.9360e-02,  4.3008e-02],\n",
      "         [ 5.6918e-03,  7.8002e-03, -5.0266e-02],\n",
      "         [ 2.0062e-02,  2.3312e-04,  1.7592e-02],\n",
      "         [-1.0633e-02, -4.1858e-02, -1.4737e-02],\n",
      "         [-7.0436e-02, -1.8444e-02,  2.2110e-02],\n",
      "         [ 2.5031e-02, -6.7900e-02,  6.0147e-02],\n",
      "         [-5.7496e-02, -5.2899e-02,  6.2391e-02],\n",
      "         [-4.6986e-03,  1.6259e-02, -3.7214e-02],\n",
      "         [ 5.6267e-02,  3.7262e-02, -1.5977e-02],\n",
      "         [-4.5449e-02, -6.2827e-02, -3.6150e-02],\n",
      "         [ 4.6786e-02, -6.8223e-02, -2.3370e-02],\n",
      "         [-6.6486e-03, -1.9267e-02, -4.4165e-02],\n",
      "         [-5.5715e-02, -3.8018e-02,  2.0667e-02],\n",
      "         [ 3.0223e-03,  4.6115e-02,  5.6425e-02],\n",
      "         [ 6.7284e-02, -3.8943e-02,  3.9886e-02],\n",
      "         [ 1.7763e-02,  6.5198e-02, -6.4783e-02],\n",
      "         [-5.3207e-03,  4.1297e-02,  2.1118e-02],\n",
      "         [ 1.1786e-02, -1.4189e-02, -1.4802e-02],\n",
      "         [ 2.7216e-02,  5.2483e-02,  2.9490e-02],\n",
      "         [-6.4373e-02, -6.5622e-02,  3.9463e-02],\n",
      "         [-3.4072e-02,  4.6576e-02, -4.1680e-02],\n",
      "         [ 7.0776e-02, -6.4390e-03,  3.3322e-02],\n",
      "         [-5.0010e-03,  1.9687e-02,  2.7945e-02],\n",
      "         [ 1.4875e-02, -5.9214e-03, -3.7026e-02],\n",
      "         [ 4.1742e-03,  1.7948e-02,  5.2315e-02],\n",
      "         [ 4.7306e-02, -2.3809e-02, -6.6184e-02],\n",
      "         [ 2.7490e-02, -2.4228e-02,  2.5937e-02],\n",
      "         [-2.7299e-02,  5.2404e-02, -2.0327e-02],\n",
      "         [-2.6326e-02, -6.3974e-02,  4.8369e-03],\n",
      "         [-6.4203e-02, -3.6081e-02,  4.0555e-02],\n",
      "         [ 1.2491e-02,  1.9627e-02,  6.5769e-02],\n",
      "         [-5.3574e-02,  2.7788e-02,  4.2934e-03],\n",
      "         [-4.6366e-02,  6.4750e-02,  6.9853e-03],\n",
      "         [-5.3792e-02, -1.1193e-03, -5.8174e-05],\n",
      "         [ 1.3405e-02, -5.3723e-02,  2.9751e-02],\n",
      "         [ 7.1051e-02,  6.0811e-02,  1.1349e-02],\n",
      "         [ 4.8918e-02,  3.0547e-02,  3.7669e-02],\n",
      "         [-2.8988e-02, -1.8335e-02,  6.3006e-02],\n",
      "         [ 3.2930e-02,  2.6107e-02,  1.0375e-03],\n",
      "         [ 2.6018e-02,  6.1361e-02,  6.9056e-02],\n",
      "         [-2.7981e-02, -5.6634e-02, -6.5631e-02],\n",
      "         [-4.4328e-02, -6.2518e-02,  2.9737e-02],\n",
      "         [ 2.6856e-02, -6.0314e-02, -6.0921e-02],\n",
      "         [-1.8105e-02, -2.8189e-02,  5.6155e-02],\n",
      "         [-3.8139e-02, -3.9659e-03,  1.6601e-02],\n",
      "         [ 2.5125e-02,  3.3659e-03, -3.2215e-02],\n",
      "         [-5.0371e-03, -1.1874e-02,  7.7087e-03],\n",
      "         [-4.7943e-02, -4.2662e-02,  3.5546e-02],\n",
      "         [-6.3338e-02, -4.0661e-02,  1.1961e-02],\n",
      "         [ 1.3273e-02,  3.7531e-02,  5.6901e-02],\n",
      "         [ 4.0761e-02,  6.5177e-02,  5.8657e-02],\n",
      "         [ 1.5249e-02,  5.4706e-03,  5.2168e-02],\n",
      "         [ 4.6078e-02, -5.1515e-02,  6.6773e-02],\n",
      "         [-1.4272e-03,  5.3411e-02, -4.6253e-02],\n",
      "         [ 6.9720e-02,  1.8484e-03, -2.0839e-02],\n",
      "         [ 2.0429e-02,  5.5699e-02,  1.4153e-02],\n",
      "         [ 1.2369e-02,  4.5212e-02, -3.3681e-02],\n",
      "         [ 6.6455e-02,  3.8447e-02, -3.5506e-02]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.0.bias | Size: torch.Size([64]) | Values : tensor([ 0.0480, -0.0695], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.1.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.1.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv3.0.weight | Size: torch.Size([64, 64, 3]) | Values : tensor([[[-0.0198,  0.0568,  0.0513],\n",
      "         [-0.0299, -0.0115,  0.0051],\n",
      "         [-0.0379, -0.0434,  0.0051],\n",
      "         [-0.0508,  0.0305,  0.0329],\n",
      "         [-0.0632,  0.0029,  0.0328],\n",
      "         [ 0.0004, -0.0158,  0.0711],\n",
      "         [-0.0586, -0.0204,  0.0229],\n",
      "         [ 0.0288,  0.0248,  0.0437],\n",
      "         [ 0.0659,  0.0382, -0.0183],\n",
      "         [-0.0569,  0.0679,  0.0304],\n",
      "         [ 0.0597, -0.0118,  0.0267],\n",
      "         [ 0.0306, -0.0697,  0.0423],\n",
      "         [ 0.0385, -0.0409,  0.0534],\n",
      "         [-0.0527,  0.0432, -0.0600],\n",
      "         [ 0.0285, -0.0168, -0.0327],\n",
      "         [-0.0070,  0.0340, -0.0237],\n",
      "         [-0.0486,  0.0399,  0.0386],\n",
      "         [-0.0017,  0.0504,  0.0518],\n",
      "         [ 0.0317, -0.0258,  0.0453],\n",
      "         [ 0.0532, -0.0708, -0.0715],\n",
      "         [-0.0229,  0.0376,  0.0341],\n",
      "         [ 0.0193,  0.0301, -0.0306],\n",
      "         [-0.0044, -0.0505,  0.0055],\n",
      "         [ 0.0162, -0.0631,  0.0264],\n",
      "         [ 0.0133, -0.0563, -0.0421],\n",
      "         [-0.0330,  0.0204,  0.0221],\n",
      "         [ 0.0445,  0.0600, -0.0167],\n",
      "         [ 0.0654,  0.0469,  0.0707],\n",
      "         [ 0.0098, -0.0316,  0.0501],\n",
      "         [-0.0477,  0.0280,  0.0327],\n",
      "         [-0.0008,  0.0030, -0.0453],\n",
      "         [-0.0514, -0.0387,  0.0260],\n",
      "         [ 0.0538, -0.0680, -0.0034],\n",
      "         [ 0.0399,  0.0249, -0.0509],\n",
      "         [ 0.0687,  0.0510,  0.0718],\n",
      "         [-0.0542,  0.0614, -0.0230],\n",
      "         [-0.0678, -0.0192, -0.0200],\n",
      "         [ 0.0073, -0.0392,  0.0621],\n",
      "         [ 0.0088, -0.0402,  0.0676],\n",
      "         [ 0.0203, -0.0438, -0.0695],\n",
      "         [-0.0002, -0.0057,  0.0569],\n",
      "         [ 0.0587, -0.0100,  0.0131],\n",
      "         [-0.0246, -0.0722, -0.0665],\n",
      "         [ 0.0163,  0.0165,  0.0675],\n",
      "         [ 0.0114, -0.0316, -0.0197],\n",
      "         [ 0.0287, -0.0522,  0.0527],\n",
      "         [-0.0485, -0.0659, -0.0082],\n",
      "         [ 0.0564,  0.0337, -0.0141],\n",
      "         [ 0.0191, -0.0638, -0.0213],\n",
      "         [-0.0406, -0.0074, -0.0200],\n",
      "         [ 0.0082, -0.0682,  0.0555],\n",
      "         [ 0.0254,  0.0587,  0.0378],\n",
      "         [ 0.0012, -0.0016,  0.0505],\n",
      "         [ 0.0414, -0.0217, -0.0708],\n",
      "         [-0.0049,  0.0255,  0.0402],\n",
      "         [ 0.0132, -0.0428, -0.0688],\n",
      "         [ 0.0236, -0.0545,  0.0377],\n",
      "         [ 0.0174,  0.0378, -0.0445],\n",
      "         [-0.0137, -0.0450, -0.0697],\n",
      "         [-0.0392, -0.0186,  0.0160],\n",
      "         [ 0.0026, -0.0459, -0.0173],\n",
      "         [-0.0301,  0.0345,  0.0132],\n",
      "         [ 0.0064,  0.0030,  0.0015],\n",
      "         [ 0.0517,  0.0250,  0.0349]],\n",
      "\n",
      "        [[ 0.0159,  0.0408,  0.0024],\n",
      "         [ 0.0690,  0.0300,  0.0179],\n",
      "         [-0.0061,  0.0513,  0.0217],\n",
      "         [-0.0536,  0.0343, -0.0304],\n",
      "         [-0.0452,  0.0606,  0.0573],\n",
      "         [ 0.0273,  0.0220, -0.0303],\n",
      "         [ 0.0711, -0.0274,  0.0188],\n",
      "         [-0.0626, -0.0178, -0.0442],\n",
      "         [-0.0669, -0.0684, -0.0442],\n",
      "         [ 0.0038, -0.0671,  0.0036],\n",
      "         [-0.0535,  0.0003, -0.0328],\n",
      "         [-0.0015, -0.0517,  0.0098],\n",
      "         [ 0.0028,  0.0628, -0.0665],\n",
      "         [ 0.0519, -0.0509, -0.0645],\n",
      "         [ 0.0319,  0.0176, -0.0123],\n",
      "         [ 0.0273,  0.0370,  0.0535],\n",
      "         [-0.0262,  0.0486, -0.0192],\n",
      "         [ 0.0531, -0.0042,  0.0490],\n",
      "         [ 0.0256, -0.0080,  0.0706],\n",
      "         [ 0.0185,  0.0566, -0.0474],\n",
      "         [-0.0663, -0.0052,  0.0593],\n",
      "         [ 0.0397,  0.0270, -0.0612],\n",
      "         [ 0.0294, -0.0351, -0.0088],\n",
      "         [-0.0665,  0.0018,  0.0028],\n",
      "         [ 0.0122, -0.0248,  0.0540],\n",
      "         [-0.0157, -0.0382,  0.0153],\n",
      "         [-0.0191,  0.0137, -0.0573],\n",
      "         [-0.0198, -0.0280,  0.0173],\n",
      "         [ 0.0004, -0.0112,  0.0511],\n",
      "         [-0.0202,  0.0657, -0.0274],\n",
      "         [ 0.0367,  0.0382,  0.0391],\n",
      "         [ 0.0316, -0.0098, -0.0149],\n",
      "         [-0.0379,  0.0481, -0.0706],\n",
      "         [-0.0281, -0.0530,  0.0639],\n",
      "         [ 0.0141,  0.0041,  0.0494],\n",
      "         [ 0.0083,  0.0036,  0.0392],\n",
      "         [-0.0091, -0.0110,  0.0029],\n",
      "         [ 0.0721, -0.0112, -0.0714],\n",
      "         [ 0.0557,  0.0054,  0.0249],\n",
      "         [ 0.0122, -0.0439,  0.0600],\n",
      "         [-0.0524,  0.0384, -0.0651],\n",
      "         [ 0.0189, -0.0300, -0.0356],\n",
      "         [-0.0354, -0.0206, -0.0666],\n",
      "         [ 0.0013,  0.0398,  0.0175],\n",
      "         [ 0.0312, -0.0530,  0.0249],\n",
      "         [ 0.0517, -0.0424, -0.0096],\n",
      "         [ 0.0358, -0.0403, -0.0488],\n",
      "         [ 0.0606, -0.0457, -0.0339],\n",
      "         [-0.0017,  0.0163,  0.0314],\n",
      "         [-0.0621, -0.0388, -0.0679],\n",
      "         [ 0.0273, -0.0383, -0.0539],\n",
      "         [-0.0237,  0.0097,  0.0111],\n",
      "         [-0.0563,  0.0561, -0.0713],\n",
      "         [ 0.0202, -0.0097, -0.0536],\n",
      "         [ 0.0225,  0.0530,  0.0314],\n",
      "         [ 0.0404,  0.0123,  0.0486],\n",
      "         [ 0.0569, -0.0563, -0.0465],\n",
      "         [ 0.0115,  0.0654,  0.0222],\n",
      "         [ 0.0197,  0.0259,  0.0668],\n",
      "         [ 0.0044, -0.0574, -0.0093],\n",
      "         [-0.0515, -0.0113, -0.0695],\n",
      "         [-0.0181, -0.0018, -0.0439],\n",
      "         [-0.0162, -0.0658, -0.0009],\n",
      "         [-0.0609,  0.0704,  0.0349]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv3.0.bias | Size: torch.Size([64]) | Values : tensor([-0.0139, -0.0465], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv3.1.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv3.1.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm1.weight_ih_l0 | Size: torch.Size([256, 64]) | Values : tensor([[-0.0445, -0.0336, -0.1048,  0.0715,  0.0323, -0.1068, -0.0547, -0.0789,\n",
      "          0.0231, -0.0122, -0.0612,  0.0010,  0.0458,  0.0577,  0.1078, -0.0104,\n",
      "          0.0058, -0.0952, -0.0668,  0.0334,  0.0745,  0.1221,  0.1125,  0.1217,\n",
      "          0.0948, -0.0522,  0.1208, -0.0759, -0.1197,  0.0282,  0.0340,  0.0363,\n",
      "         -0.0123, -0.0336,  0.0384,  0.0398, -0.0610, -0.0285, -0.0059,  0.0594,\n",
      "         -0.0891,  0.0332, -0.0515,  0.0760, -0.0125,  0.1071, -0.0776, -0.0217,\n",
      "          0.0662,  0.1196,  0.0180, -0.0832,  0.0168,  0.0613, -0.0543, -0.0439,\n",
      "          0.0919, -0.0557, -0.0661,  0.0960,  0.0832, -0.0597,  0.1034,  0.0332],\n",
      "        [-0.0520,  0.0988,  0.1099,  0.0834,  0.0124, -0.1058, -0.0109, -0.0305,\n",
      "          0.0388,  0.0166, -0.1005, -0.1140, -0.0134, -0.0786,  0.0860,  0.1244,\n",
      "         -0.0334,  0.0124, -0.0210, -0.0454, -0.0383, -0.0950, -0.1036, -0.1151,\n",
      "          0.0272,  0.0297,  0.0490, -0.0778,  0.0649, -0.0767,  0.0539,  0.0505,\n",
      "         -0.0579,  0.0629,  0.0375,  0.0353, -0.0006,  0.0134,  0.0691, -0.0205,\n",
      "         -0.1191, -0.0416,  0.0306,  0.0255, -0.0460, -0.0254,  0.0028,  0.0938,\n",
      "          0.0961, -0.0868, -0.0479, -0.0778, -0.0995,  0.0242, -0.0358, -0.0534,\n",
      "          0.0145,  0.1046,  0.1220, -0.0038,  0.0046, -0.0274,  0.0649, -0.0346]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm1.weight_hh_l0 | Size: torch.Size([256, 64]) | Values : tensor([[ 6.9439e-02,  4.8719e-02,  5.6051e-02,  3.4260e-02,  7.4888e-02,\n",
      "          3.8947e-02, -5.8548e-02,  8.8698e-02, -7.9315e-02, -8.6584e-02,\n",
      "          7.5030e-02,  4.3161e-02, -7.7190e-02, -6.8659e-02, -6.6754e-02,\n",
      "          2.2125e-02,  6.5006e-02, -4.8080e-02,  5.5858e-02,  7.4328e-02,\n",
      "         -6.6336e-03, -8.1771e-02, -5.0226e-02,  9.0599e-02, -1.4253e-02,\n",
      "          9.0456e-02, -2.0369e-02,  7.8247e-02, -1.1169e-01,  1.0284e-01,\n",
      "         -8.1290e-02,  1.2413e-01, -3.4884e-02,  4.6736e-02, -3.1780e-02,\n",
      "          5.8415e-02,  7.0344e-02, -3.9701e-02, -2.8498e-02, -9.4537e-02,\n",
      "         -1.1212e-01,  4.5430e-02, -3.0114e-02,  1.2023e-01,  5.6104e-02,\n",
      "          8.6769e-02, -5.5729e-02, -3.7315e-02,  8.9774e-02, -1.0652e-01,\n",
      "         -1.1751e-01, -6.0898e-02, -9.8753e-02, -5.1727e-02, -9.0737e-02,\n",
      "         -1.2360e-01,  2.6649e-02,  8.6978e-02,  8.2260e-03,  8.0624e-02,\n",
      "         -1.6236e-02, -2.0448e-02,  1.1291e-01,  2.6997e-02],\n",
      "        [-6.5757e-02, -2.9065e-02, -7.5295e-02,  8.1129e-02, -2.0703e-02,\n",
      "          9.8309e-02, -6.8058e-02, -1.0968e-01,  1.1089e-01, -1.0580e-01,\n",
      "         -1.3129e-03,  4.5057e-02, -1.1259e-01,  6.6638e-05,  7.5075e-02,\n",
      "         -1.0771e-02,  2.9519e-02, -1.2429e-01,  8.5096e-02, -1.0494e-01,\n",
      "         -6.7909e-02, -2.2642e-02,  7.0074e-02,  3.3028e-02, -2.4595e-02,\n",
      "         -4.1796e-02, -1.8339e-03, -9.1478e-02, -2.0959e-02, -8.9497e-02,\n",
      "         -3.2947e-02,  7.6386e-02,  1.0579e-01,  4.6384e-02, -8.8469e-03,\n",
      "          3.2122e-02,  1.6323e-02, -4.9830e-02, -1.0361e-01, -7.2820e-02,\n",
      "          1.0673e-01, -7.7360e-02,  1.7715e-02, -1.1586e-01,  2.6286e-02,\n",
      "         -7.7053e-03,  9.2745e-02,  1.0282e-02, -1.0530e-01,  8.8862e-02,\n",
      "          6.5480e-03, -4.8549e-02, -9.1131e-03,  8.7562e-02, -1.0035e-01,\n",
      "          6.0370e-03,  9.4805e-02,  1.9265e-03, -9.3678e-02,  3.2483e-02,\n",
      "         -2.9446e-02, -6.9678e-02, -4.7204e-02,  1.8086e-02]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm1.bias_ih_l0 | Size: torch.Size([256]) | Values : tensor([-0.0727,  0.1158], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm1.bias_hh_l0 | Size: torch.Size([256]) | Values : tensor([-0.0807, -0.0864], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm2.weight_ih_l0 | Size: torch.Size([256, 64]) | Values : tensor([[-0.0995, -0.0439,  0.0529,  0.0325, -0.0639, -0.0913,  0.0100, -0.0673,\n",
      "         -0.1010, -0.1065,  0.1118, -0.0668, -0.0282,  0.1174,  0.0749, -0.0112,\n",
      "          0.1114, -0.1122,  0.0640,  0.0113, -0.0908,  0.0070, -0.1106, -0.0056,\n",
      "         -0.0937, -0.0741,  0.0108,  0.0139,  0.1150,  0.0740, -0.0179, -0.1105,\n",
      "          0.0107,  0.0657, -0.1148,  0.0774, -0.1128,  0.0662,  0.0657,  0.0250,\n",
      "         -0.0757,  0.0073, -0.0443, -0.0663, -0.1186, -0.0006,  0.0155, -0.0821,\n",
      "         -0.1248, -0.0225, -0.0103,  0.0789,  0.0576,  0.0552, -0.0351, -0.0121,\n",
      "          0.0759, -0.0401,  0.0952,  0.1169, -0.0615, -0.1216,  0.0931,  0.0683],\n",
      "        [ 0.0453,  0.0798, -0.0944, -0.0542, -0.0252,  0.1144,  0.1170,  0.1177,\n",
      "          0.0871, -0.0059, -0.0307,  0.0939,  0.0769, -0.0165,  0.0326, -0.0035,\n",
      "          0.0386, -0.0791, -0.0625, -0.0419,  0.0196,  0.1141,  0.0287,  0.1011,\n",
      "          0.1167,  0.0923,  0.1003,  0.0121,  0.0559, -0.0299,  0.0841, -0.0734,\n",
      "          0.0350, -0.0905, -0.0757, -0.0463,  0.0544, -0.0925,  0.1004,  0.0739,\n",
      "         -0.1099, -0.0220, -0.0874, -0.0979,  0.0128, -0.0581, -0.0944, -0.0242,\n",
      "          0.0211,  0.1188, -0.0389,  0.0668, -0.0245,  0.1122,  0.0224, -0.0109,\n",
      "         -0.1094, -0.0158,  0.0264,  0.0907,  0.0611, -0.0844, -0.0461, -0.1119]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm2.weight_hh_l0 | Size: torch.Size([256, 64]) | Values : tensor([[-0.0374, -0.0438, -0.0426,  0.0999,  0.0389,  0.1001, -0.0831,  0.0304,\n",
      "          0.0496,  0.0134,  0.0453, -0.0419,  0.0389,  0.0082, -0.0153, -0.0909,\n",
      "          0.0629, -0.0389,  0.0619, -0.0428, -0.0050,  0.0925, -0.0903,  0.0169,\n",
      "         -0.0903,  0.0723, -0.0927, -0.0223,  0.0922,  0.0417,  0.0099, -0.1205,\n",
      "         -0.0712,  0.1083, -0.0182,  0.0099, -0.0815, -0.1088,  0.0757, -0.1206,\n",
      "          0.0579, -0.0607, -0.1238, -0.0879,  0.1006, -0.0577, -0.0904,  0.0881,\n",
      "          0.0094,  0.0917,  0.0694,  0.1204,  0.0962,  0.0112, -0.0369, -0.0186,\n",
      "         -0.0487,  0.0016,  0.0365, -0.0370,  0.1132,  0.0737,  0.0309,  0.0119],\n",
      "        [ 0.1029, -0.0633, -0.1084,  0.0374,  0.1076,  0.0540,  0.0837,  0.0266,\n",
      "          0.0764, -0.0280,  0.1162, -0.0996, -0.1169,  0.0826,  0.0571,  0.0528,\n",
      "         -0.1042,  0.0303, -0.0504,  0.0553,  0.0198,  0.0749, -0.0180, -0.0038,\n",
      "          0.0539,  0.0626,  0.0381, -0.0372, -0.0352, -0.0633,  0.0981,  0.1039,\n",
      "          0.0445,  0.0147,  0.1238, -0.0548, -0.0126,  0.0633, -0.0342,  0.0347,\n",
      "          0.1099, -0.0941, -0.0822, -0.1239, -0.1001, -0.0866, -0.0543,  0.0238,\n",
      "         -0.0852,  0.1087,  0.0433,  0.0623,  0.0994,  0.0859,  0.1180, -0.0167,\n",
      "          0.1223, -0.0412,  0.0960,  0.0968,  0.0156, -0.0916,  0.1108, -0.0341]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm2.bias_ih_l0 | Size: torch.Size([256]) | Values : tensor([0.0804, 0.0241], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm2.bias_hh_l0 | Size: torch.Size([256]) | Values : tensor([0.0723, 0.0698], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc.weight | Size: torch.Size([2, 64]) | Values : tensor([[ 0.0150,  0.0940,  0.0180, -0.0902,  0.0018, -0.0760, -0.0778,  0.0437,\n",
      "         -0.0620,  0.0306, -0.0335,  0.0121,  0.0130,  0.0619,  0.0964, -0.0528,\n",
      "         -0.0820, -0.1094, -0.0733, -0.0316,  0.1063, -0.1088,  0.0065,  0.0024,\n",
      "          0.0470,  0.0221, -0.0002,  0.0618,  0.0379,  0.0516, -0.1188,  0.1089,\n",
      "          0.0345, -0.1195,  0.0820, -0.0348,  0.1229,  0.0468,  0.0150, -0.1131,\n",
      "          0.0046, -0.0932,  0.1011,  0.1139, -0.1038, -0.0008, -0.0990,  0.0956,\n",
      "          0.1009,  0.0467,  0.1107, -0.0108, -0.1099, -0.0932, -0.0124,  0.0077,\n",
      "          0.0754, -0.0942,  0.0464,  0.0221, -0.1132,  0.0878, -0.1013, -0.0564],\n",
      "        [-0.0992, -0.0602,  0.1150,  0.1120, -0.0566,  0.0066,  0.0039, -0.1099,\n",
      "         -0.1058, -0.1199, -0.0872, -0.0263, -0.0133, -0.0080, -0.0354,  0.0114,\n",
      "          0.0364,  0.0183,  0.0368,  0.0646, -0.0363, -0.1032, -0.0373, -0.0206,\n",
      "         -0.0580,  0.0327, -0.0708, -0.0605,  0.0903,  0.0838,  0.0448, -0.1120,\n",
      "         -0.0820,  0.1138, -0.0941,  0.0660, -0.0788, -0.0775, -0.0292,  0.0721,\n",
      "          0.0590, -0.0140, -0.1124, -0.1159, -0.0929, -0.0189,  0.0165,  0.0276,\n",
      "         -0.0114, -0.0405, -0.0275, -0.1109,  0.1101,  0.0406, -0.0840, -0.0876,\n",
      "          0.0223,  0.0557,  0.0545, -0.0997, -0.0083, -0.1041, -0.1009,  0.0440]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc.bias | Size: torch.Size([2]) | Values : tensor([0.0826, 0.0068], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create an instance of the model\n",
    "model_ConvLSTM = ConvLSTM()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_ConvLSTM.parameters(), lr=learning_rate)\n",
    "# Initialize the scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=patience, verbose=True)\n",
    "print(f\"Model structure: {model_ConvLSTM}\\n\\n\")\n",
    "for name, param in model_ConvLSTM.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "loss: 0.592867  [   64/23290]\n",
      "loss: 0.086140  [ 6464/23290]\n",
      "loss: 0.289499  [12864/23290]\n",
      "loss: 0.091736  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.071727 \n",
      "\n",
      "Epoch 1:\n",
      "loss: 0.046841  [   64/23290]\n",
      "loss: 0.083007  [ 6464/23290]\n",
      "loss: 0.311324  [12864/23290]\n",
      "loss: 0.348079  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.2%, Avg loss: 0.067952 \n",
      "\n",
      "Epoch 2:\n",
      "loss: 0.234132  [   64/23290]\n",
      "loss: 0.026267  [ 6464/23290]\n",
      "loss: 0.068958  [12864/23290]\n",
      "loss: 0.199290  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.061039 \n",
      "\n",
      "Epoch 3:\n",
      "loss: 0.248649  [   64/23290]\n",
      "loss: 0.047592  [ 6464/23290]\n",
      "loss: 0.074691  [12864/23290]\n",
      "loss: 0.034837  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.062057 \n",
      "\n",
      "Epoch 4:\n",
      "loss: 0.230389  [   64/23290]\n",
      "loss: 0.181171  [ 6464/23290]\n",
      "loss: 0.039082  [12864/23290]\n",
      "loss: 0.031964  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.057835 \n",
      "\n",
      "Epoch 5:\n",
      "loss: 0.148043  [   64/23290]\n",
      "loss: 0.164073  [ 6464/23290]\n",
      "loss: 0.106799  [12864/23290]\n",
      "loss: 0.326409  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.044546 \n",
      "\n",
      "Epoch 6:\n",
      "loss: 0.084193  [   64/23290]\n",
      "loss: 0.028175  [ 6464/23290]\n",
      "loss: 0.058619  [12864/23290]\n",
      "loss: 0.202696  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.053159 \n",
      "\n",
      "Epoch 7:\n",
      "loss: 0.126778  [   64/23290]\n",
      "loss: 0.049214  [ 6464/23290]\n",
      "loss: 0.009363  [12864/23290]\n",
      "loss: 0.014961  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.040960 \n",
      "\n",
      "Epoch 8:\n",
      "loss: 0.072638  [   64/23290]\n",
      "loss: 0.055030  [ 6464/23290]\n",
      "loss: 0.020771  [12864/23290]\n",
      "loss: 0.029869  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.056058 \n",
      "\n",
      "Epoch 9:\n",
      "loss: 0.023767  [   64/23290]\n",
      "loss: 0.105972  [ 6464/23290]\n",
      "loss: 0.016137  [12864/23290]\n",
      "loss: 0.095930  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.043361 \n",
      "\n",
      "Epoch 10:\n",
      "loss: 0.012132  [   64/23290]\n",
      "loss: 0.117472  [ 6464/23290]\n",
      "loss: 0.204374  [12864/23290]\n",
      "loss: 0.039070  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.032669 \n",
      "\n",
      "Epoch 11:\n",
      "loss: 0.037240  [   64/23290]\n",
      "loss: 0.177435  [ 6464/23290]\n",
      "loss: 0.250110  [12864/23290]\n",
      "loss: 0.053935  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.049856 \n",
      "\n",
      "Epoch 12:\n",
      "loss: 0.080514  [   64/23290]\n",
      "loss: 0.023413  [ 6464/23290]\n",
      "loss: 0.072437  [12864/23290]\n",
      "loss: 0.132663  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.036633 \n",
      "\n",
      "Epoch 13:\n",
      "loss: 0.136286  [   64/23290]\n",
      "loss: 0.119933  [ 6464/23290]\n",
      "loss: 0.023352  [12864/23290]\n",
      "loss: 0.039470  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.041889 \n",
      "\n",
      "Epoch 14:\n",
      "loss: 0.033977  [   64/23290]\n",
      "loss: 0.039155  [ 6464/23290]\n",
      "loss: 0.054386  [12864/23290]\n",
      "loss: 0.061718  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.057879 \n",
      "\n",
      "Epoch 15:\n",
      "loss: 0.162064  [   64/23290]\n",
      "loss: 0.027441  [ 6464/23290]\n",
      "loss: 0.058439  [12864/23290]\n",
      "loss: 0.014811  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.043594 \n",
      "\n",
      "Early stopping due to no improvement in validation loss.\n"
     ]
    }
   ],
   "source": [
    "train(train_dataloader, model_ConvLSTM, loss_fn, optimizer,val_dataloader, \n",
    "           patience=patience, scheduler=scheduler, epochs=epochs, device=device, B_size=B_size, A_size=A_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 90.3%, Avg loss: 0.322582 \n",
      "\n",
      " Label 0\n",
      "    accuracy\t0.903\n",
      " specificity\t0.806\n",
      " sensitivity\t1.000\n",
      " Label 1\n",
      "    accuracy\t0.903\n",
      " specificity\t1.000\n",
      " sensitivity\t0.806\n",
      "[[31  0]\n",
      " [ 6 25]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAGZCAYAAACnsGcEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAuUUlEQVR4nO3de1xVdb7/8fcGZUPKhlABGREvlZdMLTWHqNQ0iVFHUye1fg/Rym5qR6ljYxc168RUk5ca1GnOeBkny5xTdh0zyctMUqkdRpvKlLQoBZWToJRo7O/vD2PHFlT22nvBdvt6Ph7rofu71+W7Ngs++/O9rOUwxhgBAOCjsIauAADg3EQAAQBYQgABAFhCAAEAWEIAAQBYQgABAFhCAAEAWEIAAQBYQgABAFhy3geQXbt2aeDAgYqJiZHD4dDq1asDuv+9e/fK4XBo6dKlAd3vuaxv377q27dvQPdZWFioyMhIvf/++wHdb7B6+umn1a5dO4WHh6t79+4+bXvq5x+s16g/v5sbNmyQw+HQhg0bPGXjxo1TmzZtPK9LSkrUpEkTvf3224Gr9HkmKAJIQUGB7rzzTrVr106RkZFyuVxKS0vT/Pnz9cMPP9h67MzMTO3YsUP/9V//peXLl6tnz562Hq8+jRs3Tg6HQy6Xq9bPcdeuXXI4HHI4HPr973/v8/737dunWbNmKT8/PwC19c/s2bPVu3dvpaWleZV/++23uummmxQbGyuXy6WhQ4fqyy+/bKBa1u7tt9/WrFmz6rz+2rVrNW3aNKWlpWnJkiV64okn7KtcHetz2223qUuXLgoPD/f6I+0Pu383mzVrpttvv12PPPJIQPd7XjEN7M033zRRUVEmNjbW3Hvvveb55583f/jDH8zo0aNN48aNzYQJE2w79vfff28kmYceesi2Y7jdbvPDDz+YH3/80bZjnE5mZqZp1KiRCQ8PNytXrqzx/syZM01kZKSRZJ5++mmf979lyxYjySxZssSn7SoqKkxFRYXPxzudAwcOmMaNG5sVK1Z4lR85csRcfPHFJj4+3jz55JNmzpw5Jjk52bRq1cocOnQoYMf318SJE40vv4oPPPCACQsLs/wZ9unTx/Tp08fzes+ePZZ+jlUyMzNNZGSkueqqq0yrVq1MSkqKpf1U5+/v5vr1640ks379eq96nlq3Tz/91Egyubm5ftT2/NWgGciePXs0evRopaSk6NNPP9X8+fM1YcIETZw4US+++KI+/fRTXXrppbYd/+DBg5Kk2NhY247hcDgUGRmp8PBw245xJk6nU/3799eLL75Y470VK1Zo0KBB9VaX77//XpIUERGhiIiIgO33r3/9qxo1aqQhQ4Z4lS9YsEC7du3Sm2++qWnTpmnq1Klau3at9u/fr2eeeSZgx69vBw4cUFRUVEA/Q3888cQTKisr0/vvv69u3boFZJ/18bspSZ06dVKXLl2CrvnunNGQ0euuu+4yksz7779fp/VPnDhhZs+ebdq1a2ciIiJMSkqKmT59ujl27JjXeikpKWbQoEHmH//4h+nVq5dxOp2mbdu2ZtmyZZ51Zs6caSR5LVXfTmr7plJ9m+rWrl1r0tLSTExMjGnSpIm55JJLzPTp0z3vn+7bXW5urrn66qvNBRdcYGJiYsyvf/1r8+mnn9Z6vF27dpnMzEwTExNjXC6XGTdunCkvLz/r55WZmWmaNGlili5dapxOp/nuu+8873300UdGkvmf//mfGhlISUmJue+++0yXLl1MkyZNTHR0tLnhhhtMfn6+Z52qb3inLlXn2adPH3PppZearVu3mmuuucZERUWZ//iP//C8V/0b8NixY43T6axx/gMHDjSxsbHm22+/PeN5XnvttaZv3741ynv16mV69epVo3zgwIGmffv2XmVfffWV+eyzz854nOrnvXLlSvP444+bX/ziF8bpdJrrrrvO7Nq1q8b6L7/8srniiitMZGSkadasmbnlllvMN99843k/MzOz1s/xdM70mS9evNj069fPtGjRwkRERJhOnTqZBQsW1NhHoDOQ6gYNGnTGDGT37t1m9+7dZ9zHmX439+7da+6++25zySWXmMjISBMXF2dGjhxp9uzZ47WPumYgxhgzdepUExsba9xudx3PElUaNAN544031K5dO1111VV1Wv/222/XjBkzdMUVV2ju3Lnq06ePsrOzNXr06Brr7t69WyNHjtT111+vZ555RhdeeKHGjRunf//735Kk4cOHa+7cuZKkMWPGaPny5Zo3b55P9f/3v/+twYMHq6KiQrNnz9YzzzyjX//612ftyF23bp3S09N14MABzZo1S1lZWdq8ebPS0tK0d+/eGuvfdNNNOnLkiLKzs3XTTTdp6dKlevTRR+tcz+HDh8vhcOiVV17xlK1YsUIdO3bUFVdcUWP9L7/8UqtXr9bgwYM1Z84c/ed//qd27NihPn36aN++fZJOfnObPXu2JOmOO+7Q8uXLtXz5cl177bWe/ZSUlCgjI0Pdu3fXvHnz1K9fv1rrN3/+fLVo0UKZmZmqrKyUJP3xj3/U2rVr9dxzzykpKem053bixAlt2bKlxnm43W5t37691nbzK6+8UgUFBTpy5IinbOzYserUqdNpj3Oq3/3ud3r11Vd1//33a/r06frggw90yy23eK2zdOlS3XTTTQoPD1d2drYmTJigV155RVdffbUOHz4sSbrzzjt1/fXXS5LnM1y+fPlpj7t8+XJdc801cjqdNT7zhQsXKiUlRQ8++KCeeeYZJScn65577lFOTk6dz8tu/fv3V//+/c+4zpl+N7ds2aLNmzdr9OjRevbZZ3XXXXcpNzdXffv29WS4vurRo4cOHz7s+dsAHzRU5CotLTWSzNChQ+u0fn5+vpFkbr/9dq/y+++/30gy7733nqcsJSXFSDKbNm3ylB04cMA4nU5z3333ecqqvnmd2v5f1wxk7ty5RpI5ePDgaetd27e77t27m/j4eFNSUuIp+9e//mXCwsLM2LFjaxzv1ltv9drnjTfeaJo1a3baY1Y/jyZNmhhjjBk5cqTp37+/McaYyspKk5iYaB599NFaP4Njx46ZysrKGufhdDrN7NmzPWVn6gPp06ePkWQWLVpU63vVvwEbY8w777xjJJnHH3/cfPnll6Zp06Zm2LBhZz3H3bt3G0nmueee8yo/ePCgkeRV3yo5OTlGkvn8889r1Pdsqr7ZdurUyasPYv78+UaS2bFjhzHGmOPHj5v4+HjTpUsX88MPP3jWe/PNN40kM2PGDE+Zr30g1X+u1X3//fc1ytLT0027du28yhoyA0lJSalTH8npfjdrO8e8vDwjyfzlL3/xlPmSgWzevNmTVcI3DZaBlJWVSZKio6PrtH7VULusrCyv8vvuu0+S9NZbb3mVd+7cWddcc43ndYsWLdShQ4eAjsCpap997bXX5Ha767TN/v37lZ+fr3HjxikuLs5T3rVrV11//fW1Dim86667vF5fc801Kikp8XyGdXHzzTdrw4YNKioq0nvvvaeioiLdfPPNta7rdDoVFnby0qisrFRJSYmaNm2qDh066OOPP67zMZ1Op8aPH1+ndQcOHKg777xTs2fP1vDhwxUZGak//vGPZ92upKREknThhRd6lVeNOnM6nTW2iYyM9FpHOjns0/jwbLXx48d79UFUXWtV19fWrVt14MAB3XPPPZ7jSdKgQYPUsWPHGtdrIERFRXn+X1paqkOHDqlPnz768ssvVVpaGvDjWbF3795as+y6qn6OJ06cUElJiS666CLFxsb6dG1WV3XtHDp0yHK9zlcNFkBcLpckeTUjnMlXX32lsLAwXXTRRV7liYmJio2N1VdffeVV3rp16xr7uPDCC/Xdd99ZrHFNo0aNUlpamm6//XYlJCRo9OjRevnll88YTKrq2aFDhxrvderUSYcOHVJ5eblX+annUnXB+3Iuv/rVrxQdHa2VK1fqhRdeUK9evWp8llXcbrfmzp2riy++WE6nU82bN1eLFi20fft2n/4Q/eIXv/Cpo/f3v/+94uLilJ+fr2effVbx8fF13vbUP/5Vf2gqKipqrHvs2DGvdaw428/kTD/njh071rheA+H999/XgAED1KRJE8XGxqpFixZ68MEHJSloAoi/fvjhB82YMUPJycle1+bhw4ctn2PVteNwOAJZVY9jx46prKzM76Xqug0mjRrqwC6XS0lJSfrkk0982q6uP+TTjXqqy7fM0x2jqn2+SlRUlDZt2qT169frrbfe0po1a7Ry5Updd911Wrt2bcBGXvlzLlWcTqeGDx+uZcuW6csvvzzjvIMnnnhCjzzyiG699VY99thjiouLU1hYmKZMmVLnTEvy/Q/0//7v/+rAgQOSpB07dmjMmDFn3aZZs2aSagbTuLg4OZ1O7d+/v8Y2VWVn6ls5m0D8TAKpoKBA/fv3V8eOHTVnzhwlJycrIiJCb7/9tubOnevTzy2YTZ48WUuWLNGUKVOUmprqmWQ4evRoy+dYde00b948kFWVdDJ4tE1pqqIDlWdf+SwSExO1Z88er4y2oTVYAJGkwYMH6/nnn1deXp5SU1PPuG5KSorcbrd27drl1dlZXFysw4cPKyUlJWD1uvDCCz2dnNXV9q0xLCzM0zE4Z84cPfHEE3rooYe0fv16DRgwoNbzkKSdO3fWeO/zzz9X8+bN1aRJE/9PohY333yzFi9erLCwsFoHHlT529/+pn79+unPf/6zV/nhw4e9fskC+Y2tvLxc48ePV+fOnXXVVVfpqaee0o033qhevXqdcbvWrVsrKipKe/bs8SoPCwvTZZddpq1bt9bY5sMPP1S7du3q3HxqRfWf83XXXef13s6dO72u10B8jm+88YYqKir0+uuve2VH69ev93vfweRvf/ubMjMzvYZhHzt2rNbf17qqunZ8GURRV8ePH1fRgUrt2ZYiV7T1Bp+yI2617fGVjh8/HlQBpEFHYU2bNk1NmjTR7bffruLi4hrvFxQUaP78+ZJONsFIqjFSas6cOZIU0PkM7du3V2lpqbZv3+4p279/v1599VWv9f7v//6vxrZVt5WorelEklq2bKnu3btr2bJlXhf9J598orVr13rO0w79+vXTY489pj/84Q9KTEw87Xrh4eE1vkmvWrVK3377rVdZVaDz55e3ygMPPKCvv/5ay5Yt05w5c9SmTRtlZmae9nOs0rhxY/Xs2bPWQDFy5Eht2bLF672dO3fqvffe029+8xuvdb/++mt9/vnnfp9HlZ49eyo+Pl6LFi3yOoe///3v+uyzz7yu10B8jlUZUfWfW2lpqZYsWWJ5n3YoKChQQUGB5e1ruzafe+65Gq0Dvti2bZtiYmJsnXPWpKn/SzBq0Aykffv2WrFihUaNGqVOnTpp7Nix6tKli44fP67Nmzdr1apVGjdunCSpW7duyszM1PPPP6/Dhw+rT58++uijj7Rs2TINGzbstENErRg9erQeeOAB3Xjjjbr33nv1/fffa+HChbrkkku8Oupmz56tTZs2adCgQUpJSdGBAwe0YMECtWrVSldfffVp9//0008rIyNDqampuu222/TDDz/oueeeU0xMjE+3tPBVWFiYHn744bOuN3jwYM2ePVvjx4/XVVddpR07duiFF15Qu3btvNZr3769YmNjtWjRIkVHR6tJkybq3bu32rZt61O93nvvPS1YsEAzZ870DMddsmSJ+vbtq0ceeURPPfXUGbcfOnSoHnroIZWVlXn61iTpnnvu0Z/+9CcNGjRI999/vxo3bqw5c+YoISHBM/iiytixY7Vx48aANUE1btxYTz75pMaPH68+ffpozJgxKi4u1vz589WmTRtNnTrVs26PHj0kSffee6/S09MVHh5+xgyxNgMHDlRERISGDBmiO++8U0ePHtWf/vQnxcfH19qMdzZ79+5V27ZtlZmZedZJdtu3b9frr78u6eTw+dLSUj3++OOSTv7eVp/gWTWE12pH+uDBg7V8+XLFxMSoc+fOysvL07p16zxNmVa8++67GjJkiG19ICGtoYZ/VffFF1+YCRMmmDZt2piIiAgTHR1t0tLSzHPPPec1SfDEiRPm0UcfNW3btjWNGzc2ycnJZ5xIeKrTDV+s7TYea9euNV26dDERERGmQ4cO5q9//WuNYby5ublm6NChJikpyURERJikpCQzZswY88UXX9Q4xqlDJNetW2fS0tJMVFSUcblcZsiQIaedSHjqMOElS5YYSTUmT53qdMM9qzvdMN777rvPtGzZ0kRFRZm0tDSTl5dX6/Db1157zXTu3Nk0atSo1omEtam+n7KyMpOSkmKuuOIKc+LECa/1pk6dasLCwkxeXt4Zz6G4uNg0atTILF++vMZ7hYWFZuTIkcblcpmmTZuawYMH1zrhz9dhvKtWrfIqP93PeeXKlebyyy83TqfTxMXF1ZhIaIwxP/74o5k8ebJp0aKFcTgcZ63H6X6ur7/+uunatauJjIw0bdq0MU8++aRZvHhxjWulLsN4d+zYYSSZ3/72t2f+QMzP12NtS2Zmpte6/g7j/e6778z48eNN8+bNTdOmTU16err5/PPPTUpKitex6jqM97PPPjOSzLp1685aJyuqpisU7Wxtvt/XxvJStLO1kWRKS0ttqadVDmMaqNcPCKDbbrtNX3zxhf7xj380dFVCwoIFCzRt2jQVFBQoISGhoatjmylTpmjTpk3atm2bLRlIWVmZYmJitG9nK7/7QJI6fKPS0lKvLLuhBcXdeAF/zZw5U1u2bDlvbudut/Xr1+vee+8N6eBRUlKi//7v/9bjjz9O85VFBBCEhNatW+vYsWM1bucOa1atWtXgt4m3W7NmzXT06FFbB65UqTTG78UXCxcuVNeuXeVyueRyuZSamqq///3vnvePHTumiRMnqlmzZmratKlGjBhR60CmsyGAAIDN3DJ+L75o1aqVfve732nbtm3aunWrrrvuOg0dOtRzv6+pU6fqjTfe0KpVq7Rx40bt27dPw4cP9/m86AMBAJtU9YF89XmS330gKR33+dUHEhcXp6efflojR45UixYttGLFCo0cOVLSyTlonTp1Ul5enn75y1/WeZ9kIABgM7eMKv1YfM1AqqusrNRLL72k8vJypaamatu2bTpx4oTXROeOHTuqdevWysvL82nfDToPBADOB1aaoU7dXlKNG6g6nc5abxgqnbwdUGpqqo4dO6amTZvq1VdfVefOnZWfn6+IiIgaD+tKSEhQUVGRT/UiAwGAc0RycrJiYmI8S3Z29mnX7dChg/Lz8/Xhhx/q7rvvVmZmpj799NOA1ocMBABsZmUk1anbS1JhYaFXH8jpsg/p5KOjq+643aNHD23ZskXz58/XqFGjdPz4cR0+fNgrCykuLj7jLY5qQwYShHJyctSmTRtFRkaqd+/e+uijjxq6SjiHbdq0SUOGDFFSUpIcDodWr17d0FU677gDsEjyDMutWs4UQGrUwe1WRUWFevToocaNGys3N9fz3s6dO/X111+f9aa2pyIDCTIrV65UVlaWFi1apN69e2vevHlKT0/Xzp07fXo+BlClvLxc3bp106233mppqCb8V9UZ7s/2vpg+fboyMjLUunVrHTlyRCtWrNCGDRv0zjvvKCYmRrfddpuysrIUFxcnl8ulyZMnKzU11acRWBIBJOjMmTNHEyZM8DzJb9GiRXrrrbe0ePFi/fa3v23g2uFclJGRoYyMjIauBurRgQMHNHbsWO3fv18xMTHq2rWr3nnnHV1//fWSpLlz5yosLEwjRoxQRUWF0tPTtWDBAp+PQwAJIsePH9e2bds0ffp0T1lYWJgGDBjg8/A6AMGj0pxc/NneF6c+y+dUkZGRysnJUU5OjvVKiT6QoHLo0CFVVlbWuP+QleF1AIJHoPpAgg0BBABgCU1YQaR58+YKDw+vcVMzK8PrAAQPtxyqlPU7/rr92NZOZCBBJCIiQj169PAaXud2u5Wbm+vz8DoAwcNt/F+CERlIkMnKylJmZqZ69uypK6+8UvPmzVN5eblnVBbgq6NHj2r37t2e13v27FF+fr7i4uLUunXrBqwZznUEkCAzatQoHTx4UDNmzFBRUZG6d++uNWvWhPSDfWCvrVu3ql+/fp7XWVlZklSn550jMCr9bMLyZ1s7cTt3ALBJ1e3cN/+7pZr6cTv3o0fcuurS/TzSFgAQGmjCAgCbuY1DbuPHKCw/trUTAQQAbBaqfSA0YQEALCEDAQCbVSpMlX58X68MYF0CiQACADYzfvaBGPpAAOD8RB8I6lVFRYVmzZqlioqKhq4KQgTXFAKNiYRBqmoCUrBNHMK5i2uq/lV95n/f3lZN/JhIWH7ErYyue4LuZ0cTFgDYzC2H3H40+Lj9eByunWjCAgBYUu8ZiNvt1r59+xQdHS2HIzg7hoJBWVmZ17+Av7im6sYYoyNHjigpKUlhYYH5jh2qnej1HkD27dun5OTk+j7sOYvPCoHGNVU3hYWFatWqVUD2VWnCVGn8mAcSpF3V9R5AoqOjJUlffdxGrqa0oCEwbrzksoauAkLEjzqhf+ptz98qnF69B5CqZitX0zC5/BiVAFTXyNG4oauAUPHTl/1ANrGf7EQPvUfaMgoLAGzm9vNWJozCAgCEFDIQALAZnegAAEvcCmMiIQAAVchAAMBmlcahSj9uye7PtnYigACAzfx/oFRwNmERQADAZm4TJrcfnejuIO1Epw8EAGAJGQgA2IwmLACAJW751xHuDlxVAoomLACAJWQgAGAz/ycSBud3fQIIANjM/1uZBGcACc5aAQCCHhkIANiM54EAACyhCQsAgGrIQADAZv5PJAzO7/oEEACwmds45PZnImGQ3o03OMMaACDokYEAgM3cfjZhMZEQAM5T/t/OnQACAOelSjlU6cdcDn+2tVNwhjUAQNAjAwEAm9GEBQCwpFL+NUNVBq4qARWcYQ0AYFl2drZ69eql6OhoxcfHa9iwYdq5c6fXOn379pXD4fBa7rrrLp+OQwABAJtVNWH5s/hi48aNmjhxoj744AO9++67OnHihAYOHKjy8nKv9SZMmKD9+/d7lqeeesqn49CEBQA2q++bKa5Zs8br9dKlSxUfH69t27bp2muv9ZRfcMEFSkxMtFwvMhAACHGlpaWSpLi4OK/yF154Qc2bN1eXLl00ffp0ff/99z7tlwwEAGxm/HweiPlp27KyMq9yp9Mpp9N5xm3dbremTJmitLQ0denSxVN+8803KyUlRUlJSdq+fbseeOAB7dy5U6+88kqd60UAAQCbBaoJKzk52at85syZmjVr1hm3nThxoj755BP985//9Cq/4447PP+/7LLL1LJlS/Xv318FBQVq3759nepFAAGAc0RhYaFcLpfn9dmyj0mTJunNN9/Upk2b1KpVqzOu27t3b0nS7t27CSAAECwCdTt3l8vlFUBOxxijyZMn69VXX9WGDRvUtm3bs26Tn58vSWrZsmWd60UAAQCb1fcDpSZOnKgVK1botddeU3R0tIqKiiRJMTExioqKUkFBgVasWKFf/epXatasmbZv366pU6fq2muvVdeuXet8HAIIAISYhQsXSjo5WbC6JUuWaNy4cYqIiNC6des0b948lZeXKzk5WSNGjNDDDz/s03EIIABgs/p+IqEx5ozvJycna+PGjZbrU4UAAgA2cyvMr4dC8UApADhPVRqHKv3IQPzZ1k7BGdYAAEGPDAQAbFbffSD1hQACADYzfj5QygTpA6WCs1YAgKBHBgIANquUw88nEtKEBQDnJbfxrx/DfeZpHQ2GJiwAgCVkIABgMyuPpT11+2BEAAEAm7n9fKCUP9vaKTjDGgAg6JGBAIDNQvVWJgQQALBZqPaBBGetAABBjwwEAGzmlp/3wgrSTnQCCADYzPg5CssQQADg/BSqd+OlDwQAYAkZCADYLFRHYRFAAMBmNGEBAFANGQgA2CxU74VFAAEAm9GEBQBANWQgAGCzUM1ACCAAYLNQDSA0YQEALCEDAQCbkYFUk5OTozZt2igyMlK9e/fWRx99FOh6AUDIMPp5KK+VxTT0CZyGzwFk5cqVysrK0syZM/Xxxx+rW7duSk9P14EDB+yoHwCc86oyEH+WYORzAJkzZ44mTJig8ePHq3Pnzlq0aJEuuOACLV682I76AQCClE99IMePH9e2bds0ffp0T1lYWJgGDBigvLy8WrepqKhQRUWF53VZWZnFqgLAuYk+EEmHDh1SZWWlEhISvMoTEhJUVFRU6zbZ2dmKiYnxLMnJydZrCwDnIJqwLJo+fbpKS0s9S2Fhod2HBADUA5+asJo3b67w8HAVFxd7lRcXFysxMbHWbZxOp5xOp/UaAsA5jiYsSREREerRo4dyc3M9ZW63W7m5uUpNTQ145QAgFBjj8HsJRj5PJMzKylJmZqZ69uypK6+8UvPmzVN5ebnGjx9vR/0AAEHK5wAyatQoHTx4UDNmzFBRUZG6d++uNWvW1OhYBwCcxPNAqpk0aZImTZoU6LoAQEiiDwQAgGq4mSIA2MzfjvCQ6UQHAPiGJiwAAKohAwEAm9GEBQCwxPjZhEUAAYDzlJFk/HgqVMg8UAoAAIkMBABs55ZDjhCciU4GAgA2q++bKWZnZ6tXr16Kjo5WfHy8hg0bpp07d3qtc+zYMU2cOFHNmjVT06ZNNWLEiBp3Wj8bAggAhJiNGzdq4sSJ+uCDD/Tuu+/qxIkTGjhwoMrLyz3rTJ06VW+88YZWrVqljRs3at++fRo+fLhPx6EJCwBs5jYOOepxIuGaNWu8Xi9dulTx8fHatm2brr32WpWWlurPf/6zVqxYoeuuu06StGTJEnXq1EkffPCBfvnLX9bpOGQgAGAzY/xf/FFaWipJiouLkyRt27ZNJ06c0IABAzzrdOzYUa1bt1ZeXl6d90sGAgDniLKyMq/XdXniq9vt1pQpU5SWlqYuXbpIkoqKihQREaHY2FivdRMSElRUVFTn+pCBAIDNAtWJnpycrJiYGM+SnZ191mNPnDhRn3zyiV566aWAnxcZCADYLFC3MiksLJTL5fKUny37mDRpkt58801t2rRJrVq18pQnJibq+PHjOnz4sFcWUlxcrMTExDrXiwwEAM4RLpfLazldADHGaNKkSXr11Vf13nvvqW3btl7v9+jRQ40bN1Zubq6nbOfOnfr666+Vmppa5/qQgQCAzep7FNbEiRO1YsUKvfbaa4qOjvb0a8TExCgqKkoxMTG67bbblJWVpbi4OLlcLk2ePFmpqal1HoElEUAAwHb+jqTydduFCxdKkvr27etVvmTJEo0bN06SNHfuXIWFhWnEiBGqqKhQenq6FixY4NNxCCAAEGJMHSJOZGSkcnJylJOTY/k4BBAAsNnJDMSfTvQAViaACCAAYDMeKAUAsMTIv2d6BGkCwjBeAIA1ZCAAYDOasAAA1oRoGxZNWAAAS8hAAMBufjZhiSYsADg/1fdM9PpCExYAwBIyEACwGaOwAADWGId//RhBGkBowgIAWEIGAgA2C9VOdAIIANiNiYQAAPyMDAQAbMYoLACAdUHaDOUPAggA2CxUMxD6QAAAlpCBAIDdQnQUFgEEAGzn+GnxZ/vgQxMWAMASMhAAsBtNWAAAS0I0gNCEBQCwhAwEAOwWordzJ4AAgM1C9W68NGEBACwhAwEAu4VoJzoBBADsFqJ9IDRhAQAsIQMBAJs5zMnFn+2DEQEEAOxGHwgAwBL6QAAA+BkZCADYjSYsAIAlIRpAaMICAFhCBgIAdgvRDIQAAgB2YxQWAAA/IwMBAJsxEx0AYE2I9oHQhAUAsIQAAgCwhCYsALCZQ372gQSsJoHVYAHk17f9PzVqFNlQh0eIueZfHzR0FRAiKo6e0IarGroW5wYyEACwG/NAAACWmAAsPtq0aZOGDBmipKQkORwOrV692uv9cePGyeFweC033HCDT8cggACA3RoggJSXl6tbt27Kyck57To33HCD9u/f71lefPFFn45BExYAhKCMjAxlZGSccR2n06nExETLxyADAQCbVc1E92exw4YNGxQfH68OHTro7rvvVklJiU/bk4EAgN0CNBO9rKzMq9jpdMrpdFra5Q033KDhw4erbdu2Kigo0IMPPqiMjAzl5eUpPDy8TvsggADAOSI5Odnr9cyZMzVr1ixL+xo9erTn/5dddpm6du2q9u3ba8OGDerfv3+d9kEAAQC7BSgDKSwslMvl8hRbzT5q065dOzVv3ly7d+8mgABAsAjU3XhdLpdXAAmkb775RiUlJWrZsmWdtyGAAEAIOnr0qHbv3u15vWfPHuXn5ysuLk5xcXF69NFHNWLECCUmJqqgoEDTpk3TRRddpPT09DofgwACAHZrgJnoW7duVb9+/Tyvs7KyJEmZmZlauHChtm/frmXLlunw4cNKSkrSwIED9dhjj/nULEYAAQC7NcDzQPr27StjTr/hO++840eFTmIeCADAEjIQALAZj7QFAFgToo+0JYAAgN38vR1JkAYQ+kAAAJaQgQCA3WjCAgBYEqIBhCYsAIAlZCAAYLNQHcZLBgIAsIQAAgCwhCYsALBbiHaiE0AAwGb0gQAAUA0ZCADUhyDNIvxBAAEAu4VoHwhNWAAAS8hAAMBmodqJTgABALuFaBMWAQQAbBaqGQh9IAAAS8hAAMBuNGEBACwJ0QBCExYAwBIyEACwWah2ohNAAMBuNGEBAPAzMhAAsFuIZiAEEACwWaj2gdCEBQCwhAwEAOxGExYAwAqasAAAqIYMBADsRhMWAMASAggAwArHT4s/2wcj+kAAAJaQgQCA3WjCAgBYwTBeAACqIQMBALvRhAUAsCxIg4A/aMICAFhCBgIANgvVTnQCCADYLUT7QGjCAgBYQgYCADajCQsAYA1NWAAA/IwAAgA2q2rC8mfx1aZNmzRkyBAlJSXJ4XBo9erVXu8bYzRjxgy1bNlSUVFRGjBggHbt2uXTMQggAGA3E4DFR+Xl5erWrZtycnJqff+pp57Ss88+q0WLFunDDz9UkyZNlJ6ermPHjtX5GPSBAIDdGqAPJCMjQxkZGbXvzhjNmzdPDz/8sIYOHSpJ+stf/qKEhAStXr1ao0ePrtMxyEAA4DyzZ88eFRUVacCAAZ6ymJgY9e7dW3l5eXXeDxkIANgsUMN4y8rKvMqdTqecTqfP+ysqKpIkJSQkeJUnJCR43qsLMhAAsFuA+kCSk5MVExPjWbKzs+v3PE5BBgIA54jCwkK5XC7PayvZhyQlJiZKkoqLi9WyZUtPeXFxsbp3717n/ZCBAIDNHMb4vUiSy+XyWqwGkLZt2yoxMVG5ubmesrKyMn344YdKTU2t837IQADAbg0wCuvo0aPavXu35/WePXuUn5+vuLg4tW7dWlOmTNHjjz+uiy++WG3bttUjjzyipKQkDRs2rM7H8DkDOdvkFABAw9u6dasuv/xyXX755ZKkrKwsXX755ZoxY4Ykadq0aZo8ebLuuOMO9erVS0ePHtWaNWsUGRlZ52P4nIFUTU659dZbNXz4cF83B4DzTkPcTLFv374y5vQbOhwOzZ49W7Nnz7ZcL58DyJkmpwAAahGiN1O0vQ+koqJCFRUVntenjmMGAJybbB+FlZ2d7TVuOTk52e5DAkBQaYibKdYH2wPI9OnTVVpa6lkKCwvtPiQABJcGuJlifbC9CcvqVHsAQHBjHggA2IxH2v7kbJNTAACnYBTWSVu3blW/fv08r7OysiRJmZmZWrp0acAqBgChJFizCH/4HEDONjkFAHB+oA8EAOxmzMnFn+2DEAEEAGwWqp3o3M4dAGAJGQgA2I1RWAAAKxzuk4s/2wcjmrAAAJaQgQCA3WjCAgBYwSgsAACqIQMBALsxkRAAYAVNWAAAVEMGAgB2YxQWAMCKUG3CIoAAgN1CtBOdPhAAgCVkIABgM5qwAADWhGgnOk1YAABLyEAAwGY0YQEArHGbk4s/2wchmrAAAJaQgQCA3UK0E50AAgA2c8jPPpCA1SSwaMICAFhCBgIAdgvRW5kQQADAZgzjBQBYE6Kd6PSBAAAsIQMBAJs5jJHDj34Mf7a1EwEEAOzm/mnxZ/sgRBMWAMASMhAAsBlNWAAAaxiFBQDAz8hAAMBuzEQHAFgRqjPRacICAFhCBgIAdqMJCwBghcN9cvFn+2BEExYAhJhZs2bJ4XB4LR07dgz4cchAAMBuDdCEdemll2rdunWe140aBf7PPQEEAOzWABMJGzVqpMTERD8OenY0YQGAzapuZeLP4qtdu3YpKSlJ7dq10y233KKvv/464OdFBgIA54iysjKv106nU06ns8Z6vXv31tKlS9WhQwft379fjz76qK655hp98sknio6ODlh9yEAAwG5VfSD+LJKSk5MVExPjWbKzs2s9XEZGhn7zm9+oa9euSk9P19tvv63Dhw/r5ZdfDuhpkYEAgN2M/Humx08tWIWFhXK5XJ7i2rKP2sTGxuqSSy7R7t27/ahETWQgAHCOcLlcXktdA8jRo0dVUFCgli1bBrQ+BBAAsFl9d6Lff//92rhxo/bu3avNmzfrxhtvVHh4uMaMGRPQ86IJCwDsZuTnPBDfVv/mm280ZswYlZSUqEWLFrr66qv1wQcfqEWLFtbrUAsCCACEmJdeeqlejkMAAQC7cTNFAIAlbkkOP7cPQnSiAwAsIQMBAJtZvR1J9e2DEQEEAOwWon0gNGEBACwhAwEAu4VoBkIAAQC7EUAAAJYwjBcAgJ+RgQCAzRjGCwCwJkT7QGjCAgBYQgYCAHZzG8nhRxbhDs4MhAACAHYL0Saseg8g5qcP4scfK+r70AhhFUdPNHQVECIqyk9eSyZI/2gHk3oPIEeOHJEk5eU9Wd+HRgj7x1UNXQOEmiNHjigmJiZAe/MzA/H1kYT1pN4DSFJSkgoLCxUdHS2Hw5+ZNaGtrKxMycnJKiwslMvlaujqIARwTdWNMUZHjhxRUlJSIHdKE1YghIWFqVWrVvV92HOWy+Xilx0BxTV1doHLPEIbnegAYDe3kV/NUIzCAoDzlHGfXPzZPggxkTBIOZ1OzZw5U06ns6GrghDBNYVAcxjGqgGALcrKyhQTE6MByXerUZj1wP2ju0LrCheqtLQ0qPqvaMICALvRBwIAsCREh/HSBwIAsIQMBADsZuRnBhKwmgQUAQQA7EYTFgAAPyMDAQC7ud2S/JgM6A7OiYQEEACwG01YAAD8jAwEAOwWohkIAQQA7BaiM9FpwgIAWEIGAgA2M8Yt48ct2f3Z1k4EEACwmzH+NUMFaR8ITVgAAEvIQADAbsbPTvQgzUAIIABgN7dbcoTeI20JIABgtxDNQOgDAQBYQgYCADYzbreMH01YDOMFgPMVTVgAAPyMDAQA7OY2kiP0MhACCADYzRj59UCpIA0gNGEBACwhAwEAmxm3kfGjCcuQgQDAecq4/V8syMnJUZs2bRQZGanevXvro48+CuhpEUAAIAStXLlSWVlZmjlzpj7++GN169ZN6enpOnDgQMCOQQABAJsZt/F78dWcOXM0YcIEjR8/Xp07d9aiRYt0wQUXaPHixQE7LwIIANitnpuwjh8/rm3btmnAgAGesrCwMA0YMEB5eXkBOy060QHAZj/qhF8T0X/UCUlSWVmZV7nT6ZTT6ayx/qFDh1RZWamEhASv8oSEBH3++efWK3IKAggA2CQiIkKJiYn6Z9Hbfu+radOmSk5O9iqbOXOmZs2a5fe+rSKAAIBNIiMjtWfPHh0/ftzvfRlj5HA4vMpqyz4kqXnz5goPD1dxcbFXeXFxsRITE/2uSxUCCADYKDIyUpGRkfV6zIiICPXo0UO5ubkaNmyYJMntdis3N1eTJk0K2HEIIAAQgrKyspSZmamePXvqyiuv1Lx581ReXq7x48cH7BgEEAAIQaNGjdLBgwc1Y8YMFRUVqXv37lqzZk2NjnV/OEywzpEHAAQ15oEAACwhgAAALCGAAAAsIYAAACwhgAAALCGAAAAsIYAAACwhgAAALCGAAAAsIYAAACwhgAAALCGAAAAs+f+ZORgySSHs2wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# final test\n",
    "test(test_dataloader, model_ConvLSTM, loss_fn, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=16, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding='same')\n",
    "        self.bn2 = nn.BatchNorm1d(16)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=64, kernel_size=1)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.convr = nn.Conv1d(in_channels=in_channels, out_channels=64, kernel_size=1)\n",
    "    def forward(self, input):\n",
    "        residual = self.convr(input)\n",
    "        x = self.conv1(input)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x += residual\n",
    "        x = self.relu3(x)\n",
    "        return x\n",
    "\n",
    "class IdentityBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(IdentityBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=16, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding='same')\n",
    "        self.bn2 = nn.BatchNorm1d(16)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=64, kernel_size=1)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "    def forward(self, input):\n",
    "        \n",
    "        residual = input\n",
    "        x = self.conv1(input)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x += residual\n",
    "        x = self.relu3(x)\n",
    "        return x\n",
    "\n",
    "class ResNet24(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet24, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=9, out_channels=64, kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.convblk1 = ConvBlock(64)\n",
    "        self.convblk2 = ConvBlock(64)\n",
    "        self.identityblk1 = IdentityBlock(64)\n",
    "        self.convblk3 = ConvBlock(64)\n",
    "        self.identityblk2 = IdentityBlock(64)\n",
    "        self.convblk4 = ConvBlock(64)\n",
    "        self.identityblk3 = IdentityBlock(64)\n",
    "        \n",
    "        self.pool2 = nn.AvgPool1d(2)\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.Flatten(),\n",
    "                                nn.Linear(in_features=704, out_features=2),\n",
    "        #                        nn.Softmax()\n",
    "                                )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.convblk1(x)\n",
    "        x = self.convblk2(x)\n",
    "        x = self.identityblk1(x)\n",
    "        x = self.convblk3(x)\n",
    "        x = self.identityblk2(x)\n",
    "        x = self.convblk4(x)\n",
    "        x = self.identityblk3(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: ResNet24(\n",
      "  (conv1): Conv1d(9, 64, kernel_size=(3,), stride=(1,))\n",
      "  (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (convblk1): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (convblk2): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (identityblk1): IdentityBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "  )\n",
      "  (convblk3): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (identityblk2): IdentityBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "  )\n",
      "  (convblk4): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (identityblk3): IdentityBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "  )\n",
      "  (pool2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
      "  (fc): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=704, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer: conv1.weight | Size: torch.Size([64, 9, 3]) | Values : tensor([[[ 0.1042,  0.0215,  0.0486],\n",
      "         [-0.0358, -0.0476, -0.1100],\n",
      "         [-0.0034, -0.1593, -0.0417],\n",
      "         [ 0.0897,  0.0999,  0.0823],\n",
      "         [ 0.1378,  0.0639, -0.1167],\n",
      "         [-0.0194, -0.0467,  0.0065],\n",
      "         [ 0.1458, -0.0433,  0.0488],\n",
      "         [-0.0779,  0.0611,  0.0298],\n",
      "         [-0.0448, -0.0149, -0.1731]],\n",
      "\n",
      "        [[-0.0005,  0.1503, -0.1748],\n",
      "         [-0.0575, -0.1720, -0.1133],\n",
      "         [ 0.0963, -0.0410,  0.0604],\n",
      "         [ 0.1252,  0.0898, -0.0269],\n",
      "         [ 0.0126, -0.0777,  0.1645],\n",
      "         [ 0.1070,  0.1214,  0.0616],\n",
      "         [ 0.0099,  0.0622,  0.0762],\n",
      "         [ 0.1346, -0.1586, -0.0663],\n",
      "         [-0.1760,  0.0251, -0.1517]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.bias | Size: torch.Size([64]) | Values : tensor([-0.1660,  0.0325], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.weight | Size: torch.Size([64, 64, 3]) | Values : tensor([[[ 6.0490e-02, -3.8438e-03,  2.6881e-02],\n",
      "         [ 5.9798e-02,  2.0935e-02,  7.9875e-04],\n",
      "         [-4.0477e-02, -3.8661e-02, -1.7598e-02],\n",
      "         [-1.2431e-02,  3.2082e-02, -2.9378e-02],\n",
      "         [-5.0653e-02,  1.4824e-02, -2.5334e-02],\n",
      "         [ 5.5837e-02, -2.9814e-02,  3.8861e-02],\n",
      "         [-3.0741e-02,  6.6004e-02,  1.8466e-02],\n",
      "         [-3.5737e-03, -1.3477e-02, -6.5250e-04],\n",
      "         [ 6.5717e-02,  6.3720e-02, -8.3808e-03],\n",
      "         [-6.9893e-02,  2.4165e-02,  6.2597e-02],\n",
      "         [ 3.3300e-02, -3.1465e-02, -5.3450e-02],\n",
      "         [-4.1005e-02,  6.5149e-02, -3.5430e-02],\n",
      "         [-4.5582e-02, -8.7189e-04,  2.0949e-02],\n",
      "         [-3.2657e-02,  6.8457e-02, -3.4855e-02],\n",
      "         [ 5.1337e-02,  2.1322e-02,  3.9636e-02],\n",
      "         [ 5.1538e-02,  2.2478e-02,  9.0560e-03],\n",
      "         [ 5.6039e-03,  5.4476e-02, -5.0589e-02],\n",
      "         [-7.5412e-03,  3.2551e-02,  1.5892e-02],\n",
      "         [ 1.0386e-02,  2.2525e-02, -5.3665e-03],\n",
      "         [-3.0137e-02,  5.4504e-02,  5.7974e-02],\n",
      "         [-3.0674e-02, -2.4976e-02,  2.7416e-02],\n",
      "         [-1.9181e-02,  4.0384e-02, -7.5624e-03],\n",
      "         [ 2.1244e-02, -3.2760e-02, -1.0299e-02],\n",
      "         [-3.7092e-02, -3.6533e-02,  5.1856e-03],\n",
      "         [ 4.4207e-02, -4.6146e-02, -1.2730e-02],\n",
      "         [-5.9194e-02, -5.2787e-02,  2.9768e-02],\n",
      "         [ 3.3181e-02, -1.7313e-02,  4.8427e-02],\n",
      "         [ 2.4411e-02, -5.0665e-02, -2.1183e-02],\n",
      "         [ 3.5527e-02,  5.3073e-02, -6.1099e-02],\n",
      "         [ 4.0609e-02,  3.5034e-03,  3.1959e-02],\n",
      "         [-6.2991e-02,  6.0041e-02, -1.1347e-02],\n",
      "         [-3.7728e-02, -4.9732e-02,  2.7353e-02],\n",
      "         [ 6.8533e-02, -6.2630e-02,  5.5494e-03],\n",
      "         [ 3.1421e-02, -2.8780e-02, -4.4472e-03],\n",
      "         [ 1.3123e-02,  1.5230e-02,  1.5739e-02],\n",
      "         [-5.5285e-02,  5.1258e-02, -4.0802e-02],\n",
      "         [-5.1468e-02, -5.7462e-02, -2.8048e-02],\n",
      "         [ 5.0539e-02, -3.3498e-02,  7.1192e-02],\n",
      "         [ 2.8279e-02,  6.3494e-02, -5.1035e-02],\n",
      "         [-6.6264e-02,  3.7218e-03, -7.6208e-03],\n",
      "         [-8.6945e-03,  3.5439e-03, -5.2268e-02],\n",
      "         [ 6.5028e-02,  1.2961e-02,  2.4397e-02],\n",
      "         [-4.3106e-02, -2.9914e-02, -6.3877e-02],\n",
      "         [-4.9962e-02,  4.2712e-02, -9.3846e-03],\n",
      "         [ 6.7468e-02,  1.1914e-02, -2.7144e-02],\n",
      "         [ 1.7348e-02, -2.9413e-02,  3.0404e-02],\n",
      "         [ 5.0752e-03,  6.1064e-02, -1.6102e-02],\n",
      "         [-5.1222e-02, -2.1562e-02, -2.3644e-02],\n",
      "         [ 3.8399e-02,  2.5882e-02, -2.5777e-02],\n",
      "         [ 1.0024e-02, -5.1137e-03,  1.3720e-02],\n",
      "         [-3.7155e-02,  2.2660e-03,  3.0877e-02],\n",
      "         [-2.5656e-02,  3.7083e-02, -7.0411e-02],\n",
      "         [ 4.6097e-03, -4.8246e-03, -2.0032e-02],\n",
      "         [ 5.0949e-02,  4.9677e-02, -1.1752e-02],\n",
      "         [ 6.7763e-02, -1.0172e-02, -5.5108e-02],\n",
      "         [ 3.3289e-03,  5.3648e-02,  6.2356e-02],\n",
      "         [ 5.1271e-02, -9.6454e-03,  6.1712e-02],\n",
      "         [-5.3872e-02, -6.5247e-02, -4.9081e-02],\n",
      "         [ 1.8505e-02,  5.6606e-02,  1.8472e-02],\n",
      "         [-2.1773e-02,  2.8482e-02,  6.7896e-02],\n",
      "         [-4.9836e-02, -3.4704e-02,  1.2776e-02],\n",
      "         [-4.2076e-02, -4.8570e-02,  6.8301e-03],\n",
      "         [-6.5076e-02,  3.2287e-03, -4.5512e-02],\n",
      "         [ 1.1464e-02,  4.0728e-02, -5.6451e-02]],\n",
      "\n",
      "        [[ 1.9552e-02, -7.1662e-02, -7.0718e-02],\n",
      "         [ 6.7173e-02, -5.1516e-02, -3.5091e-02],\n",
      "         [ 5.3379e-02, -6.3642e-02,  2.1486e-02],\n",
      "         [ 6.6393e-02,  7.8383e-03,  2.4129e-02],\n",
      "         [-6.3278e-02, -6.7299e-02,  4.4579e-02],\n",
      "         [-3.0502e-03,  9.7172e-03,  5.4467e-02],\n",
      "         [-2.6422e-02, -7.7827e-03,  6.2230e-02],\n",
      "         [-5.9526e-02, -1.1492e-02, -4.2755e-02],\n",
      "         [ 6.9576e-02, -4.2462e-02,  5.5971e-02],\n",
      "         [ 3.5735e-02, -1.8382e-02,  6.2363e-02],\n",
      "         [ 4.8574e-02, -5.6538e-02,  3.1920e-02],\n",
      "         [-6.1009e-02, -7.1820e-02,  4.6716e-02],\n",
      "         [ 6.7641e-03,  5.9899e-02,  2.9124e-02],\n",
      "         [ 5.9672e-02, -5.6837e-02,  1.3496e-02],\n",
      "         [ 1.8541e-03, -4.9336e-02,  6.6529e-02],\n",
      "         [-2.1867e-02, -6.0105e-02, -6.7394e-02],\n",
      "         [ 1.9406e-02,  6.0538e-02, -1.6151e-02],\n",
      "         [ 5.2468e-02,  1.4424e-02, -3.2702e-02],\n",
      "         [ 6.7083e-02,  6.6339e-02, -9.2824e-03],\n",
      "         [ 4.9696e-02, -3.3850e-02, -2.9076e-02],\n",
      "         [ 4.9360e-02, -2.9449e-02,  3.9990e-02],\n",
      "         [-1.0277e-02, -2.6926e-02, -3.3629e-02],\n",
      "         [-2.5924e-02, -6.6459e-02, -4.8441e-02],\n",
      "         [-7.0167e-02, -2.0254e-02, -2.4279e-02],\n",
      "         [ 1.7998e-02,  2.9142e-02,  4.8882e-02],\n",
      "         [-2.6702e-02,  2.2864e-02, -2.4732e-02],\n",
      "         [-1.1617e-02,  4.1122e-02, -1.2292e-02],\n",
      "         [-5.1666e-03, -8.8383e-03, -7.0296e-02],\n",
      "         [-2.7825e-02, -1.3626e-03, -6.1323e-02],\n",
      "         [-4.9723e-02,  8.5533e-03,  3.7111e-02],\n",
      "         [ 7.1976e-02,  5.4236e-02,  6.7000e-02],\n",
      "         [ 9.0728e-03,  3.2037e-02, -5.6243e-02],\n",
      "         [-1.8150e-02,  5.4708e-02, -2.0509e-02],\n",
      "         [ 1.6146e-02, -6.8414e-02,  2.2270e-03],\n",
      "         [ 5.0494e-03, -4.3450e-02,  1.9177e-03],\n",
      "         [ 5.8083e-02, -6.2406e-02,  3.4365e-03],\n",
      "         [-1.7711e-02,  2.0030e-02,  5.3091e-02],\n",
      "         [ 6.6895e-02,  6.1362e-02, -1.2126e-03],\n",
      "         [ 4.0831e-02,  1.5706e-05,  6.9485e-02],\n",
      "         [-5.5655e-02,  5.6712e-02, -1.6833e-03],\n",
      "         [-2.9660e-02,  4.2850e-02, -6.3179e-02],\n",
      "         [ 5.8106e-02, -6.5849e-02, -3.3246e-02],\n",
      "         [-3.7462e-02, -7.5750e-03, -1.4039e-02],\n",
      "         [ 5.9389e-02, -4.5204e-02, -1.1356e-02],\n",
      "         [ 1.6173e-02, -5.9115e-02, -2.8671e-02],\n",
      "         [ 7.2006e-02, -5.9908e-02,  6.8605e-02],\n",
      "         [ 6.3738e-03,  3.9137e-02, -8.2232e-03],\n",
      "         [ 1.3618e-02,  7.2240e-03,  6.5632e-02],\n",
      "         [ 2.8146e-02, -2.2407e-02, -2.8457e-02],\n",
      "         [-1.7753e-02, -2.5112e-02, -5.8517e-02],\n",
      "         [ 5.2765e-02, -3.7788e-02,  3.9184e-02],\n",
      "         [-2.5108e-02,  4.0463e-02, -2.6403e-02],\n",
      "         [-9.7961e-03,  4.1096e-02,  8.1177e-03],\n",
      "         [ 3.7308e-02, -5.4774e-02, -5.3936e-02],\n",
      "         [-3.0526e-02, -5.9354e-03,  4.4043e-02],\n",
      "         [ 6.1549e-02, -4.9352e-03, -8.0279e-03],\n",
      "         [ 3.4138e-02,  4.3284e-02,  1.4416e-02],\n",
      "         [ 2.6462e-02,  3.0842e-02,  6.9638e-03],\n",
      "         [-5.1458e-02, -6.8306e-02,  2.8351e-02],\n",
      "         [-5.4509e-02, -3.4964e-03,  6.3045e-02],\n",
      "         [-6.7660e-02, -4.0779e-02, -2.5364e-02],\n",
      "         [ 8.9865e-03, -2.3108e-02,  2.5912e-03],\n",
      "         [-4.1883e-02, -6.0388e-02,  3.6832e-02],\n",
      "         [-5.6103e-02, -4.8749e-02, -6.7938e-02]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.bias | Size: torch.Size([64]) | Values : tensor([ 0.0224, -0.0020], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[-0.0072],\n",
      "         [ 0.0408],\n",
      "         [ 0.0458],\n",
      "         [-0.0511],\n",
      "         [ 0.1141],\n",
      "         [ 0.0916],\n",
      "         [ 0.0571],\n",
      "         [-0.0487],\n",
      "         [-0.0067],\n",
      "         [ 0.0515],\n",
      "         [-0.0158],\n",
      "         [-0.1061],\n",
      "         [ 0.0816],\n",
      "         [ 0.1108],\n",
      "         [-0.0571],\n",
      "         [-0.0537],\n",
      "         [-0.1216],\n",
      "         [ 0.0571],\n",
      "         [-0.1127],\n",
      "         [-0.0525],\n",
      "         [ 0.0148],\n",
      "         [ 0.1019],\n",
      "         [ 0.1004],\n",
      "         [ 0.0993],\n",
      "         [ 0.0845],\n",
      "         [ 0.0077],\n",
      "         [ 0.0872],\n",
      "         [ 0.0657],\n",
      "         [ 0.0765],\n",
      "         [ 0.0323],\n",
      "         [ 0.0180],\n",
      "         [ 0.0490],\n",
      "         [ 0.0852],\n",
      "         [-0.1068],\n",
      "         [ 0.0236],\n",
      "         [ 0.0166],\n",
      "         [ 0.1134],\n",
      "         [ 0.0224],\n",
      "         [ 0.0502],\n",
      "         [ 0.0708],\n",
      "         [-0.1149],\n",
      "         [ 0.0291],\n",
      "         [ 0.0256],\n",
      "         [ 0.1224],\n",
      "         [ 0.1109],\n",
      "         [ 0.0085],\n",
      "         [-0.0849],\n",
      "         [-0.0793],\n",
      "         [-0.1039],\n",
      "         [-0.0870],\n",
      "         [-0.0816],\n",
      "         [ 0.0384],\n",
      "         [-0.0538],\n",
      "         [ 0.0777],\n",
      "         [-0.0670],\n",
      "         [-0.0023],\n",
      "         [-0.0933],\n",
      "         [-0.0078],\n",
      "         [-0.0733],\n",
      "         [ 0.0820],\n",
      "         [-0.0030],\n",
      "         [ 0.1231],\n",
      "         [ 0.0517],\n",
      "         [ 0.0107]],\n",
      "\n",
      "        [[ 0.0125],\n",
      "         [ 0.0754],\n",
      "         [ 0.0807],\n",
      "         [ 0.0450],\n",
      "         [ 0.0617],\n",
      "         [ 0.0894],\n",
      "         [ 0.0243],\n",
      "         [-0.1164],\n",
      "         [-0.0938],\n",
      "         [ 0.0936],\n",
      "         [-0.0873],\n",
      "         [ 0.0502],\n",
      "         [-0.0981],\n",
      "         [-0.0977],\n",
      "         [ 0.0209],\n",
      "         [-0.1167],\n",
      "         [-0.0196],\n",
      "         [-0.0553],\n",
      "         [ 0.0311],\n",
      "         [ 0.0508],\n",
      "         [ 0.0992],\n",
      "         [ 0.0376],\n",
      "         [ 0.0526],\n",
      "         [-0.0038],\n",
      "         [-0.0825],\n",
      "         [ 0.0172],\n",
      "         [-0.0768],\n",
      "         [-0.0802],\n",
      "         [-0.0323],\n",
      "         [-0.0180],\n",
      "         [-0.1027],\n",
      "         [ 0.0034],\n",
      "         [ 0.0667],\n",
      "         [-0.0699],\n",
      "         [-0.0636],\n",
      "         [-0.0262],\n",
      "         [ 0.0693],\n",
      "         [-0.0586],\n",
      "         [-0.1085],\n",
      "         [-0.1062],\n",
      "         [-0.0614],\n",
      "         [ 0.0556],\n",
      "         [-0.0354],\n",
      "         [-0.0508],\n",
      "         [-0.0427],\n",
      "         [ 0.0448],\n",
      "         [ 0.0231],\n",
      "         [ 0.0384],\n",
      "         [-0.0042],\n",
      "         [-0.0975],\n",
      "         [ 0.1074],\n",
      "         [ 0.1036],\n",
      "         [-0.0133],\n",
      "         [-0.0516],\n",
      "         [ 0.0118],\n",
      "         [ 0.0611],\n",
      "         [-0.0751],\n",
      "         [-0.0449],\n",
      "         [ 0.0718],\n",
      "         [-0.0141],\n",
      "         [ 0.0945],\n",
      "         [ 0.1178],\n",
      "         [-0.0186],\n",
      "         [ 0.0788]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv1.bias | Size: torch.Size([16]) | Values : tensor([0.1234, 0.0741], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[-0.0985, -0.1040,  0.0384],\n",
      "         [-0.1331, -0.0860, -0.0330],\n",
      "         [ 0.0728, -0.0815, -0.0043],\n",
      "         [-0.0622, -0.1293, -0.0036],\n",
      "         [-0.1227,  0.0527, -0.0372],\n",
      "         [-0.0508,  0.1381, -0.0263],\n",
      "         [ 0.1131, -0.0273, -0.1068],\n",
      "         [ 0.1173, -0.0587, -0.0553],\n",
      "         [ 0.0402, -0.0779, -0.0607],\n",
      "         [-0.1361,  0.0277,  0.0667],\n",
      "         [ 0.1234, -0.1118, -0.1396],\n",
      "         [-0.0690, -0.0159,  0.0701],\n",
      "         [-0.0012,  0.0185, -0.0356],\n",
      "         [ 0.0471, -0.1004,  0.0197],\n",
      "         [-0.0647,  0.0459, -0.0463],\n",
      "         [-0.0134, -0.0726, -0.0075]],\n",
      "\n",
      "        [[-0.0927,  0.0138, -0.0630],\n",
      "         [ 0.0064,  0.0785,  0.0479],\n",
      "         [-0.0390, -0.1291,  0.0108],\n",
      "         [-0.0579,  0.0400,  0.0974],\n",
      "         [-0.1324, -0.0532,  0.1431],\n",
      "         [-0.0114, -0.0053,  0.1199],\n",
      "         [-0.0050, -0.1262, -0.0500],\n",
      "         [-0.1343,  0.0333, -0.0475],\n",
      "         [-0.0511, -0.1142,  0.1363],\n",
      "         [-0.0739,  0.1366,  0.0275],\n",
      "         [-0.0768,  0.0001,  0.0450],\n",
      "         [ 0.0118,  0.1152,  0.1345],\n",
      "         [-0.0140,  0.0802,  0.0762],\n",
      "         [-0.1035, -0.0177,  0.0285],\n",
      "         [-0.1424, -0.0810,  0.0788],\n",
      "         [ 0.0555, -0.0769, -0.0766]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv2.bias | Size: torch.Size([16]) | Values : tensor([0.0442, 0.0904], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[ 0.0554],\n",
      "         [ 0.1808],\n",
      "         [ 0.1958],\n",
      "         [-0.1486],\n",
      "         [-0.0705],\n",
      "         [ 0.0872],\n",
      "         [-0.0161],\n",
      "         [-0.1785],\n",
      "         [-0.1675],\n",
      "         [-0.0860],\n",
      "         [-0.2240],\n",
      "         [ 0.1179],\n",
      "         [ 0.0301],\n",
      "         [ 0.0628],\n",
      "         [-0.1698],\n",
      "         [-0.1065]],\n",
      "\n",
      "        [[ 0.1308],\n",
      "         [-0.1431],\n",
      "         [ 0.1543],\n",
      "         [-0.2238],\n",
      "         [-0.2490],\n",
      "         [ 0.0445],\n",
      "         [ 0.0693],\n",
      "         [ 0.1246],\n",
      "         [ 0.0244],\n",
      "         [-0.0595],\n",
      "         [-0.0346],\n",
      "         [-0.1616],\n",
      "         [ 0.0884],\n",
      "         [-0.0215],\n",
      "         [-0.1024],\n",
      "         [-0.0749]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv3.bias | Size: torch.Size([64]) | Values : tensor([-0.2306,  0.1384], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[ 0.0177],\n",
      "         [ 0.0008],\n",
      "         [ 0.0035],\n",
      "         [ 0.0527],\n",
      "         [-0.1125],\n",
      "         [ 0.0013],\n",
      "         [ 0.0459],\n",
      "         [ 0.0851],\n",
      "         [-0.0748],\n",
      "         [ 0.0838],\n",
      "         [-0.1081],\n",
      "         [-0.0504],\n",
      "         [ 0.0933],\n",
      "         [ 0.0361],\n",
      "         [-0.0572],\n",
      "         [ 0.0129],\n",
      "         [-0.0239],\n",
      "         [-0.1203],\n",
      "         [ 0.0428],\n",
      "         [ 0.0455],\n",
      "         [ 0.0988],\n",
      "         [-0.0405],\n",
      "         [ 0.0499],\n",
      "         [ 0.0628],\n",
      "         [ 0.1107],\n",
      "         [ 0.0236],\n",
      "         [-0.0968],\n",
      "         [ 0.0220],\n",
      "         [ 0.0912],\n",
      "         [-0.0080],\n",
      "         [-0.0768],\n",
      "         [ 0.0251],\n",
      "         [-0.0445],\n",
      "         [ 0.0775],\n",
      "         [-0.0143],\n",
      "         [ 0.0151],\n",
      "         [-0.0115],\n",
      "         [ 0.0921],\n",
      "         [-0.0371],\n",
      "         [ 0.0861],\n",
      "         [-0.0615],\n",
      "         [-0.0025],\n",
      "         [ 0.0104],\n",
      "         [ 0.0757],\n",
      "         [-0.1060],\n",
      "         [-0.0358],\n",
      "         [ 0.0997],\n",
      "         [-0.0927],\n",
      "         [ 0.0032],\n",
      "         [-0.0578],\n",
      "         [ 0.0681],\n",
      "         [ 0.1171],\n",
      "         [-0.1008],\n",
      "         [ 0.0948],\n",
      "         [-0.0131],\n",
      "         [ 0.0133],\n",
      "         [-0.0634],\n",
      "         [-0.0607],\n",
      "         [-0.0438],\n",
      "         [ 0.0277],\n",
      "         [-0.0454],\n",
      "         [ 0.0139],\n",
      "         [-0.0557],\n",
      "         [-0.1022]],\n",
      "\n",
      "        [[-0.0595],\n",
      "         [ 0.0153],\n",
      "         [ 0.0584],\n",
      "         [ 0.0315],\n",
      "         [-0.1127],\n",
      "         [ 0.1211],\n",
      "         [ 0.1195],\n",
      "         [ 0.1150],\n",
      "         [-0.0555],\n",
      "         [ 0.0607],\n",
      "         [-0.0828],\n",
      "         [-0.1231],\n",
      "         [-0.0960],\n",
      "         [ 0.0807],\n",
      "         [ 0.0662],\n",
      "         [-0.0987],\n",
      "         [-0.0460],\n",
      "         [ 0.0251],\n",
      "         [ 0.0110],\n",
      "         [-0.0913],\n",
      "         [ 0.0633],\n",
      "         [ 0.1106],\n",
      "         [-0.1112],\n",
      "         [ 0.0115],\n",
      "         [ 0.0807],\n",
      "         [-0.1083],\n",
      "         [ 0.0197],\n",
      "         [-0.0909],\n",
      "         [-0.0970],\n",
      "         [-0.0882],\n",
      "         [-0.0728],\n",
      "         [ 0.0522],\n",
      "         [ 0.0153],\n",
      "         [-0.0863],\n",
      "         [-0.0468],\n",
      "         [ 0.0167],\n",
      "         [ 0.0060],\n",
      "         [-0.0666],\n",
      "         [ 0.1248],\n",
      "         [-0.0332],\n",
      "         [-0.0960],\n",
      "         [ 0.0236],\n",
      "         [-0.0172],\n",
      "         [ 0.0387],\n",
      "         [-0.0120],\n",
      "         [ 0.0626],\n",
      "         [-0.0219],\n",
      "         [ 0.1038],\n",
      "         [-0.0234],\n",
      "         [ 0.1053],\n",
      "         [ 0.0525],\n",
      "         [ 0.0906],\n",
      "         [ 0.0806],\n",
      "         [-0.0582],\n",
      "         [-0.0410],\n",
      "         [ 0.1102],\n",
      "         [ 0.0036],\n",
      "         [-0.0883],\n",
      "         [-0.0211],\n",
      "         [-0.0493],\n",
      "         [ 0.1058],\n",
      "         [ 0.1063],\n",
      "         [ 0.0500],\n",
      "         [ 0.0069]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.convr.bias | Size: torch.Size([64]) | Values : tensor([ 0.1194, -0.0420], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[-0.0499],\n",
      "         [-0.0637],\n",
      "         [ 0.0956],\n",
      "         [ 0.0850],\n",
      "         [-0.1050],\n",
      "         [ 0.0133],\n",
      "         [-0.0958],\n",
      "         [ 0.0393],\n",
      "         [ 0.0534],\n",
      "         [-0.0356],\n",
      "         [-0.1102],\n",
      "         [-0.0703],\n",
      "         [ 0.0295],\n",
      "         [-0.0457],\n",
      "         [-0.1152],\n",
      "         [-0.0042],\n",
      "         [ 0.0478],\n",
      "         [-0.0515],\n",
      "         [-0.0827],\n",
      "         [ 0.0667],\n",
      "         [ 0.0289],\n",
      "         [-0.0037],\n",
      "         [ 0.1181],\n",
      "         [-0.0225],\n",
      "         [ 0.0577],\n",
      "         [ 0.0166],\n",
      "         [-0.0338],\n",
      "         [ 0.0446],\n",
      "         [ 0.1111],\n",
      "         [-0.0727],\n",
      "         [-0.0593],\n",
      "         [-0.0673],\n",
      "         [-0.0275],\n",
      "         [ 0.0795],\n",
      "         [-0.0997],\n",
      "         [-0.1004],\n",
      "         [ 0.0941],\n",
      "         [-0.0034],\n",
      "         [-0.0099],\n",
      "         [-0.0677],\n",
      "         [-0.0890],\n",
      "         [ 0.0003],\n",
      "         [-0.0105],\n",
      "         [ 0.0961],\n",
      "         [ 0.0951],\n",
      "         [ 0.0359],\n",
      "         [ 0.0717],\n",
      "         [ 0.0011],\n",
      "         [-0.0451],\n",
      "         [ 0.0315],\n",
      "         [ 0.0241],\n",
      "         [-0.0996],\n",
      "         [-0.0107],\n",
      "         [ 0.0602],\n",
      "         [ 0.0106],\n",
      "         [-0.1220],\n",
      "         [-0.0261],\n",
      "         [-0.1209],\n",
      "         [ 0.1175],\n",
      "         [ 0.0535],\n",
      "         [-0.1147],\n",
      "         [ 0.0517],\n",
      "         [ 0.0865],\n",
      "         [-0.0371]],\n",
      "\n",
      "        [[-0.0719],\n",
      "         [-0.0972],\n",
      "         [ 0.0405],\n",
      "         [ 0.1022],\n",
      "         [-0.0599],\n",
      "         [-0.0627],\n",
      "         [-0.0544],\n",
      "         [-0.0312],\n",
      "         [-0.0361],\n",
      "         [ 0.0082],\n",
      "         [-0.0920],\n",
      "         [-0.1094],\n",
      "         [ 0.0864],\n",
      "         [ 0.0611],\n",
      "         [ 0.0791],\n",
      "         [ 0.0914],\n",
      "         [ 0.0563],\n",
      "         [-0.1105],\n",
      "         [-0.0249],\n",
      "         [ 0.0989],\n",
      "         [-0.0967],\n",
      "         [ 0.0002],\n",
      "         [-0.0401],\n",
      "         [ 0.0638],\n",
      "         [ 0.1072],\n",
      "         [-0.0130],\n",
      "         [ 0.0692],\n",
      "         [ 0.0992],\n",
      "         [ 0.0774],\n",
      "         [ 0.0724],\n",
      "         [-0.0925],\n",
      "         [-0.0915],\n",
      "         [-0.0967],\n",
      "         [ 0.0754],\n",
      "         [-0.0346],\n",
      "         [-0.1219],\n",
      "         [ 0.0871],\n",
      "         [ 0.1123],\n",
      "         [-0.1181],\n",
      "         [ 0.0658],\n",
      "         [-0.0103],\n",
      "         [ 0.0963],\n",
      "         [-0.1205],\n",
      "         [-0.0460],\n",
      "         [ 0.1054],\n",
      "         [-0.0576],\n",
      "         [ 0.0079],\n",
      "         [-0.0194],\n",
      "         [ 0.0689],\n",
      "         [-0.0932],\n",
      "         [-0.0993],\n",
      "         [ 0.0434],\n",
      "         [ 0.0915],\n",
      "         [-0.0981],\n",
      "         [ 0.0292],\n",
      "         [-0.1054],\n",
      "         [-0.0266],\n",
      "         [-0.0397],\n",
      "         [ 0.0389],\n",
      "         [-0.0412],\n",
      "         [ 0.1191],\n",
      "         [-0.0292],\n",
      "         [ 0.0046],\n",
      "         [-0.0263]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv1.bias | Size: torch.Size([16]) | Values : tensor([0.0869, 0.0311], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[ 0.0798,  0.0978,  0.0933],\n",
      "         [ 0.0759,  0.0397,  0.0024],\n",
      "         [-0.1173,  0.1037,  0.0916],\n",
      "         [-0.0843, -0.1420, -0.0947],\n",
      "         [ 0.1146, -0.0960,  0.1088],\n",
      "         [-0.0805,  0.0916, -0.0167],\n",
      "         [-0.1228, -0.1187, -0.0182],\n",
      "         [-0.1293, -0.1378,  0.0708],\n",
      "         [ 0.1194, -0.0120, -0.0715],\n",
      "         [-0.0870,  0.1227, -0.0958],\n",
      "         [ 0.1037,  0.1394,  0.1425],\n",
      "         [-0.0285,  0.1008,  0.1259],\n",
      "         [-0.1247,  0.0085, -0.0252],\n",
      "         [ 0.0493,  0.1212,  0.1101],\n",
      "         [-0.0390, -0.0889,  0.1026],\n",
      "         [-0.0054,  0.0407, -0.1097]],\n",
      "\n",
      "        [[-0.1408, -0.0322,  0.0097],\n",
      "         [-0.0973,  0.1150,  0.1177],\n",
      "         [ 0.0677,  0.0800,  0.1279],\n",
      "         [-0.0663, -0.0231,  0.1127],\n",
      "         [-0.1013,  0.0319, -0.1269],\n",
      "         [ 0.1004, -0.1401, -0.0173],\n",
      "         [-0.1416,  0.1375,  0.0875],\n",
      "         [-0.0137, -0.0820,  0.0302],\n",
      "         [-0.1326, -0.0409,  0.1159],\n",
      "         [ 0.0261,  0.0620, -0.0502],\n",
      "         [ 0.0989, -0.0727, -0.0582],\n",
      "         [ 0.0922, -0.0454,  0.0822],\n",
      "         [-0.1253, -0.0446,  0.0109],\n",
      "         [-0.1397, -0.0804,  0.0634],\n",
      "         [ 0.0673, -0.0351,  0.1230],\n",
      "         [ 0.1030, -0.1394, -0.0582]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv2.bias | Size: torch.Size([16]) | Values : tensor([ 0.0601, -0.0089], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[-0.0589],\n",
      "         [ 0.1522],\n",
      "         [-0.2419],\n",
      "         [ 0.1622],\n",
      "         [-0.2050],\n",
      "         [-0.2380],\n",
      "         [ 0.0185],\n",
      "         [-0.0521],\n",
      "         [-0.2214],\n",
      "         [-0.0989],\n",
      "         [ 0.2305],\n",
      "         [ 0.0236],\n",
      "         [-0.1467],\n",
      "         [-0.2128],\n",
      "         [ 0.1632],\n",
      "         [ 0.1811]],\n",
      "\n",
      "        [[-0.0750],\n",
      "         [-0.1942],\n",
      "         [ 0.0488],\n",
      "         [-0.0633],\n",
      "         [ 0.2068],\n",
      "         [-0.2142],\n",
      "         [-0.1271],\n",
      "         [-0.1648],\n",
      "         [-0.0729],\n",
      "         [-0.2288],\n",
      "         [ 0.1388],\n",
      "         [ 0.2375],\n",
      "         [-0.1159],\n",
      "         [-0.0055],\n",
      "         [ 0.0514],\n",
      "         [-0.1441]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv3.bias | Size: torch.Size([64]) | Values : tensor([0.2096, 0.1425], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[ 0.0839],\n",
      "         [ 0.0881],\n",
      "         [-0.1207],\n",
      "         [ 0.0225],\n",
      "         [-0.0428],\n",
      "         [-0.0638],\n",
      "         [-0.0306],\n",
      "         [-0.1020],\n",
      "         [ 0.0475],\n",
      "         [ 0.0016],\n",
      "         [-0.1227],\n",
      "         [-0.0873],\n",
      "         [-0.1008],\n",
      "         [ 0.1082],\n",
      "         [ 0.0804],\n",
      "         [-0.0289],\n",
      "         [ 0.1242],\n",
      "         [-0.0649],\n",
      "         [ 0.1175],\n",
      "         [ 0.1158],\n",
      "         [-0.0055],\n",
      "         [ 0.0803],\n",
      "         [-0.0272],\n",
      "         [-0.0468],\n",
      "         [-0.0344],\n",
      "         [ 0.0888],\n",
      "         [-0.0958],\n",
      "         [ 0.0764],\n",
      "         [-0.0310],\n",
      "         [-0.0981],\n",
      "         [ 0.0929],\n",
      "         [ 0.0177],\n",
      "         [ 0.0225],\n",
      "         [-0.0856],\n",
      "         [ 0.0190],\n",
      "         [ 0.0434],\n",
      "         [ 0.1089],\n",
      "         [ 0.0517],\n",
      "         [-0.0716],\n",
      "         [ 0.0014],\n",
      "         [-0.0329],\n",
      "         [-0.0481],\n",
      "         [-0.0884],\n",
      "         [-0.1223],\n",
      "         [-0.0352],\n",
      "         [-0.0912],\n",
      "         [ 0.0744],\n",
      "         [ 0.1112],\n",
      "         [-0.0994],\n",
      "         [ 0.0120],\n",
      "         [-0.0377],\n",
      "         [ 0.1225],\n",
      "         [-0.1155],\n",
      "         [-0.0168],\n",
      "         [ 0.1144],\n",
      "         [-0.0632],\n",
      "         [ 0.0036],\n",
      "         [-0.0787],\n",
      "         [-0.1240],\n",
      "         [ 0.0923],\n",
      "         [ 0.0468],\n",
      "         [ 0.0254],\n",
      "         [-0.0426],\n",
      "         [-0.0347]],\n",
      "\n",
      "        [[ 0.0416],\n",
      "         [ 0.1119],\n",
      "         [-0.0750],\n",
      "         [-0.1013],\n",
      "         [-0.0352],\n",
      "         [-0.0855],\n",
      "         [ 0.0169],\n",
      "         [-0.0532],\n",
      "         [ 0.1212],\n",
      "         [-0.0142],\n",
      "         [-0.0702],\n",
      "         [ 0.0746],\n",
      "         [ 0.0310],\n",
      "         [ 0.1021],\n",
      "         [ 0.0003],\n",
      "         [ 0.0236],\n",
      "         [-0.0446],\n",
      "         [ 0.0648],\n",
      "         [ 0.0881],\n",
      "         [-0.0975],\n",
      "         [-0.1037],\n",
      "         [-0.0093],\n",
      "         [-0.0946],\n",
      "         [-0.0675],\n",
      "         [-0.0341],\n",
      "         [ 0.0691],\n",
      "         [-0.0480],\n",
      "         [ 0.0546],\n",
      "         [ 0.0688],\n",
      "         [ 0.0292],\n",
      "         [ 0.0195],\n",
      "         [ 0.0019],\n",
      "         [-0.0703],\n",
      "         [ 0.0990],\n",
      "         [ 0.0375],\n",
      "         [-0.0950],\n",
      "         [ 0.0466],\n",
      "         [ 0.1219],\n",
      "         [ 0.0724],\n",
      "         [ 0.0620],\n",
      "         [-0.0462],\n",
      "         [-0.0917],\n",
      "         [-0.0083],\n",
      "         [ 0.0040],\n",
      "         [-0.0966],\n",
      "         [-0.1154],\n",
      "         [-0.0493],\n",
      "         [ 0.0895],\n",
      "         [ 0.1152],\n",
      "         [ 0.0348],\n",
      "         [ 0.1100],\n",
      "         [ 0.0166],\n",
      "         [ 0.0268],\n",
      "         [-0.0839],\n",
      "         [ 0.0673],\n",
      "         [-0.0880],\n",
      "         [-0.0154],\n",
      "         [-0.0822],\n",
      "         [-0.0719],\n",
      "         [-0.0070],\n",
      "         [ 0.0932],\n",
      "         [ 0.0601],\n",
      "         [-0.0676],\n",
      "         [-0.0199]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.convr.bias | Size: torch.Size([64]) | Values : tensor([ 0.0264, -0.0367], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[-0.1017],\n",
      "         [-0.0513],\n",
      "         [ 0.1015],\n",
      "         [-0.0936],\n",
      "         [-0.0105],\n",
      "         [ 0.0243],\n",
      "         [ 0.1215],\n",
      "         [ 0.1008],\n",
      "         [-0.0136],\n",
      "         [ 0.0851],\n",
      "         [-0.1038],\n",
      "         [ 0.0339],\n",
      "         [ 0.0850],\n",
      "         [ 0.1120],\n",
      "         [ 0.0734],\n",
      "         [-0.0318],\n",
      "         [-0.1027],\n",
      "         [ 0.0808],\n",
      "         [-0.0423],\n",
      "         [-0.1195],\n",
      "         [-0.0222],\n",
      "         [-0.0392],\n",
      "         [-0.1177],\n",
      "         [-0.1020],\n",
      "         [ 0.0707],\n",
      "         [ 0.1022],\n",
      "         [-0.0200],\n",
      "         [ 0.0342],\n",
      "         [-0.0754],\n",
      "         [-0.0492],\n",
      "         [-0.1139],\n",
      "         [-0.0174],\n",
      "         [-0.1060],\n",
      "         [ 0.0111],\n",
      "         [-0.0395],\n",
      "         [ 0.0920],\n",
      "         [-0.0326],\n",
      "         [ 0.0379],\n",
      "         [-0.0973],\n",
      "         [ 0.0198],\n",
      "         [-0.1173],\n",
      "         [-0.1228],\n",
      "         [-0.0419],\n",
      "         [-0.0081],\n",
      "         [ 0.0017],\n",
      "         [-0.0012],\n",
      "         [-0.1062],\n",
      "         [-0.1062],\n",
      "         [-0.0024],\n",
      "         [ 0.0758],\n",
      "         [-0.1235],\n",
      "         [-0.0196],\n",
      "         [-0.0323],\n",
      "         [ 0.0195],\n",
      "         [-0.0277],\n",
      "         [-0.0549],\n",
      "         [-0.0375],\n",
      "         [ 0.0180],\n",
      "         [-0.0968],\n",
      "         [ 0.0969],\n",
      "         [ 0.0376],\n",
      "         [-0.1025],\n",
      "         [-0.0582],\n",
      "         [-0.0495]],\n",
      "\n",
      "        [[ 0.1051],\n",
      "         [ 0.0846],\n",
      "         [ 0.0113],\n",
      "         [-0.0763],\n",
      "         [ 0.1090],\n",
      "         [-0.0296],\n",
      "         [ 0.0994],\n",
      "         [-0.0191],\n",
      "         [ 0.0561],\n",
      "         [-0.0800],\n",
      "         [-0.0099],\n",
      "         [-0.0324],\n",
      "         [ 0.1154],\n",
      "         [ 0.0218],\n",
      "         [-0.0150],\n",
      "         [ 0.0184],\n",
      "         [ 0.1131],\n",
      "         [ 0.0732],\n",
      "         [ 0.0012],\n",
      "         [-0.0732],\n",
      "         [ 0.0186],\n",
      "         [-0.0965],\n",
      "         [-0.0702],\n",
      "         [-0.0020],\n",
      "         [ 0.1245],\n",
      "         [ 0.0037],\n",
      "         [-0.0699],\n",
      "         [ 0.0077],\n",
      "         [ 0.1132],\n",
      "         [-0.0589],\n",
      "         [ 0.1204],\n",
      "         [ 0.1104],\n",
      "         [ 0.0348],\n",
      "         [ 0.0648],\n",
      "         [-0.1185],\n",
      "         [-0.0608],\n",
      "         [ 0.1176],\n",
      "         [-0.0994],\n",
      "         [ 0.0571],\n",
      "         [-0.0095],\n",
      "         [ 0.0125],\n",
      "         [-0.0338],\n",
      "         [-0.0153],\n",
      "         [-0.0281],\n",
      "         [ 0.0275],\n",
      "         [-0.0854],\n",
      "         [-0.0699],\n",
      "         [-0.0089],\n",
      "         [ 0.0203],\n",
      "         [ 0.0090],\n",
      "         [ 0.0562],\n",
      "         [ 0.0511],\n",
      "         [ 0.0822],\n",
      "         [ 0.0753],\n",
      "         [ 0.0816],\n",
      "         [-0.0103],\n",
      "         [ 0.1098],\n",
      "         [-0.0127],\n",
      "         [ 0.0372],\n",
      "         [-0.0513],\n",
      "         [-0.0029],\n",
      "         [-0.1098],\n",
      "         [ 0.0700],\n",
      "         [ 0.0751]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.conv1.bias | Size: torch.Size([16]) | Values : tensor([0.1041, 0.0960], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[ 0.0206,  0.0452, -0.1216],\n",
      "         [-0.0234, -0.0335,  0.1143],\n",
      "         [-0.0633, -0.1305,  0.1192],\n",
      "         [-0.1145, -0.0468,  0.0807],\n",
      "         [ 0.0259, -0.1056,  0.0697],\n",
      "         [ 0.0509, -0.0333, -0.0348],\n",
      "         [ 0.1371,  0.0983,  0.1088],\n",
      "         [-0.0056, -0.1256,  0.0906],\n",
      "         [ 0.0154,  0.0293,  0.0743],\n",
      "         [ 0.0909,  0.1208,  0.0063],\n",
      "         [ 0.1205,  0.0544, -0.0931],\n",
      "         [-0.0414,  0.1167, -0.0647],\n",
      "         [-0.0329,  0.0736,  0.1031],\n",
      "         [-0.0792,  0.0495, -0.1032],\n",
      "         [ 0.0119,  0.0251, -0.0866],\n",
      "         [-0.0537, -0.0601,  0.1158]],\n",
      "\n",
      "        [[-0.0331,  0.0183, -0.1425],\n",
      "         [ 0.0946,  0.0416, -0.0426],\n",
      "         [ 0.0922,  0.1174, -0.1349],\n",
      "         [ 0.1068,  0.0027, -0.0842],\n",
      "         [ 0.0686,  0.1266,  0.0727],\n",
      "         [ 0.1200,  0.0367,  0.1279],\n",
      "         [ 0.0693, -0.0051,  0.1339],\n",
      "         [-0.1283,  0.1406, -0.0899],\n",
      "         [ 0.0374, -0.0890,  0.1426],\n",
      "         [-0.0111,  0.0020, -0.1104],\n",
      "         [ 0.0602, -0.0288, -0.1043],\n",
      "         [ 0.1030,  0.0530, -0.1174],\n",
      "         [-0.0524,  0.1214,  0.1127],\n",
      "         [ 0.1438,  0.0139, -0.1176],\n",
      "         [ 0.1000,  0.0302,  0.0922],\n",
      "         [-0.1185,  0.0066, -0.1157]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.conv2.bias | Size: torch.Size([16]) | Values : tensor([-0.1222, -0.1197], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[ 0.0889],\n",
      "         [-0.0771],\n",
      "         [ 0.0296],\n",
      "         [ 0.1507],\n",
      "         [ 0.1119],\n",
      "         [-0.1321],\n",
      "         [ 0.1279],\n",
      "         [ 0.0242],\n",
      "         [-0.0381],\n",
      "         [-0.1831],\n",
      "         [-0.0025],\n",
      "         [-0.2200],\n",
      "         [-0.1196],\n",
      "         [-0.0102],\n",
      "         [ 0.1581],\n",
      "         [ 0.1150]],\n",
      "\n",
      "        [[-0.0188],\n",
      "         [-0.0840],\n",
      "         [-0.1821],\n",
      "         [-0.1599],\n",
      "         [-0.1928],\n",
      "         [-0.1832],\n",
      "         [-0.0312],\n",
      "         [ 0.1255],\n",
      "         [ 0.0113],\n",
      "         [ 0.0180],\n",
      "         [-0.0748],\n",
      "         [ 0.1356],\n",
      "         [ 0.1206],\n",
      "         [ 0.0282],\n",
      "         [ 0.1084],\n",
      "         [-0.2222]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.conv3.bias | Size: torch.Size([64]) | Values : tensor([0.2114, 0.1276], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[-0.1200],\n",
      "         [ 0.1212],\n",
      "         [-0.0289],\n",
      "         [-0.0570],\n",
      "         [ 0.0030],\n",
      "         [ 0.1087],\n",
      "         [ 0.0927],\n",
      "         [ 0.0227],\n",
      "         [ 0.0944],\n",
      "         [ 0.1238],\n",
      "         [-0.0007],\n",
      "         [-0.0882],\n",
      "         [ 0.0673],\n",
      "         [-0.0865],\n",
      "         [-0.0873],\n",
      "         [-0.0727],\n",
      "         [ 0.0604],\n",
      "         [-0.0102],\n",
      "         [ 0.0288],\n",
      "         [-0.0724],\n",
      "         [-0.0382],\n",
      "         [ 0.0863],\n",
      "         [ 0.0743],\n",
      "         [-0.0503],\n",
      "         [ 0.0728],\n",
      "         [ 0.0826],\n",
      "         [ 0.0293],\n",
      "         [-0.0492],\n",
      "         [ 0.0437],\n",
      "         [ 0.0280],\n",
      "         [ 0.0483],\n",
      "         [ 0.0290],\n",
      "         [-0.0720],\n",
      "         [-0.0864],\n",
      "         [-0.0158],\n",
      "         [-0.0500],\n",
      "         [-0.0557],\n",
      "         [-0.0360],\n",
      "         [-0.0267],\n",
      "         [ 0.0914],\n",
      "         [-0.0344],\n",
      "         [ 0.1112],\n",
      "         [ 0.1136],\n",
      "         [-0.1081],\n",
      "         [-0.0218],\n",
      "         [ 0.0619],\n",
      "         [ 0.0315],\n",
      "         [ 0.1005],\n",
      "         [ 0.1184],\n",
      "         [-0.0367],\n",
      "         [-0.0626],\n",
      "         [-0.0466],\n",
      "         [-0.1060],\n",
      "         [-0.0142],\n",
      "         [-0.1137],\n",
      "         [ 0.0541],\n",
      "         [-0.0659],\n",
      "         [-0.0275],\n",
      "         [ 0.0380],\n",
      "         [-0.0512],\n",
      "         [ 0.0783],\n",
      "         [-0.0309],\n",
      "         [ 0.0567],\n",
      "         [-0.0936]],\n",
      "\n",
      "        [[ 0.0653],\n",
      "         [-0.0863],\n",
      "         [-0.0264],\n",
      "         [ 0.0716],\n",
      "         [-0.0352],\n",
      "         [-0.1020],\n",
      "         [-0.0612],\n",
      "         [-0.0474],\n",
      "         [-0.0875],\n",
      "         [ 0.0227],\n",
      "         [-0.1009],\n",
      "         [-0.0060],\n",
      "         [-0.0881],\n",
      "         [ 0.0635],\n",
      "         [ 0.0190],\n",
      "         [ 0.0129],\n",
      "         [-0.0973],\n",
      "         [-0.0522],\n",
      "         [ 0.0636],\n",
      "         [ 0.0385],\n",
      "         [ 0.0469],\n",
      "         [ 0.0178],\n",
      "         [-0.1234],\n",
      "         [-0.0589],\n",
      "         [ 0.0045],\n",
      "         [-0.0432],\n",
      "         [ 0.0854],\n",
      "         [ 0.0616],\n",
      "         [-0.0045],\n",
      "         [ 0.0565],\n",
      "         [ 0.0288],\n",
      "         [ 0.0210],\n",
      "         [ 0.0685],\n",
      "         [ 0.0514],\n",
      "         [ 0.0677],\n",
      "         [-0.1120],\n",
      "         [-0.0710],\n",
      "         [-0.0628],\n",
      "         [ 0.0771],\n",
      "         [ 0.1186],\n",
      "         [ 0.0241],\n",
      "         [-0.0909],\n",
      "         [ 0.0714],\n",
      "         [ 0.0466],\n",
      "         [ 0.0875],\n",
      "         [-0.0807],\n",
      "         [-0.0775],\n",
      "         [ 0.0357],\n",
      "         [ 0.0578],\n",
      "         [ 0.1243],\n",
      "         [-0.0116],\n",
      "         [-0.0337],\n",
      "         [ 0.0828],\n",
      "         [-0.0005],\n",
      "         [-0.1073],\n",
      "         [ 0.1162],\n",
      "         [-0.1240],\n",
      "         [-0.0639],\n",
      "         [ 0.0958],\n",
      "         [-0.1039],\n",
      "         [ 0.0127],\n",
      "         [ 0.0482],\n",
      "         [ 0.1226],\n",
      "         [-0.0563]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv1.bias | Size: torch.Size([16]) | Values : tensor([-0.0919,  0.0144], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[ 0.0907, -0.0971, -0.0893],\n",
      "         [ 0.0049, -0.0123, -0.0974],\n",
      "         [ 0.0948,  0.1056,  0.0875],\n",
      "         [-0.1254, -0.1234,  0.0049],\n",
      "         [ 0.1286,  0.0879, -0.0708],\n",
      "         [ 0.0913, -0.0736,  0.0270],\n",
      "         [-0.0854,  0.1046, -0.0682],\n",
      "         [-0.1274, -0.0723, -0.0550],\n",
      "         [-0.1147,  0.1061,  0.0839],\n",
      "         [ 0.0301,  0.0849,  0.0154],\n",
      "         [-0.0464,  0.0034,  0.0054],\n",
      "         [-0.1015,  0.0237, -0.0912],\n",
      "         [ 0.0348,  0.1331, -0.0612],\n",
      "         [-0.0695,  0.1269,  0.0121],\n",
      "         [ 0.0085, -0.1362, -0.0978],\n",
      "         [ 0.0253,  0.0806,  0.1332]],\n",
      "\n",
      "        [[ 0.0357, -0.1162,  0.1098],\n",
      "         [ 0.0848,  0.1351, -0.1028],\n",
      "         [ 0.0233,  0.0878, -0.0194],\n",
      "         [-0.0870, -0.0602,  0.0736],\n",
      "         [-0.1201, -0.0908, -0.0869],\n",
      "         [-0.0798,  0.0973,  0.0413],\n",
      "         [ 0.1210, -0.0456, -0.0094],\n",
      "         [-0.0121, -0.0057, -0.0076],\n",
      "         [ 0.0336, -0.1262, -0.1409],\n",
      "         [-0.1266, -0.0911,  0.0938],\n",
      "         [ 0.0424, -0.0719,  0.0681],\n",
      "         [-0.0981,  0.0318, -0.0606],\n",
      "         [ 0.0836, -0.0015,  0.0148],\n",
      "         [ 0.0065,  0.0606,  0.0380],\n",
      "         [-0.1298, -0.0909, -0.0563],\n",
      "         [ 0.1234, -0.0945,  0.0166]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv2.bias | Size: torch.Size([16]) | Values : tensor([-0.0439,  0.0506], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[ 0.0528],\n",
      "         [ 0.0178],\n",
      "         [ 0.1248],\n",
      "         [ 0.1861],\n",
      "         [ 0.1283],\n",
      "         [-0.1544],\n",
      "         [ 0.2088],\n",
      "         [-0.0634],\n",
      "         [ 0.1708],\n",
      "         [-0.2238],\n",
      "         [ 0.1844],\n",
      "         [-0.2253],\n",
      "         [ 0.2046],\n",
      "         [ 0.0714],\n",
      "         [-0.0259],\n",
      "         [ 0.2285]],\n",
      "\n",
      "        [[-0.2089],\n",
      "         [-0.0268],\n",
      "         [-0.1708],\n",
      "         [ 0.0403],\n",
      "         [-0.0828],\n",
      "         [ 0.1595],\n",
      "         [ 0.0349],\n",
      "         [ 0.0368],\n",
      "         [-0.0004],\n",
      "         [-0.0413],\n",
      "         [ 0.1234],\n",
      "         [ 0.0762],\n",
      "         [-0.0883],\n",
      "         [-0.0801],\n",
      "         [ 0.2470],\n",
      "         [ 0.1223]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv3.bias | Size: torch.Size([64]) | Values : tensor([-0.2132,  0.1806], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[-0.0333],\n",
      "         [ 0.0905],\n",
      "         [-0.0788],\n",
      "         [-0.0255],\n",
      "         [-0.0746],\n",
      "         [-0.0832],\n",
      "         [-0.0515],\n",
      "         [-0.0830],\n",
      "         [-0.1184],\n",
      "         [-0.0126],\n",
      "         [-0.0809],\n",
      "         [-0.0092],\n",
      "         [ 0.0517],\n",
      "         [-0.0980],\n",
      "         [-0.0643],\n",
      "         [-0.0830],\n",
      "         [-0.0321],\n",
      "         [ 0.0955],\n",
      "         [-0.0668],\n",
      "         [ 0.0853],\n",
      "         [ 0.0782],\n",
      "         [ 0.0660],\n",
      "         [-0.0593],\n",
      "         [-0.0594],\n",
      "         [ 0.0944],\n",
      "         [-0.0279],\n",
      "         [ 0.0763],\n",
      "         [ 0.0123],\n",
      "         [-0.0788],\n",
      "         [ 0.1001],\n",
      "         [-0.1062],\n",
      "         [ 0.1239],\n",
      "         [-0.0233],\n",
      "         [-0.0785],\n",
      "         [ 0.0663],\n",
      "         [ 0.0624],\n",
      "         [-0.0459],\n",
      "         [ 0.0566],\n",
      "         [-0.0018],\n",
      "         [-0.0736],\n",
      "         [-0.0396],\n",
      "         [-0.0985],\n",
      "         [ 0.0105],\n",
      "         [ 0.0525],\n",
      "         [-0.0989],\n",
      "         [ 0.0340],\n",
      "         [ 0.1248],\n",
      "         [ 0.0841],\n",
      "         [ 0.1117],\n",
      "         [ 0.0309],\n",
      "         [ 0.0554],\n",
      "         [-0.0076],\n",
      "         [-0.0183],\n",
      "         [ 0.1213],\n",
      "         [ 0.0454],\n",
      "         [ 0.0278],\n",
      "         [-0.0200],\n",
      "         [-0.0221],\n",
      "         [ 0.0501],\n",
      "         [-0.1093],\n",
      "         [-0.0230],\n",
      "         [ 0.1129],\n",
      "         [ 0.0478],\n",
      "         [-0.0042]],\n",
      "\n",
      "        [[-0.0884],\n",
      "         [ 0.0244],\n",
      "         [-0.0433],\n",
      "         [ 0.0371],\n",
      "         [ 0.1171],\n",
      "         [ 0.0017],\n",
      "         [-0.0709],\n",
      "         [-0.0427],\n",
      "         [-0.0098],\n",
      "         [ 0.0291],\n",
      "         [ 0.0920],\n",
      "         [ 0.0074],\n",
      "         [-0.0841],\n",
      "         [ 0.0398],\n",
      "         [ 0.0958],\n",
      "         [ 0.1206],\n",
      "         [ 0.0972],\n",
      "         [-0.1108],\n",
      "         [ 0.0676],\n",
      "         [-0.0676],\n",
      "         [-0.0889],\n",
      "         [-0.0916],\n",
      "         [-0.0626],\n",
      "         [-0.0727],\n",
      "         [-0.0049],\n",
      "         [-0.0538],\n",
      "         [-0.0451],\n",
      "         [ 0.0918],\n",
      "         [-0.0891],\n",
      "         [ 0.0633],\n",
      "         [ 0.0603],\n",
      "         [-0.0014],\n",
      "         [ 0.0993],\n",
      "         [-0.0784],\n",
      "         [-0.0570],\n",
      "         [-0.1225],\n",
      "         [-0.1021],\n",
      "         [-0.0363],\n",
      "         [ 0.0987],\n",
      "         [-0.0773],\n",
      "         [ 0.0359],\n",
      "         [ 0.0493],\n",
      "         [-0.0774],\n",
      "         [-0.0180],\n",
      "         [-0.0580],\n",
      "         [ 0.0995],\n",
      "         [-0.0820],\n",
      "         [ 0.0536],\n",
      "         [-0.1121],\n",
      "         [ 0.0229],\n",
      "         [-0.0404],\n",
      "         [-0.0130],\n",
      "         [ 0.0689],\n",
      "         [ 0.0083],\n",
      "         [-0.0689],\n",
      "         [ 0.0215],\n",
      "         [ 0.0946],\n",
      "         [-0.1067],\n",
      "         [ 0.1121],\n",
      "         [-0.0279],\n",
      "         [-0.0025],\n",
      "         [ 0.0160],\n",
      "         [-0.0766],\n",
      "         [-0.0293]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.convr.bias | Size: torch.Size([64]) | Values : tensor([ 0.1222, -0.0292], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[-0.0851],\n",
      "         [-0.0904],\n",
      "         [ 0.0007],\n",
      "         [ 0.0172],\n",
      "         [ 0.0547],\n",
      "         [ 0.0169],\n",
      "         [ 0.0159],\n",
      "         [ 0.0764],\n",
      "         [-0.1005],\n",
      "         [ 0.0941],\n",
      "         [-0.0275],\n",
      "         [ 0.0073],\n",
      "         [-0.1073],\n",
      "         [ 0.0795],\n",
      "         [ 0.0874],\n",
      "         [-0.0047],\n",
      "         [ 0.0799],\n",
      "         [-0.0766],\n",
      "         [ 0.0263],\n",
      "         [ 0.0401],\n",
      "         [-0.0382],\n",
      "         [ 0.0073],\n",
      "         [-0.0299],\n",
      "         [ 0.1175],\n",
      "         [ 0.0468],\n",
      "         [ 0.0101],\n",
      "         [ 0.0938],\n",
      "         [ 0.0485],\n",
      "         [ 0.0054],\n",
      "         [ 0.0229],\n",
      "         [ 0.1126],\n",
      "         [-0.0242],\n",
      "         [-0.0025],\n",
      "         [ 0.0383],\n",
      "         [-0.0950],\n",
      "         [ 0.0179],\n",
      "         [-0.0868],\n",
      "         [ 0.0569],\n",
      "         [-0.0432],\n",
      "         [-0.0610],\n",
      "         [-0.0614],\n",
      "         [ 0.1067],\n",
      "         [ 0.0918],\n",
      "         [ 0.0867],\n",
      "         [ 0.0582],\n",
      "         [-0.0495],\n",
      "         [ 0.0521],\n",
      "         [ 0.1073],\n",
      "         [-0.0146],\n",
      "         [-0.0006],\n",
      "         [-0.0389],\n",
      "         [ 0.0470],\n",
      "         [ 0.0052],\n",
      "         [-0.0405],\n",
      "         [-0.0327],\n",
      "         [-0.0320],\n",
      "         [ 0.0371],\n",
      "         [-0.0491],\n",
      "         [-0.0444],\n",
      "         [ 0.0201],\n",
      "         [-0.0323],\n",
      "         [-0.1091],\n",
      "         [ 0.1093],\n",
      "         [-0.1235]],\n",
      "\n",
      "        [[-0.0455],\n",
      "         [-0.0879],\n",
      "         [ 0.0224],\n",
      "         [-0.0689],\n",
      "         [-0.0443],\n",
      "         [ 0.0156],\n",
      "         [-0.0259],\n",
      "         [ 0.0232],\n",
      "         [-0.0447],\n",
      "         [-0.0461],\n",
      "         [ 0.1189],\n",
      "         [-0.1148],\n",
      "         [-0.0270],\n",
      "         [ 0.0613],\n",
      "         [-0.1033],\n",
      "         [-0.0194],\n",
      "         [-0.0909],\n",
      "         [ 0.1156],\n",
      "         [-0.0558],\n",
      "         [-0.0543],\n",
      "         [-0.0409],\n",
      "         [-0.0742],\n",
      "         [ 0.0080],\n",
      "         [-0.0385],\n",
      "         [-0.1118],\n",
      "         [ 0.1010],\n",
      "         [ 0.0697],\n",
      "         [-0.0321],\n",
      "         [-0.1224],\n",
      "         [-0.0870],\n",
      "         [-0.0435],\n",
      "         [-0.0100],\n",
      "         [-0.0650],\n",
      "         [ 0.0491],\n",
      "         [-0.0664],\n",
      "         [-0.1030],\n",
      "         [-0.0329],\n",
      "         [ 0.0794],\n",
      "         [-0.0903],\n",
      "         [-0.0572],\n",
      "         [-0.0728],\n",
      "         [ 0.0759],\n",
      "         [-0.0790],\n",
      "         [ 0.0267],\n",
      "         [-0.0455],\n",
      "         [-0.1218],\n",
      "         [ 0.0068],\n",
      "         [-0.0965],\n",
      "         [-0.0094],\n",
      "         [-0.0289],\n",
      "         [ 0.0685],\n",
      "         [-0.0804],\n",
      "         [ 0.0263],\n",
      "         [-0.0042],\n",
      "         [ 0.0355],\n",
      "         [ 0.0469],\n",
      "         [-0.0555],\n",
      "         [ 0.0364],\n",
      "         [-0.0764],\n",
      "         [-0.0680],\n",
      "         [ 0.1207],\n",
      "         [ 0.0096],\n",
      "         [-0.1022],\n",
      "         [ 0.0533]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.conv1.bias | Size: torch.Size([16]) | Values : tensor([-0.0183, -0.0748], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[ 0.1436,  0.0537, -0.1244],\n",
      "         [-0.0913,  0.1205, -0.0940],\n",
      "         [-0.0244, -0.1387,  0.1432],\n",
      "         [-0.0104,  0.1315, -0.1164],\n",
      "         [ 0.1086,  0.0994, -0.1076],\n",
      "         [-0.1313, -0.0515,  0.0870],\n",
      "         [-0.0739,  0.0290,  0.1428],\n",
      "         [-0.0358,  0.0443,  0.0826],\n",
      "         [-0.0909, -0.0893, -0.1124],\n",
      "         [-0.0705,  0.0881,  0.0296],\n",
      "         [-0.1163, -0.0414,  0.0304],\n",
      "         [ 0.0816, -0.1230, -0.0190],\n",
      "         [ 0.1325,  0.0813,  0.0631],\n",
      "         [ 0.0225, -0.0594, -0.0752],\n",
      "         [-0.0214,  0.0533, -0.1051],\n",
      "         [ 0.0339, -0.1299,  0.1116]],\n",
      "\n",
      "        [[ 0.1243, -0.0775, -0.0584],\n",
      "         [ 0.1133, -0.0551, -0.0987],\n",
      "         [ 0.0669,  0.1227, -0.0624],\n",
      "         [ 0.1125, -0.0732,  0.0423],\n",
      "         [-0.0284, -0.0389,  0.0742],\n",
      "         [-0.0218, -0.0601,  0.0967],\n",
      "         [-0.0826,  0.0160, -0.1159],\n",
      "         [ 0.1354,  0.1303,  0.1069],\n",
      "         [ 0.1195, -0.0596,  0.1305],\n",
      "         [ 0.0462, -0.1005, -0.1213],\n",
      "         [-0.0661, -0.0245,  0.0555],\n",
      "         [-0.0910, -0.0892,  0.1308],\n",
      "         [-0.0711, -0.0359,  0.0170],\n",
      "         [-0.0958,  0.0207,  0.0544],\n",
      "         [-0.0366, -0.1250,  0.1301],\n",
      "         [-0.1067,  0.1435, -0.1229]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.conv2.bias | Size: torch.Size([16]) | Values : tensor([-0.1210, -0.0538], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[ 0.0546],\n",
      "         [ 0.2485],\n",
      "         [ 0.1436],\n",
      "         [ 0.1070],\n",
      "         [-0.1129],\n",
      "         [-0.1031],\n",
      "         [-0.0936],\n",
      "         [-0.0580],\n",
      "         [ 0.0021],\n",
      "         [-0.1262],\n",
      "         [-0.2039],\n",
      "         [ 0.2171],\n",
      "         [ 0.0780],\n",
      "         [-0.2330],\n",
      "         [ 0.1452],\n",
      "         [ 0.1327]],\n",
      "\n",
      "        [[-0.1379],\n",
      "         [-0.0947],\n",
      "         [-0.0299],\n",
      "         [-0.1306],\n",
      "         [ 0.1162],\n",
      "         [ 0.0509],\n",
      "         [ 0.0520],\n",
      "         [-0.0925],\n",
      "         [-0.2253],\n",
      "         [ 0.2104],\n",
      "         [ 0.0435],\n",
      "         [-0.2230],\n",
      "         [-0.2355],\n",
      "         [-0.0794],\n",
      "         [-0.2442],\n",
      "         [ 0.2206]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.conv3.bias | Size: torch.Size([64]) | Values : tensor([-0.0547, -0.2035], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[-0.0194],\n",
      "         [ 0.1051],\n",
      "         [ 0.1095],\n",
      "         [ 0.0274],\n",
      "         [ 0.0357],\n",
      "         [ 0.0090],\n",
      "         [-0.0822],\n",
      "         [-0.0008],\n",
      "         [-0.0308],\n",
      "         [ 0.0802],\n",
      "         [-0.0982],\n",
      "         [-0.1220],\n",
      "         [-0.0720],\n",
      "         [ 0.0223],\n",
      "         [-0.0461],\n",
      "         [-0.0950],\n",
      "         [ 0.0727],\n",
      "         [-0.0805],\n",
      "         [-0.0529],\n",
      "         [ 0.1089],\n",
      "         [ 0.0406],\n",
      "         [ 0.0650],\n",
      "         [-0.0767],\n",
      "         [ 0.0802],\n",
      "         [-0.1131],\n",
      "         [ 0.0040],\n",
      "         [ 0.0857],\n",
      "         [ 0.1070],\n",
      "         [-0.0872],\n",
      "         [ 0.0845],\n",
      "         [-0.0319],\n",
      "         [-0.0915],\n",
      "         [-0.0007],\n",
      "         [-0.0058],\n",
      "         [-0.1084],\n",
      "         [-0.0263],\n",
      "         [ 0.1028],\n",
      "         [ 0.0052],\n",
      "         [ 0.0599],\n",
      "         [-0.0269],\n",
      "         [ 0.0828],\n",
      "         [ 0.0589],\n",
      "         [ 0.0171],\n",
      "         [-0.0707],\n",
      "         [ 0.0465],\n",
      "         [ 0.0807],\n",
      "         [ 0.0462],\n",
      "         [-0.0022],\n",
      "         [-0.0630],\n",
      "         [ 0.1119],\n",
      "         [ 0.0765],\n",
      "         [ 0.0708],\n",
      "         [ 0.0593],\n",
      "         [-0.0520],\n",
      "         [ 0.0969],\n",
      "         [-0.0584],\n",
      "         [ 0.0138],\n",
      "         [ 0.0593],\n",
      "         [-0.1134],\n",
      "         [-0.1063],\n",
      "         [ 0.1120],\n",
      "         [-0.0184],\n",
      "         [ 0.0250],\n",
      "         [ 0.1024]],\n",
      "\n",
      "        [[-0.0771],\n",
      "         [ 0.0737],\n",
      "         [ 0.1113],\n",
      "         [-0.0188],\n",
      "         [ 0.0267],\n",
      "         [ 0.1052],\n",
      "         [-0.1037],\n",
      "         [ 0.0644],\n",
      "         [-0.0855],\n",
      "         [ 0.1200],\n",
      "         [-0.0634],\n",
      "         [ 0.1017],\n",
      "         [ 0.1097],\n",
      "         [-0.1117],\n",
      "         [-0.0917],\n",
      "         [ 0.0173],\n",
      "         [-0.1115],\n",
      "         [ 0.1137],\n",
      "         [-0.0293],\n",
      "         [ 0.1030],\n",
      "         [-0.0474],\n",
      "         [-0.0705],\n",
      "         [ 0.0345],\n",
      "         [ 0.0318],\n",
      "         [-0.0468],\n",
      "         [-0.0511],\n",
      "         [-0.0787],\n",
      "         [-0.0731],\n",
      "         [-0.0346],\n",
      "         [-0.1036],\n",
      "         [ 0.0873],\n",
      "         [ 0.0374],\n",
      "         [ 0.1022],\n",
      "         [ 0.1089],\n",
      "         [ 0.1183],\n",
      "         [-0.0237],\n",
      "         [ 0.0798],\n",
      "         [-0.0533],\n",
      "         [ 0.1130],\n",
      "         [-0.1093],\n",
      "         [-0.0268],\n",
      "         [-0.0874],\n",
      "         [ 0.0148],\n",
      "         [-0.1098],\n",
      "         [-0.1146],\n",
      "         [-0.0303],\n",
      "         [-0.0858],\n",
      "         [ 0.0971],\n",
      "         [ 0.0238],\n",
      "         [ 0.1121],\n",
      "         [-0.0783],\n",
      "         [-0.0869],\n",
      "         [-0.0219],\n",
      "         [ 0.0737],\n",
      "         [ 0.1136],\n",
      "         [-0.0180],\n",
      "         [ 0.0639],\n",
      "         [-0.0615],\n",
      "         [-0.1078],\n",
      "         [-0.0391],\n",
      "         [-0.0705],\n",
      "         [-0.1149],\n",
      "         [-0.0857],\n",
      "         [-0.0762]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv1.bias | Size: torch.Size([16]) | Values : tensor([0.0488, 0.1142], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[ 0.0490, -0.0288,  0.1261],\n",
      "         [ 0.0099,  0.0956,  0.0703],\n",
      "         [-0.0691, -0.0026, -0.1368],\n",
      "         [ 0.0316, -0.1118, -0.0426],\n",
      "         [ 0.0849,  0.0186,  0.0228],\n",
      "         [-0.0223, -0.0954, -0.0448],\n",
      "         [ 0.0820, -0.0380, -0.0604],\n",
      "         [ 0.0198,  0.1410,  0.0695],\n",
      "         [ 0.0891,  0.0223, -0.0738],\n",
      "         [-0.1438,  0.0417, -0.0859],\n",
      "         [-0.0118, -0.0973,  0.0010],\n",
      "         [-0.1253, -0.1385,  0.0031],\n",
      "         [ 0.0542, -0.0925,  0.0266],\n",
      "         [ 0.0328,  0.1153, -0.0872],\n",
      "         [-0.1421, -0.1232, -0.1442],\n",
      "         [ 0.1282, -0.0173, -0.1207]],\n",
      "\n",
      "        [[ 0.0729, -0.0458, -0.0905],\n",
      "         [ 0.0445,  0.1056, -0.0350],\n",
      "         [-0.0091,  0.0559, -0.0263],\n",
      "         [-0.0153, -0.1106,  0.1285],\n",
      "         [ 0.1263, -0.1130, -0.1345],\n",
      "         [-0.1086,  0.0257,  0.1328],\n",
      "         [-0.0829, -0.0759, -0.1384],\n",
      "         [-0.1002,  0.0984, -0.0665],\n",
      "         [-0.0045,  0.0590,  0.0875],\n",
      "         [-0.1124, -0.1340, -0.1213],\n",
      "         [-0.1339,  0.1262, -0.0432],\n",
      "         [-0.0163, -0.1433, -0.1141],\n",
      "         [ 0.0135, -0.0187,  0.0793],\n",
      "         [ 0.0905,  0.0869, -0.0580],\n",
      "         [ 0.0193, -0.1140, -0.1288],\n",
      "         [-0.1060, -0.0683,  0.1191]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv2.bias | Size: torch.Size([16]) | Values : tensor([ 0.0769, -0.0825], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[-0.1801],\n",
      "         [-0.1435],\n",
      "         [ 0.1551],\n",
      "         [ 0.0190],\n",
      "         [ 0.0735],\n",
      "         [-0.1216],\n",
      "         [-0.2230],\n",
      "         [-0.2461],\n",
      "         [-0.0104],\n",
      "         [-0.1975],\n",
      "         [-0.0460],\n",
      "         [ 0.1844],\n",
      "         [ 0.1864],\n",
      "         [ 0.1975],\n",
      "         [ 0.2137],\n",
      "         [-0.2478]],\n",
      "\n",
      "        [[-0.2009],\n",
      "         [-0.0122],\n",
      "         [-0.1080],\n",
      "         [ 0.2092],\n",
      "         [ 0.1153],\n",
      "         [ 0.0249],\n",
      "         [-0.0348],\n",
      "         [-0.0097],\n",
      "         [-0.0730],\n",
      "         [ 0.0160],\n",
      "         [-0.1059],\n",
      "         [ 0.2267],\n",
      "         [ 0.2027],\n",
      "         [-0.2317],\n",
      "         [ 0.0237],\n",
      "         [-0.1698]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv3.bias | Size: torch.Size([64]) | Values : tensor([0.0682, 0.1721], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[ 0.0618],\n",
      "         [ 0.0121],\n",
      "         [ 0.0696],\n",
      "         [ 0.1021],\n",
      "         [ 0.1097],\n",
      "         [-0.1168],\n",
      "         [-0.0053],\n",
      "         [ 0.0764],\n",
      "         [ 0.0494],\n",
      "         [-0.0637],\n",
      "         [-0.1114],\n",
      "         [ 0.0689],\n",
      "         [ 0.0350],\n",
      "         [ 0.0847],\n",
      "         [-0.1096],\n",
      "         [-0.0630],\n",
      "         [ 0.0152],\n",
      "         [-0.1222],\n",
      "         [-0.0287],\n",
      "         [-0.0960],\n",
      "         [-0.0821],\n",
      "         [ 0.0787],\n",
      "         [ 0.0086],\n",
      "         [-0.0880],\n",
      "         [-0.0293],\n",
      "         [-0.0858],\n",
      "         [-0.0936],\n",
      "         [ 0.0617],\n",
      "         [ 0.0696],\n",
      "         [-0.0184],\n",
      "         [-0.0693],\n",
      "         [ 0.1034],\n",
      "         [-0.0267],\n",
      "         [-0.0158],\n",
      "         [ 0.0824],\n",
      "         [ 0.1002],\n",
      "         [-0.1194],\n",
      "         [-0.0185],\n",
      "         [ 0.0906],\n",
      "         [-0.0938],\n",
      "         [ 0.0202],\n",
      "         [ 0.0082],\n",
      "         [-0.1000],\n",
      "         [-0.0708],\n",
      "         [ 0.0297],\n",
      "         [ 0.0918],\n",
      "         [ 0.1242],\n",
      "         [ 0.0113],\n",
      "         [-0.0828],\n",
      "         [ 0.0388],\n",
      "         [-0.0949],\n",
      "         [-0.0490],\n",
      "         [-0.0725],\n",
      "         [-0.1011],\n",
      "         [-0.0044],\n",
      "         [ 0.0126],\n",
      "         [-0.0736],\n",
      "         [ 0.0572],\n",
      "         [ 0.0071],\n",
      "         [ 0.0349],\n",
      "         [-0.1057],\n",
      "         [ 0.0003],\n",
      "         [-0.0513],\n",
      "         [ 0.0411]],\n",
      "\n",
      "        [[-0.0386],\n",
      "         [-0.1049],\n",
      "         [ 0.1030],\n",
      "         [ 0.0092],\n",
      "         [ 0.0236],\n",
      "         [ 0.0717],\n",
      "         [ 0.0642],\n",
      "         [ 0.0547],\n",
      "         [-0.1032],\n",
      "         [ 0.0705],\n",
      "         [ 0.0371],\n",
      "         [-0.0971],\n",
      "         [ 0.0596],\n",
      "         [ 0.1036],\n",
      "         [ 0.0319],\n",
      "         [-0.0595],\n",
      "         [-0.0684],\n",
      "         [ 0.0062],\n",
      "         [ 0.0537],\n",
      "         [ 0.0897],\n",
      "         [ 0.0071],\n",
      "         [ 0.0963],\n",
      "         [-0.0521],\n",
      "         [ 0.0270],\n",
      "         [-0.0627],\n",
      "         [ 0.0256],\n",
      "         [-0.1053],\n",
      "         [ 0.0237],\n",
      "         [-0.0488],\n",
      "         [-0.0775],\n",
      "         [-0.1171],\n",
      "         [ 0.0956],\n",
      "         [ 0.1210],\n",
      "         [ 0.1170],\n",
      "         [-0.0998],\n",
      "         [-0.0360],\n",
      "         [-0.0823],\n",
      "         [ 0.0821],\n",
      "         [-0.0857],\n",
      "         [ 0.0481],\n",
      "         [ 0.0343],\n",
      "         [-0.0528],\n",
      "         [ 0.0134],\n",
      "         [ 0.0417],\n",
      "         [-0.0928],\n",
      "         [-0.0130],\n",
      "         [ 0.0554],\n",
      "         [-0.0312],\n",
      "         [ 0.0116],\n",
      "         [ 0.0155],\n",
      "         [ 0.0551],\n",
      "         [ 0.0727],\n",
      "         [-0.0253],\n",
      "         [-0.1167],\n",
      "         [ 0.1088],\n",
      "         [-0.1221],\n",
      "         [-0.0389],\n",
      "         [-0.0158],\n",
      "         [ 0.1010],\n",
      "         [ 0.0542],\n",
      "         [ 0.0574],\n",
      "         [ 0.0711],\n",
      "         [ 0.0616],\n",
      "         [-0.0045]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.convr.bias | Size: torch.Size([64]) | Values : tensor([ 0.0583, -0.0351], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[ 9.1880e-02],\n",
      "         [-1.4375e-02],\n",
      "         [-1.0228e-03],\n",
      "         [ 8.6393e-02],\n",
      "         [ 9.8727e-02],\n",
      "         [ 5.3423e-02],\n",
      "         [ 1.5242e-02],\n",
      "         [ 1.1532e-01],\n",
      "         [ 8.8418e-02],\n",
      "         [-1.2487e-01],\n",
      "         [-1.1808e-02],\n",
      "         [-1.1438e-01],\n",
      "         [ 4.9577e-02],\n",
      "         [-3.5780e-02],\n",
      "         [ 3.2987e-02],\n",
      "         [ 1.7459e-02],\n",
      "         [ 8.1511e-02],\n",
      "         [ 5.3651e-02],\n",
      "         [ 3.6115e-02],\n",
      "         [ 1.7136e-02],\n",
      "         [-6.3178e-02],\n",
      "         [ 6.7511e-02],\n",
      "         [ 9.6072e-02],\n",
      "         [ 1.2195e-01],\n",
      "         [-5.9601e-02],\n",
      "         [-7.8725e-03],\n",
      "         [ 3.0231e-03],\n",
      "         [ 9.8835e-02],\n",
      "         [-1.0054e-01],\n",
      "         [-8.1971e-02],\n",
      "         [-9.3593e-02],\n",
      "         [-3.6493e-04],\n",
      "         [-2.6062e-02],\n",
      "         [ 5.3019e-02],\n",
      "         [-1.2295e-01],\n",
      "         [ 1.0782e-01],\n",
      "         [ 4.9783e-02],\n",
      "         [-3.9050e-02],\n",
      "         [-4.4584e-02],\n",
      "         [ 1.2001e-01],\n",
      "         [-4.0648e-02],\n",
      "         [-9.8137e-02],\n",
      "         [-1.0896e-01],\n",
      "         [-3.9643e-02],\n",
      "         [ 6.7304e-02],\n",
      "         [-4.2260e-02],\n",
      "         [ 5.2983e-02],\n",
      "         [ 9.3972e-02],\n",
      "         [ 9.2040e-02],\n",
      "         [ 5.0255e-02],\n",
      "         [-4.9768e-02],\n",
      "         [-6.2249e-03],\n",
      "         [ 1.1163e-01],\n",
      "         [-3.0289e-02],\n",
      "         [-1.1198e-01],\n",
      "         [ 1.2212e-01],\n",
      "         [-2.4530e-02],\n",
      "         [ 1.2282e-01],\n",
      "         [-1.0470e-01],\n",
      "         [ 9.8653e-02],\n",
      "         [ 6.3305e-02],\n",
      "         [-4.0809e-02],\n",
      "         [-2.8933e-03],\n",
      "         [-1.2435e-01]],\n",
      "\n",
      "        [[-7.8247e-02],\n",
      "         [ 3.5739e-02],\n",
      "         [ 5.8877e-02],\n",
      "         [-8.7159e-02],\n",
      "         [-1.1864e-02],\n",
      "         [-5.9675e-02],\n",
      "         [ 7.0281e-02],\n",
      "         [-3.5377e-02],\n",
      "         [-7.7887e-03],\n",
      "         [-1.7705e-02],\n",
      "         [-2.8909e-02],\n",
      "         [-9.9552e-02],\n",
      "         [-9.0539e-02],\n",
      "         [ 1.1425e-01],\n",
      "         [-8.1735e-02],\n",
      "         [-1.0295e-01],\n",
      "         [ 1.2513e-02],\n",
      "         [ 7.3054e-02],\n",
      "         [ 9.8888e-02],\n",
      "         [-1.0195e-02],\n",
      "         [-4.6051e-02],\n",
      "         [ 1.1340e-01],\n",
      "         [ 6.5251e-02],\n",
      "         [ 1.9827e-02],\n",
      "         [-8.4463e-02],\n",
      "         [ 8.1478e-02],\n",
      "         [-5.2489e-02],\n",
      "         [ 7.2250e-02],\n",
      "         [-9.4918e-02],\n",
      "         [ 4.5861e-02],\n",
      "         [-8.9373e-02],\n",
      "         [ 1.1832e-01],\n",
      "         [ 1.1411e-01],\n",
      "         [-3.4572e-02],\n",
      "         [-1.5433e-02],\n",
      "         [ 1.2534e-02],\n",
      "         [ 1.9891e-02],\n",
      "         [ 3.8311e-02],\n",
      "         [-9.2390e-02],\n",
      "         [ 2.1697e-02],\n",
      "         [-2.5095e-02],\n",
      "         [-1.1128e-01],\n",
      "         [ 6.5188e-02],\n",
      "         [ 8.0248e-02],\n",
      "         [ 1.4040e-02],\n",
      "         [ 5.9539e-02],\n",
      "         [-4.3631e-02],\n",
      "         [ 9.4144e-02],\n",
      "         [ 7.8902e-02],\n",
      "         [ 6.3389e-02],\n",
      "         [-1.0827e-01],\n",
      "         [-1.2416e-01],\n",
      "         [-1.1497e-01],\n",
      "         [-9.6106e-02],\n",
      "         [ 4.2474e-02],\n",
      "         [-6.1543e-02],\n",
      "         [-2.0015e-02],\n",
      "         [ 3.2244e-02],\n",
      "         [-4.0925e-02],\n",
      "         [ 3.1327e-03],\n",
      "         [-5.0736e-02],\n",
      "         [-6.5591e-02],\n",
      "         [-3.6001e-05],\n",
      "         [-5.6773e-02]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.conv1.bias | Size: torch.Size([16]) | Values : tensor([0.0200, 0.0022], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[-1.4354e-01, -1.2812e-01, -8.3200e-02],\n",
      "         [ 2.8099e-02,  1.3995e-01, -7.8371e-02],\n",
      "         [-5.0435e-02, -1.3053e-01, -2.9218e-02],\n",
      "         [ 2.9368e-02, -7.7198e-02,  1.3297e-01],\n",
      "         [-1.1378e-01, -2.6492e-02, -6.3877e-03],\n",
      "         [ 3.1429e-02, -1.7294e-02, -4.0776e-02],\n",
      "         [-1.0864e-01, -2.2291e-02,  1.1742e-01],\n",
      "         [-2.5791e-02,  9.3773e-05, -2.8007e-02],\n",
      "         [-1.2086e-02,  6.5121e-02, -1.3127e-01],\n",
      "         [-7.5416e-02,  6.5055e-02,  1.3133e-01],\n",
      "         [-1.3835e-02, -1.9494e-02, -1.9998e-03],\n",
      "         [-1.2337e-01,  9.1926e-02,  4.6638e-02],\n",
      "         [-1.1555e-01,  6.6547e-02, -5.6536e-03],\n",
      "         [ 6.9802e-02, -6.4155e-02, -1.1332e-01],\n",
      "         [-2.4114e-02,  1.2039e-01, -1.8518e-02],\n",
      "         [ 8.2431e-02,  3.0214e-02,  5.0283e-02]],\n",
      "\n",
      "        [[-5.6583e-02,  1.2572e-02,  5.6911e-04],\n",
      "         [-6.8073e-02,  1.3645e-01, -1.4649e-03],\n",
      "         [ 1.4403e-01, -3.0569e-02, -1.3524e-02],\n",
      "         [-1.1989e-01,  4.3694e-02,  9.9947e-02],\n",
      "         [-1.1535e-01, -4.0796e-02,  1.0977e-01],\n",
      "         [ 9.3610e-02,  7.3797e-02,  1.1276e-01],\n",
      "         [-8.0888e-02,  1.2701e-02, -1.3131e-01],\n",
      "         [ 3.9448e-02,  8.7523e-02, -1.7835e-02],\n",
      "         [-1.3820e-01,  7.0078e-02, -5.5351e-02],\n",
      "         [-9.8317e-02, -1.1434e-01, -1.6435e-02],\n",
      "         [ 9.6930e-02,  1.0538e-03,  1.1979e-01],\n",
      "         [-1.3179e-01,  1.1559e-01,  1.1902e-01],\n",
      "         [-7.5580e-02, -5.8415e-02,  7.1760e-03],\n",
      "         [ 2.4512e-03, -1.3788e-01, -2.0928e-02],\n",
      "         [-2.8779e-02, -1.1427e-01,  1.1351e-01],\n",
      "         [ 1.3340e-01, -7.0843e-02, -7.9420e-02]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.conv2.bias | Size: torch.Size([16]) | Values : tensor([-0.1116, -0.0826], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[ 1.5372e-01],\n",
      "         [ 8.7943e-02],\n",
      "         [ 1.4798e-01],\n",
      "         [ 7.8080e-02],\n",
      "         [ 6.3618e-02],\n",
      "         [-1.4895e-01],\n",
      "         [ 1.8476e-01],\n",
      "         [ 1.4392e-01],\n",
      "         [ 1.8010e-01],\n",
      "         [-9.5093e-02],\n",
      "         [-5.6548e-02],\n",
      "         [ 2.4278e-01],\n",
      "         [ 7.5383e-02],\n",
      "         [-2.0581e-01],\n",
      "         [ 3.6244e-03],\n",
      "         [ 4.1944e-02]],\n",
      "\n",
      "        [[-1.8305e-01],\n",
      "         [ 2.3765e-01],\n",
      "         [-1.7897e-01],\n",
      "         [-1.0411e-01],\n",
      "         [ 2.4731e-01],\n",
      "         [ 5.3175e-02],\n",
      "         [-2.1905e-01],\n",
      "         [ 2.2711e-01],\n",
      "         [ 1.4803e-02],\n",
      "         [ 1.6071e-01],\n",
      "         [ 7.1943e-05],\n",
      "         [ 4.7072e-02],\n",
      "         [ 2.5627e-02],\n",
      "         [ 1.3432e-01],\n",
      "         [ 1.9766e-01],\n",
      "         [ 2.4445e-03]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.conv3.bias | Size: torch.Size([64]) | Values : tensor([0.0173, 0.2030], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc.1.weight | Size: torch.Size([2, 704]) | Values : tensor([[ 0.0288, -0.0305,  0.0075,  ...,  0.0195, -0.0092, -0.0043],\n",
      "        [ 0.0144,  0.0026,  0.0130,  ..., -0.0370,  0.0102,  0.0002]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc.1.bias | Size: torch.Size([2]) | Values : tensor([ 0.0056, -0.0370], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from models.ResNet24 import ResNet24\n",
    "\n",
    "# Create an instance of the model\n",
    "model_resnet = ResNet24().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_resnet.parameters(), lr=learning_rate)\n",
    "# Initialize the scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=patience, verbose=True)\n",
    "print(f\"Model structure: {model_resnet}\\n\\n\")\n",
    "for name, param in model_resnet.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "loss: 1.372937  [   64/23290]\n",
      "loss: 0.051326  [ 6464/23290]\n",
      "loss: 0.069794  [12864/23290]\n",
      "loss: 0.351553  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.088575 \n",
      "\n",
      "Epoch 1:\n",
      "loss: 0.121594  [   64/23290]\n",
      "loss: 0.161675  [ 6464/23290]\n",
      "loss: 0.168580  [12864/23290]\n",
      "loss: 0.386021  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.071978 \n",
      "\n",
      "Epoch 2:\n",
      "loss: 0.083918  [   64/23290]\n",
      "loss: 0.066072  [ 6464/23290]\n",
      "loss: 0.043095  [12864/23290]\n",
      "loss: 0.160842  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.070012 \n",
      "\n",
      "Epoch 3:\n",
      "loss: 0.048979  [   64/23290]\n",
      "loss: 0.182078  [ 6464/23290]\n",
      "loss: 0.078956  [12864/23290]\n",
      "loss: 0.081511  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.078104 \n",
      "\n",
      "Epoch 4:\n",
      "loss: 0.070805  [   64/23290]\n",
      "loss: 0.061576  [ 6464/23290]\n",
      "loss: 0.016617  [12864/23290]\n",
      "loss: 0.231080  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.048517 \n",
      "\n",
      "Epoch 5:\n",
      "loss: 0.210002  [   64/23290]\n",
      "loss: 0.131951  [ 6464/23290]\n",
      "loss: 0.559788  [12864/23290]\n",
      "loss: 0.241953  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.051215 \n",
      "\n",
      "Epoch 6:\n",
      "loss: 0.038955  [   64/23290]\n",
      "loss: 0.193390  [ 6464/23290]\n",
      "loss: 0.043909  [12864/23290]\n",
      "loss: 0.247401  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.042972 \n",
      "\n",
      "Epoch 7:\n",
      "loss: 0.119031  [   64/23290]\n",
      "loss: 0.604144  [ 6464/23290]\n",
      "loss: 0.019023  [12864/23290]\n",
      "loss: 0.090766  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.051223 \n",
      "\n",
      "Epoch 8:\n",
      "loss: 0.025295  [   64/23290]\n",
      "loss: 0.035854  [ 6464/23290]\n",
      "loss: 0.019519  [12864/23290]\n",
      "loss: 0.061390  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.062806 \n",
      "\n",
      "Epoch 9:\n",
      "loss: 0.059701  [   64/23290]\n",
      "loss: 0.009115  [ 6464/23290]\n",
      "loss: 0.081307  [12864/23290]\n",
      "loss: 0.115580  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.049947 \n",
      "\n",
      "Epoch 10:\n",
      "loss: 0.035815  [   64/23290]\n",
      "loss: 0.042042  [ 6464/23290]\n",
      "loss: 0.122105  [12864/23290]\n",
      "loss: 0.283042  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.043769 \n",
      "\n",
      "Epoch 11:\n",
      "loss: 0.034339  [   64/23290]\n",
      "loss: 0.169212  [ 6464/23290]\n",
      "loss: 0.045218  [12864/23290]\n",
      "loss: 0.027759  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.059080 \n",
      "\n",
      "Early stopping due to no improvement in validation loss.\n"
     ]
    }
   ],
   "source": [
    "train(train_dataloader, model_resnet, loss_fn, optimizer,val_dataloader, \n",
    "        patience=patience, scheduler=scheduler, device=device, epochs=epochs, B_size=B_size, A_size=A_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.835674 \n",
      "\n",
      " Label 0\n",
      "    accuracy\t0.839\n",
      " specificity\t0.677\n",
      " sensitivity\t1.000\n",
      " Label 1\n",
      "    accuracy\t0.839\n",
      " specificity\t1.000\n",
      " sensitivity\t0.677\n",
      "[[31  0]\n",
      " [10 21]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# final test\n",
    "test(test_dataloader, model_resnet, loss_fn, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TinyFallNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=16, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding='same')\n",
    "        self.bn2 = nn.BatchNorm1d(16)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=64, kernel_size=1)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.convr = nn.Conv1d(in_channels=in_channels, out_channels=64, kernel_size=1)\n",
    "    def forward(self, input):\n",
    "        residual = self.convr(input)\n",
    "        x = self.conv1(input)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x += residual\n",
    "        x = self.relu3(x)\n",
    "        return x\n",
    "\n",
    "class TinyFallNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TinyFallNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=9, out_channels=64, kernel_size=3)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.convblk1 = ConvBlock(64)\n",
    "        self.convblk2 = ConvBlock(64)\n",
    "        self.convblk3 = ConvBlock(64)\n",
    "        self.convblk4 = ConvBlock(64)\n",
    "        \n",
    "        self.pool2 = nn.AvgPool1d(2)\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.Flatten(),\n",
    "                                nn.Linear(in_features=768, out_features=2),\n",
    "                                nn.Softmax())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.convblk1(x)\n",
    "        x = self.convblk2(x)\n",
    "        x = self.convblk3(x)\n",
    "        x = self.convblk4(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: TinyFallNet(\n",
      "  (conv1): Conv1d(9, 64, kernel_size=(3,), stride=(1,))\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (convblk1): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (convblk2): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (convblk3): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (convblk4): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (pool2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
      "  (fc): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=768, out_features=2, bias=True)\n",
      "    (2): Softmax(dim=None)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: conv1.weight | Size: torch.Size([64, 9, 3]) | Values : tensor([[[-0.0750,  0.1589, -0.1657],\n",
      "         [-0.0295,  0.0671,  0.1055],\n",
      "         [-0.1272,  0.1911,  0.0734],\n",
      "         [ 0.0240, -0.1226,  0.1451],\n",
      "         [ 0.0156, -0.0270, -0.1890],\n",
      "         [-0.0245,  0.0154, -0.0644],\n",
      "         [ 0.0743,  0.0181,  0.0670],\n",
      "         [-0.1418, -0.0791,  0.0301],\n",
      "         [-0.0880, -0.0973, -0.0092]],\n",
      "\n",
      "        [[ 0.0684,  0.0912, -0.1415],\n",
      "         [ 0.1526, -0.1618,  0.1475],\n",
      "         [-0.0571,  0.1131, -0.0075],\n",
      "         [-0.1629, -0.1026,  0.0392],\n",
      "         [-0.0639,  0.1318, -0.0841],\n",
      "         [-0.0191, -0.1093,  0.0695],\n",
      "         [-0.0236,  0.0931,  0.1423],\n",
      "         [ 0.0421,  0.0686,  0.1450],\n",
      "         [ 0.1166,  0.0265, -0.1520]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.bias | Size: torch.Size([64]) | Values : tensor([ 0.1026, -0.1774], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[ 0.0039],\n",
      "         [-0.1104],\n",
      "         [-0.0967],\n",
      "         [ 0.0389],\n",
      "         [-0.0151],\n",
      "         [ 0.0295],\n",
      "         [-0.1245],\n",
      "         [ 0.0426],\n",
      "         [ 0.0445],\n",
      "         [ 0.0771],\n",
      "         [ 0.0044],\n",
      "         [ 0.1013],\n",
      "         [-0.1077],\n",
      "         [-0.0331],\n",
      "         [-0.0589],\n",
      "         [-0.0843],\n",
      "         [-0.1171],\n",
      "         [ 0.1011],\n",
      "         [-0.0852],\n",
      "         [ 0.1201],\n",
      "         [ 0.0136],\n",
      "         [-0.0401],\n",
      "         [-0.0932],\n",
      "         [-0.0323],\n",
      "         [ 0.0447],\n",
      "         [ 0.0429],\n",
      "         [-0.0038],\n",
      "         [ 0.0444],\n",
      "         [-0.0315],\n",
      "         [-0.0733],\n",
      "         [ 0.1072],\n",
      "         [-0.0162],\n",
      "         [ 0.0798],\n",
      "         [ 0.0009],\n",
      "         [ 0.0681],\n",
      "         [-0.0853],\n",
      "         [-0.0248],\n",
      "         [ 0.0725],\n",
      "         [-0.1032],\n",
      "         [ 0.0189],\n",
      "         [ 0.0679],\n",
      "         [-0.0430],\n",
      "         [ 0.0310],\n",
      "         [ 0.0910],\n",
      "         [ 0.0101],\n",
      "         [ 0.1007],\n",
      "         [ 0.1225],\n",
      "         [ 0.0419],\n",
      "         [-0.0392],\n",
      "         [-0.0034],\n",
      "         [-0.0014],\n",
      "         [ 0.0574],\n",
      "         [ 0.0386],\n",
      "         [-0.0020],\n",
      "         [ 0.0818],\n",
      "         [ 0.0219],\n",
      "         [-0.0014],\n",
      "         [-0.0457],\n",
      "         [ 0.0567],\n",
      "         [-0.0748],\n",
      "         [-0.1239],\n",
      "         [ 0.0085],\n",
      "         [-0.0028],\n",
      "         [-0.0783]],\n",
      "\n",
      "        [[-0.0046],\n",
      "         [ 0.0794],\n",
      "         [-0.0083],\n",
      "         [ 0.0922],\n",
      "         [ 0.0421],\n",
      "         [ 0.0875],\n",
      "         [ 0.0639],\n",
      "         [-0.1205],\n",
      "         [-0.0013],\n",
      "         [ 0.1122],\n",
      "         [ 0.0659],\n",
      "         [ 0.0588],\n",
      "         [-0.1092],\n",
      "         [-0.0614],\n",
      "         [-0.0556],\n",
      "         [ 0.0673],\n",
      "         [ 0.0956],\n",
      "         [ 0.0980],\n",
      "         [ 0.0149],\n",
      "         [-0.0397],\n",
      "         [ 0.0236],\n",
      "         [ 0.0396],\n",
      "         [-0.0575],\n",
      "         [-0.0028],\n",
      "         [-0.0324],\n",
      "         [-0.0635],\n",
      "         [-0.0477],\n",
      "         [-0.0929],\n",
      "         [ 0.0083],\n",
      "         [ 0.1023],\n",
      "         [ 0.1146],\n",
      "         [-0.0686],\n",
      "         [ 0.0939],\n",
      "         [ 0.1203],\n",
      "         [ 0.0352],\n",
      "         [ 0.0098],\n",
      "         [ 0.0794],\n",
      "         [ 0.1234],\n",
      "         [-0.1235],\n",
      "         [-0.0045],\n",
      "         [-0.0762],\n",
      "         [-0.0753],\n",
      "         [ 0.0840],\n",
      "         [ 0.0653],\n",
      "         [-0.0064],\n",
      "         [ 0.0715],\n",
      "         [ 0.1099],\n",
      "         [ 0.1130],\n",
      "         [ 0.0610],\n",
      "         [-0.0207],\n",
      "         [ 0.0409],\n",
      "         [-0.0227],\n",
      "         [ 0.1230],\n",
      "         [ 0.0248],\n",
      "         [ 0.1056],\n",
      "         [-0.0388],\n",
      "         [ 0.0408],\n",
      "         [-0.0599],\n",
      "         [-0.0597],\n",
      "         [ 0.0089],\n",
      "         [-0.0280],\n",
      "         [ 0.0548],\n",
      "         [ 0.0765],\n",
      "         [-0.0661]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv1.bias | Size: torch.Size([16]) | Values : tensor([ 0.0676, -0.0914], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[ 0.1352,  0.0212, -0.0852],\n",
      "         [-0.0352,  0.0744, -0.1183],\n",
      "         [ 0.0293, -0.1053, -0.0072],\n",
      "         [ 0.0444, -0.1416,  0.1256],\n",
      "         [-0.0144,  0.0643,  0.0649],\n",
      "         [-0.0836, -0.1065,  0.0891],\n",
      "         [-0.1011,  0.1020,  0.1063],\n",
      "         [-0.1137, -0.0204, -0.0498],\n",
      "         [ 0.0838, -0.0306,  0.0838],\n",
      "         [ 0.0229, -0.0247,  0.0099],\n",
      "         [-0.1015,  0.1370, -0.1382],\n",
      "         [-0.1328,  0.1135,  0.0095],\n",
      "         [ 0.1143,  0.1425, -0.0839],\n",
      "         [-0.0157, -0.0060, -0.0390],\n",
      "         [ 0.0960, -0.0185,  0.0669],\n",
      "         [ 0.1259,  0.0446,  0.0156]],\n",
      "\n",
      "        [[ 0.0154, -0.0665,  0.0737],\n",
      "         [ 0.0128, -0.0251,  0.0218],\n",
      "         [ 0.0630,  0.0221,  0.0987],\n",
      "         [ 0.0675, -0.1007,  0.0567],\n",
      "         [-0.0835, -0.1164,  0.0384],\n",
      "         [-0.0711, -0.0806,  0.1405],\n",
      "         [-0.1165, -0.0075,  0.0697],\n",
      "         [ 0.0306, -0.0995,  0.0264],\n",
      "         [ 0.0021,  0.0242,  0.0010],\n",
      "         [-0.0281, -0.0460,  0.0399],\n",
      "         [-0.1379, -0.0269, -0.0934],\n",
      "         [-0.1110, -0.0919,  0.1100],\n",
      "         [-0.1441,  0.0551, -0.1367],\n",
      "         [ 0.0590, -0.0688,  0.0089],\n",
      "         [ 0.0642, -0.1210,  0.1146],\n",
      "         [ 0.0518, -0.1028,  0.0329]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv2.bias | Size: torch.Size([16]) | Values : tensor([ 0.0220, -0.0669], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[-0.1189],\n",
      "         [ 0.2466],\n",
      "         [-0.0692],\n",
      "         [-0.2327],\n",
      "         [-0.0512],\n",
      "         [ 0.2396],\n",
      "         [ 0.2423],\n",
      "         [ 0.1255],\n",
      "         [ 0.0145],\n",
      "         [ 0.0750],\n",
      "         [-0.2201],\n",
      "         [-0.0594],\n",
      "         [ 0.0288],\n",
      "         [-0.2246],\n",
      "         [-0.1262],\n",
      "         [ 0.2163]],\n",
      "\n",
      "        [[ 0.0188],\n",
      "         [ 0.1010],\n",
      "         [-0.0121],\n",
      "         [ 0.1653],\n",
      "         [-0.2427],\n",
      "         [-0.1243],\n",
      "         [ 0.1657],\n",
      "         [-0.1953],\n",
      "         [ 0.0856],\n",
      "         [ 0.1430],\n",
      "         [-0.0319],\n",
      "         [ 0.1290],\n",
      "         [ 0.0604],\n",
      "         [-0.1089],\n",
      "         [ 0.1861],\n",
      "         [ 0.1993]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv3.bias | Size: torch.Size([64]) | Values : tensor([0.1329, 0.1901], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[ 0.0680],\n",
      "         [-0.0137],\n",
      "         [-0.0138],\n",
      "         [-0.0996],\n",
      "         [-0.0638],\n",
      "         [ 0.0889],\n",
      "         [-0.1013],\n",
      "         [ 0.0741],\n",
      "         [ 0.1194],\n",
      "         [ 0.0459],\n",
      "         [ 0.0504],\n",
      "         [-0.0449],\n",
      "         [-0.0847],\n",
      "         [ 0.0142],\n",
      "         [ 0.0288],\n",
      "         [ 0.1190],\n",
      "         [-0.0075],\n",
      "         [ 0.0053],\n",
      "         [ 0.0208],\n",
      "         [ 0.0553],\n",
      "         [ 0.1130],\n",
      "         [ 0.0295],\n",
      "         [-0.0441],\n",
      "         [ 0.0238],\n",
      "         [ 0.0370],\n",
      "         [-0.0159],\n",
      "         [-0.0011],\n",
      "         [ 0.0753],\n",
      "         [-0.0492],\n",
      "         [-0.0912],\n",
      "         [-0.0099],\n",
      "         [ 0.1091],\n",
      "         [-0.0980],\n",
      "         [ 0.0452],\n",
      "         [ 0.0193],\n",
      "         [-0.0360],\n",
      "         [-0.0800],\n",
      "         [-0.1059],\n",
      "         [ 0.0989],\n",
      "         [-0.0291],\n",
      "         [ 0.0849],\n",
      "         [ 0.0661],\n",
      "         [ 0.0247],\n",
      "         [-0.1179],\n",
      "         [ 0.0518],\n",
      "         [ 0.0645],\n",
      "         [-0.0623],\n",
      "         [-0.0562],\n",
      "         [ 0.0245],\n",
      "         [ 0.1074],\n",
      "         [ 0.1124],\n",
      "         [ 0.0175],\n",
      "         [-0.0181],\n",
      "         [ 0.0463],\n",
      "         [ 0.1054],\n",
      "         [ 0.1178],\n",
      "         [ 0.0222],\n",
      "         [-0.0757],\n",
      "         [ 0.0856],\n",
      "         [ 0.0467],\n",
      "         [ 0.0085],\n",
      "         [ 0.1175],\n",
      "         [ 0.0418],\n",
      "         [-0.0953]],\n",
      "\n",
      "        [[ 0.0776],\n",
      "         [-0.1082],\n",
      "         [ 0.0372],\n",
      "         [-0.0462],\n",
      "         [ 0.1073],\n",
      "         [-0.0792],\n",
      "         [ 0.0909],\n",
      "         [ 0.1106],\n",
      "         [ 0.0910],\n",
      "         [-0.0304],\n",
      "         [-0.1229],\n",
      "         [-0.0050],\n",
      "         [-0.0884],\n",
      "         [-0.0681],\n",
      "         [-0.1060],\n",
      "         [ 0.0376],\n",
      "         [-0.0828],\n",
      "         [-0.0211],\n",
      "         [-0.0494],\n",
      "         [ 0.0878],\n",
      "         [-0.0528],\n",
      "         [-0.1126],\n",
      "         [-0.0340],\n",
      "         [-0.0072],\n",
      "         [-0.0788],\n",
      "         [-0.0308],\n",
      "         [-0.1230],\n",
      "         [-0.0926],\n",
      "         [ 0.0898],\n",
      "         [-0.0181],\n",
      "         [ 0.0199],\n",
      "         [-0.0108],\n",
      "         [-0.0318],\n",
      "         [-0.0138],\n",
      "         [-0.0615],\n",
      "         [ 0.0750],\n",
      "         [-0.0376],\n",
      "         [ 0.0312],\n",
      "         [ 0.1032],\n",
      "         [-0.0138],\n",
      "         [-0.0978],\n",
      "         [ 0.0757],\n",
      "         [-0.1158],\n",
      "         [-0.0655],\n",
      "         [-0.1111],\n",
      "         [ 0.0953],\n",
      "         [ 0.0342],\n",
      "         [-0.1010],\n",
      "         [ 0.0579],\n",
      "         [-0.1179],\n",
      "         [-0.0844],\n",
      "         [-0.0446],\n",
      "         [ 0.0177],\n",
      "         [-0.1241],\n",
      "         [ 0.0557],\n",
      "         [ 0.0982],\n",
      "         [-0.0530],\n",
      "         [ 0.0729],\n",
      "         [ 0.0074],\n",
      "         [ 0.1058],\n",
      "         [-0.0547],\n",
      "         [-0.0393],\n",
      "         [-0.0484],\n",
      "         [ 0.1079]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.convr.bias | Size: torch.Size([64]) | Values : tensor([-0.0965,  0.1052], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[-0.0664],\n",
      "         [ 0.1162],\n",
      "         [ 0.0191],\n",
      "         [-0.0752],\n",
      "         [ 0.0432],\n",
      "         [-0.0988],\n",
      "         [-0.0717],\n",
      "         [-0.0429],\n",
      "         [-0.0148],\n",
      "         [ 0.0738],\n",
      "         [ 0.0634],\n",
      "         [-0.0938],\n",
      "         [ 0.0191],\n",
      "         [-0.0586],\n",
      "         [-0.0648],\n",
      "         [ 0.1144],\n",
      "         [-0.0104],\n",
      "         [ 0.0951],\n",
      "         [-0.1009],\n",
      "         [-0.0869],\n",
      "         [ 0.0160],\n",
      "         [ 0.0898],\n",
      "         [ 0.0914],\n",
      "         [-0.0595],\n",
      "         [ 0.1121],\n",
      "         [ 0.0045],\n",
      "         [ 0.0151],\n",
      "         [-0.1206],\n",
      "         [ 0.0713],\n",
      "         [ 0.1232],\n",
      "         [ 0.0444],\n",
      "         [ 0.0708],\n",
      "         [-0.0224],\n",
      "         [ 0.0965],\n",
      "         [-0.1198],\n",
      "         [-0.0625],\n",
      "         [-0.1189],\n",
      "         [ 0.0564],\n",
      "         [ 0.0413],\n",
      "         [-0.0364],\n",
      "         [ 0.0337],\n",
      "         [-0.0959],\n",
      "         [-0.0038],\n",
      "         [ 0.0005],\n",
      "         [ 0.0716],\n",
      "         [ 0.0565],\n",
      "         [-0.0127],\n",
      "         [ 0.1141],\n",
      "         [ 0.1206],\n",
      "         [-0.0597],\n",
      "         [ 0.1223],\n",
      "         [ 0.0316],\n",
      "         [ 0.0610],\n",
      "         [ 0.0911],\n",
      "         [ 0.1229],\n",
      "         [-0.0448],\n",
      "         [-0.0398],\n",
      "         [ 0.0169],\n",
      "         [-0.0892],\n",
      "         [-0.0684],\n",
      "         [ 0.0966],\n",
      "         [-0.0348],\n",
      "         [-0.0232],\n",
      "         [-0.0277]],\n",
      "\n",
      "        [[-0.0655],\n",
      "         [-0.0136],\n",
      "         [ 0.0578],\n",
      "         [ 0.1242],\n",
      "         [ 0.0167],\n",
      "         [-0.0735],\n",
      "         [-0.1181],\n",
      "         [ 0.0874],\n",
      "         [ 0.0382],\n",
      "         [ 0.0501],\n",
      "         [ 0.0107],\n",
      "         [-0.1062],\n",
      "         [ 0.0660],\n",
      "         [-0.0495],\n",
      "         [-0.0383],\n",
      "         [-0.0258],\n",
      "         [ 0.0523],\n",
      "         [ 0.0100],\n",
      "         [ 0.0722],\n",
      "         [-0.0552],\n",
      "         [-0.0650],\n",
      "         [-0.0747],\n",
      "         [-0.0609],\n",
      "         [-0.1015],\n",
      "         [ 0.0753],\n",
      "         [ 0.0960],\n",
      "         [ 0.1066],\n",
      "         [ 0.0829],\n",
      "         [ 0.0571],\n",
      "         [-0.1063],\n",
      "         [ 0.0908],\n",
      "         [ 0.0949],\n",
      "         [-0.0538],\n",
      "         [ 0.0472],\n",
      "         [ 0.0627],\n",
      "         [ 0.0606],\n",
      "         [ 0.1226],\n",
      "         [ 0.0298],\n",
      "         [-0.1249],\n",
      "         [-0.0090],\n",
      "         [-0.0120],\n",
      "         [-0.0790],\n",
      "         [ 0.0990],\n",
      "         [ 0.0816],\n",
      "         [ 0.0544],\n",
      "         [-0.0299],\n",
      "         [ 0.0722],\n",
      "         [-0.0951],\n",
      "         [ 0.0958],\n",
      "         [ 0.0239],\n",
      "         [ 0.0418],\n",
      "         [ 0.0696],\n",
      "         [ 0.0931],\n",
      "         [-0.0442],\n",
      "         [-0.1193],\n",
      "         [ 0.1210],\n",
      "         [-0.0502],\n",
      "         [ 0.0916],\n",
      "         [-0.0273],\n",
      "         [ 0.0451],\n",
      "         [-0.0205],\n",
      "         [-0.0130],\n",
      "         [-0.0228],\n",
      "         [-0.0654]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv1.bias | Size: torch.Size([16]) | Values : tensor([0.0763, 0.0384], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[-0.0879, -0.0650, -0.0354],\n",
      "         [-0.0214, -0.0415,  0.0230],\n",
      "         [-0.1407,  0.0985, -0.0039],\n",
      "         [ 0.0356,  0.0100,  0.1314],\n",
      "         [-0.0049, -0.1215, -0.1180],\n",
      "         [ 0.1215, -0.0903, -0.0242],\n",
      "         [-0.0889,  0.0148, -0.0072],\n",
      "         [ 0.0725,  0.0657, -0.1123],\n",
      "         [-0.0663,  0.0632,  0.1017],\n",
      "         [-0.0440, -0.1078, -0.1219],\n",
      "         [ 0.0894, -0.0117,  0.0597],\n",
      "         [ 0.1258,  0.1088, -0.0291],\n",
      "         [ 0.0980,  0.0702,  0.0241],\n",
      "         [ 0.0035,  0.0429, -0.0832],\n",
      "         [-0.0293, -0.0874, -0.1176],\n",
      "         [-0.1296, -0.0120,  0.0690]],\n",
      "\n",
      "        [[-0.1018,  0.0277,  0.1179],\n",
      "         [-0.0929, -0.1365,  0.0658],\n",
      "         [ 0.0643, -0.1087, -0.0339],\n",
      "         [ 0.0963, -0.0053, -0.0905],\n",
      "         [-0.0075,  0.0658,  0.1100],\n",
      "         [ 0.0161, -0.0770, -0.0590],\n",
      "         [-0.1191, -0.1040, -0.0486],\n",
      "         [-0.0879, -0.1329,  0.1203],\n",
      "         [ 0.0069, -0.0068, -0.0537],\n",
      "         [-0.0104, -0.0965, -0.1076],\n",
      "         [ 0.0428, -0.0244,  0.0598],\n",
      "         [-0.0914,  0.0508, -0.1029],\n",
      "         [-0.0255, -0.0365, -0.1271],\n",
      "         [ 0.1434,  0.0878,  0.1122],\n",
      "         [-0.0087, -0.0927, -0.0067],\n",
      "         [-0.0556,  0.0432, -0.1405]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv2.bias | Size: torch.Size([16]) | Values : tensor([-0.1046,  0.1255], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[-0.1589],\n",
      "         [ 0.1523],\n",
      "         [ 0.0593],\n",
      "         [ 0.0832],\n",
      "         [ 0.1178],\n",
      "         [ 0.1771],\n",
      "         [-0.1761],\n",
      "         [-0.1047],\n",
      "         [-0.0636],\n",
      "         [ 0.0297],\n",
      "         [-0.2056],\n",
      "         [ 0.1071],\n",
      "         [ 0.1245],\n",
      "         [ 0.1786],\n",
      "         [ 0.2079],\n",
      "         [-0.1335]],\n",
      "\n",
      "        [[-0.0010],\n",
      "         [ 0.0606],\n",
      "         [ 0.0538],\n",
      "         [ 0.0085],\n",
      "         [-0.1711],\n",
      "         [ 0.0481],\n",
      "         [-0.1588],\n",
      "         [-0.1155],\n",
      "         [ 0.2098],\n",
      "         [ 0.2144],\n",
      "         [ 0.0016],\n",
      "         [ 0.0690],\n",
      "         [ 0.1554],\n",
      "         [-0.2132],\n",
      "         [ 0.0670],\n",
      "         [-0.2025]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv3.bias | Size: torch.Size([64]) | Values : tensor([0.0537, 0.1150], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[ 0.0213],\n",
      "         [ 0.0937],\n",
      "         [-0.0296],\n",
      "         [ 0.1168],\n",
      "         [-0.1056],\n",
      "         [ 0.0809],\n",
      "         [-0.0555],\n",
      "         [-0.0314],\n",
      "         [-0.1104],\n",
      "         [ 0.0397],\n",
      "         [-0.0090],\n",
      "         [-0.1036],\n",
      "         [ 0.1228],\n",
      "         [-0.0851],\n",
      "         [ 0.0861],\n",
      "         [-0.0661],\n",
      "         [ 0.1248],\n",
      "         [ 0.0004],\n",
      "         [ 0.0943],\n",
      "         [ 0.1095],\n",
      "         [ 0.0910],\n",
      "         [-0.1045],\n",
      "         [ 0.0418],\n",
      "         [ 0.0581],\n",
      "         [-0.0586],\n",
      "         [-0.0652],\n",
      "         [-0.1100],\n",
      "         [ 0.0441],\n",
      "         [-0.0189],\n",
      "         [-0.0630],\n",
      "         [ 0.1230],\n",
      "         [ 0.0318],\n",
      "         [-0.0965],\n",
      "         [ 0.0993],\n",
      "         [-0.1071],\n",
      "         [ 0.0249],\n",
      "         [ 0.0229],\n",
      "         [-0.0032],\n",
      "         [-0.0375],\n",
      "         [ 0.0400],\n",
      "         [-0.0732],\n",
      "         [-0.0056],\n",
      "         [ 0.0007],\n",
      "         [-0.0363],\n",
      "         [-0.1074],\n",
      "         [-0.0978],\n",
      "         [ 0.0359],\n",
      "         [ 0.0665],\n",
      "         [ 0.0205],\n",
      "         [-0.0243],\n",
      "         [ 0.1025],\n",
      "         [-0.1232],\n",
      "         [-0.1163],\n",
      "         [-0.0452],\n",
      "         [-0.0090],\n",
      "         [-0.0649],\n",
      "         [ 0.1217],\n",
      "         [-0.0214],\n",
      "         [ 0.1039],\n",
      "         [-0.0438],\n",
      "         [-0.0598],\n",
      "         [ 0.1092],\n",
      "         [ 0.0961],\n",
      "         [ 0.0213]],\n",
      "\n",
      "        [[ 0.0184],\n",
      "         [ 0.0701],\n",
      "         [-0.0597],\n",
      "         [-0.0033],\n",
      "         [-0.1096],\n",
      "         [ 0.0196],\n",
      "         [-0.0756],\n",
      "         [-0.0759],\n",
      "         [-0.1142],\n",
      "         [-0.0039],\n",
      "         [ 0.0681],\n",
      "         [ 0.0016],\n",
      "         [-0.1087],\n",
      "         [-0.0301],\n",
      "         [-0.0921],\n",
      "         [ 0.1108],\n",
      "         [ 0.1019],\n",
      "         [-0.0075],\n",
      "         [-0.0985],\n",
      "         [ 0.0509],\n",
      "         [ 0.0863],\n",
      "         [ 0.1044],\n",
      "         [-0.0539],\n",
      "         [-0.0338],\n",
      "         [ 0.0197],\n",
      "         [ 0.0664],\n",
      "         [-0.0773],\n",
      "         [-0.1064],\n",
      "         [ 0.0575],\n",
      "         [ 0.0002],\n",
      "         [-0.0274],\n",
      "         [ 0.0479],\n",
      "         [ 0.0965],\n",
      "         [ 0.0305],\n",
      "         [ 0.0728],\n",
      "         [ 0.0611],\n",
      "         [ 0.0689],\n",
      "         [ 0.1123],\n",
      "         [-0.0108],\n",
      "         [-0.0658],\n",
      "         [-0.0489],\n",
      "         [-0.1016],\n",
      "         [ 0.1244],\n",
      "         [ 0.1023],\n",
      "         [-0.0858],\n",
      "         [-0.0259],\n",
      "         [-0.0021],\n",
      "         [-0.0935],\n",
      "         [-0.0512],\n",
      "         [ 0.0012],\n",
      "         [ 0.1165],\n",
      "         [ 0.0978],\n",
      "         [ 0.0135],\n",
      "         [ 0.1070],\n",
      "         [ 0.0983],\n",
      "         [ 0.0895],\n",
      "         [ 0.1123],\n",
      "         [ 0.0045],\n",
      "         [ 0.1230],\n",
      "         [ 0.0539],\n",
      "         [-0.0256],\n",
      "         [-0.0219],\n",
      "         [ 0.1157],\n",
      "         [-0.1008]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.convr.bias | Size: torch.Size([64]) | Values : tensor([-0.0849,  0.0840], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[-0.0268],\n",
      "         [ 0.0942],\n",
      "         [ 0.0738],\n",
      "         [ 0.0023],\n",
      "         [-0.1217],\n",
      "         [-0.0468],\n",
      "         [ 0.0756],\n",
      "         [ 0.0988],\n",
      "         [ 0.0189],\n",
      "         [-0.0659],\n",
      "         [ 0.1045],\n",
      "         [-0.0268],\n",
      "         [ 0.0769],\n",
      "         [-0.0226],\n",
      "         [-0.0751],\n",
      "         [-0.0181],\n",
      "         [ 0.0338],\n",
      "         [-0.0264],\n",
      "         [-0.0376],\n",
      "         [-0.0273],\n",
      "         [ 0.0929],\n",
      "         [-0.0722],\n",
      "         [ 0.0697],\n",
      "         [ 0.0761],\n",
      "         [-0.0472],\n",
      "         [-0.0329],\n",
      "         [-0.0858],\n",
      "         [ 0.0917],\n",
      "         [ 0.0114],\n",
      "         [ 0.0375],\n",
      "         [ 0.0636],\n",
      "         [ 0.1041],\n",
      "         [ 0.0830],\n",
      "         [ 0.1119],\n",
      "         [ 0.0567],\n",
      "         [-0.1248],\n",
      "         [ 0.0546],\n",
      "         [-0.1096],\n",
      "         [ 0.0592],\n",
      "         [-0.0169],\n",
      "         [ 0.0332],\n",
      "         [ 0.0666],\n",
      "         [-0.1016],\n",
      "         [ 0.1086],\n",
      "         [ 0.0678],\n",
      "         [-0.0836],\n",
      "         [-0.0488],\n",
      "         [ 0.0517],\n",
      "         [ 0.0456],\n",
      "         [ 0.1020],\n",
      "         [-0.0169],\n",
      "         [-0.0590],\n",
      "         [ 0.0283],\n",
      "         [ 0.0069],\n",
      "         [ 0.0339],\n",
      "         [-0.0728],\n",
      "         [ 0.0715],\n",
      "         [-0.1139],\n",
      "         [-0.0436],\n",
      "         [ 0.0952],\n",
      "         [-0.0802],\n",
      "         [-0.0676],\n",
      "         [-0.0274],\n",
      "         [-0.0722]],\n",
      "\n",
      "        [[-0.1081],\n",
      "         [ 0.0044],\n",
      "         [ 0.0173],\n",
      "         [-0.1033],\n",
      "         [ 0.0053],\n",
      "         [-0.1041],\n",
      "         [ 0.0674],\n",
      "         [ 0.1131],\n",
      "         [-0.1235],\n",
      "         [-0.0960],\n",
      "         [-0.0633],\n",
      "         [ 0.1082],\n",
      "         [-0.0703],\n",
      "         [-0.0545],\n",
      "         [-0.0230],\n",
      "         [-0.0052],\n",
      "         [-0.0255],\n",
      "         [-0.0117],\n",
      "         [ 0.0097],\n",
      "         [ 0.0655],\n",
      "         [ 0.0028],\n",
      "         [ 0.0782],\n",
      "         [ 0.0911],\n",
      "         [-0.0006],\n",
      "         [-0.0958],\n",
      "         [-0.0355],\n",
      "         [ 0.1140],\n",
      "         [-0.1007],\n",
      "         [-0.0316],\n",
      "         [ 0.0275],\n",
      "         [ 0.1089],\n",
      "         [-0.1188],\n",
      "         [-0.0593],\n",
      "         [-0.0599],\n",
      "         [-0.0210],\n",
      "         [ 0.0603],\n",
      "         [-0.0611],\n",
      "         [-0.0318],\n",
      "         [ 0.0291],\n",
      "         [-0.1099],\n",
      "         [-0.0550],\n",
      "         [-0.0992],\n",
      "         [ 0.0548],\n",
      "         [ 0.0771],\n",
      "         [ 0.0230],\n",
      "         [-0.1141],\n",
      "         [-0.0631],\n",
      "         [ 0.0549],\n",
      "         [ 0.0609],\n",
      "         [ 0.0754],\n",
      "         [ 0.0133],\n",
      "         [-0.0723],\n",
      "         [ 0.1029],\n",
      "         [ 0.0488],\n",
      "         [ 0.1010],\n",
      "         [-0.1048],\n",
      "         [ 0.0271],\n",
      "         [ 0.1018],\n",
      "         [ 0.1026],\n",
      "         [-0.0252],\n",
      "         [-0.1196],\n",
      "         [-0.1048],\n",
      "         [ 0.0363],\n",
      "         [ 0.0674]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv1.bias | Size: torch.Size([16]) | Values : tensor([-0.0226,  0.0574], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[ 0.0354, -0.0034,  0.0429],\n",
      "         [ 0.0827, -0.0186, -0.1294],\n",
      "         [ 0.0763,  0.0318, -0.0187],\n",
      "         [-0.0440, -0.0574, -0.0347],\n",
      "         [ 0.0664,  0.1297, -0.0498],\n",
      "         [-0.0842,  0.0759, -0.0017],\n",
      "         [ 0.1362,  0.0717, -0.1427],\n",
      "         [ 0.1008,  0.0333,  0.1047],\n",
      "         [ 0.0857,  0.0578, -0.1213],\n",
      "         [-0.0064, -0.0793, -0.0761],\n",
      "         [-0.0530,  0.1371,  0.0749],\n",
      "         [-0.0759,  0.0431, -0.1101],\n",
      "         [ 0.1082,  0.0521, -0.1285],\n",
      "         [-0.1178,  0.0418,  0.0448],\n",
      "         [-0.0003,  0.0764,  0.0335],\n",
      "         [ 0.1157, -0.0673,  0.0864]],\n",
      "\n",
      "        [[ 0.0220,  0.0485, -0.0509],\n",
      "         [ 0.0991, -0.1353,  0.0755],\n",
      "         [-0.0255, -0.0822,  0.0787],\n",
      "         [ 0.1081,  0.0608,  0.1371],\n",
      "         [ 0.0483, -0.0362,  0.1131],\n",
      "         [ 0.0421, -0.1089,  0.0540],\n",
      "         [-0.1322, -0.0344, -0.1418],\n",
      "         [-0.1292,  0.0693,  0.0675],\n",
      "         [ 0.1350,  0.0446,  0.0853],\n",
      "         [ 0.1212,  0.1297, -0.0923],\n",
      "         [-0.1423, -0.0279, -0.1384],\n",
      "         [ 0.1107, -0.0263,  0.0976],\n",
      "         [-0.0983,  0.0859,  0.0997],\n",
      "         [ 0.1215,  0.1244,  0.0628],\n",
      "         [ 0.0510, -0.0618,  0.0564],\n",
      "         [-0.0133,  0.1194, -0.0835]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv2.bias | Size: torch.Size([16]) | Values : tensor([ 0.0699, -0.0112], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[-0.2391],\n",
      "         [ 0.1636],\n",
      "         [ 0.0230],\n",
      "         [ 0.1281],\n",
      "         [-0.0859],\n",
      "         [ 0.0031],\n",
      "         [ 0.0816],\n",
      "         [ 0.1796],\n",
      "         [ 0.1518],\n",
      "         [ 0.0104],\n",
      "         [ 0.0678],\n",
      "         [ 0.0930],\n",
      "         [-0.2181],\n",
      "         [ 0.1368],\n",
      "         [-0.2477],\n",
      "         [ 0.1228]],\n",
      "\n",
      "        [[ 0.1659],\n",
      "         [ 0.2241],\n",
      "         [ 0.0693],\n",
      "         [-0.1397],\n",
      "         [ 0.0158],\n",
      "         [ 0.0934],\n",
      "         [-0.0601],\n",
      "         [-0.0242],\n",
      "         [ 0.0923],\n",
      "         [ 0.2233],\n",
      "         [-0.2177],\n",
      "         [-0.0019],\n",
      "         [-0.0417],\n",
      "         [ 0.0344],\n",
      "         [-0.0887],\n",
      "         [-0.1301]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv3.bias | Size: torch.Size([64]) | Values : tensor([-0.0126,  0.1923], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[ 0.1133],\n",
      "         [-0.0775],\n",
      "         [ 0.0354],\n",
      "         [ 0.0828],\n",
      "         [-0.0018],\n",
      "         [ 0.0528],\n",
      "         [-0.1090],\n",
      "         [-0.0273],\n",
      "         [ 0.0680],\n",
      "         [-0.0451],\n",
      "         [ 0.0464],\n",
      "         [-0.0279],\n",
      "         [-0.0052],\n",
      "         [-0.1227],\n",
      "         [ 0.0612],\n",
      "         [ 0.0025],\n",
      "         [ 0.0632],\n",
      "         [-0.0694],\n",
      "         [ 0.0619],\n",
      "         [ 0.0723],\n",
      "         [ 0.0650],\n",
      "         [-0.0383],\n",
      "         [ 0.0404],\n",
      "         [ 0.0923],\n",
      "         [-0.1025],\n",
      "         [ 0.0178],\n",
      "         [ 0.0407],\n",
      "         [ 0.1165],\n",
      "         [-0.1143],\n",
      "         [-0.0722],\n",
      "         [-0.0002],\n",
      "         [-0.1154],\n",
      "         [ 0.0078],\n",
      "         [-0.0029],\n",
      "         [-0.1047],\n",
      "         [-0.0607],\n",
      "         [-0.0474],\n",
      "         [-0.0205],\n",
      "         [-0.0171],\n",
      "         [ 0.0438],\n",
      "         [-0.0645],\n",
      "         [-0.0716],\n",
      "         [ 0.0413],\n",
      "         [ 0.1075],\n",
      "         [ 0.0665],\n",
      "         [ 0.0518],\n",
      "         [-0.1174],\n",
      "         [ 0.0860],\n",
      "         [-0.0412],\n",
      "         [-0.1204],\n",
      "         [ 0.1241],\n",
      "         [-0.0123],\n",
      "         [ 0.0336],\n",
      "         [-0.0776],\n",
      "         [ 0.0901],\n",
      "         [ 0.1142],\n",
      "         [ 0.0873],\n",
      "         [-0.0109],\n",
      "         [ 0.0002],\n",
      "         [ 0.0092],\n",
      "         [ 0.0714],\n",
      "         [ 0.0203],\n",
      "         [-0.1242],\n",
      "         [-0.0072]],\n",
      "\n",
      "        [[-0.0632],\n",
      "         [-0.0497],\n",
      "         [-0.0601],\n",
      "         [-0.0765],\n",
      "         [-0.1142],\n",
      "         [ 0.0598],\n",
      "         [-0.0431],\n",
      "         [ 0.1021],\n",
      "         [-0.0688],\n",
      "         [ 0.0932],\n",
      "         [-0.0850],\n",
      "         [-0.0369],\n",
      "         [ 0.0057],\n",
      "         [ 0.0400],\n",
      "         [-0.1149],\n",
      "         [ 0.0734],\n",
      "         [ 0.0581],\n",
      "         [-0.0685],\n",
      "         [-0.0518],\n",
      "         [ 0.0848],\n",
      "         [-0.0649],\n",
      "         [-0.0474],\n",
      "         [ 0.0290],\n",
      "         [-0.0639],\n",
      "         [-0.1144],\n",
      "         [ 0.0834],\n",
      "         [ 0.0051],\n",
      "         [ 0.0064],\n",
      "         [-0.1156],\n",
      "         [-0.0282],\n",
      "         [ 0.0912],\n",
      "         [ 0.1055],\n",
      "         [ 0.0948],\n",
      "         [-0.0179],\n",
      "         [-0.0725],\n",
      "         [-0.0226],\n",
      "         [ 0.0670],\n",
      "         [ 0.0226],\n",
      "         [-0.0800],\n",
      "         [ 0.0002],\n",
      "         [-0.0058],\n",
      "         [ 0.0815],\n",
      "         [ 0.0465],\n",
      "         [-0.1053],\n",
      "         [-0.0968],\n",
      "         [ 0.0724],\n",
      "         [-0.1182],\n",
      "         [ 0.0319],\n",
      "         [ 0.0221],\n",
      "         [ 0.1195],\n",
      "         [-0.0930],\n",
      "         [ 0.0189],\n",
      "         [ 0.0101],\n",
      "         [ 0.0868],\n",
      "         [ 0.0828],\n",
      "         [-0.0353],\n",
      "         [ 0.0675],\n",
      "         [-0.0342],\n",
      "         [ 0.0481],\n",
      "         [-0.1110],\n",
      "         [-0.0808],\n",
      "         [-0.0293],\n",
      "         [-0.0951],\n",
      "         [ 0.0969]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.convr.bias | Size: torch.Size([64]) | Values : tensor([-0.0846, -0.0643], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[ 0.0493],\n",
      "         [ 0.0039],\n",
      "         [ 0.0549],\n",
      "         [-0.0752],\n",
      "         [ 0.0871],\n",
      "         [-0.0892],\n",
      "         [-0.0980],\n",
      "         [ 0.0222],\n",
      "         [-0.0092],\n",
      "         [-0.0527],\n",
      "         [-0.0600],\n",
      "         [-0.0322],\n",
      "         [ 0.0760],\n",
      "         [ 0.0160],\n",
      "         [ 0.0225],\n",
      "         [-0.1043],\n",
      "         [-0.0975],\n",
      "         [-0.0574],\n",
      "         [-0.0755],\n",
      "         [-0.0311],\n",
      "         [ 0.0212],\n",
      "         [-0.0944],\n",
      "         [-0.0065],\n",
      "         [ 0.0820],\n",
      "         [-0.0862],\n",
      "         [-0.0875],\n",
      "         [-0.1018],\n",
      "         [ 0.0797],\n",
      "         [-0.0989],\n",
      "         [ 0.0185],\n",
      "         [-0.0125],\n",
      "         [-0.0832],\n",
      "         [ 0.0975],\n",
      "         [ 0.0242],\n",
      "         [ 0.0901],\n",
      "         [-0.0633],\n",
      "         [ 0.0809],\n",
      "         [ 0.0013],\n",
      "         [-0.0911],\n",
      "         [ 0.1034],\n",
      "         [-0.1000],\n",
      "         [ 0.0218],\n",
      "         [ 0.0238],\n",
      "         [ 0.0296],\n",
      "         [ 0.0059],\n",
      "         [-0.0379],\n",
      "         [-0.0888],\n",
      "         [ 0.0610],\n",
      "         [ 0.1081],\n",
      "         [ 0.0305],\n",
      "         [ 0.0892],\n",
      "         [-0.1069],\n",
      "         [ 0.1128],\n",
      "         [-0.0879],\n",
      "         [ 0.0555],\n",
      "         [ 0.0183],\n",
      "         [ 0.0447],\n",
      "         [ 0.0734],\n",
      "         [ 0.1114],\n",
      "         [-0.1045],\n",
      "         [ 0.0540],\n",
      "         [ 0.0087],\n",
      "         [ 0.1245],\n",
      "         [-0.0698]],\n",
      "\n",
      "        [[-0.0170],\n",
      "         [ 0.1134],\n",
      "         [-0.0043],\n",
      "         [ 0.0540],\n",
      "         [ 0.0797],\n",
      "         [ 0.1041],\n",
      "         [-0.0819],\n",
      "         [ 0.1140],\n",
      "         [-0.0969],\n",
      "         [ 0.1035],\n",
      "         [-0.0271],\n",
      "         [ 0.1199],\n",
      "         [-0.1140],\n",
      "         [-0.0034],\n",
      "         [-0.0130],\n",
      "         [-0.0474],\n",
      "         [-0.0251],\n",
      "         [-0.1018],\n",
      "         [ 0.1161],\n",
      "         [-0.0195],\n",
      "         [-0.0071],\n",
      "         [-0.0042],\n",
      "         [-0.0874],\n",
      "         [-0.1134],\n",
      "         [-0.0607],\n",
      "         [-0.1044],\n",
      "         [-0.0211],\n",
      "         [ 0.1148],\n",
      "         [ 0.0926],\n",
      "         [-0.0434],\n",
      "         [ 0.0341],\n",
      "         [-0.1138],\n",
      "         [ 0.0978],\n",
      "         [ 0.0472],\n",
      "         [-0.1103],\n",
      "         [ 0.0307],\n",
      "         [-0.0117],\n",
      "         [ 0.0195],\n",
      "         [-0.1044],\n",
      "         [ 0.0579],\n",
      "         [-0.0464],\n",
      "         [ 0.1047],\n",
      "         [-0.1027],\n",
      "         [ 0.0610],\n",
      "         [ 0.1063],\n",
      "         [ 0.1095],\n",
      "         [ 0.0539],\n",
      "         [ 0.1126],\n",
      "         [-0.0390],\n",
      "         [ 0.0355],\n",
      "         [-0.0427],\n",
      "         [-0.0032],\n",
      "         [-0.0785],\n",
      "         [-0.0665],\n",
      "         [-0.0945],\n",
      "         [ 0.0036],\n",
      "         [ 0.0665],\n",
      "         [-0.0022],\n",
      "         [-0.1131],\n",
      "         [-0.0409],\n",
      "         [-0.0828],\n",
      "         [-0.0357],\n",
      "         [-0.0430],\n",
      "         [ 0.0651]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv1.bias | Size: torch.Size([16]) | Values : tensor([-0.0098,  0.1073], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[-0.0511, -0.1001, -0.0349],\n",
      "         [ 0.0702,  0.0858,  0.0606],\n",
      "         [ 0.0903,  0.1236,  0.0434],\n",
      "         [-0.0247, -0.0130,  0.0797],\n",
      "         [ 0.0347,  0.0967,  0.1423],\n",
      "         [ 0.0300,  0.1402,  0.1154],\n",
      "         [ 0.0294,  0.0168,  0.0257],\n",
      "         [ 0.0627,  0.1429,  0.0554],\n",
      "         [-0.0237,  0.0036, -0.0187],\n",
      "         [ 0.1333, -0.0834,  0.0356],\n",
      "         [-0.1167,  0.1288,  0.0500],\n",
      "         [-0.1103, -0.0080,  0.1359],\n",
      "         [ 0.0219,  0.0616,  0.1135],\n",
      "         [-0.0138, -0.0579, -0.0504],\n",
      "         [-0.1307, -0.0916, -0.0580],\n",
      "         [ 0.0271,  0.0440, -0.0658]],\n",
      "\n",
      "        [[ 0.0383, -0.0948, -0.0473],\n",
      "         [-0.0884,  0.0215,  0.1170],\n",
      "         [-0.0548, -0.1312,  0.1137],\n",
      "         [ 0.1001, -0.1384, -0.0075],\n",
      "         [ 0.1186, -0.0251,  0.0701],\n",
      "         [ 0.0892, -0.0055,  0.1075],\n",
      "         [-0.0522,  0.0225,  0.1035],\n",
      "         [-0.0712, -0.0748, -0.0605],\n",
      "         [ 0.1386,  0.0709, -0.0315],\n",
      "         [-0.1392,  0.1257, -0.1320],\n",
      "         [-0.1151, -0.0576, -0.0011],\n",
      "         [ 0.1427, -0.0295, -0.1388],\n",
      "         [-0.0058, -0.0512,  0.0987],\n",
      "         [-0.0999, -0.1150, -0.1241],\n",
      "         [-0.0427,  0.0448, -0.1138],\n",
      "         [-0.0491,  0.0196, -0.0047]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv2.bias | Size: torch.Size([16]) | Values : tensor([-0.1223, -0.0693], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[ 0.1358],\n",
      "         [ 0.2470],\n",
      "         [ 0.0363],\n",
      "         [ 0.1227],\n",
      "         [-0.0496],\n",
      "         [ 0.2379],\n",
      "         [ 0.1994],\n",
      "         [-0.2160],\n",
      "         [ 0.0121],\n",
      "         [ 0.2416],\n",
      "         [-0.0967],\n",
      "         [ 0.1562],\n",
      "         [-0.2020],\n",
      "         [-0.2049],\n",
      "         [-0.2361],\n",
      "         [ 0.0050]],\n",
      "\n",
      "        [[ 0.0351],\n",
      "         [-0.0263],\n",
      "         [-0.2013],\n",
      "         [ 0.2245],\n",
      "         [-0.0738],\n",
      "         [ 0.0206],\n",
      "         [ 0.0629],\n",
      "         [ 0.0038],\n",
      "         [ 0.0051],\n",
      "         [-0.1878],\n",
      "         [ 0.1629],\n",
      "         [ 0.1279],\n",
      "         [-0.2449],\n",
      "         [ 0.1661],\n",
      "         [ 0.2184],\n",
      "         [-0.1073]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv3.bias | Size: torch.Size([64]) | Values : tensor([-0.2161, -0.1765], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[-0.0860],\n",
      "         [-0.0288],\n",
      "         [-0.1117],\n",
      "         [ 0.0699],\n",
      "         [-0.0235],\n",
      "         [-0.0085],\n",
      "         [ 0.1073],\n",
      "         [ 0.0635],\n",
      "         [-0.0719],\n",
      "         [-0.1220],\n",
      "         [ 0.1203],\n",
      "         [-0.0598],\n",
      "         [-0.0160],\n",
      "         [ 0.0297],\n",
      "         [ 0.1061],\n",
      "         [ 0.0940],\n",
      "         [ 0.0788],\n",
      "         [-0.0646],\n",
      "         [-0.1189],\n",
      "         [ 0.0072],\n",
      "         [ 0.0384],\n",
      "         [-0.1089],\n",
      "         [-0.0013],\n",
      "         [ 0.0478],\n",
      "         [-0.0058],\n",
      "         [-0.0954],\n",
      "         [-0.0203],\n",
      "         [-0.0500],\n",
      "         [-0.0299],\n",
      "         [-0.0425],\n",
      "         [-0.0893],\n",
      "         [ 0.1080],\n",
      "         [ 0.0163],\n",
      "         [ 0.0719],\n",
      "         [ 0.0635],\n",
      "         [ 0.0669],\n",
      "         [-0.0569],\n",
      "         [-0.0833],\n",
      "         [ 0.1133],\n",
      "         [ 0.0077],\n",
      "         [ 0.1196],\n",
      "         [ 0.0520],\n",
      "         [ 0.0086],\n",
      "         [-0.0496],\n",
      "         [-0.0509],\n",
      "         [ 0.0565],\n",
      "         [ 0.1061],\n",
      "         [-0.0032],\n",
      "         [-0.0077],\n",
      "         [ 0.0149],\n",
      "         [ 0.0225],\n",
      "         [-0.1040],\n",
      "         [ 0.0499],\n",
      "         [ 0.1165],\n",
      "         [-0.1227],\n",
      "         [-0.1172],\n",
      "         [-0.0440],\n",
      "         [-0.0605],\n",
      "         [-0.0290],\n",
      "         [-0.0982],\n",
      "         [-0.0580],\n",
      "         [ 0.0589],\n",
      "         [ 0.0997],\n",
      "         [-0.0094]],\n",
      "\n",
      "        [[ 0.0410],\n",
      "         [-0.1079],\n",
      "         [-0.0794],\n",
      "         [ 0.0391],\n",
      "         [-0.1119],\n",
      "         [ 0.0024],\n",
      "         [-0.0875],\n",
      "         [ 0.0901],\n",
      "         [-0.0742],\n",
      "         [-0.1207],\n",
      "         [-0.0246],\n",
      "         [ 0.1168],\n",
      "         [ 0.0445],\n",
      "         [-0.0845],\n",
      "         [ 0.1085],\n",
      "         [-0.0416],\n",
      "         [ 0.1140],\n",
      "         [-0.0648],\n",
      "         [ 0.1072],\n",
      "         [-0.0741],\n",
      "         [-0.0421],\n",
      "         [ 0.1149],\n",
      "         [-0.0258],\n",
      "         [-0.0183],\n",
      "         [-0.0249],\n",
      "         [-0.0054],\n",
      "         [-0.0422],\n",
      "         [ 0.0997],\n",
      "         [-0.0278],\n",
      "         [-0.0542],\n",
      "         [ 0.1128],\n",
      "         [ 0.0234],\n",
      "         [ 0.0504],\n",
      "         [ 0.0472],\n",
      "         [ 0.0613],\n",
      "         [ 0.0482],\n",
      "         [ 0.0206],\n",
      "         [-0.0707],\n",
      "         [ 0.0731],\n",
      "         [ 0.0373],\n",
      "         [ 0.0373],\n",
      "         [-0.0965],\n",
      "         [ 0.1150],\n",
      "         [-0.0200],\n",
      "         [-0.0753],\n",
      "         [ 0.0500],\n",
      "         [ 0.0624],\n",
      "         [-0.0042],\n",
      "         [ 0.1120],\n",
      "         [ 0.0157],\n",
      "         [-0.0104],\n",
      "         [-0.0849],\n",
      "         [-0.1031],\n",
      "         [-0.0890],\n",
      "         [-0.0257],\n",
      "         [-0.0922],\n",
      "         [ 0.0682],\n",
      "         [-0.1112],\n",
      "         [-0.0697],\n",
      "         [-0.1154],\n",
      "         [-0.0144],\n",
      "         [ 0.0078],\n",
      "         [-0.0382],\n",
      "         [-0.0373]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.convr.bias | Size: torch.Size([64]) | Values : tensor([-0.0045,  0.0451], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc.1.weight | Size: torch.Size([2, 768]) | Values : tensor([[-0.0352,  0.0061, -0.0174,  ...,  0.0160,  0.0232,  0.0081],\n",
      "        [-0.0326,  0.0080,  0.0165,  ...,  0.0019,  0.0271, -0.0247]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc.1.bias | Size: torch.Size([2]) | Values : tensor([0.0196, 0.0293], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from models.TinyFallNet import TinyFallNet\n",
    "\n",
    "# Create an instance of the model\n",
    "model_tinyFallNet = TinyFallNet().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_tinyFallNet.parameters(), lr=learning_rate)\n",
    "# Initialize the scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=patience, verbose=True)\n",
    "\n",
    "print(f\"Model structure: {model_tinyFallNet}\\n\\n\")\n",
    "for name, param in model_tinyFallNet.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.403193  [   64/23290]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\python\\lib\\site-packages\\torch\\nn\\modules\\container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.332907  [ 6464/23290]\n",
      "loss: 0.313266  [12864/23290]\n",
      "loss: 0.676014  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338264 \n",
      "\n",
      "Epoch 1:\n",
      "loss: 1.098921  [   64/23290]\n",
      "loss: 0.676019  [ 6464/23290]\n",
      "loss: 0.487121  [12864/23290]\n",
      "loss: 0.313264  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 2:\n",
      "loss: 0.313262  [   64/23290]\n",
      "loss: 0.676017  [ 6464/23290]\n",
      "loss: 0.676019  [12864/23290]\n",
      "loss: 0.879943  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 3:\n",
      "loss: 0.487121  [   64/23290]\n",
      "loss: 0.313262  [ 6464/23290]\n",
      "loss: 1.098907  [12864/23290]\n",
      "loss: 0.676015  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 4:\n",
      "loss: 0.487121  [   64/23290]\n",
      "loss: 1.332905  [ 6464/23290]\n",
      "loss: 0.676014  [12864/23290]\n",
      "loss: 1.098907  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 5:\n",
      "loss: 0.676014  [   64/23290]\n",
      "loss: 1.332905  [ 6464/23290]\n",
      "loss: 0.487121  [12864/23290]\n",
      "loss: 0.676015  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 6:\n",
      "loss: 0.676014  [   64/23290]\n",
      "loss: 0.487121  [ 6464/23290]\n",
      "loss: 0.879943  [12864/23290]\n",
      "loss: 0.487121  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 00007: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Epoch 7:\n",
      "loss: 0.879943  [   64/23290]\n",
      "loss: 0.487121  [ 6464/23290]\n",
      "loss: 0.487121  [12864/23290]\n",
      "loss: 0.676014  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 8:\n",
      "loss: 0.879943  [   64/23290]\n",
      "loss: 0.676014  [ 6464/23290]\n",
      "loss: 0.487121  [12864/23290]\n",
      "loss: 0.879943  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 9:\n",
      "loss: 0.879943  [   64/23290]\n",
      "loss: 1.098907  [ 6464/23290]\n",
      "loss: 0.676014  [12864/23290]\n",
      "loss: 0.676014  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 10:\n",
      "loss: 0.676014  [   64/23290]\n",
      "loss: 0.487120  [ 6464/23290]\n",
      "loss: 1.332905  [12864/23290]\n",
      "loss: 0.676014  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 11:\n",
      "loss: 0.676014  [   64/23290]\n",
      "loss: 0.676014  [ 6464/23290]\n",
      "loss: 0.676014  [12864/23290]\n",
      "loss: 1.332905  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 12:\n",
      "loss: 0.676014  [   64/23290]\n",
      "loss: 1.098907  [ 6464/23290]\n",
      "loss: 0.676014  [12864/23290]\n",
      "loss: 0.487121  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 00013: reducing learning rate of group 0 to 5.0000e-06.\n",
      "Epoch 13:\n",
      "loss: 0.487121  [   64/23290]\n",
      "loss: 0.487121  [ 6464/23290]\n",
      "loss: 0.313262  [12864/23290]\n",
      "loss: 1.098907  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 14:\n",
      "loss: 0.879943  [   64/23290]\n",
      "loss: 0.879944  [ 6464/23290]\n",
      "loss: 0.879943  [12864/23290]\n",
      "loss: 1.098907  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 15:\n",
      "loss: 0.676014  [   64/23290]\n",
      "loss: 0.487121  [ 6464/23290]\n",
      "loss: 0.676014  [12864/23290]\n",
      "loss: 0.313262  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 16:\n",
      "loss: 0.879943  [   64/23290]\n",
      "loss: 0.676014  [ 6464/23290]\n",
      "loss: 1.581939  [12864/23290]\n",
      "loss: 1.098907  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 17:\n",
      "loss: 0.487121  [   64/23290]\n",
      "loss: 0.879943  [ 6464/23290]\n",
      "loss: 0.676014  [12864/23290]\n",
      "loss: 1.332905  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 18:\n",
      "loss: 0.313262  [   64/23290]\n",
      "loss: 1.581939  [ 6464/23290]\n",
      "loss: 0.879943  [12864/23290]\n",
      "loss: 0.879943  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 00019: reducing learning rate of group 0 to 5.0000e-07.\n",
      "Epoch 19:\n",
      "loss: 0.676014  [   64/23290]\n",
      "loss: 0.879943  [ 6464/23290]\n",
      "loss: 0.487121  [12864/23290]\n",
      "loss: 1.332906  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Early stopping due to no improvement in validation loss.\n"
     ]
    }
   ],
   "source": [
    "train(train_dataloader, model_tinyFallNet, loss_fn, optimizer,val_dataloader, \n",
    "        patience=patience, scheduler=scheduler, device=device, epochs=epochs, B_size=B_size, A_size=A_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.813262 \n",
      "\n",
      " Label 0\n",
      "    accuracy\t0.500\n",
      " specificity\t0.000\n",
      " sensitivity\t1.000\n",
      " Label 1\n",
      "    accuracy\t0.500\n",
      " specificity\t1.000\n",
      " sensitivity\t0.000\n",
      "[[31  0]\n",
      " [31  0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# final test\n",
    "test(test_dataloader, model_tinyFallNet, loss_fn, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvLSTM\n",
      "Test Error: \n",
      " Accuracy: 90.3%, Avg loss: 0.322582 \n",
      "\n",
      " Label 0\n",
      "    accuracy\t0.903\n",
      " specificity\t0.806\n",
      " sensitivity\t1.000\n",
      " Label 1\n",
      "    accuracy\t0.903\n",
      " specificity\t1.000\n",
      " sensitivity\t0.806\n",
      "[[31  0]\n",
      " [ 6 25]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAGZCAYAAACnsGcEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAuUUlEQVR4nO3de1xVdb7/8fcGZUPKhlABGREvlZdMLTWHqNQ0iVFHUye1fg/Rym5qR6ljYxc168RUk5ca1GnOeBkny5xTdh0zyctMUqkdRpvKlLQoBZWToJRo7O/vD2PHFlT22nvBdvt6Ph7rofu71+W7Ngs++/O9rOUwxhgBAOCjsIauAADg3EQAAQBYQgABAFhCAAEAWEIAAQBYQgABAFhCAAEAWEIAAQBYQgABAFhy3geQXbt2aeDAgYqJiZHD4dDq1asDuv+9e/fK4XBo6dKlAd3vuaxv377q27dvQPdZWFioyMhIvf/++wHdb7B6+umn1a5dO4WHh6t79+4+bXvq5x+s16g/v5sbNmyQw+HQhg0bPGXjxo1TmzZtPK9LSkrUpEkTvf3224Gr9HkmKAJIQUGB7rzzTrVr106RkZFyuVxKS0vT/Pnz9cMPP9h67MzMTO3YsUP/9V//peXLl6tnz562Hq8+jRs3Tg6HQy6Xq9bPcdeuXXI4HHI4HPr973/v8/737dunWbNmKT8/PwC19c/s2bPVu3dvpaWleZV/++23uummmxQbGyuXy6WhQ4fqyy+/bKBa1u7tt9/WrFmz6rz+2rVrNW3aNKWlpWnJkiV64okn7KtcHetz2223qUuXLgoPD/f6I+0Pu383mzVrpttvv12PPPJIQPd7XjEN7M033zRRUVEmNjbW3Hvvveb55583f/jDH8zo0aNN48aNzYQJE2w79vfff28kmYceesi2Y7jdbvPDDz+YH3/80bZjnE5mZqZp1KiRCQ8PNytXrqzx/syZM01kZKSRZJ5++mmf979lyxYjySxZssSn7SoqKkxFRYXPxzudAwcOmMaNG5sVK1Z4lR85csRcfPHFJj4+3jz55JNmzpw5Jjk52bRq1cocOnQoYMf318SJE40vv4oPPPCACQsLs/wZ9unTx/Tp08fzes+ePZZ+jlUyMzNNZGSkueqqq0yrVq1MSkqKpf1U5+/v5vr1640ks379eq96nlq3Tz/91Egyubm5ftT2/NWgGciePXs0evRopaSk6NNPP9X8+fM1YcIETZw4US+++KI+/fRTXXrppbYd/+DBg5Kk2NhY247hcDgUGRmp8PBw245xJk6nU/3799eLL75Y470VK1Zo0KBB9VaX77//XpIUERGhiIiIgO33r3/9qxo1aqQhQ4Z4lS9YsEC7du3Sm2++qWnTpmnq1Klau3at9u/fr2eeeSZgx69vBw4cUFRUVEA/Q3888cQTKisr0/vvv69u3boFZJ/18bspSZ06dVKXLl2CrvnunNGQ0euuu+4yksz7779fp/VPnDhhZs+ebdq1a2ciIiJMSkqKmT59ujl27JjXeikpKWbQoEHmH//4h+nVq5dxOp2mbdu2ZtmyZZ51Zs6caSR5LVXfTmr7plJ9m+rWrl1r0tLSTExMjGnSpIm55JJLzPTp0z3vn+7bXW5urrn66qvNBRdcYGJiYsyvf/1r8+mnn9Z6vF27dpnMzEwTExNjXC6XGTdunCkvLz/r55WZmWmaNGlili5dapxOp/nuu+8873300UdGkvmf//mfGhlISUmJue+++0yXLl1MkyZNTHR0tLnhhhtMfn6+Z52qb3inLlXn2adPH3PppZearVu3mmuuucZERUWZ//iP//C8V/0b8NixY43T6axx/gMHDjSxsbHm22+/PeN5XnvttaZv3741ynv16mV69epVo3zgwIGmffv2XmVfffWV+eyzz854nOrnvXLlSvP444+bX/ziF8bpdJrrrrvO7Nq1q8b6L7/8srniiitMZGSkadasmbnlllvMN99843k/MzOz1s/xdM70mS9evNj069fPtGjRwkRERJhOnTqZBQsW1NhHoDOQ6gYNGnTGDGT37t1m9+7dZ9zHmX439+7da+6++25zySWXmMjISBMXF2dGjhxp9uzZ47WPumYgxhgzdepUExsba9xudx3PElUaNAN544031K5dO1111VV1Wv/222/XjBkzdMUVV2ju3Lnq06ePsrOzNXr06Brr7t69WyNHjtT111+vZ555RhdeeKHGjRunf//735Kk4cOHa+7cuZKkMWPGaPny5Zo3b55P9f/3v/+twYMHq6KiQrNnz9YzzzyjX//612ftyF23bp3S09N14MABzZo1S1lZWdq8ebPS0tK0d+/eGuvfdNNNOnLkiLKzs3XTTTdp6dKlevTRR+tcz+HDh8vhcOiVV17xlK1YsUIdO3bUFVdcUWP9L7/8UqtXr9bgwYM1Z84c/ed//qd27NihPn36aN++fZJOfnObPXu2JOmOO+7Q8uXLtXz5cl177bWe/ZSUlCgjI0Pdu3fXvHnz1K9fv1rrN3/+fLVo0UKZmZmqrKyUJP3xj3/U2rVr9dxzzykpKem053bixAlt2bKlxnm43W5t37691nbzK6+8UgUFBTpy5IinbOzYserUqdNpj3Oq3/3ud3r11Vd1//33a/r06frggw90yy23eK2zdOlS3XTTTQoPD1d2drYmTJigV155RVdffbUOHz4sSbrzzjt1/fXXS5LnM1y+fPlpj7t8+XJdc801cjqdNT7zhQsXKiUlRQ8++KCeeeYZJScn65577lFOTk6dz8tu/fv3V//+/c+4zpl+N7ds2aLNmzdr9OjRevbZZ3XXXXcpNzdXffv29WS4vurRo4cOHz7s+dsAHzRU5CotLTWSzNChQ+u0fn5+vpFkbr/9dq/y+++/30gy7733nqcsJSXFSDKbNm3ylB04cMA4nU5z3333ecqqvnmd2v5f1wxk7ty5RpI5ePDgaetd27e77t27m/j4eFNSUuIp+9e//mXCwsLM2LFjaxzv1ltv9drnjTfeaJo1a3baY1Y/jyZNmhhjjBk5cqTp37+/McaYyspKk5iYaB599NFaP4Njx46ZysrKGufhdDrN7NmzPWVn6gPp06ePkWQWLVpU63vVvwEbY8w777xjJJnHH3/cfPnll6Zp06Zm2LBhZz3H3bt3G0nmueee8yo/ePCgkeRV3yo5OTlGkvn8889r1Pdsqr7ZdurUyasPYv78+UaS2bFjhzHGmOPHj5v4+HjTpUsX88MPP3jWe/PNN40kM2PGDE+Zr30g1X+u1X3//fc1ytLT0027du28yhoyA0lJSalTH8npfjdrO8e8vDwjyfzlL3/xlPmSgWzevNmTVcI3DZaBlJWVSZKio6PrtH7VULusrCyv8vvuu0+S9NZbb3mVd+7cWddcc43ndYsWLdShQ4eAjsCpap997bXX5Ha767TN/v37lZ+fr3HjxikuLs5T3rVrV11//fW1Dim86667vF5fc801Kikp8XyGdXHzzTdrw4YNKioq0nvvvaeioiLdfPPNta7rdDoVFnby0qisrFRJSYmaNm2qDh066OOPP67zMZ1Op8aPH1+ndQcOHKg777xTs2fP1vDhwxUZGak//vGPZ92upKREknThhRd6lVeNOnM6nTW2iYyM9FpHOjns0/jwbLXx48d79UFUXWtV19fWrVt14MAB3XPPPZ7jSdKgQYPUsWPHGtdrIERFRXn+X1paqkOHDqlPnz768ssvVVpaGvDjWbF3795as+y6qn6OJ06cUElJiS666CLFxsb6dG1WV3XtHDp0yHK9zlcNFkBcLpckeTUjnMlXX32lsLAwXXTRRV7liYmJio2N1VdffeVV3rp16xr7uPDCC/Xdd99ZrHFNo0aNUlpamm6//XYlJCRo9OjRevnll88YTKrq2aFDhxrvderUSYcOHVJ5eblX+annUnXB+3Iuv/rVrxQdHa2VK1fqhRdeUK9evWp8llXcbrfmzp2riy++WE6nU82bN1eLFi20fft2n/4Q/eIXv/Cpo/f3v/+94uLilJ+fr2effVbx8fF13vbUP/5Vf2gqKipqrHvs2DGvdaw428/kTD/njh071rheA+H999/XgAED1KRJE8XGxqpFixZ68MEHJSloAoi/fvjhB82YMUPJycle1+bhw4ctn2PVteNwOAJZVY9jx46prKzM76Xqug0mjRrqwC6XS0lJSfrkk0982q6uP+TTjXqqy7fM0x2jqn2+SlRUlDZt2qT169frrbfe0po1a7Ry5Updd911Wrt2bcBGXvlzLlWcTqeGDx+uZcuW6csvvzzjvIMnnnhCjzzyiG699VY99thjiouLU1hYmKZMmVLnTEvy/Q/0//7v/+rAgQOSpB07dmjMmDFn3aZZs2aSagbTuLg4OZ1O7d+/v8Y2VWVn6ls5m0D8TAKpoKBA/fv3V8eOHTVnzhwlJycrIiJCb7/9tubOnevTzy2YTZ48WUuWLNGUKVOUmprqmWQ4evRoy+dYde00b948kFWVdDJ4tE1pqqIDlWdf+SwSExO1Z88er4y2oTVYAJGkwYMH6/nnn1deXp5SU1PPuG5KSorcbrd27drl1dlZXFysw4cPKyUlJWD1uvDCCz2dnNXV9q0xLCzM0zE4Z84cPfHEE3rooYe0fv16DRgwoNbzkKSdO3fWeO/zzz9X8+bN1aRJE/9PohY333yzFi9erLCwsFoHHlT529/+pn79+unPf/6zV/nhw4e9fskC+Y2tvLxc48ePV+fOnXXVVVfpqaee0o033qhevXqdcbvWrVsrKipKe/bs8SoPCwvTZZddpq1bt9bY5sMPP1S7du3q3HxqRfWf83XXXef13s6dO72u10B8jm+88YYqKir0+uuve2VH69ev93vfweRvf/ubMjMzvYZhHzt2rNbf17qqunZ8GURRV8ePH1fRgUrt2ZYiV7T1Bp+yI2617fGVjh8/HlQBpEFHYU2bNk1NmjTR7bffruLi4hrvFxQUaP78+ZJONsFIqjFSas6cOZIU0PkM7du3V2lpqbZv3+4p279/v1599VWv9f7v//6vxrZVt5WorelEklq2bKnu3btr2bJlXhf9J598orVr13rO0w79+vXTY489pj/84Q9KTEw87Xrh4eE1vkmvWrVK3377rVdZVaDz55e3ygMPPKCvv/5ay5Yt05w5c9SmTRtlZmae9nOs0rhxY/Xs2bPWQDFy5Eht2bLF672dO3fqvffe029+8xuvdb/++mt9/vnnfp9HlZ49eyo+Pl6LFi3yOoe///3v+uyzz7yu10B8jlUZUfWfW2lpqZYsWWJ5n3YoKChQQUGB5e1ruzafe+65Gq0Dvti2bZtiYmJsnXPWpKn/SzBq0Aykffv2WrFihUaNGqVOnTpp7Nix6tKli44fP67Nmzdr1apVGjdunCSpW7duyszM1PPPP6/Dhw+rT58++uijj7Rs2TINGzbstENErRg9erQeeOAB3Xjjjbr33nv1/fffa+HChbrkkku8Oupmz56tTZs2adCgQUpJSdGBAwe0YMECtWrVSldfffVp9//0008rIyNDqampuu222/TDDz/oueeeU0xMjE+3tPBVWFiYHn744bOuN3jwYM2ePVvjx4/XVVddpR07duiFF15Qu3btvNZr3769YmNjtWjRIkVHR6tJkybq3bu32rZt61O93nvvPS1YsEAzZ870DMddsmSJ+vbtq0ceeURPPfXUGbcfOnSoHnroIZWVlXn61iTpnnvu0Z/+9CcNGjRI999/vxo3bqw5c+YoISHBM/iiytixY7Vx48aANUE1btxYTz75pMaPH68+ffpozJgxKi4u1vz589WmTRtNnTrVs26PHj0kSffee6/S09MVHh5+xgyxNgMHDlRERISGDBmiO++8U0ePHtWf/vQnxcfH19qMdzZ79+5V27ZtlZmZedZJdtu3b9frr78u6eTw+dLSUj3++OOSTv7eVp/gWTWE12pH+uDBg7V8+XLFxMSoc+fOysvL07p16zxNmVa8++67GjJkiG19ICGtoYZ/VffFF1+YCRMmmDZt2piIiAgTHR1t0tLSzHPPPec1SfDEiRPm0UcfNW3btjWNGzc2ycnJZ5xIeKrTDV+s7TYea9euNV26dDERERGmQ4cO5q9//WuNYby5ublm6NChJikpyURERJikpCQzZswY88UXX9Q4xqlDJNetW2fS0tJMVFSUcblcZsiQIaedSHjqMOElS5YYSTUmT53qdMM9qzvdMN777rvPtGzZ0kRFRZm0tDSTl5dX6/Db1157zXTu3Nk0atSo1omEtam+n7KyMpOSkmKuuOIKc+LECa/1pk6dasLCwkxeXt4Zz6G4uNg0atTILF++vMZ7hYWFZuTIkcblcpmmTZuawYMH1zrhz9dhvKtWrfIqP93PeeXKlebyyy83TqfTxMXF1ZhIaIwxP/74o5k8ebJp0aKFcTgcZ63H6X6ur7/+uunatauJjIw0bdq0MU8++aRZvHhxjWulLsN4d+zYYSSZ3/72t2f+QMzP12NtS2Zmpte6/g7j/e6778z48eNN8+bNTdOmTU16err5/PPPTUpKitex6jqM97PPPjOSzLp1685aJyuqpisU7Wxtvt/XxvJStLO1kWRKS0ttqadVDmMaqNcPCKDbbrtNX3zxhf7xj380dFVCwoIFCzRt2jQVFBQoISGhoatjmylTpmjTpk3atm2bLRlIWVmZYmJitG9nK7/7QJI6fKPS0lKvLLuhBcXdeAF/zZw5U1u2bDlvbudut/Xr1+vee+8N6eBRUlKi//7v/9bjjz9O85VFBBCEhNatW+vYsWM1bucOa1atWtXgt4m3W7NmzXT06FFbB65UqTTG78UXCxcuVNeuXeVyueRyuZSamqq///3vnvePHTumiRMnqlmzZmratKlGjBhR60CmsyGAAIDN3DJ+L75o1aqVfve732nbtm3aunWrrrvuOg0dOtRzv6+pU6fqjTfe0KpVq7Rx40bt27dPw4cP9/m86AMBAJtU9YF89XmS330gKR33+dUHEhcXp6efflojR45UixYttGLFCo0cOVLSyTlonTp1Ul5enn75y1/WeZ9kIABgM7eMKv1YfM1AqqusrNRLL72k8vJypaamatu2bTpx4oTXROeOHTuqdevWysvL82nfDToPBADOB1aaoU7dXlKNG6g6nc5abxgqnbwdUGpqqo4dO6amTZvq1VdfVefOnZWfn6+IiIgaD+tKSEhQUVGRT/UiAwGAc0RycrJiYmI8S3Z29mnX7dChg/Lz8/Xhhx/q7rvvVmZmpj799NOA1ocMBABsZmUk1anbS1JhYaFXH8jpsg/p5KOjq+643aNHD23ZskXz58/XqFGjdPz4cR0+fNgrCykuLj7jLY5qQwYShHJyctSmTRtFRkaqd+/e+uijjxq6SjiHbdq0SUOGDFFSUpIcDodWr17d0FU677gDsEjyDMutWs4UQGrUwe1WRUWFevToocaNGys3N9fz3s6dO/X111+f9aa2pyIDCTIrV65UVlaWFi1apN69e2vevHlKT0/Xzp07fXo+BlClvLxc3bp106233mppqCb8V9UZ7s/2vpg+fboyMjLUunVrHTlyRCtWrNCGDRv0zjvvKCYmRrfddpuysrIUFxcnl8ulyZMnKzU11acRWBIBJOjMmTNHEyZM8DzJb9GiRXrrrbe0ePFi/fa3v23g2uFclJGRoYyMjIauBurRgQMHNHbsWO3fv18xMTHq2rWr3nnnHV1//fWSpLlz5yosLEwjRoxQRUWF0tPTtWDBAp+PQwAJIsePH9e2bds0ffp0T1lYWJgGDBjg8/A6AMGj0pxc/NneF6c+y+dUkZGRysnJUU5OjvVKiT6QoHLo0CFVVlbWuP+QleF1AIJHoPpAgg0BBABgCU1YQaR58+YKDw+vcVMzK8PrAAQPtxyqlPU7/rr92NZOZCBBJCIiQj169PAaXud2u5Wbm+vz8DoAwcNt/F+CERlIkMnKylJmZqZ69uypK6+8UvPmzVN5eblnVBbgq6NHj2r37t2e13v27FF+fr7i4uLUunXrBqwZznUEkCAzatQoHTx4UDNmzFBRUZG6d++uNWvWhPSDfWCvrVu3ql+/fp7XWVlZklSn550jMCr9bMLyZ1s7cTt3ALBJ1e3cN/+7pZr6cTv3o0fcuurS/TzSFgAQGmjCAgCbuY1DbuPHKCw/trUTAQQAbBaqfSA0YQEALCEDAQCbVSpMlX58X68MYF0CiQACADYzfvaBGPpAAOD8RB8I6lVFRYVmzZqlioqKhq4KQgTXFAKNiYRBqmoCUrBNHMK5i2uq/lV95n/f3lZN/JhIWH7ErYyue4LuZ0cTFgDYzC2H3H40+Lj9eByunWjCAgBYUu8ZiNvt1r59+xQdHS2HIzg7hoJBWVmZ17+Av7im6sYYoyNHjigpKUlhYYH5jh2qnej1HkD27dun5OTk+j7sOYvPCoHGNVU3hYWFatWqVUD2VWnCVGn8mAcSpF3V9R5AoqOjJUlffdxGrqa0oCEwbrzksoauAkLEjzqhf+ptz98qnF69B5CqZitX0zC5/BiVAFTXyNG4oauAUPHTl/1ANrGf7EQPvUfaMgoLAGzm9vNWJozCAgCEFDIQALAZnegAAEvcCmMiIQAAVchAAMBmlcahSj9uye7PtnYigACAzfx/oFRwNmERQADAZm4TJrcfnejuIO1Epw8EAGAJGQgA2IwmLACAJW751xHuDlxVAoomLACAJWQgAGAz/ycSBud3fQIIANjM/1uZBGcACc5aAQCCHhkIANiM54EAACyhCQsAgGrIQADAZv5PJAzO7/oEEACwmds45PZnImGQ3o03OMMaACDokYEAgM3cfjZhMZEQAM5T/t/OnQACAOelSjlU6cdcDn+2tVNwhjUAQNAjAwEAm9GEBQCwpFL+NUNVBq4qARWcYQ0AYFl2drZ69eql6OhoxcfHa9iwYdq5c6fXOn379pXD4fBa7rrrLp+OQwABAJtVNWH5s/hi48aNmjhxoj744AO9++67OnHihAYOHKjy8nKv9SZMmKD9+/d7lqeeesqn49CEBQA2q++bKa5Zs8br9dKlSxUfH69t27bp2muv9ZRfcMEFSkxMtFwvMhAACHGlpaWSpLi4OK/yF154Qc2bN1eXLl00ffp0ff/99z7tlwwEAGxm/HweiPlp27KyMq9yp9Mpp9N5xm3dbremTJmitLQ0denSxVN+8803KyUlRUlJSdq+fbseeOAB7dy5U6+88kqd60UAAQCbBaoJKzk52at85syZmjVr1hm3nThxoj755BP985//9Cq/4447PP+/7LLL1LJlS/Xv318FBQVq3759nepFAAGAc0RhYaFcLpfn9dmyj0mTJunNN9/Upk2b1KpVqzOu27t3b0nS7t27CSAAECwCdTt3l8vlFUBOxxijyZMn69VXX9WGDRvUtm3bs26Tn58vSWrZsmWd60UAAQCb1fcDpSZOnKgVK1botddeU3R0tIqKiiRJMTExioqKUkFBgVasWKFf/epXatasmbZv366pU6fq2muvVdeuXet8HAIIAISYhQsXSjo5WbC6JUuWaNy4cYqIiNC6des0b948lZeXKzk5WSNGjNDDDz/s03EIIABgs/p+IqEx5ozvJycna+PGjZbrU4UAAgA2cyvMr4dC8UApADhPVRqHKv3IQPzZ1k7BGdYAAEGPDAQAbFbffSD1hQACADYzfj5QygTpA6WCs1YAgKBHBgIANquUw88nEtKEBQDnJbfxrx/DfeZpHQ2GJiwAgCVkIABgMyuPpT11+2BEAAEAm7n9fKCUP9vaKTjDGgAg6JGBAIDNQvVWJgQQALBZqPaBBGetAABBjwwEAGzmlp/3wgrSTnQCCADYzPg5CssQQADg/BSqd+OlDwQAYAkZCADYLFRHYRFAAMBmNGEBAFANGQgA2CxU74VFAAEAm9GEBQBANWQgAGCzUM1ACCAAYLNQDSA0YQEALCEDAQCbkYFUk5OTozZt2igyMlK9e/fWRx99FOh6AUDIMPp5KK+VxTT0CZyGzwFk5cqVysrK0syZM/Xxxx+rW7duSk9P14EDB+yoHwCc86oyEH+WYORzAJkzZ44mTJig8ePHq3Pnzlq0aJEuuOACLV682I76AQCClE99IMePH9e2bds0ffp0T1lYWJgGDBigvLy8WrepqKhQRUWF53VZWZnFqgLAuYk+EEmHDh1SZWWlEhISvMoTEhJUVFRU6zbZ2dmKiYnxLMnJydZrCwDnIJqwLJo+fbpKS0s9S2Fhod2HBADUA5+asJo3b67w8HAVFxd7lRcXFysxMbHWbZxOp5xOp/UaAsA5jiYsSREREerRo4dyc3M9ZW63W7m5uUpNTQ145QAgFBjj8HsJRj5PJMzKylJmZqZ69uypK6+8UvPmzVN5ebnGjx9vR/0AAEHK5wAyatQoHTx4UDNmzFBRUZG6d++uNWvW1OhYBwCcxPNAqpk0aZImTZoU6LoAQEiiDwQAgGq4mSIA2MzfjvCQ6UQHAPiGJiwAAKohAwEAm9GEBQCwxPjZhEUAAYDzlJFk/HgqVMg8UAoAAIkMBABs55ZDjhCciU4GAgA2q++bKWZnZ6tXr16Kjo5WfHy8hg0bpp07d3qtc+zYMU2cOFHNmjVT06ZNNWLEiBp3Wj8bAggAhJiNGzdq4sSJ+uCDD/Tuu+/qxIkTGjhwoMrLyz3rTJ06VW+88YZWrVqljRs3at++fRo+fLhPx6EJCwBs5jYOOepxIuGaNWu8Xi9dulTx8fHatm2brr32WpWWlurPf/6zVqxYoeuuu06StGTJEnXq1EkffPCBfvnLX9bpOGQgAGAzY/xf/FFaWipJiouLkyRt27ZNJ06c0IABAzzrdOzYUa1bt1ZeXl6d90sGAgDniLKyMq/XdXniq9vt1pQpU5SWlqYuXbpIkoqKihQREaHY2FivdRMSElRUVFTn+pCBAIDNAtWJnpycrJiYGM+SnZ191mNPnDhRn3zyiV566aWAnxcZCADYLFC3MiksLJTL5fKUny37mDRpkt58801t2rRJrVq18pQnJibq+PHjOnz4sFcWUlxcrMTExDrXiwwEAM4RLpfLazldADHGaNKkSXr11Vf13nvvqW3btl7v9+jRQ40bN1Zubq6nbOfOnfr666+Vmppa5/qQgQCAzep7FNbEiRO1YsUKvfbaa4qOjvb0a8TExCgqKkoxMTG67bbblJWVpbi4OLlcLk2ePFmpqal1HoElEUAAwHb+jqTydduFCxdKkvr27etVvmTJEo0bN06SNHfuXIWFhWnEiBGqqKhQenq6FixY4NNxCCAAEGJMHSJOZGSkcnJylJOTY/k4BBAAsNnJDMSfTvQAViaACCAAYDMeKAUAsMTIv2d6BGkCwjBeAIA1ZCAAYDOasAAA1oRoGxZNWAAAS8hAAMBufjZhiSYsADg/1fdM9PpCExYAwBIyEACwGaOwAADWGId//RhBGkBowgIAWEIGAgA2C9VOdAIIANiNiYQAAPyMDAQAbMYoLACAdUHaDOUPAggA2CxUMxD6QAAAlpCBAIDdQnQUFgEEAGzn+GnxZ/vgQxMWAMASMhAAsBtNWAAAS0I0gNCEBQCwhAwEAOwWordzJ4AAgM1C9W68NGEBACwhAwEAu4VoJzoBBADsFqJ9IDRhAQAsIQMBAJs5zMnFn+2DEQEEAOxGHwgAwBL6QAAA+BkZCADYjSYsAIAlIRpAaMICAFhCBgIAdgvRDIQAAgB2YxQWAAA/IwMBAJsxEx0AYE2I9oHQhAUAsIQAAgCwhCYsALCZQ372gQSsJoHVYAHk17f9PzVqFNlQh0eIueZfHzR0FRAiKo6e0IarGroW5wYyEACwG/NAAACWmAAsPtq0aZOGDBmipKQkORwOrV692uv9cePGyeFweC033HCDT8cggACA3RoggJSXl6tbt27Kyck57To33HCD9u/f71lefPFFn45BExYAhKCMjAxlZGSccR2n06nExETLxyADAQCbVc1E92exw4YNGxQfH68OHTro7rvvVklJiU/bk4EAgN0CNBO9rKzMq9jpdMrpdFra5Q033KDhw4erbdu2Kigo0IMPPqiMjAzl5eUpPDy8TvsggADAOSI5Odnr9cyZMzVr1ixL+xo9erTn/5dddpm6du2q9u3ba8OGDerfv3+d9kEAAQC7BSgDKSwslMvl8hRbzT5q065dOzVv3ly7d+8mgABAsAjU3XhdLpdXAAmkb775RiUlJWrZsmWdtyGAAEAIOnr0qHbv3u15vWfPHuXn5ysuLk5xcXF69NFHNWLECCUmJqqgoEDTpk3TRRddpPT09DofgwACAHZrgJnoW7duVb9+/Tyvs7KyJEmZmZlauHChtm/frmXLlunw4cNKSkrSwIED9dhjj/nULEYAAQC7NcDzQPr27StjTr/hO++840eFTmIeCADAEjIQALAZj7QFAFgToo+0JYAAgN38vR1JkAYQ+kAAAJaQgQCA3WjCAgBYEqIBhCYsAIAlZCAAYLNQHcZLBgIAsIQAAgCwhCYsALBbiHaiE0AAwGb0gQAAUA0ZCADUhyDNIvxBAAEAu4VoHwhNWAAAS8hAAMBmodqJTgABALuFaBMWAQQAbBaqGQh9IAAAS8hAAMBuNGEBACwJ0QBCExYAwBIyEACwWah2ohNAAMBuNGEBAPAzMhAAsFuIZiAEEACwWaj2gdCEBQCwhAwEAOxGExYAwAqasAAAqIYMBADsRhMWAMASAggAwArHT4s/2wcj+kAAAJaQgQCA3WjCAgBYwTBeAACqIQMBALvRhAUAsCxIg4A/aMICAFhCBgIANgvVTnQCCADYLUT7QGjCAgBYQgYCADajCQsAYA1NWAAA/IwAAgA2q2rC8mfx1aZNmzRkyBAlJSXJ4XBo9erVXu8bYzRjxgy1bNlSUVFRGjBggHbt2uXTMQggAGA3E4DFR+Xl5erWrZtycnJqff+pp57Ss88+q0WLFunDDz9UkyZNlJ6ermPHjtX5GPSBAIDdGqAPJCMjQxkZGbXvzhjNmzdPDz/8sIYOHSpJ+stf/qKEhAStXr1ao0ePrtMxyEAA4DyzZ88eFRUVacCAAZ6ymJgY9e7dW3l5eXXeDxkIANgsUMN4y8rKvMqdTqecTqfP+ysqKpIkJSQkeJUnJCR43qsLMhAAsFuA+kCSk5MVExPjWbKzs+v3PE5BBgIA54jCwkK5XC7PayvZhyQlJiZKkoqLi9WyZUtPeXFxsbp3717n/ZCBAIDNHMb4vUiSy+XyWqwGkLZt2yoxMVG5ubmesrKyMn344YdKTU2t837IQADAbg0wCuvo0aPavXu35/WePXuUn5+vuLg4tW7dWlOmTNHjjz+uiy++WG3bttUjjzyipKQkDRs2rM7H8DkDOdvkFABAw9u6dasuv/xyXX755ZKkrKwsXX755ZoxY4Ykadq0aZo8ebLuuOMO9erVS0ePHtWaNWsUGRlZ52P4nIFUTU659dZbNXz4cF83B4DzTkPcTLFv374y5vQbOhwOzZ49W7Nnz7ZcL58DyJkmpwAAahGiN1O0vQ+koqJCFRUVntenjmMGAJybbB+FlZ2d7TVuOTk52e5DAkBQaYibKdYH2wPI9OnTVVpa6lkKCwvtPiQABJcGuJlifbC9CcvqVHsAQHBjHggA2IxH2v7kbJNTAACnYBTWSVu3blW/fv08r7OysiRJmZmZWrp0acAqBgChJFizCH/4HEDONjkFAHB+oA8EAOxmzMnFn+2DEAEEAGwWqp3o3M4dAGAJGQgA2I1RWAAAKxzuk4s/2wcjmrAAAJaQgQCA3WjCAgBYwSgsAACqIQMBALsxkRAAYAVNWAAAVEMGAgB2YxQWAMCKUG3CIoAAgN1CtBOdPhAAgCVkIABgM5qwAADWhGgnOk1YAABLyEAAwGY0YQEArHGbk4s/2wchmrAAAJaQgQCA3UK0E50AAgA2c8jPPpCA1SSwaMICAFhCBgIAdgvRW5kQQADAZgzjBQBYE6Kd6PSBAAAsIQMBAJs5jJHDj34Mf7a1EwEEAOzm/mnxZ/sgRBMWAMASMhAAsBlNWAAAaxiFBQDAz8hAAMBuzEQHAFgRqjPRacICAFhCBgIAdqMJCwBghcN9cvFn+2BEExYAhJhZs2bJ4XB4LR07dgz4cchAAMBuDdCEdemll2rdunWe140aBf7PPQEEAOzWABMJGzVqpMTERD8OenY0YQGAzapuZeLP4qtdu3YpKSlJ7dq10y233KKvv/464OdFBgIA54iysjKv106nU06ns8Z6vXv31tKlS9WhQwft379fjz76qK655hp98sknio6ODlh9yEAAwG5VfSD+LJKSk5MVExPjWbKzs2s9XEZGhn7zm9+oa9euSk9P19tvv63Dhw/r5ZdfDuhpkYEAgN2M/Humx08tWIWFhXK5XJ7i2rKP2sTGxuqSSy7R7t27/ahETWQgAHCOcLlcXktdA8jRo0dVUFCgli1bBrQ+BBAAsFl9d6Lff//92rhxo/bu3avNmzfrxhtvVHh4uMaMGRPQ86IJCwDsZuTnPBDfVv/mm280ZswYlZSUqEWLFrr66qv1wQcfqEWLFtbrUAsCCACEmJdeeqlejkMAAQC7cTNFAIAlbkkOP7cPQnSiAwAsIQMBAJtZvR1J9e2DEQEEAOwWon0gNGEBACwhAwEAu4VoBkIAAQC7EUAAAJYwjBcAgJ+RgQCAzRjGCwCwJkT7QGjCAgBYQgYCAHZzG8nhRxbhDs4MhAACAHYL0Saseg8g5qcP4scfK+r70AhhFUdPNHQVECIqyk9eSyZI/2gHk3oPIEeOHJEk5eU9Wd+HRgj7x1UNXQOEmiNHjigmJiZAe/MzA/H1kYT1pN4DSFJSkgoLCxUdHS2Hw5+ZNaGtrKxMycnJKiwslMvlaujqIARwTdWNMUZHjhxRUlJSIHdKE1YghIWFqVWrVvV92HOWy+Xilx0BxTV1doHLPEIbnegAYDe3kV/NUIzCAoDzlHGfXPzZPggxkTBIOZ1OzZw5U06ns6GrghDBNYVAcxjGqgGALcrKyhQTE6MByXerUZj1wP2ju0LrCheqtLQ0qPqvaMICALvRBwIAsCREh/HSBwIAsIQMBADsZuRnBhKwmgQUAQQA7EYTFgAAPyMDAQC7ud2S/JgM6A7OiYQEEACwG01YAAD8jAwEAOwWohkIAQQA7BaiM9FpwgIAWEIGAgA2M8Yt48ct2f3Z1k4EEACwmzH+NUMFaR8ITVgAAEvIQADAbsbPTvQgzUAIIABgN7dbcoTeI20JIABgtxDNQOgDAQBYQgYCADYzbreMH01YDOMFgPMVTVgAAPyMDAQA7OY2kiP0MhACCADYzRj59UCpIA0gNGEBACwhAwEAmxm3kfGjCcuQgQDAecq4/V8syMnJUZs2bRQZGanevXvro48+CuhpEUAAIAStXLlSWVlZmjlzpj7++GN169ZN6enpOnDgQMCOQQABAJsZt/F78dWcOXM0YcIEjR8/Xp07d9aiRYt0wQUXaPHixQE7LwIIANitnpuwjh8/rm3btmnAgAGesrCwMA0YMEB5eXkBOy060QHAZj/qhF8T0X/UCUlSWVmZV7nT6ZTT6ayx/qFDh1RZWamEhASv8oSEBH3++efWK3IKAggA2CQiIkKJiYn6Z9Hbfu+radOmSk5O9iqbOXOmZs2a5fe+rSKAAIBNIiMjtWfPHh0/ftzvfRlj5HA4vMpqyz4kqXnz5goPD1dxcbFXeXFxsRITE/2uSxUCCADYKDIyUpGRkfV6zIiICPXo0UO5ubkaNmyYJMntdis3N1eTJk0K2HEIIAAQgrKyspSZmamePXvqyiuv1Lx581ReXq7x48cH7BgEEAAIQaNGjdLBgwc1Y8YMFRUVqXv37lqzZk2NjnV/OEywzpEHAAQ15oEAACwhgAAALCGAAAAsIYAAACwhgAAALCGAAAAsIYAAACwhgAAALCGAAAAsIYAAACwhgAAALCGAAAAs+f+ZORgySSHs2wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ConvLSTM\n",
    "print('ConvLSTM')\n",
    "test(test_dataloader, model_ConvLSTM, loss_fn, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet24\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.835674 \n",
      "\n",
      " Label 0\n",
      "    accuracy\t0.839\n",
      " specificity\t0.677\n",
      " sensitivity\t1.000\n",
      " Label 1\n",
      "    accuracy\t0.839\n",
      " specificity\t1.000\n",
      " sensitivity\t0.677\n",
      "[[31  0]\n",
      " [10 21]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ResNet24\n",
    "print('ResNet24')\n",
    "test(test_dataloader, model_resnet, loss_fn, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinyFallNet\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.813262 \n",
      "\n",
      " Label 0\n",
      "    accuracy\t0.500\n",
      " specificity\t0.000\n",
      " sensitivity\t1.000\n",
      " Label 1\n",
      "    accuracy\t0.500\n",
      " specificity\t1.000\n",
      " sensitivity\t0.000\n",
      "[[31  0]\n",
      " [31  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\python\\lib\\site-packages\\torch\\nn\\modules\\container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAGZCAYAAACnsGcEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAuMUlEQVR4nO3de1xVdb7/8fcGZUPKhlABGREvlZdMLTWHqNQ0iVFHUye1Hg/Rym5qR6ljYxc168RUk5ca1GnOeBkny5xTdh0zyctMUakdjjaVKWpRCiq/BMVEY39/fzjs2ILKXnsv2G5fz8djPXR/97p812bBZ3++l7UcxhgjAAB8FNbQFQAAnJ8IIAAASwggAABLCCAAAEsIIAAASwggAABLCCAAAEsIIAAASwggAABLLvgAsnPnTg0cOFAxMTFyOBxavXp1QPe/d+9eORwOLV26NKD7PZ/17dtXffv2Deg+CwsLFRkZqQ8//DCg+w1Wzz77rNq1a6fw8HB1797dp21P//yD9Rr153dzw4YNcjgc2rBhg6ds3LhxatOmjed1SUmJmjRponfffTdwlb7ABEUAKSgo0N1336127dopMjJSLpdLaWlpmj9/vn788Udbj52Zmant27frv/7rv7R8+XL17NnT1uPVp3HjxsnhcMjlctX6Oe7cuVMOh0MOh0O///3vfd7/vn37NGvWLOXn5wegtv6ZPXu2evfurbS0NK/y77//XrfccotiY2Plcrk0dOhQ7d69u4FqWbt3331Xs2bNqvP6a9eu1bRp05SWlqYlS5boqaeesq9ydazPHXfcoS5duig8PNzrj7Q/7P7dbNasme6880499thjAd3vBcU0sLfffttERUWZ2NhYc//995sXX3zR/OEPfzCjR482jRs3NhMmTLDt2MeOHTOSzCOPPGLbMdxut/nxxx/NTz/9ZNsxziQzM9M0atTIhIeHm5UrV9Z4f+bMmSYyMtJIMs8++6zP+9+8ebORZJYsWeLTdhUVFaaiosLn453JgQMHTOPGjc2KFSu8yo8cOWIuvfRSEx8fb55++mkzZ84ck5ycbFq1amUOHToUsOP7a+LEicaXX8WHHnrIhIWFWf4M+/TpY/r06eN5vWfPHks/xyqZmZkmMjLSXHPNNaZVq1YmJSXF0n6q8/d3c/369UaSWb9+vVc9T6/bF198YSSZ3NxcP2p74WrQDGTPnj0aPXq0UlJS9MUXX2j+/PmaMGGCJk6cqJdffllffPGFLr/8ctuOf/DgQUlSbGysbcdwOByKjIxUeHi4bcc4G6fTqf79++vll1+u8d6KFSs0aNCgeqvLsWPHJEkRERGKiIgI2H7/+te/qlGjRhoyZIhX+YIFC7Rz5069/fbbmjZtmqZOnaq1a9dq//79eu655wJ2/Pp24MABRUVFBfQz9MdTTz2lsrIyffjhh+rWrVtA9lkfv5uS1KlTJ3Xp0iXomu/OGw0Zve655x4jyXz44Yd1Wv/kyZNm9uzZpl27diYiIsKkpKSY6dOnm+PHj3utl5KSYgYNGmT+8Y9/mF69ehmn02natm1rli1b5lln5syZRpLXUvXtpLZvKtW3qW7t2rUmLS3NxMTEmCZNmpjLLrvMTJ8+3fP+mb7d5ebmmmuvvdZcdNFFJiYmxvz61782X3zxRa3H27lzp8nMzDQxMTHG5XKZcePGmfLy8nN+XpmZmaZJkyZm6dKlxul0mh9++MHz3qeffmokmf/5n/+pkYGUlJSYBx54wHTp0sU0adLEREdHm5tuusnk5+d71qn6hnf6UnWeffr0MZdffrnZsmWLue6660xUVJT5j//4D8971b8Bjx071jidzhrnP3DgQBMbG2u+//77s57n9ddfb/r27VujvFevXqZXr141ygcOHGjat2/vVfbNN9+YL7/88qzHqX7eK1euNE8++aT5xS9+YZxOp7nhhhvMzp07a6z/6quvmquuuspERkaaZs2amdtuu8189913nvczMzNr/RzP5Gyf+eLFi02/fv1MixYtTEREhOnUqZNZsGBBjX0EOgOpbtCgQWfNQHbt2mV27dp11n2c7Xdz79695t577zWXXXaZiYyMNHFxcWbkyJFmz549XvuoawZijDFTp041sbGxxu121/EsUaVBM5C33npL7dq10zXXXFOn9e+8807NmDFDV111lebOnas+ffooOztbo0ePrrHurl27NHLkSN1444167rnndPHFF2vcuHH617/+JUkaPny45s6dK0kaM2aMli9frnnz5vlU/3/9618aPHiwKioqNHv2bD333HP69a9/fc6O3HXr1ik9PV0HDhzQrFmzlJWVpY8++khpaWnau3dvjfVvueUWHTlyRNnZ2brlllu0dOlSPf7443Wu5/Dhw+VwOPTaa695ylasWKGOHTvqqquuqrH+7t27tXr1ag0ePFhz5szRf/7nf2r79u3q06eP9u3bJ+nUN7fZs2dLku666y4tX75cy5cv1/XXX+/ZT0lJiTIyMtS9e3fNmzdP/fr1q7V+8+fPV4sWLZSZmanKykpJ0h//+EetXbtWL7zwgpKSks54bidPntTmzZtrnIfb7da2bdtqbTe/+uqrVVBQoCNHjnjKxo4dq06dOp3xOKf73e9+p9dff10PPvigpk+fro8//li33Xab1zpLly7VLbfcovDwcGVnZ2vChAl67bXXdO211+rw4cOSpLvvvls33nijJHk+w+XLl5/xuMuXL9d1110np9NZ4zNfuHChUlJS9PDDD+u5555TcnKy7rvvPuXk5NT5vOzWv39/9e/f/6zrnO13c/Pmzfroo480evRoPf/887rnnnuUm5urvn37ejJcX/Xo0UOHDx/2/G2ADxoqcpWWlhpJZujQoXVaPz8/30gyd955p1f5gw8+aCSZDz74wFOWkpJiJJlNmzZ5yg4cOGCcTqd54IEHPGVV37xOb/+vawYyd+5cI8kcPHjwjPWu7dtd9+7dTXx8vCkpKfGU/d///Z8JCwszY8eOrXG822+/3WufN998s2nWrNkZj1n9PJo0aWKMMWbkyJGmf//+xhhjKisrTWJionn88cdr/QyOHz9uKisra5yH0+k0s2fP9pSdrQ+kT58+RpJZtGhRre9V/wZsjDHvvfeekWSefPJJs3v3btO0aVMzbNiwc57jrl27jCTzwgsveJUfPHjQSPKqb5WcnBwjyXz11Vc16nsuVd9sO3Xq5NUHMX/+fCPJbN++3RhjzIkTJ0x8fLzp0qWL+fHHHz3rvf3220aSmTFjhqfM1z6Q6j/X6o4dO1ajLD093bRr186rrCEzkJSUlDr1kZzpd7O2c8zLyzOSzF/+8hdPmS8ZyEcffeTJKuGbBstAysrKJEnR0dF1Wr9qqF1WVpZX+QMPPCBJeuedd7zKO3furOuuu87zukWLFurQoUNAR+BUtc++8cYbcrvdddpm//79ys/P17hx4xQXF+cp79q1q2688cZahxTec889Xq+vu+46lZSUeD7Durj11lu1YcMGFRUV6YMPPlBRUZFuvfXWWtd1Op0KCzt1aVRWVqqkpERNmzZVhw4d9Nlnn9X5mE6nU+PHj6/TugMHDtTdd9+t2bNna/jw4YqMjNQf//jHc25XUlIiSbr44ou9yqtGnTmdzhrbREZGeq0jnRr2aXx4ttr48eO9+iCqrrWq62vLli06cOCA7rvvPs/xJGnQoEHq2LFjjes1EKKiojz/Ly0t1aFDh9SnTx/t3r1bpaWlAT+eFXv37q01y66r6ud48uRJlZSU6JJLLlFsbKxP12Z1VdfOoUOHLNfrQtVgAcTlckmSVzPC2XzzzTcKCwvTJZdc4lWemJio2NhYffPNN17lrVu3rrGPiy++WD/88IPFGtc0atQopaWl6c4771RCQoJGjx6tV1999azBpKqeHTp0qPFep06ddOjQIZWXl3uVn34uVRe8L+fyq1/9StHR0Vq5cqVeeukl9erVq8ZnWcXtdmvu3Lm69NJL5XQ61bx5c7Vo0ULbtm3z6Q/RL37xC586en//+98rLi5O+fn5ev755xUfH1/nbU//41/1h6aioqLGusePH/dax4pz/UzO9nPu2LFjjes1ED788EMNGDBATZo0UWxsrFq0aKGHH35YkoImgPjrxx9/1IwZM5ScnOx1bR4+fNjyOVZdOw6HI5BV9Th+/LjKysr8Xqqu22DSqKEO7HK5lJSUpM8//9yn7er6Qz7TqKe6fMs80zGq2uerREVFadOmTVq/fr3eeecdrVmzRitXrtQNN9ygtWvXBmzklT/nUsXpdGr48OFatmyZdu/efdZ5B0899ZQee+wx3X777XriiScUFxensLAwTZkypc6ZluT7H+j//d//1YEDByRJ27dv15gxY865TbNmzSTVDKZxcXFyOp3av39/jW2qys7Wt3IugfiZBFJBQYH69++vjh07as6cOUpOTlZERITeffddzZ0716efWzCbPHmylixZoilTpig1NdUzyXD06NGWz7Hq2mnevHkgqyrpVPBom9JURQcqz73yOSQmJmrPnj1eGW1Da7AAIkmDBw/Wiy++qLy8PKWmpp513ZSUFLndbu3cudOrs7O4uFiHDx9WSkpKwOp18cUXezo5q6vtW2NYWJinY3DOnDl66qmn9Mgjj2j9+vUaMGBArechSTt27Kjx3ldffaXmzZurSZMm/p9ELW699VYtXrxYYWFhtQ48qPK3v/1N/fr105///Gev8sOHD3v9kgXyG1t5ebnGjx+vzp0765prrtEzzzyjm2++Wb169Trrdq1bt1ZUVJT27NnjVR4WFqYrrrhCW7ZsqbHNJ598onbt2tW5+dSK6j/nG264weu9HTt2eF2vgfgc33rrLVVUVOjNN9/0yo7Wr1/v976Dyd/+9jdlZmZ6DcM+fvx4rb+vdVV17fgyiKKuTpw4oaIDldqzNUWuaOsNPmVH3Grb4xudOHEiqAJIg47CmjZtmpo0aaI777xTxcXFNd4vKCjQ/PnzJZ1qgpFUY6TUnDlzJCmg8xnat2+v0tJSbdu2zVO2f/9+vf76617r/b//9/9qbFt1W4namk4kqWXLlurevbuWLVvmddF//vnnWrt2rec87dCvXz898cQT+sMf/qDExMQzrhceHl7jm/SqVav0/fffe5VVBTp/fnmrPPTQQ/r222+1bNkyzZkzR23atFFmZuYZP8cqjRs3Vs+ePWsNFCNHjtTmzZu93tuxY4c++OAD/eY3v/Fa99tvv9VXX33l93lU6dmzp+Lj47Vo0SKvc/j73/+uL7/80ut6DcTnWJURVf+5lZaWasmSJZb3aYeCggIVFBRY3r62a/OFF16o0Trgi61btyomJsbWOWdNmvq/BKMGzUDat2+vFStWaNSoUerUqZPGjh2rLl266MSJE/roo4+0atUqjRs3TpLUrVs3ZWZm6sUXX9Thw4fVp08fffrpp1q2bJmGDRt2xiGiVowePVoPPfSQbr75Zt1///06duyYFi5cqMsuu8yro2727NnatGmTBg0apJSUFB04cEALFixQq1atdO21155x/88++6wyMjKUmpqqO+64Qz/++KNeeOEFxcTE+HRLC1+FhYXp0UcfPed6gwcP1uzZszV+/Hhdc8012r59u1566SW1a9fOa7327dsrNjZWixYtUnR0tJo0aaLevXurbdu2PtXrgw8+0IIFCzRz5kzPcNwlS5aob9++euyxx/TMM8+cdfuhQ4fqkUceUVlZmadvTZLuu+8+/elPf9KgQYP04IMPqnHjxpozZ44SEhI8gy+qjB07Vhs3bgxYE1Tjxo319NNPa/z48erTp4/GjBmj4uJizZ8/X23atNHUqVM96/bo0UOSdP/99ys9PV3h4eFnzRBrM3DgQEVERGjIkCG6++67dfToUf3pT39SfHx8rc1457J37161bdtWmZmZ55xkt23bNr355puSTg2fLy0t1ZNPPinp1O9t9QmeVUN4rXakDx48WMuXL1dMTIw6d+6svLw8rVu3ztOUacX777+vIUOG2NYHEtIaavhXdV9//bWZMGGCadOmjYmIiDDR0dEmLS3NvPDCC16TBE+ePGkef/xx07ZtW9O4cWOTnJx81omEpzvT8MXabuOxdu1a06VLFxMREWE6dOhg/vrXv9YYxpubm2uGDh1qkpKSTEREhElKSjJjxowxX3/9dY1jnD5Ect26dSYtLc1ERUUZl8tlhgwZcsaJhKcPE16yZImRVGPy1OnONNyzujMN433ggQdMy5YtTVRUlElLSzN5eXm1Dr994403TOfOnU2jRo1qnUhYm+r7KSsrMykpKeaqq64yJ0+e9Fpv6tSpJiwszOTl5Z31HIqLi02jRo3M8uXLa7xXWFhoRo4caVwul2natKkZPHhwrRP+fB3Gu2rVKq/yM/2cV65caa688krjdDpNXFxcjYmExhjz008/mcmTJ5sWLVoYh8Nxznqc6ef65ptvmq5du5rIyEjTpk0b8/TTT5vFixfXuFbqMox3+/btRpL57W9/e/YPxPx8Pda2ZGZmeq3r7zDeH374wYwfP940b97cNG3a1KSnp5uvvvrKpKSkeB2rrsN4v/zySyPJrFu37px1sqJqukLRjtbm2L42lpeiHa2NJFNaWmpLPa1yGNNAvX5AAN1xxx36+uuv9Y9//KOhqxISFixYoGnTpqmgoEAJCQkNXR3bTJkyRZs2bdLWrVttyUDKysoUExOjfTta+d0HktThO5WWlnpl2Q0tKO7GC/hr5syZ2rx58wVzO3e7rV+/Xvfff39IB4+SkhL993//t5588kmarywigCAktG7dWsePH69xO3dYs2rVqga/TbzdmjVrpqNHj9o6cKVKpTF+L75YuHChunbtKpfLJZfLpdTUVP3973/3vH/8+HFNnDhRzZo1U9OmTTVixIhaBzKdCwEEAGzmlvF78UWrVq30u9/9Tlu3btWWLVt0ww03aOjQoZ77fU2dOlVvvfWWVq1apY0bN2rfvn0aPny4z+dFHwgA2KSqD+Sbr5L87gNJ6bjPrz6QuLg4Pfvssxo5cqRatGihFStWaOTIkZJOzUHr1KmT8vLy9Mtf/rLO+yQDAQCbuWVU6cfiawZSXWVlpV555RWVl5crNTVVW7du1cmTJ70mOnfs2FGtW7dWXl6eT/tu0HkgAHAhsNIMdfr2kmrcQNXpdNZ6w1Dp1O2AUlNTdfz4cTVt2lSvv/66OnfurPz8fEVERNR4WFdCQoKKiop8qhcZCACcJ5KTkxUTE+NZsrOzz7huhw4dlJ+fr08++UT33nuvMjMz9cUXXwS0PmQgAGAzKyOpTt9ekgoLC736QM6UfUinHh1ddcftHj16aPPmzZo/f75GjRqlEydO6PDhw15ZSHFx8VlvcVQbMpAglJOTozZt2igyMlK9e/fWp59+2tBVwnls06ZNGjJkiJKSkuRwOLR69eqGrtIFxx2ARZJnWG7VcrYAUqMObrcqKirUo0cPNW7cWLm5uZ73duzYoW+//facN7U9HRlIkFm5cqWysrK0aNEi9e7dW/PmzVN6erp27Njh0/MxgCrl5eXq1q2bbr/9dktDNeG/qs5wf7b3xfTp05WRkaHWrVvryJEjWrFihTZs2KD33ntPMTExuuOOO5SVlaW4uDi5XC5NnjxZqampPo3AkgggQWfOnDmaMGGC50l+ixYt0jvvvKPFixfrt7/9bQPXDuejjIwMZWRkNHQ1UI8OHDigsWPHav/+/YqJiVHXrl313nvv6cYbb5QkzZ07V2FhYRoxYoQqKiqUnp6uBQsW+HwcAkgQOXHihLZu3arp06d7ysLCwjRgwACfh9cBCB6V5tTiz/a+OP1ZPqeLjIxUTk6OcnJyrFdK9IEElUOHDqmysrLG/YesDK8DEDwC1QcSbAggAABLaMIKIs2bN1d4eHiNm5pZGV4HIHi45VClrN/x1+3HtnYiAwkiERER6tGjh9fwOrfbrdzcXJ+H1wEIHm7j/xKMyECCTFZWljIzM9WzZ09dffXVmjdvnsrLyz2jsgBfHT16VLt27fK83rNnj/Lz8xUXF6fWrVs3YM1wviOABJlRo0bp4MGDmjFjhoqKitS9e3etWbMmpB/sA3tt2bJF/fr187zOysqSpDo97xyBUelnE5Y/29qJ27kDgE2qbuf+0b9aqqkft3M/esStay7fzyNtAQChgSYsALCZ2zjkNn6MwvJjWzsRQADAZqHaB0ITFgDAEjIQALBZpcJU6cf39coA1iWQCCAAYDPjZx+IoQ8EAC5M9IGgXlVUVGjWrFmqqKho6KogRHBNIdCYSBikqiYgBdvEIZy/uKbqX9Vn/vdtbdXEj4mE5Ufcyui6J+h+djRhAYDN3HLI7UeDj9uPx+HaiSYsAIAl9Z6BuN1u7du3T9HR0XI4grNjKBiUlZV5/Qv4i2uqbowxOnLkiJKSkhQWFpjv2KHaiV7vAWTfvn1KTk6u78Oet/isEGhcU3VTWFioVq1aBWRflSZMlcaPeSBB2lVd7wEkOjpakvTNZ23kakoLGgLj5suuaOgqIET8pJP6p971/K3CmdV7AKlqtnI1DZPLj1EJQHWNHI0bugoIFf/+sh/IJvZTneih90hbRmEBgM3cft7KhFFYAICQQgYCADajEx0AYIlbYUwkBACgChkIANis0jhU6cct2f3Z1k4EEACwmf8PlArOJiwCCADYzG3C5PajE90dpJ3o9IEAACwhAwEAm9GEBQCwxC3/OsLdgatKQNGEBQCwhAwEAGzm/0TC4PyuTwABAJv5fyuT4AwgwVkrAEDQIwMBAJvxPBAAgCU0YQEAUA0ZCADYzP+JhMH5XZ8AAgA2cxuH3P5MJAzSu/EGZ1gDAAQ9MhAAsJnbzyYsJhICwAXK/9u5E0AA4IJUKYcq/ZjL4c+2dgrOsAYACHpkIABgM5qwAACWVMq/ZqjKwFUloIIzrAEALMvOzlavXr0UHR2t+Ph4DRs2TDt27PBap2/fvnI4HF7LPffc49NxCCAAYLOqJix/Fl9s3LhREydO1Mcff6z3339fJ0+e1MCBA1VeXu613oQJE7R//37P8swzz/h0HJqwAMBm9X0zxTVr1ni9Xrp0qeLj47V161Zdf/31nvKLLrpIiYmJlutFBgIAIa60tFSSFBcX51X+0ksvqXnz5urSpYumT5+uY8eO+bRfMhAAsJnx83kg5t/blpWVeZU7nU45nc6zbut2uzVlyhSlpaWpS5cunvJbb71VKSkpSkpK0rZt2/TQQw9px44deu211+pcLwIIANgsUE1YycnJXuUzZ87UrFmzzrrtxIkT9fnnn+uf//ynV/ldd93l+f8VV1yhli1bqn///iooKFD79u3rVC8CCACcJwoLC+VyuTyvz5V9TJo0SW+//bY2bdqkVq1anXXd3r17S5J27dpFAAGAYBGo27m7XC6vAHImxhhNnjxZr7/+ujZs2KC2bduec5v8/HxJUsuWLetcLwIIANisvh8oNXHiRK1YsUJvvPGGoqOjVVRUJEmKiYlRVFSUCgoKtGLFCv3qV79Ss2bNtG3bNk2dOlXXX3+9unbtWufjEEAAIMQsXLhQ0qnJgtUtWbJE48aNU0REhNatW6d58+apvLxcycnJGjFihB599FGfjkMAAQCb1fcTCY0xZ30/OTlZGzdutFyfKgQQALCZW2F+PRSKB0oBwAWq0jhU6UcG4s+2dgrOsAYACHpkIABgs/ruA6kvBBAAsJnx84FSJkgfKBWctQIABD0yEACwWaUcfj6RkCYsALgguY1//Rjus0/raDA0YQEALCEDAQCbWXks7enbByMCCADYzO3nA6X82dZOwRnWAABBjwwEAGwWqrcyIYAAgM1CtQ8kOGsFAAh6ZCAAYDO3/LwXVpB2ohNAAMBmxs9RWIYAAgAXplC9Gy99IAAAS8hAAMBmoToKiwACADajCQsAgGrIQADAZqF6LywCCADYjCYsAACqIQMBAJuFagZCAAEAm4VqAKEJCwBgCRkIANiMDKSanJwctWnTRpGRkerdu7c+/fTTQNcLAEKG0c9Dea0spqFP4Ax8DiArV65UVlaWZs6cqc8++0zdunVTenq6Dhw4YEf9AOC8V5WB+LMEI58DyJw5czRhwgSNHz9enTt31qJFi3TRRRdp8eLFdtQPABCkfOoDOXHihLZu3arp06d7ysLCwjRgwADl5eXVuk1FRYUqKio8r8vKyixWFQDOT/SBSDp06JAqKyuVkJDgVZ6QkKCioqJat8nOzlZMTIxnSU5Otl5bADgP0YRl0fTp01VaWupZCgsL7T4kAKAe+NSE1bx5c4WHh6u4uNirvLi4WImJibVu43Q65XQ6rdcQAM5zNGFJioiIUI8ePZSbm+spc7vdys3NVWpqasArBwChwBiH30sw8nkiYVZWljIzM9WzZ09dffXVmjdvnsrLyzV+/Hg76gcACFI+B5BRo0bp4MGDmjFjhoqKitS9e3etWbOmRsc6AOAUngdSzaRJkzRp0qRA1wUAQhJ9IAAAVMPNFAHAZv52hIdMJzoAwDc0YQEAUA0ZCADYjCYsAIAlxs8mLAIIAFygjCTjx1OhQuaBUgAASGQgAGA7txxyhOBMdDIQALBZfd9MMTs7W7169VJ0dLTi4+M1bNgw7dixw2ud48ePa+LEiWrWrJmaNm2qESNG1LjT+rkQQAAgxGzcuFETJ07Uxx9/rPfff18nT57UwIEDVV5e7lln6tSpeuutt7Rq1Spt3LhR+/bt0/Dhw306Dk1YAGAzt3HIUY8TCdesWeP1eunSpYqPj9fWrVt1/fXXq7S0VH/+85+1YsUK3XDDDZKkJUuWqFOnTvr444/1y1/+sk7HIQMBAJsZ4//ij9LSUklSXFycJGnr1q06efKkBgwY4FmnY8eOat26tfLy8uq8XzIQADhPlJWVeb2uyxNf3W63pkyZorS0NHXp0kWSVFRUpIiICMXGxnqtm5CQoKKiojrXhwwEAGwWqE705ORkxcTEeJbs7OxzHnvixIn6/PPP9corrwT8vMhAAMBmgbqVSWFhoVwul6f8XNnHpEmT9Pbbb2vTpk1q1aqVpzwxMVEnTpzQ4cOHvbKQ4uJiJSYm1rleZCAAcJ5wuVxey5kCiDFGkyZN0uuvv64PPvhAbdu29Xq/R48eaty4sXJzcz1lO3bs0LfffqvU1NQ614cMBABsVt+jsCZOnKgVK1bojTfeUHR0tKdfIyYmRlFRUYqJidEdd9yhrKwsxcXFyeVyafLkyUpNTa3zCCyJAAIAtvN3JJWv2y5cuFCS1LdvX6/yJUuWaNy4cZKkuXPnKiwsTCNGjFBFRYXS09O1YMECn45DAAGAEGPqEHEiIyOVk5OjnJwcy8chgACAzU5lIP50ogewMgFEAAEAm/FAKQCAJUb+PdMjSBMQhvECAKwhAwEAm9GEBQCwJkTbsGjCAgBYQgYCAHbzswlLNGEBwIWpvmei1xeasAAAlpCBAIDNGIUFALDGOPzrxwjSAEITFgDAEjIQALBZqHaiE0AAwG5MJAQA4GdkIABgM0ZhAQCsC9JmKH8QQADAZqGagdAHAgCwhAwEAOwWoqOwCCAAYDvHvxd/tg8+NGEBACwhAwEAu9GEBQCwJEQDCE1YAABLyEAAwG4hejt3AggA2CxU78ZLExYAwBIyEACwW4h2ohNAAMBuIdoHQhMWAMASMhAAsJnDnFr82T4YEUAAwG70gQAALKEPBACAn5GBAIDdaMICAFgSogGEJiwAgCVkIABgtxDNQAggAGA3RmEBAPAzMhAAsBkz0QEA1oRoHwhNWAAASwggAABLaMICAJs55GcfSMBqElhkIAAAS8hAAMBuzAMBAFhiArD4aNOmTRoyZIiSkpLkcDi0evVqr/fHjRsnh8Phtdx0000+HYMAAgB2a4AAUl5erm7duiknJ+eM69x0003av3+/Z3n55Zd9OgZNWAAQgjIyMpSRkXHWdZxOpxITEy0fgwwEAGxWNRPdn8UOGzZsUHx8vDp06KB7771XJSUlPm1PBgIAdgvQTPSysjKvYqfTKafTaWmXN910k4YPH662bduqoKBADz/8sDIyMpSXl6fw8PA67YMAAgDnieTkZK/XM2fO1KxZsyzta/To0Z7/X3HFFeratavat2+vDRs2qH///nXaBwEEAOwWoAyksLBQLpfLU2w1+6hNu3bt1Lx5c+3atYsAAgDBIlB343W5XF4BJJC+++47lZSUqGXLlnXehgACACHo6NGj2rVrl+f1nj17lJ+fr7i4OMXFxenxxx/XiBEjlJiYqIKCAk2bNk2XXHKJ0tPT63wMAggA2K0BZqJv2bJF/fr187zOysqSJGVmZmrhwoXatm2bli1bpsOHDyspKUkDBw7UE0884VOzGAEEAOzWAM8D6du3r4w584bvvfeeHxU6hXkgAABLyEAAwGY80hYAYE2IPtKWAAIAdvP3diRBGkDoAwEAWEIGAgB2owkLAGBJiAYQmrAAAJaQgQCAzUJ1GC8ZCADAEgIIAMASmrAAwG4h2olOAAEAm9EHAgBANWQgAFAfgjSL8AcBBADsFqJ9IDRhAQAsIQMBAJuFaic6AQQA7BaiTVgEEACwWahmIPSBAAAsIQMBALvRhAUAsCREAwhNWAAAS8hAAMBmodqJTgABALvRhAUAwM/IQADAbiGagRBAAMBmodoHQhMWAMASMhAAsBtNWAAAK2jCAgCgGjIQALAbTVgAAEsIIAAAKxz/XvzZPhjRBwIAsIQMBADsRhMWAMAKhvECAFANGQgA2I0mLACAZUEaBPxBExYAwBIyEACwWah2ohNAAMBuIdoHQhMWAMASMhAAsBlNWAAAa2jCAgDgZwQQALBZVROWP4uvNm3apCFDhigpKUkOh0OrV6/2et8YoxkzZqhly5aKiorSgAEDtHPnTp+OQQABALuZACw+Ki8vV7du3ZSTk1Pr+88884yef/55LVq0SJ988omaNGmi9PR0HT9+vM7HoA8EAOzWAH0gGRkZysjIqH13xmjevHl69NFHNXToUEnSX/7yFyUkJGj16tUaPXp0nY5BBgIAF5g9e/aoqKhIAwYM8JTFxMSod+/eysvLq/N+yEAAwGaBGsZbVlbmVe50OuV0On3eX1FRkSQpISHBqzwhIcHzXl2QgQCA3QLUB5KcnKyYmBjPkp2dXb/ncRoyEAA4TxQWFsrlcnleW8k+JCkxMVGSVFxcrJYtW3rKi4uL1b179zrvhwwEAGzmMMbvRZJcLpfXYjWAtG3bVomJicrNzfWUlZWV6ZNPPlFqamqd90MGAgB2a4BRWEePHtWuXbs8r/fs2aP8/HzFxcWpdevWmjJlip588kldeumlatu2rR577DElJSVp2LBhdT6GzxnIuSanAAAa3pYtW3TllVfqyiuvlCRlZWXpyiuv1IwZMyRJ06ZN0+TJk3XXXXepV69eOnr0qNasWaPIyMg6H8PnDKRqcsrtt9+u4cOH+7o5AFxwGuJmin379pUxZ97Q4XBo9uzZmj17tuV6+RxAzjY5BQBQixC9maLtfSAVFRWqqKjwvD59HDMA4Pxk+yis7Oxsr3HLycnJdh8SAIJKQ9xMsT7YHkCmT5+u0tJSz1JYWGj3IQEguDTAzRTrg+1NWFan2gMAghvzQADAZjzS9t/ONTkFAHAaRmGdsmXLFvXr18/zOisrS5KUmZmppUuXBqxiABBKgjWL8IfPAeRck1MAABcG+kAAwG7GnFr82T4IEUAAwGah2onO7dwBAJaQgQCA3RiFBQCwwuE+tfizfTCiCQsAYAkZCADYjSYsAIAVjMICAKAaMhAAsBsTCQEAVtCEBQBANWQgAGA3RmEBAKwI1SYsAggA2C1EO9HpAwEAWEIGAgA2owkLAGBNiHai04QFALCEDAQAbEYTFgDAGrc5tfizfRCiCQsAYAkZCADYLUQ70QkgAGAzh/zsAwlYTQKLJiwAgCVkIABgtxC9lQkBBABsxjBeAIA1IdqJTh8IAMASMhAAsJnDGDn86MfwZ1s7EUAAwG7ufy/+bB+EaMICAFhCBgIANqMJCwBgDaOwAAD4GRkIANiNmegAACtCdSY6TVgAAEvIQADAbjRhAQCscLhPLf5sH4xowgKAEDNr1iw5HA6vpWPHjgE/DhkIANitAZqwLr/8cq1bt87zulGjwP+5J4AAgN0aYCJho0aNlJiY6MdBz40mLACwWdWtTPxZfLVz504lJSWpXbt2uu222/Ttt98G/LzIQADgPFFWVub12ul0yul01livd+/eWrp0qTp06KD9+/fr8ccf13XXXafPP/9c0dHRAasPGQgA2K2qD8SfRVJycrJiYmI8S3Z2dq2Hy8jI0G9+8xt17dpV6enpevfdd3X48GG9+uqrAT0tMhAAsJuRf8/0+HcLVmFhoVwul6e4tuyjNrGxsbrsssu0a9cuPypRExkIAJwnXC6X11LXAHL06FEVFBSoZcuWAa0PAQQAbFbfnegPPvigNm7cqL179+qjjz7SzTffrPDwcI0ZMyag50UTFgDYzcjPeSC+rf7dd99pzJgxKikpUYsWLXTttdfq448/VosWLazXoRYEEAAIMa+88kq9HIcAAgB242aKAABL3JIcfm4fhOhEBwBYQgYCADazejuS6tsHIwIIANgtRPtAaMICAFhCBgIAdgvRDIQAAgB2I4AAACxhGC8AAD8jAwEAmzGMFwBgTYj2gdCEBQCwhAwEAOzmNpLDjyzCHZwZCAEEAOwWok1Y9R5AzL8/iLKjQTouDeeln8zJhq4CQsRPOnUtmSD9ox1M6j2AHDlyRJKUctXe+j40Qtruhq4AQsyRI0cUExMToL35mYH4+kjCelLvASQpKUmFhYWKjo6Ww+HPzJrQVlZWpuTkZBUWFsrlcjV0dRACuKbqxhijI0eOKCkpKZA7pQkrEMLCwtSqVav6Pux5y+Vy8cuOgOKaOrfAZR6hjU50ALCb28ivZihGYQHABcq4Ty3+bB+EmEgYpJxOp2bOnCmn09nQVUGI4JpCoDkMY9UAwBZlZWWKiYnRgOR71SjMeuD+yV2hdYULVVpaGlT9VzRhAYDd6AMBAFgSosN46QMBAFhCBgIAdjPyMwMJWE0CigACAHajCQsAgJ+RgQCA3dxuSX5MBnQH50RCAggA2I0mLAAAfkYGAgB2C9EMhAACAHYL0ZnoNGEBACwhAwEAmxnjlvHjluz+bGsnAggA2M0Y/5qhgrQPhCYsAIAlZCAAYDfjZyd6kGYgBBAAsJvbLTlC75G2BBAAsFuIZiD0gQAALCEDAQCbGbdbxo8mLIbxAsCFiiYsAAB+RgYCAHZzG8kRehkIAQQA7GaM/HqgVJAGEJqwAACWkIEAgM2M28j40YRlyEAA4AJl3P4vFuTk5KhNmzaKjIxU79699emnnwb0tAggABCCVq5cqaysLM2cOVOfffaZunXrpvT0dB04cCBgxyCAAIDNjNv4vfhqzpw5mjBhgsaPH6/OnTtr0aJFuuiii7R48eKAnRcBBADsVs9NWCdOnNDWrVs1YMAAT1lYWJgGDBigvLy8gJ0WnegAYLOfdNKvieg/6aQkqayszKvc6XTK6XTWWP/QoUOqrKxUQkKCV3lCQoK++uor6xU5DQEEAGwSERGhxMRE/bPoXb/31bRpUyUnJ3uVzZw5U7NmzfJ731YRQADAJpGRkdqzZ49OnDjh976MMXI4HF5ltWUfktS8eXOFh4eruLjYq7y4uFiJiYl+16UKAQQAbBQZGanIyMh6PWZERIR69Oih3NxcDRs2TJLkdruVm5urSZMmBew4BBAACEFZWVnKzMxUz549dfXVV2vevHkqLy/X+PHjA3YMAggAhKBRo0bp4MGDmjFjhoqKitS9e3etWbOmRse6PxwmWOfIAwCCGvNAAACWEEAAAJYQQAAAlhBAAACWEEAAAJYQQAAAlhBAAACWEEAAAJYQQAAAlhBAAACWEEAAAJYQQAAAlvx/nhIPZUR8iR0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TinyFallNet\n",
    "print('TinyFallNet')\n",
    "test(test_dataloader, model_tinyFallNet, loss_fn, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fall_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
