{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.signal import resample\n",
    "\n",
    "from data_organizer_Kfall import DataOrganizer\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from utils import train, test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/32 folder...\n",
      "(815, 9, 50)\n",
      "Processing 2/32 folder...\n",
      "(790, 9, 50)\n",
      "Processing 3/32 folder...\n",
      "(805, 9, 50)\n",
      "Processing 4/32 folder...\n",
      "(795, 9, 50)\n",
      "Processing 5/32 folder...\n",
      "(780, 9, 50)\n",
      "Processing 6/32 folder...\n",
      "(805, 9, 50)\n",
      "Processing 7/32 folder...\n",
      "(790, 9, 50)\n",
      "Processing 8/32 folder...\n",
      "(815, 9, 50)\n",
      "Processing 9/32 folder...\n",
      "(815, 9, 50)\n",
      "Processing 10/32 folder...\n",
      "(800, 9, 50)\n",
      "Processing 11/32 folder...\n",
      "(785, 9, 50)\n",
      "Processing 12/32 folder...\n",
      "(780, 9, 50)\n",
      "Processing 13/32 folder...\n",
      "(810, 9, 50)\n",
      "Processing 14/32 folder...\n",
      "(800, 9, 50)\n",
      "Processing 15/32 folder...\n",
      "(815, 9, 50)\n",
      "Processing 16/32 folder...\n",
      "(815, 9, 50)\n",
      "Processing 17/32 folder...\n",
      "(805, 9, 50)\n",
      "Processing 18/32 folder...\n",
      "(810, 9, 50)\n",
      "Processing 19/32 folder...\n",
      "(800, 9, 50)\n",
      "Processing 20/32 folder...\n",
      "(710, 9, 50)\n",
      "Processing 21/32 folder...\n",
      "(810, 9, 50)\n",
      "Processing 22/32 folder...\n",
      "(815, 9, 50)\n",
      "Processing 23/32 folder...\n",
      "(765, 9, 50)\n",
      "Processing 24/32 folder...\n",
      "(1219, 9, 50)\n",
      "Processing 25/32 folder...\n",
      "(740, 9, 50)\n",
      "Processing 26/32 folder...\n",
      "(815, 9, 50)\n",
      "Processing 27/32 folder...\n",
      "(805, 9, 50)\n",
      "Processing 28/32 folder...\n",
      "(780, 9, 50)\n",
      "Processing 29/32 folder...\n",
      "(800, 9, 50)\n",
      "Processing 30/32 folder...\n",
      "(765, 9, 50)\n",
      "Processing 31/32 folder...\n",
      "(750, 9, 50)\n",
      "Processing 32/32 folder...\n",
      "(810, 9, 50)\n"
     ]
    }
   ],
   "source": [
    "# mac\n",
    "sensor_data_folder = '/Users/liuxinqing/Documents/Kfall/sensor_data'  # Update with the path to sensor data\n",
    "label_data_folder = '/Users/liuxinqing/Documents/Kfall/label_data'  \n",
    "# windows \n",
    "#sensor_data_folder = 'G:\\MLonMCU\\Kfall_dataset\\sensor_data'  # Update with the path to sensor data\n",
    "#label_data_folder = 'G:\\MLonMCU\\Kfall_dataset\\label_data' \n",
    "\n",
    "#window_size = 256\n",
    "# Kfall: window_size = 50\n",
    "window_size = 50\n",
    "threshold = 0.1\n",
    "num_window_fall_data = 50\n",
    "num_window_not_fall_data = 5\n",
    "\n",
    "data, label = DataOrganizer(sensor_data_folder, \n",
    "                            label_data_folder, \n",
    "                            window_size, \n",
    "                            threshold, \n",
    "                            num_window_fall_data, \n",
    "                            num_window_not_fall_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_channels:  9\n",
      "data.shape:  (25814, 9, 50)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "in_channels = data.shape[1]\n",
    "print('in_channels: ', in_channels)\n",
    "# the input data should have the shape (batch_size, in_channels, sequence_length)\n",
    "#data = data.reshape(data.shape[0], in_channels, -1)\n",
    "print('data.shape: ', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_size:  25020\n",
      "A_size:  794\n",
      "data.shape:  (25814, 9, 50)\n",
      "(76, 9, 50)\n",
      "X_train_tensor.dtype:  torch.float64\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "label = label.astype(np.int64)\n",
    "# (y == 0).sum()\n",
    "B_size = (label == 0).sum()\n",
    "A_size = (label == 1).sum()\n",
    "print('B_size: ', B_size)\t\n",
    "print('A_size: ', A_size)\n",
    "# transpose the data to (batch_size, in_channels, sequence_length)\n",
    "#data = np.transpose(data, (0, 2, 1))\n",
    "print('data.shape: ', data.shape)\n",
    "# normalize the data\n",
    "data = (data - data.mean()) / data.std()\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.05, random_state=42)\n",
    "\n",
    "# Further split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.05, random_state=42)\n",
    "\n",
    "#print(np.unique(y_train)) # [0 1]\n",
    "y_train = y_train.astype(np.int64)\n",
    "y_test = y_test.astype(np.int64)\n",
    "\n",
    "\n",
    "# select the test data that is not zero\n",
    "X_test_true = X_test[y_test != 0]\n",
    "y_test_true = y_test[y_test != 0]\n",
    "# length of the test data\n",
    "test_len = X_test_true.shape[0]\n",
    "X_test_false = X_test[y_test == 0]\n",
    "y_test_false = y_test[y_test == 0]\n",
    "# X_test.shape:  (17, 50, 9)\n",
    "# randomly len number of test data that is zero\n",
    "index = np.random.choice(X_test_false.shape[0], test_len, replace=False)\n",
    "# X_test.shape:  (17, 50, 9)\n",
    "# randomly len number of test data that is zero\n",
    "#index = np.random.choice(X_test_false.shape[0], len, replace=False)\n",
    "\n",
    "\n",
    "X_test_false = X_test[index]\n",
    "y_test_false = y_test[index]\n",
    "\n",
    "# concatenate the true and false test data\n",
    "X_test = np.concatenate((X_test_true, X_test_false), axis=0)\n",
    "y_test = np.concatenate((y_test_true, y_test_false), axis=0)\n",
    "#X_test = X_test[y_test != 0]\n",
    "#y_test = y_test[y_test != 0]\n",
    "print(X_test.shape)\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.from_numpy(X_train)\n",
    "y_train_tensor = torch.from_numpy(y_train)\n",
    "X_val_tensor = torch.from_numpy(X_val)\n",
    "y_val_tensor = torch.from_numpy(y_val)\n",
    "X_test_tensor = torch.from_numpy(X_test)\n",
    "y_test_tensor = torch.from_numpy(y_test)\n",
    "\n",
    "\n",
    "# print datatype of X_train_tensor\n",
    "X_train_tensor = X_train_tensor.double()\n",
    "print('X_train_tensor.dtype: ', X_train_tensor.dtype)\n",
    "X_test = X_train_tensor.double()\n",
    "\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 5e-4\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(nn.Conv1d(in_channels=9, out_channels=64, kernel_size=3, padding=1),\n",
    "                                   nn.BatchNorm1d(64),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool1d(2))\n",
    "        self.conv2 = nn.Sequential(nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "                                   nn.BatchNorm1d(64),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool1d(2))\n",
    "        self.conv3 = nn.Sequential(nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "                                   nn.BatchNorm1d(64),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool1d(2))\n",
    "\n",
    "        # LSTM layers\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size=64, hidden_size=64, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.lstm2 = nn.LSTM(input_size=64, hidden_size=64, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc = nn.Linear(64, 2)  # No need for softmax here when using nn.CrossEntropyLoss\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        # x.shape = (batch_size, channels, sequence_length)\n",
    "        # Prepare for LSTM\n",
    "        # batch_first=True: (batch, sequence_length, channels)\n",
    "\n",
    "\n",
    "        # transpose x to (batch_size, sequence_length, channels)\n",
    "        x = x.transpose(1, 2)\n",
    "        \n",
    "        # LSTM layers\n",
    "        x, _ = self.lstm1(x)  # Only take the output, ignore hidden states\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm2(x)  # Only take the output, ignore hidden states\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        # Take the outputs of the last time step\n",
    "        x = x[:, -1, :]\n",
    "        \n",
    "        # Fully connected layer\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: ConvLSTM(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv1d(9, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (lstm1): LSTM(64, 64, batch_first=True)\n",
      "  (dropout1): Dropout(p=0.5, inplace=False)\n",
      "  (lstm2): LSTM(64, 64, batch_first=True)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "Layer: conv1.0.weight | Size: torch.Size([64, 9, 3]) | Values : tensor([[[ 1.6451e-05, -9.1257e-02,  1.8212e-01],\n",
      "         [ 1.6699e-01, -1.5304e-01,  3.0431e-02],\n",
      "         [-1.3700e-02, -1.3388e-01,  1.8784e-01],\n",
      "         [-5.9187e-02, -1.4662e-02,  1.7269e-01],\n",
      "         [ 1.7909e-01,  6.6010e-02,  1.1059e-01],\n",
      "         [-8.5387e-02,  1.3168e-01, -7.9622e-03],\n",
      "         [-1.6424e-01, -1.2054e-01, -5.9633e-02],\n",
      "         [ 5.0565e-02, -1.1187e-02,  6.0509e-02],\n",
      "         [-4.0652e-02,  4.5700e-03, -4.9846e-02]],\n",
      "\n",
      "        [[ 1.5804e-01,  1.3016e-02,  1.2450e-01],\n",
      "         [ 2.8248e-03, -3.0833e-04, -9.5123e-02],\n",
      "         [ 1.5433e-01, -1.3800e-01,  7.3010e-02],\n",
      "         [ 9.2218e-02,  1.5033e-01, -1.1753e-01],\n",
      "         [ 1.3386e-01,  1.3439e-02,  9.0792e-02],\n",
      "         [-5.5879e-02,  3.1504e-02,  1.4985e-02],\n",
      "         [ 1.7956e-01, -1.1006e-01,  7.0407e-02],\n",
      "         [ 1.0023e-01, -1.3732e-02,  1.3992e-01],\n",
      "         [ 5.1957e-03,  9.7683e-02,  3.5147e-02]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.0.bias | Size: torch.Size([64]) | Values : tensor([-0.0246, -0.0742], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.1.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.1.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.0.weight | Size: torch.Size([64, 64, 3]) | Values : tensor([[[-0.0452, -0.0163,  0.0220],\n",
      "         [ 0.0209, -0.0234,  0.0466],\n",
      "         [ 0.0298, -0.0368, -0.0697],\n",
      "         [ 0.0554, -0.0497, -0.0158],\n",
      "         [ 0.0644, -0.0189,  0.0148],\n",
      "         [ 0.0156, -0.0404,  0.0429],\n",
      "         [-0.0127, -0.0533,  0.0078],\n",
      "         [ 0.0593, -0.0570,  0.0010],\n",
      "         [ 0.0216, -0.0494, -0.0191],\n",
      "         [-0.0669,  0.0356, -0.0479],\n",
      "         [ 0.0064, -0.0714,  0.0480],\n",
      "         [ 0.0224, -0.0081, -0.0542],\n",
      "         [-0.0215,  0.0679, -0.0294],\n",
      "         [ 0.0128,  0.0436,  0.0659],\n",
      "         [-0.0073, -0.0240,  0.0472],\n",
      "         [-0.0642, -0.0462, -0.0192],\n",
      "         [-0.0346,  0.0542, -0.0261],\n",
      "         [ 0.0289,  0.0104,  0.0152],\n",
      "         [-0.0635,  0.0444,  0.0540],\n",
      "         [ 0.0300, -0.0183,  0.0203],\n",
      "         [-0.0632, -0.0254,  0.0021],\n",
      "         [-0.0153, -0.0350,  0.0681],\n",
      "         [ 0.0484, -0.0171, -0.0581],\n",
      "         [-0.0068, -0.0356,  0.0140],\n",
      "         [-0.0561,  0.0600, -0.0371],\n",
      "         [-0.0003,  0.0168,  0.0652],\n",
      "         [ 0.0642,  0.0636,  0.0671],\n",
      "         [ 0.0570, -0.0656,  0.0519],\n",
      "         [-0.0183,  0.0066,  0.0018],\n",
      "         [ 0.0623,  0.0082, -0.0098],\n",
      "         [-0.0477, -0.0286, -0.0030],\n",
      "         [-0.0301,  0.0553, -0.0487],\n",
      "         [ 0.0402,  0.0421,  0.0577],\n",
      "         [ 0.0225,  0.0190, -0.0062],\n",
      "         [-0.0061,  0.0226,  0.0022],\n",
      "         [ 0.0359, -0.0480,  0.0388],\n",
      "         [-0.0417, -0.0464,  0.0437],\n",
      "         [ 0.0022, -0.0105, -0.0112],\n",
      "         [ 0.0069, -0.0148,  0.0323],\n",
      "         [ 0.0257,  0.0651, -0.0585],\n",
      "         [-0.0340, -0.0171,  0.0548],\n",
      "         [ 0.0097, -0.0261, -0.0541],\n",
      "         [ 0.0310, -0.0516,  0.0504],\n",
      "         [ 0.0501, -0.0206, -0.0563],\n",
      "         [ 0.0658,  0.0422,  0.0341],\n",
      "         [ 0.0187,  0.0179,  0.0348],\n",
      "         [-0.0483, -0.0364,  0.0031],\n",
      "         [-0.0192,  0.0702,  0.0023],\n",
      "         [ 0.0147, -0.0664, -0.0106],\n",
      "         [ 0.0314, -0.0151,  0.0391],\n",
      "         [-0.0460, -0.0482, -0.0268],\n",
      "         [-0.0571,  0.0537, -0.0434],\n",
      "         [-0.0055,  0.0254,  0.0073],\n",
      "         [ 0.0168, -0.0481,  0.0246],\n",
      "         [ 0.0198,  0.0276,  0.0414],\n",
      "         [-0.0386, -0.0060,  0.0239],\n",
      "         [-0.0232, -0.0648, -0.0302],\n",
      "         [ 0.0168, -0.0589,  0.0133],\n",
      "         [ 0.0092,  0.0285, -0.0655],\n",
      "         [-0.0403, -0.0223, -0.0408],\n",
      "         [ 0.0319, -0.0665, -0.0209],\n",
      "         [ 0.0165,  0.0058,  0.0595],\n",
      "         [-0.0156,  0.0292, -0.0682],\n",
      "         [-0.0483, -0.0681,  0.0069]],\n",
      "\n",
      "        [[-0.0556,  0.0108,  0.0413],\n",
      "         [ 0.0183,  0.0122, -0.0470],\n",
      "         [ 0.0035, -0.0260,  0.0216],\n",
      "         [ 0.0413, -0.0273,  0.0448],\n",
      "         [-0.0248, -0.0077,  0.0419],\n",
      "         [ 0.0083,  0.0333,  0.0037],\n",
      "         [-0.0137,  0.0328,  0.0626],\n",
      "         [ 0.0348,  0.0195, -0.0616],\n",
      "         [-0.0565, -0.0362,  0.0286],\n",
      "         [-0.0260, -0.0426,  0.0032],\n",
      "         [ 0.0315,  0.0510,  0.0332],\n",
      "         [-0.0042, -0.0121, -0.0456],\n",
      "         [ 0.0495, -0.0407, -0.0332],\n",
      "         [ 0.0673, -0.0194,  0.0377],\n",
      "         [ 0.0117,  0.0465, -0.0243],\n",
      "         [-0.0616, -0.0256,  0.0427],\n",
      "         [ 0.0228,  0.0216,  0.0143],\n",
      "         [ 0.0408, -0.0512,  0.0049],\n",
      "         [ 0.0130,  0.0268, -0.0586],\n",
      "         [ 0.0261,  0.0100,  0.0386],\n",
      "         [-0.0318,  0.0504,  0.0307],\n",
      "         [-0.0550,  0.0376,  0.0191],\n",
      "         [ 0.0351, -0.0568, -0.0216],\n",
      "         [ 0.0011, -0.0106,  0.0419],\n",
      "         [-0.0420,  0.0329, -0.0193],\n",
      "         [ 0.0711,  0.0136, -0.0013],\n",
      "         [ 0.0478,  0.0324, -0.0049],\n",
      "         [ 0.0561,  0.0103,  0.0670],\n",
      "         [-0.0243,  0.0708, -0.0143],\n",
      "         [ 0.0074,  0.0265, -0.0184],\n",
      "         [ 0.0059,  0.0380, -0.0150],\n",
      "         [ 0.0464, -0.0705,  0.0609],\n",
      "         [ 0.0025,  0.0187, -0.0125],\n",
      "         [-0.0149,  0.0478, -0.0303],\n",
      "         [ 0.0250,  0.0568,  0.0382],\n",
      "         [ 0.0283,  0.0281, -0.0339],\n",
      "         [ 0.0211, -0.0297, -0.0376],\n",
      "         [ 0.0147, -0.0671, -0.0015],\n",
      "         [-0.0708,  0.0004,  0.0660],\n",
      "         [ 0.0247,  0.0296, -0.0198],\n",
      "         [-0.0201, -0.0618, -0.0469],\n",
      "         [-0.0435,  0.0105,  0.0419],\n",
      "         [ 0.0590, -0.0245, -0.0202],\n",
      "         [-0.0166,  0.0591,  0.0268],\n",
      "         [ 0.0269,  0.0078,  0.0231],\n",
      "         [-0.0339,  0.0427,  0.0459],\n",
      "         [ 0.0660, -0.0331, -0.0562],\n",
      "         [ 0.0428, -0.0172,  0.0074],\n",
      "         [ 0.0467, -0.0400,  0.0256],\n",
      "         [-0.0086,  0.0710,  0.0576],\n",
      "         [-0.0109, -0.0062,  0.0420],\n",
      "         [ 0.0002, -0.0090,  0.0478],\n",
      "         [ 0.0535,  0.0326,  0.0447],\n",
      "         [ 0.0354, -0.0063, -0.0173],\n",
      "         [ 0.0573, -0.0592, -0.0245],\n",
      "         [ 0.0498, -0.0542, -0.0211],\n",
      "         [ 0.0634, -0.0533, -0.0514],\n",
      "         [ 0.0617, -0.0052, -0.0229],\n",
      "         [ 0.0605, -0.0629, -0.0318],\n",
      "         [-0.0100, -0.0471,  0.0562],\n",
      "         [-0.0436, -0.0717, -0.0165],\n",
      "         [ 0.0461,  0.0189, -0.0053],\n",
      "         [ 0.0093,  0.0028, -0.0259],\n",
      "         [ 0.0448, -0.0020,  0.0472]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.0.bias | Size: torch.Size([64]) | Values : tensor([-0.0009,  0.0696], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.1.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.1.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv3.0.weight | Size: torch.Size([64, 64, 3]) | Values : tensor([[[ 2.6744e-02,  2.0613e-02,  2.8805e-03],\n",
      "         [-2.1494e-02, -8.1200e-03,  1.5923e-02],\n",
      "         [-3.4247e-02, -1.5352e-02, -4.5431e-02],\n",
      "         [-2.1232e-02,  2.4525e-02,  6.3618e-03],\n",
      "         [-5.5636e-02,  4.9078e-02, -1.8504e-04],\n",
      "         [ 2.5147e-03,  3.0505e-02, -5.2912e-02],\n",
      "         [ 6.5890e-02, -7.9238e-03, -5.7996e-02],\n",
      "         [ 2.7381e-02, -5.0292e-02,  4.1324e-02],\n",
      "         [ 5.2840e-02, -4.3221e-02, -5.2700e-02],\n",
      "         [ 1.3689e-02, -4.1770e-02,  5.5036e-03],\n",
      "         [-6.8560e-02,  6.6904e-02,  1.0263e-02],\n",
      "         [ 6.5703e-02,  1.1732e-02, -4.7663e-02],\n",
      "         [-2.6595e-02, -5.2004e-02,  3.6923e-03],\n",
      "         [-3.9576e-02,  2.0880e-02, -1.8438e-02],\n",
      "         [ 4.7956e-02, -4.1148e-02, -4.1189e-02],\n",
      "         [ 4.9830e-02, -3.7737e-02, -6.0975e-02],\n",
      "         [-7.1568e-02, -5.1216e-02,  8.8730e-03],\n",
      "         [-3.9321e-02,  5.9582e-02, -5.6386e-02],\n",
      "         [ 7.1944e-02,  4.2891e-02, -5.4952e-02],\n",
      "         [-4.7139e-02,  1.5142e-02, -9.6884e-03],\n",
      "         [-3.0670e-02, -4.0790e-02,  4.0484e-02],\n",
      "         [-4.5230e-02, -3.9708e-02, -6.5948e-02],\n",
      "         [ 1.7527e-02, -1.1571e-02, -3.8743e-02],\n",
      "         [ 5.4033e-02,  8.5724e-03,  7.2932e-03],\n",
      "         [-4.9101e-02,  5.1443e-02, -4.9956e-02],\n",
      "         [-3.8837e-02,  1.4700e-02,  9.8707e-03],\n",
      "         [ 1.4504e-02,  6.7476e-02, -4.6941e-02],\n",
      "         [ 3.4149e-02,  1.9739e-02, -3.9543e-02],\n",
      "         [ 3.1807e-02, -1.4277e-02, -8.1085e-03],\n",
      "         [-1.8997e-02,  5.4142e-02, -6.8906e-02],\n",
      "         [ 1.2483e-02, -3.3285e-02,  1.6767e-02],\n",
      "         [ 7.2663e-03, -3.0228e-04,  5.2491e-02],\n",
      "         [-5.7540e-03, -2.4328e-02, -4.0452e-02],\n",
      "         [-3.4432e-02, -3.1050e-02, -3.5331e-02],\n",
      "         [ 5.4960e-02, -5.3287e-02,  4.6870e-02],\n",
      "         [ 1.3097e-02,  3.4960e-02, -7.4668e-03],\n",
      "         [ 7.1386e-02,  2.4562e-02, -7.0215e-02],\n",
      "         [-5.7771e-02, -3.3072e-02,  1.9016e-03],\n",
      "         [-6.6484e-02,  5.9336e-02, -6.9163e-02],\n",
      "         [ 6.0553e-02, -4.7988e-02,  3.8738e-02],\n",
      "         [-6.4270e-02,  5.8286e-02,  3.8390e-02],\n",
      "         [-8.2514e-03,  4.6090e-02, -1.2285e-02],\n",
      "         [ 2.9703e-02, -1.1052e-02,  3.6810e-02],\n",
      "         [-1.6952e-03,  4.1431e-02,  4.0007e-03],\n",
      "         [ 2.1274e-03, -3.7997e-02, -4.4415e-02],\n",
      "         [ 6.7562e-02,  1.6164e-03, -4.8298e-02],\n",
      "         [ 6.3996e-02,  5.5986e-03,  2.4821e-02],\n",
      "         [ 1.2350e-02,  3.2837e-02,  5.4102e-02],\n",
      "         [ 6.3172e-02, -3.5657e-02,  3.1913e-02],\n",
      "         [ 7.3983e-03,  3.9094e-02,  5.0290e-02],\n",
      "         [ 5.5369e-02,  3.0761e-02,  2.5453e-02],\n",
      "         [ 5.3044e-02, -2.1782e-02,  2.6060e-02],\n",
      "         [ 3.2299e-02, -3.8166e-02,  3.2760e-02],\n",
      "         [ 2.9005e-03,  7.8948e-03,  8.6565e-03],\n",
      "         [ 2.0269e-02,  6.2370e-02,  5.0543e-02],\n",
      "         [ 5.3757e-02,  1.7221e-02,  1.8950e-02],\n",
      "         [ 2.0866e-03, -3.7870e-02,  3.8478e-02],\n",
      "         [-6.7288e-02, -4.7060e-02, -1.9662e-02],\n",
      "         [-3.1453e-02, -1.4718e-02,  8.7769e-03],\n",
      "         [-4.0994e-02, -4.0860e-02,  1.9201e-03],\n",
      "         [-3.3045e-02,  2.4548e-02, -6.1550e-02],\n",
      "         [-6.4444e-03,  1.2802e-02,  1.3907e-02],\n",
      "         [ 5.1472e-02, -1.4436e-02, -5.4968e-02],\n",
      "         [-5.5348e-02,  2.7739e-02,  1.3995e-02]],\n",
      "\n",
      "        [[ 3.3037e-02, -7.9173e-03, -3.1374e-05],\n",
      "         [ 6.1343e-02,  6.7764e-02,  7.1667e-02],\n",
      "         [ 1.9850e-02,  1.5233e-02, -5.8518e-02],\n",
      "         [-3.5650e-02,  6.8606e-02, -2.3836e-03],\n",
      "         [-3.7376e-02, -4.3547e-02, -6.5402e-02],\n",
      "         [ 4.6705e-02,  5.9090e-02, -6.0770e-02],\n",
      "         [-1.7894e-02, -2.9544e-03, -6.2665e-02],\n",
      "         [ 6.4070e-02, -3.2280e-02, -4.0242e-02],\n",
      "         [-5.7575e-02, -5.4353e-02, -5.4658e-02],\n",
      "         [ 2.3716e-02,  4.0436e-03, -4.6399e-02],\n",
      "         [ 5.2277e-02,  5.0467e-02,  1.9795e-02],\n",
      "         [-3.1536e-02, -9.5099e-03,  5.5182e-02],\n",
      "         [-5.1840e-02,  6.0607e-02, -5.8993e-02],\n",
      "         [ 6.7851e-02, -6.3965e-02,  2.8042e-02],\n",
      "         [ 2.5881e-02, -4.7664e-03, -7.9713e-03],\n",
      "         [ 1.6621e-02,  6.2128e-02, -7.9293e-03],\n",
      "         [-3.3283e-02, -3.6331e-02, -3.8201e-02],\n",
      "         [-2.9318e-02,  4.2086e-02,  4.6244e-02],\n",
      "         [-6.7100e-03,  3.0486e-02,  2.5370e-02],\n",
      "         [-4.2586e-02,  3.7014e-02, -4.3379e-02],\n",
      "         [-1.4238e-02, -4.4748e-02, -3.5194e-02],\n",
      "         [-5.8447e-02, -5.6942e-02, -6.7230e-02],\n",
      "         [-1.4635e-02, -8.5332e-03,  5.0728e-02],\n",
      "         [-4.3407e-02, -2.3275e-02, -5.6966e-02],\n",
      "         [-3.3250e-02,  2.0813e-02, -4.3352e-02],\n",
      "         [-4.8501e-02,  9.2417e-03,  5.8649e-02],\n",
      "         [ 3.7863e-02, -2.9810e-03, -5.3842e-02],\n",
      "         [ 4.1251e-02,  5.8496e-02, -2.0987e-02],\n",
      "         [ 2.8827e-02, -3.0168e-02,  6.2104e-02],\n",
      "         [ 4.8000e-02, -3.5420e-02,  2.1960e-03],\n",
      "         [ 3.8698e-02,  3.3820e-02,  3.3303e-02],\n",
      "         [ 3.7800e-02, -6.0600e-02,  3.2915e-02],\n",
      "         [-5.1611e-02, -1.4840e-02,  4.2999e-02],\n",
      "         [-6.3217e-02,  6.6665e-02,  3.6507e-02],\n",
      "         [-1.2727e-02, -4.5490e-02,  6.7132e-02],\n",
      "         [ 6.1354e-02,  8.0060e-03, -1.1453e-02],\n",
      "         [-3.1860e-03,  5.2343e-02,  1.1905e-02],\n",
      "         [ 3.1318e-02, -1.0146e-02,  1.6607e-02],\n",
      "         [ 3.7758e-02,  5.6482e-02, -2.3690e-02],\n",
      "         [ 5.6980e-02, -1.2146e-02, -5.9837e-02],\n",
      "         [-5.9538e-02,  3.0135e-02,  5.3482e-02],\n",
      "         [ 6.0646e-03, -6.4232e-02,  2.3321e-02],\n",
      "         [ 3.8757e-02, -5.4494e-04, -3.5747e-03],\n",
      "         [ 4.9712e-02, -3.7725e-02, -2.6364e-03],\n",
      "         [-5.3371e-02, -6.7205e-02, -3.4331e-03],\n",
      "         [-2.2317e-02,  1.3535e-02,  1.8173e-02],\n",
      "         [ 6.3152e-02,  5.6612e-02,  1.0954e-03],\n",
      "         [-3.5682e-02, -4.6996e-02,  2.9412e-02],\n",
      "         [ 4.7989e-02,  4.2769e-02, -5.8169e-02],\n",
      "         [-4.4173e-02,  2.5816e-02, -6.2149e-02],\n",
      "         [ 6.9167e-02,  4.9328e-02,  1.0768e-02],\n",
      "         [ 2.1019e-02,  6.2190e-02, -1.3844e-02],\n",
      "         [ 6.0467e-02,  5.8596e-02,  4.2439e-02],\n",
      "         [ 9.7301e-03, -9.7136e-03, -1.1620e-02],\n",
      "         [-6.2010e-02, -4.3759e-02,  1.9757e-02],\n",
      "         [-1.9121e-02,  6.3555e-02, -1.7436e-04],\n",
      "         [ 3.2410e-02,  5.5456e-02, -2.1213e-02],\n",
      "         [ 2.0716e-02, -8.7158e-03, -5.4879e-02],\n",
      "         [-6.3380e-02,  3.0832e-02,  4.5681e-02],\n",
      "         [ 5.3182e-02,  7.2152e-02, -7.2319e-03],\n",
      "         [ 6.1315e-02, -3.5722e-02,  1.2161e-02],\n",
      "         [-5.8665e-02, -2.0612e-02,  5.6904e-02],\n",
      "         [ 1.0069e-02, -5.6669e-02, -6.9203e-02],\n",
      "         [ 3.5161e-02, -1.0765e-02, -6.1899e-02]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv3.0.bias | Size: torch.Size([64]) | Values : tensor([ 0.0422, -0.0423], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv3.1.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv3.1.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm1.weight_ih_l0 | Size: torch.Size([256, 64]) | Values : tensor([[-0.0528,  0.0972,  0.1011,  0.0114, -0.0297, -0.0298,  0.0295, -0.1086,\n",
      "          0.1208, -0.0456,  0.0841, -0.0941, -0.0961,  0.0506, -0.0698, -0.0484,\n",
      "          0.0405,  0.1122,  0.0004, -0.0800, -0.0793,  0.0099, -0.1234,  0.1109,\n",
      "          0.0853, -0.0018,  0.0004, -0.0705,  0.1214, -0.0235, -0.0194,  0.0388,\n",
      "         -0.0043,  0.0222, -0.0268,  0.0426,  0.0073, -0.1133, -0.0174, -0.1216,\n",
      "         -0.0649, -0.0145,  0.0862, -0.0040,  0.1225, -0.0817,  0.0104, -0.1066,\n",
      "          0.0231,  0.1246, -0.0576, -0.0546,  0.0625,  0.0309,  0.0627, -0.0813,\n",
      "          0.0963,  0.0434, -0.1118,  0.1146, -0.0721, -0.0909,  0.0855,  0.1113],\n",
      "        [-0.0391, -0.0895,  0.0088,  0.0221,  0.0036, -0.0094,  0.0580, -0.0797,\n",
      "          0.0470, -0.0729, -0.0273, -0.0594, -0.0217, -0.1167,  0.0845,  0.0113,\n",
      "         -0.0329, -0.0229,  0.0485,  0.0292, -0.0388,  0.0768,  0.0418, -0.0955,\n",
      "          0.0546, -0.0154,  0.0613,  0.0337,  0.1056,  0.1100,  0.1035,  0.0846,\n",
      "         -0.0476,  0.0163,  0.0759,  0.0049,  0.0234,  0.0284, -0.0927, -0.0546,\n",
      "         -0.1154,  0.0043, -0.0233,  0.0358, -0.1231, -0.0112,  0.0779, -0.0374,\n",
      "          0.0963, -0.0752,  0.0326,  0.0264,  0.0789,  0.0227, -0.1097,  0.0895,\n",
      "         -0.0831, -0.0024, -0.0937, -0.0919, -0.0114,  0.0501, -0.0113, -0.0317]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm1.weight_hh_l0 | Size: torch.Size([256, 64]) | Values : tensor([[ 9.9283e-02, -1.0329e-01, -1.0221e-01, -5.0928e-02, -1.1754e-01,\n",
      "         -1.9416e-02, -1.0381e-01,  1.1447e-01, -7.1635e-02, -3.2105e-02,\n",
      "         -3.3557e-02,  6.9674e-02, -2.8264e-02, -2.2552e-02, -6.4267e-02,\n",
      "         -5.4046e-02, -6.5997e-02, -5.9910e-02, -1.9175e-03,  5.8613e-02,\n",
      "         -3.4487e-03,  1.1948e-01, -1.3962e-03,  1.1327e-01,  6.3612e-02,\n",
      "         -6.6930e-02, -5.6326e-06, -8.5287e-02,  5.3044e-02, -4.6779e-02,\n",
      "          5.4751e-02,  5.2557e-02,  1.7525e-02, -5.5489e-03,  8.0574e-02,\n",
      "          9.5569e-02,  6.1049e-02, -8.9398e-02, -9.0782e-02, -7.5461e-02,\n",
      "         -1.0996e-01, -6.5047e-02, -3.5261e-03,  8.7173e-02, -1.0039e-01,\n",
      "          3.0536e-02,  7.8346e-02, -6.3166e-02, -4.2699e-02,  9.1950e-02,\n",
      "         -9.3843e-02,  1.2030e-01,  3.0565e-03,  1.6453e-02,  9.6596e-02,\n",
      "         -8.2069e-02,  7.3316e-02,  8.6956e-02,  1.0246e-01,  3.3485e-03,\n",
      "          4.2518e-02, -1.1627e-01, -6.8130e-02, -2.5709e-02],\n",
      "        [-9.7207e-02,  6.8823e-02, -5.9975e-02,  1.0051e-01,  6.3828e-02,\n",
      "          3.9465e-03,  1.9559e-03, -4.3487e-02,  2.2393e-02, -1.2207e-01,\n",
      "          3.3322e-03, -1.0621e-03,  8.5019e-02,  1.2096e-01,  3.3189e-02,\n",
      "          1.0409e-01, -7.6866e-03, -1.1681e-01, -7.2721e-02,  6.2190e-02,\n",
      "          6.8699e-02, -4.0427e-04, -5.4943e-02,  1.1057e-01, -1.1110e-01,\n",
      "         -3.4583e-02, -3.8286e-02, -8.0746e-03,  1.8792e-02, -3.5986e-02,\n",
      "         -1.9552e-02, -1.1570e-02,  1.0512e-01, -4.4691e-02, -2.0629e-02,\n",
      "          6.2937e-02,  6.4824e-02,  2.0362e-02,  1.1789e-01,  3.2248e-02,\n",
      "          7.9358e-02,  7.3571e-02,  6.9686e-02,  1.5017e-02,  6.0576e-02,\n",
      "          4.9037e-02,  1.6931e-02,  7.4899e-02,  9.0750e-02,  6.3265e-02,\n",
      "          9.2487e-02,  1.0934e-01,  1.0869e-01, -5.8884e-02, -2.7253e-02,\n",
      "          1.1245e-01,  1.0217e-01, -3.0185e-02, -6.5258e-02,  9.0563e-02,\n",
      "         -1.0333e-01, -3.4543e-02, -1.1367e-01,  5.9226e-02]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm1.bias_ih_l0 | Size: torch.Size([256]) | Values : tensor([ 0.0374, -0.0353], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm1.bias_hh_l0 | Size: torch.Size([256]) | Values : tensor([-0.0612,  0.1034], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm2.weight_ih_l0 | Size: torch.Size([256, 64]) | Values : tensor([[-3.3590e-02, -3.5369e-02,  8.9137e-03, -1.0553e-01, -3.4980e-03,\n",
      "          6.0265e-02,  1.1220e-01, -8.9766e-02, -1.4501e-02, -3.6186e-02,\n",
      "         -1.1709e-01, -2.8353e-03, -1.7221e-02,  5.7416e-02,  9.1891e-02,\n",
      "         -4.1869e-02, -9.6423e-02, -4.0934e-02, -1.1356e-01, -1.3967e-02,\n",
      "         -4.4750e-02, -6.4171e-02, -8.9363e-02,  3.2937e-02, -1.0673e-01,\n",
      "          1.2015e-01, -1.1042e-01, -6.2257e-02, -6.8184e-02,  2.9721e-02,\n",
      "          8.6355e-02, -6.4943e-02, -5.2066e-03, -2.4799e-02,  1.0700e-01,\n",
      "          1.2431e-01, -5.6324e-02, -9.6019e-04,  8.7026e-02, -6.9315e-02,\n",
      "          7.4665e-02,  1.2076e-01,  6.5977e-02, -5.0687e-02, -6.5644e-02,\n",
      "         -1.1221e-01, -6.3757e-02,  8.8820e-02,  2.8766e-02,  4.0569e-02,\n",
      "         -3.5243e-02, -1.1880e-01, -7.1796e-02,  1.8550e-02, -9.5284e-02,\n",
      "         -2.7049e-02,  7.3133e-02, -1.0261e-01,  1.1561e-01,  7.9051e-02,\n",
      "          4.1539e-02, -1.5715e-02,  1.0255e-01, -8.2395e-02],\n",
      "        [-3.9560e-02, -6.0547e-03, -7.5959e-02,  5.6011e-02,  7.2416e-03,\n",
      "         -1.7120e-03, -6.9573e-02,  1.0643e-01, -2.8421e-02, -8.1179e-03,\n",
      "          7.5656e-02,  8.4040e-02,  6.3961e-02,  7.9761e-02,  1.1005e-01,\n",
      "          1.0563e-01,  5.2872e-02,  1.0177e-01,  6.5932e-02, -3.1757e-02,\n",
      "          1.1421e-01, -5.5040e-03,  1.7207e-02,  6.1736e-05, -3.3114e-02,\n",
      "         -8.6628e-02,  1.1648e-02, -6.2943e-02,  7.0123e-02, -5.7571e-02,\n",
      "         -3.7684e-02,  6.7637e-02,  1.2173e-01, -8.6084e-02,  2.3905e-02,\n",
      "          2.7032e-02,  1.2807e-02,  7.9728e-02,  6.7916e-02, -5.8215e-03,\n",
      "          8.8472e-02, -6.6357e-02,  6.3884e-02, -8.4581e-02,  7.5189e-02,\n",
      "          1.9781e-02, -1.5500e-02, -6.1481e-02,  6.1386e-02, -1.2710e-02,\n",
      "         -5.7384e-02, -4.6481e-03, -4.9237e-02,  1.0086e-01, -1.3389e-02,\n",
      "          5.0613e-02,  1.0681e-01,  1.0886e-01, -8.3715e-02,  2.9164e-02,\n",
      "          3.8870e-02, -9.8005e-02,  2.7662e-02, -7.9701e-02]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm2.weight_hh_l0 | Size: torch.Size([256, 64]) | Values : tensor([[ 0.0037, -0.0033, -0.0384, -0.0504,  0.0778,  0.0838, -0.0324,  0.0579,\n",
      "          0.0956,  0.0248, -0.1063,  0.0258, -0.0347, -0.0208, -0.0515,  0.0658,\n",
      "         -0.0616, -0.0618, -0.0772, -0.0928,  0.0268,  0.1038,  0.1062, -0.0607,\n",
      "         -0.0328,  0.0085, -0.0647, -0.1139, -0.0402,  0.1208, -0.1205, -0.0759,\n",
      "         -0.0033, -0.1059, -0.0276,  0.0296,  0.1225,  0.0090, -0.0372, -0.0063,\n",
      "         -0.0864,  0.1197,  0.0823, -0.0814, -0.1022, -0.0725,  0.0761,  0.0862,\n",
      "         -0.0740,  0.0028, -0.1056,  0.1220,  0.0259, -0.0525, -0.0397,  0.1034,\n",
      "          0.0291,  0.0090,  0.0178, -0.0186, -0.0779,  0.1095, -0.1220,  0.0470],\n",
      "        [ 0.0425,  0.0096, -0.0825,  0.0879,  0.0122,  0.1073,  0.0161,  0.1056,\n",
      "         -0.0810,  0.0285,  0.1174, -0.0294, -0.0704,  0.0194,  0.0826,  0.0595,\n",
      "         -0.0621,  0.0133, -0.0221,  0.0262,  0.1120, -0.0554,  0.0035,  0.1180,\n",
      "         -0.1045,  0.0898, -0.1233,  0.0244, -0.0798, -0.0570,  0.0262, -0.0944,\n",
      "          0.0875,  0.0893,  0.0764, -0.0812, -0.0440,  0.0398, -0.1020, -0.0960,\n",
      "          0.1088, -0.0927, -0.0168,  0.1045,  0.1124, -0.0782, -0.0007, -0.0356,\n",
      "         -0.0785,  0.0634,  0.0375,  0.1187, -0.0829, -0.0563,  0.0321,  0.0025,\n",
      "         -0.0096,  0.0575, -0.0966, -0.0165, -0.0452, -0.0477,  0.1223, -0.0816]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm2.bias_ih_l0 | Size: torch.Size([256]) | Values : tensor([-0.0986,  0.0002], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: lstm2.bias_hh_l0 | Size: torch.Size([256]) | Values : tensor([-0.0193,  0.0873], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc.weight | Size: torch.Size([2, 64]) | Values : tensor([[-7.9596e-02, -8.4613e-02,  1.0091e-01,  6.4904e-02, -1.9796e-02,\n",
      "          1.1103e-01, -4.0990e-02, -9.7468e-02, -7.1408e-04, -8.4753e-02,\n",
      "         -7.1038e-02,  9.6357e-02,  2.6994e-02, -1.1441e-01, -6.0377e-03,\n",
      "         -1.0944e-01, -4.6305e-02,  3.8398e-02,  3.2350e-05, -3.6962e-02,\n",
      "          1.0890e-01,  6.1397e-02,  1.5849e-02, -9.2289e-02,  6.4657e-02,\n",
      "          9.1804e-02, -9.8231e-02,  6.7148e-02, -6.8283e-02, -4.1645e-02,\n",
      "          5.6161e-02, -1.0472e-01, -1.0819e-01, -8.6903e-02, -3.2697e-02,\n",
      "         -5.3857e-02, -6.9041e-02, -6.4647e-02,  1.1160e-01,  6.3541e-03,\n",
      "          3.1682e-03,  7.1373e-02,  9.9797e-02,  1.1679e-02,  2.2593e-02,\n",
      "          1.0349e-01,  3.0725e-02, -2.1853e-02,  4.1076e-02,  7.6947e-02,\n",
      "         -5.5332e-02, -3.5721e-02,  1.0007e-01, -1.1224e-01,  9.0642e-03,\n",
      "          5.3522e-02,  6.9992e-02, -5.9973e-02, -1.8759e-02,  1.0636e-01,\n",
      "          3.0337e-02,  2.5721e-02,  9.7756e-02,  1.2041e-02],\n",
      "        [ 5.6602e-03, -1.3175e-02, -3.6521e-02, -5.5129e-02,  8.9308e-02,\n",
      "         -7.6047e-02, -2.0195e-02,  8.1114e-02,  7.8931e-04, -1.0763e-01,\n",
      "          5.2408e-02, -5.6233e-02, -6.9638e-02,  6.1816e-02, -1.1438e-01,\n",
      "          8.4190e-02, -1.3964e-02,  5.9300e-02, -7.4669e-02,  6.7098e-02,\n",
      "         -7.0143e-02,  6.8721e-02,  1.2161e-01, -1.0832e-02,  1.1819e-01,\n",
      "         -8.8980e-02, -5.0177e-02, -4.1136e-02,  3.6810e-02,  1.0118e-01,\n",
      "         -3.2400e-02,  4.9096e-02,  5.9637e-02, -7.9383e-02, -4.8348e-03,\n",
      "          3.0329e-02,  3.2031e-02, -1.2388e-01, -2.5707e-03,  4.0953e-02,\n",
      "          8.6583e-02,  1.2145e-01,  2.9445e-02, -1.0408e-01,  1.0372e-01,\n",
      "         -7.3445e-02,  8.5913e-02,  8.3601e-02, -6.7051e-02,  3.1924e-02,\n",
      "         -8.1170e-02,  5.5652e-02, -9.5384e-03, -1.2965e-02,  1.2398e-01,\n",
      "          1.2553e-02, -9.9353e-02, -1.1703e-01, -2.3880e-02,  7.7846e-02,\n",
      "         -9.2256e-02,  7.9569e-02,  2.4288e-02, -6.5935e-03]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc.bias | Size: torch.Size([2]) | Values : tensor([0.0828, 0.0998], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create an instance of the model\n",
    "model_ConvLSTM = ConvLSTM()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_ConvLSTM.parameters(), lr=learning_rate)\n",
    "# Initialize the scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=patience, verbose=True)\n",
    "print(f\"Model structure: {model_ConvLSTM}\\n\\n\")\n",
    "for name, param in model_ConvLSTM.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "loss: 1.081501  [   64/23296]\n",
      "loss: 0.282175  [ 6464/23296]\n",
      "loss: 0.256181  [12864/23296]\n",
      "loss: 0.414438  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 96.6%, Avg loss: 0.087215 \n",
      "\n",
      "Epoch 1:\n",
      "loss: 0.058053  [   64/23296]\n",
      "loss: 0.042610  [ 6464/23296]\n",
      "loss: 0.218024  [12864/23296]\n",
      "loss: 0.047838  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 96.9%, Avg loss: 0.076877 \n",
      "\n",
      "Epoch 2:\n",
      "loss: 0.118779  [   64/23296]\n",
      "loss: 0.213658  [ 6464/23296]\n",
      "loss: 0.059902  [12864/23296]\n",
      "loss: 0.514033  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.061332 \n",
      "\n",
      "Epoch 3:\n",
      "loss: 0.024063  [   64/23296]\n",
      "loss: 0.412450  [ 6464/23296]\n",
      "loss: 0.391466  [12864/23296]\n",
      "loss: 0.037440  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 97.9%, Avg loss: 0.063269 \n",
      "\n",
      "Epoch 4:\n",
      "loss: 0.112607  [   64/23296]\n",
      "loss: 0.034708  [ 6464/23296]\n",
      "loss: 0.022735  [12864/23296]\n",
      "loss: 0.062237  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 97.6%, Avg loss: 0.059336 \n",
      "\n",
      "Epoch 5:\n",
      "loss: 0.180400  [   64/23296]\n",
      "loss: 0.050295  [ 6464/23296]\n",
      "loss: 0.147711  [12864/23296]\n",
      "loss: 0.086191  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 98.1%, Avg loss: 0.053317 \n",
      "\n",
      "Epoch 6:\n",
      "loss: 0.117182  [   64/23296]\n",
      "loss: 0.083665  [ 6464/23296]\n",
      "loss: 0.073475  [12864/23296]\n",
      "loss: 0.016851  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.048827 \n",
      "\n",
      "Epoch 7:\n",
      "loss: 0.037051  [   64/23296]\n",
      "loss: 0.074222  [ 6464/23296]\n",
      "loss: 0.020969  [12864/23296]\n",
      "loss: 0.031656  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.055190 \n",
      "\n",
      "Epoch 8:\n",
      "loss: 0.057175  [   64/23296]\n",
      "loss: 0.014523  [ 6464/23296]\n",
      "loss: 0.109137  [12864/23296]\n",
      "loss: 0.117678  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.044888 \n",
      "\n",
      "Epoch 9:\n",
      "loss: 0.124755  [   64/23296]\n",
      "loss: 0.234050  [ 6464/23296]\n",
      "loss: 0.018167  [12864/23296]\n",
      "loss: 0.026741  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.049143 \n",
      "\n",
      "Epoch 10:\n",
      "loss: 0.106733  [   64/23296]\n",
      "loss: 0.042367  [ 6464/23296]\n",
      "loss: 0.202976  [12864/23296]\n",
      "loss: 0.027522  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 98.6%, Avg loss: 0.044272 \n",
      "\n",
      "Epoch 11:\n",
      "loss: 0.214245  [   64/23296]\n",
      "loss: 0.149748  [ 6464/23296]\n",
      "loss: 0.028074  [12864/23296]\n",
      "loss: 0.237806  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.045046 \n",
      "\n",
      "Epoch 12:\n",
      "loss: 0.104837  [   64/23296]\n",
      "loss: 0.109297  [ 6464/23296]\n",
      "loss: 0.057612  [12864/23296]\n",
      "loss: 0.017408  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.047123 \n",
      "\n",
      "Epoch 13:\n",
      "loss: 0.055206  [   64/23296]\n",
      "loss: 0.159839  [ 6464/23296]\n",
      "loss: 0.011623  [12864/23296]\n",
      "loss: 0.013841  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 98.3%, Avg loss: 0.049426 \n",
      "\n",
      "Epoch 14:\n",
      "loss: 0.014528  [   64/23296]\n",
      "loss: 0.026145  [ 6464/23296]\n",
      "loss: 0.059123  [12864/23296]\n",
      "loss: 0.074011  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 98.8%, Avg loss: 0.038380 \n",
      "\n",
      "Epoch 15:\n",
      "loss: 0.330144  [   64/23296]\n",
      "loss: 0.074061  [ 6464/23296]\n",
      "loss: 0.069088  [12864/23296]\n",
      "loss: 0.085999  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.037202 \n",
      "\n",
      "Epoch 16:\n",
      "loss: 0.088940  [   64/23296]\n",
      "loss: 0.007215  [ 6464/23296]\n",
      "loss: 0.021195  [12864/23296]\n",
      "loss: 0.015599  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.045154 \n",
      "\n",
      "Epoch 17:\n",
      "loss: 0.078381  [   64/23296]\n",
      "loss: 0.021365  [ 6464/23296]\n",
      "loss: 0.168312  [12864/23296]\n",
      "loss: 0.217422  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.031384 \n",
      "\n",
      "Epoch 18:\n",
      "loss: 0.016308  [   64/23296]\n",
      "loss: 0.092139  [ 6464/23296]\n",
      "loss: 0.009428  [12864/23296]\n",
      "loss: 0.022879  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.040641 \n",
      "\n",
      "Epoch 19:\n",
      "loss: 0.007782  [   64/23296]\n",
      "loss: 0.051335  [ 6464/23296]\n",
      "loss: 0.030138  [12864/23296]\n",
      "loss: 0.058922  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.039385 \n",
      "\n",
      "Epoch 20:\n",
      "loss: 0.230984  [   64/23296]\n",
      "loss: 0.015470  [ 6464/23296]\n",
      "loss: 0.049967  [12864/23296]\n",
      "loss: 0.012129  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 98.9%, Avg loss: 0.032102 \n",
      "\n",
      "Epoch 21:\n",
      "loss: 0.031768  [   64/23296]\n",
      "loss: 0.006163  [ 6464/23296]\n",
      "loss: 0.014952  [12864/23296]\n",
      "loss: 0.106633  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 98.5%, Avg loss: 0.041840 \n",
      "\n",
      "Epoch 22:\n",
      "loss: 0.101766  [   64/23296]\n",
      "loss: 0.021970  [ 6464/23296]\n",
      "loss: 0.026264  [12864/23296]\n",
      "loss: 0.073600  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 99.1%, Avg loss: 0.036183 \n",
      "\n",
      "Early stopping due to no improvement in validation loss.\n"
     ]
    }
   ],
   "source": [
    "train(train_dataloader, model_ConvLSTM, loss_fn, optimizer,val_dataloader, \n",
    "           patience=patience, scheduler=scheduler, epochs=epochs, device=device, B_size=B_size, A_size=A_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 88.2%, Avg loss: 0.307775 \n",
      "\n",
      " Label 0\n",
      "    accuracy\t0.882\n",
      " specificity\t0.795\n",
      " sensitivity\t0.973\n",
      " Label 1\n",
      "    accuracy\t0.882\n",
      " specificity\t0.973\n",
      " sensitivity\t0.795\n",
      "[[36  1]\n",
      " [ 8 31]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# final test\n",
    "test(test_dataloader, model_ConvLSTM, loss_fn, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=16, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding='same')\n",
    "        self.bn2 = nn.BatchNorm1d(16)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=64, kernel_size=1)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.convr = nn.Conv1d(in_channels=in_channels, out_channels=64, kernel_size=1)\n",
    "    def forward(self, input):\n",
    "        residual = self.convr(input)\n",
    "        x = self.conv1(input)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x += residual\n",
    "        x = self.relu3(x)\n",
    "        return x\n",
    "\n",
    "class IdentityBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(IdentityBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=16, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding='same')\n",
    "        self.bn2 = nn.BatchNorm1d(16)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=64, kernel_size=1)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "    def forward(self, input):\n",
    "        \n",
    "        residual = input\n",
    "        x = self.conv1(input)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x += residual\n",
    "        x = self.relu3(x)\n",
    "        return x\n",
    "\n",
    "class ResNet24(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet24, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=9, out_channels=64, kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.convblk1 = ConvBlock(64)\n",
    "        self.convblk2 = ConvBlock(64)\n",
    "        self.identityblk1 = IdentityBlock(64)\n",
    "        self.convblk3 = ConvBlock(64)\n",
    "        self.identityblk2 = IdentityBlock(64)\n",
    "        self.convblk4 = ConvBlock(64)\n",
    "        self.identityblk3 = IdentityBlock(64)\n",
    "        \n",
    "        self.pool2 = nn.AvgPool1d(2)\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.Flatten(),\n",
    "                                nn.Linear(in_features=704, out_features=2),\n",
    "        #                        nn.Softmax()\n",
    "                                )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.convblk1(x)\n",
    "        x = self.convblk2(x)\n",
    "        x = self.identityblk1(x)\n",
    "        x = self.convblk3(x)\n",
    "        x = self.identityblk2(x)\n",
    "        x = self.convblk4(x)\n",
    "        x = self.identityblk3(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: ResNet24(\n",
      "  (conv1): Conv1d(9, 64, kernel_size=(3,), stride=(1,))\n",
      "  (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (convblk1): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (convblk2): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (identityblk1): IdentityBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "  )\n",
      "  (convblk3): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (identityblk2): IdentityBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "  )\n",
      "  (convblk4): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (identityblk3): IdentityBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "  )\n",
      "  (pool2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
      "  (fc): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=704, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: conv1.weight | Size: torch.Size([64, 9, 3]) | Values : tensor([[[ 0.1698, -0.1213, -0.1440],\n",
      "         [-0.1436, -0.0894,  0.0591],\n",
      "         [-0.0431,  0.0459,  0.1442],\n",
      "         [-0.0373,  0.1049,  0.1534],\n",
      "         [-0.0899,  0.0834, -0.1505],\n",
      "         [ 0.1660,  0.1868, -0.0222],\n",
      "         [-0.1429,  0.1407,  0.0277],\n",
      "         [ 0.0628, -0.1616, -0.0034],\n",
      "         [ 0.1642, -0.0923, -0.1444]],\n",
      "\n",
      "        [[-0.1535, -0.1701,  0.0255],\n",
      "         [-0.0379,  0.0075, -0.0754],\n",
      "         [ 0.1433,  0.0127, -0.0041],\n",
      "         [ 0.1817,  0.1063, -0.0237],\n",
      "         [-0.0519, -0.0237, -0.0938],\n",
      "         [ 0.0230, -0.0878, -0.0672],\n",
      "         [-0.1064,  0.0814, -0.1757],\n",
      "         [-0.1208,  0.0667,  0.0279],\n",
      "         [ 0.1902, -0.0039, -0.0918]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.bias | Size: torch.Size([64]) | Values : tensor([ 0.1078, -0.0595], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.weight | Size: torch.Size([64, 64, 3]) | Values : tensor([[[ 0.0616, -0.0695,  0.0595],\n",
      "         [ 0.0210, -0.0539,  0.0141],\n",
      "         [ 0.0508, -0.0172,  0.0312],\n",
      "         [-0.0398, -0.0243, -0.0386],\n",
      "         [-0.0373, -0.0264, -0.0700],\n",
      "         [-0.0399,  0.0252,  0.0276],\n",
      "         [ 0.0369, -0.0540, -0.0451],\n",
      "         [-0.0207, -0.0141, -0.0625],\n",
      "         [-0.0140, -0.0496, -0.0276],\n",
      "         [ 0.0516,  0.0628,  0.0100],\n",
      "         [ 0.0149, -0.0174, -0.0647],\n",
      "         [ 0.0366,  0.0242, -0.0447],\n",
      "         [-0.0465, -0.0139, -0.0561],\n",
      "         [-0.0710, -0.0452,  0.0094],\n",
      "         [ 0.0254,  0.0490, -0.0001],\n",
      "         [-0.0107,  0.0355,  0.0330],\n",
      "         [-0.0422, -0.0175,  0.0302],\n",
      "         [ 0.0508,  0.0615, -0.0318],\n",
      "         [-0.0614,  0.0173, -0.0076],\n",
      "         [ 0.0448,  0.0345, -0.0101],\n",
      "         [ 0.0580,  0.0554, -0.0044],\n",
      "         [ 0.0647,  0.0330,  0.0717],\n",
      "         [ 0.0093,  0.0415,  0.0309],\n",
      "         [-0.0501, -0.0706,  0.0516],\n",
      "         [ 0.0443, -0.0367, -0.0389],\n",
      "         [-0.0154, -0.0059, -0.0009],\n",
      "         [-0.0051, -0.0361, -0.0439],\n",
      "         [-0.0508,  0.0009, -0.0094],\n",
      "         [-0.0719, -0.0650,  0.0129],\n",
      "         [-0.0078,  0.0396, -0.0337],\n",
      "         [ 0.0217, -0.0280,  0.0008],\n",
      "         [-0.0539, -0.0423,  0.0668],\n",
      "         [-0.0717, -0.0120, -0.0130],\n",
      "         [-0.0468,  0.0163, -0.0602],\n",
      "         [-0.0432, -0.0291,  0.0435],\n",
      "         [ 0.0569, -0.0340,  0.0608],\n",
      "         [ 0.0436, -0.0140, -0.0531],\n",
      "         [ 0.0251,  0.0303, -0.0148],\n",
      "         [-0.0002,  0.0093, -0.0530],\n",
      "         [ 0.0590, -0.0067, -0.0431],\n",
      "         [ 0.0559, -0.0504, -0.0266],\n",
      "         [ 0.0710, -0.0183, -0.0620],\n",
      "         [ 0.0702, -0.0622,  0.0288],\n",
      "         [ 0.0478, -0.0489, -0.0224],\n",
      "         [-0.0384, -0.0689,  0.0199],\n",
      "         [-0.0446,  0.0642,  0.0026],\n",
      "         [ 0.0054, -0.0141,  0.0508],\n",
      "         [ 0.0502, -0.0486, -0.0179],\n",
      "         [ 0.0152, -0.0339,  0.0504],\n",
      "         [-0.0435,  0.0458, -0.0236],\n",
      "         [-0.0151,  0.0452, -0.0050],\n",
      "         [-0.0211,  0.0338, -0.0100],\n",
      "         [ 0.0561,  0.0251, -0.0667],\n",
      "         [-0.0015,  0.0190, -0.0688],\n",
      "         [ 0.0690, -0.0451, -0.0034],\n",
      "         [ 0.0294,  0.0267,  0.0321],\n",
      "         [-0.0188, -0.0032,  0.0099],\n",
      "         [ 0.0281,  0.0571, -0.0614],\n",
      "         [ 0.0040, -0.0028, -0.0374],\n",
      "         [ 0.0024, -0.0482, -0.0063],\n",
      "         [-0.0310,  0.0127,  0.0600],\n",
      "         [ 0.0611, -0.0112,  0.0197],\n",
      "         [ 0.0558,  0.0409,  0.0342],\n",
      "         [-0.0462, -0.0244, -0.0577]],\n",
      "\n",
      "        [[ 0.0560, -0.0335, -0.0110],\n",
      "         [-0.0671,  0.0594,  0.0643],\n",
      "         [-0.0213, -0.0432, -0.0400],\n",
      "         [-0.0618,  0.0019,  0.0596],\n",
      "         [-0.0211, -0.0470,  0.0705],\n",
      "         [ 0.0109, -0.0061, -0.0075],\n",
      "         [ 0.0024,  0.0658, -0.0188],\n",
      "         [-0.0282,  0.0662, -0.0188],\n",
      "         [ 0.0593,  0.0457, -0.0210],\n",
      "         [-0.0415,  0.0073, -0.0348],\n",
      "         [-0.0680,  0.0279, -0.0059],\n",
      "         [-0.0438,  0.0466, -0.0450],\n",
      "         [-0.0026, -0.0164,  0.0413],\n",
      "         [ 0.0549, -0.0287, -0.0550],\n",
      "         [ 0.0477,  0.0664, -0.0435],\n",
      "         [-0.0113,  0.0115, -0.0113],\n",
      "         [ 0.0428, -0.0430,  0.0557],\n",
      "         [-0.0471, -0.0063, -0.0133],\n",
      "         [ 0.0465, -0.0592, -0.0233],\n",
      "         [ 0.0591, -0.0125, -0.0294],\n",
      "         [ 0.0420,  0.0572, -0.0442],\n",
      "         [-0.0690, -0.0618,  0.0453],\n",
      "         [ 0.0432, -0.0411,  0.0510],\n",
      "         [-0.0451,  0.0257, -0.0519],\n",
      "         [-0.0301, -0.0062,  0.0391],\n",
      "         [-0.0658,  0.0568,  0.0258],\n",
      "         [-0.0602,  0.0501,  0.0082],\n",
      "         [ 0.0353,  0.0079, -0.0665],\n",
      "         [ 0.0683,  0.0678, -0.0175],\n",
      "         [ 0.0605, -0.0692,  0.0035],\n",
      "         [ 0.0109,  0.0018,  0.0647],\n",
      "         [-0.0050,  0.0647, -0.0453],\n",
      "         [-0.0567, -0.0501, -0.0096],\n",
      "         [ 0.0551,  0.0619,  0.0478],\n",
      "         [-0.0565, -0.0613, -0.0458],\n",
      "         [-0.0583, -0.0717,  0.0229],\n",
      "         [-0.0419, -0.0462, -0.0064],\n",
      "         [ 0.0655, -0.0408,  0.0201],\n",
      "         [-0.0591,  0.0231,  0.0441],\n",
      "         [ 0.0707,  0.0417,  0.0387],\n",
      "         [ 0.0123,  0.0539, -0.0500],\n",
      "         [ 0.0113,  0.0161,  0.0168],\n",
      "         [-0.0029, -0.0484,  0.0697],\n",
      "         [-0.0008,  0.0303, -0.0155],\n",
      "         [ 0.0713, -0.0310, -0.0164],\n",
      "         [-0.0423,  0.0479, -0.0272],\n",
      "         [-0.0058, -0.0063,  0.0281],\n",
      "         [ 0.0550, -0.0523, -0.0595],\n",
      "         [ 0.0020,  0.0142,  0.0513],\n",
      "         [-0.0135,  0.0589,  0.0532],\n",
      "         [-0.0023,  0.0461, -0.0243],\n",
      "         [-0.0203, -0.0457,  0.0276],\n",
      "         [ 0.0664, -0.0636, -0.0007],\n",
      "         [ 0.0621, -0.0418,  0.0010],\n",
      "         [-0.0093, -0.0192, -0.0304],\n",
      "         [-0.0115, -0.0521, -0.0475],\n",
      "         [ 0.0403, -0.0111,  0.0500],\n",
      "         [ 0.0067,  0.0183,  0.0181],\n",
      "         [ 0.0029,  0.0676, -0.0552],\n",
      "         [-0.0544,  0.0032,  0.0122],\n",
      "         [-0.0104, -0.0301, -0.0585],\n",
      "         [-0.0289, -0.0236, -0.0644],\n",
      "         [-0.0189,  0.0086,  0.0465],\n",
      "         [-0.0311, -0.0654,  0.0681]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv2.bias | Size: torch.Size([64]) | Values : tensor([ 0.0478, -0.0074], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[-0.1027],\n",
      "         [-0.0491],\n",
      "         [ 0.0115],\n",
      "         [ 0.0013],\n",
      "         [-0.1173],\n",
      "         [ 0.0142],\n",
      "         [ 0.0977],\n",
      "         [-0.1051],\n",
      "         [-0.0099],\n",
      "         [-0.1000],\n",
      "         [-0.0331],\n",
      "         [ 0.0024],\n",
      "         [-0.1031],\n",
      "         [-0.0341],\n",
      "         [ 0.0589],\n",
      "         [-0.1046],\n",
      "         [ 0.0321],\n",
      "         [ 0.0079],\n",
      "         [-0.0560],\n",
      "         [-0.1042],\n",
      "         [ 0.1123],\n",
      "         [-0.0450],\n",
      "         [-0.1020],\n",
      "         [ 0.1134],\n",
      "         [-0.0652],\n",
      "         [-0.0942],\n",
      "         [ 0.0762],\n",
      "         [-0.1074],\n",
      "         [-0.0156],\n",
      "         [ 0.1228],\n",
      "         [ 0.1108],\n",
      "         [ 0.0335],\n",
      "         [-0.0606],\n",
      "         [-0.0604],\n",
      "         [ 0.0509],\n",
      "         [ 0.1127],\n",
      "         [ 0.1023],\n",
      "         [ 0.1119],\n",
      "         [-0.1181],\n",
      "         [ 0.1015],\n",
      "         [-0.0595],\n",
      "         [-0.0486],\n",
      "         [-0.0908],\n",
      "         [ 0.0290],\n",
      "         [ 0.0687],\n",
      "         [ 0.0262],\n",
      "         [ 0.0716],\n",
      "         [ 0.0576],\n",
      "         [ 0.0677],\n",
      "         [ 0.0964],\n",
      "         [-0.1123],\n",
      "         [ 0.1081],\n",
      "         [ 0.0438],\n",
      "         [-0.0602],\n",
      "         [ 0.0321],\n",
      "         [ 0.0897],\n",
      "         [-0.0078],\n",
      "         [ 0.0496],\n",
      "         [ 0.0261],\n",
      "         [ 0.0590],\n",
      "         [ 0.0309],\n",
      "         [ 0.0405],\n",
      "         [ 0.0291],\n",
      "         [ 0.1101]],\n",
      "\n",
      "        [[-0.0278],\n",
      "         [-0.0788],\n",
      "         [ 0.0796],\n",
      "         [-0.0744],\n",
      "         [ 0.0156],\n",
      "         [ 0.1070],\n",
      "         [ 0.0258],\n",
      "         [-0.0859],\n",
      "         [-0.0371],\n",
      "         [-0.0417],\n",
      "         [-0.0990],\n",
      "         [-0.0418],\n",
      "         [ 0.0945],\n",
      "         [-0.0033],\n",
      "         [ 0.0898],\n",
      "         [-0.0976],\n",
      "         [ 0.1107],\n",
      "         [ 0.0519],\n",
      "         [-0.1187],\n",
      "         [ 0.0649],\n",
      "         [-0.1200],\n",
      "         [ 0.0559],\n",
      "         [ 0.1159],\n",
      "         [ 0.0683],\n",
      "         [-0.0375],\n",
      "         [-0.1105],\n",
      "         [-0.0965],\n",
      "         [-0.0290],\n",
      "         [-0.1107],\n",
      "         [ 0.0902],\n",
      "         [-0.0420],\n",
      "         [ 0.0796],\n",
      "         [-0.0761],\n",
      "         [-0.0820],\n",
      "         [ 0.0277],\n",
      "         [ 0.0455],\n",
      "         [ 0.0050],\n",
      "         [ 0.0940],\n",
      "         [ 0.1204],\n",
      "         [ 0.1056],\n",
      "         [-0.0321],\n",
      "         [ 0.0809],\n",
      "         [ 0.0229],\n",
      "         [-0.0261],\n",
      "         [ 0.0577],\n",
      "         [ 0.0562],\n",
      "         [-0.1135],\n",
      "         [ 0.0958],\n",
      "         [ 0.0910],\n",
      "         [ 0.0156],\n",
      "         [ 0.0387],\n",
      "         [ 0.0432],\n",
      "         [ 0.0125],\n",
      "         [-0.0240],\n",
      "         [ 0.1151],\n",
      "         [ 0.0533],\n",
      "         [-0.0560],\n",
      "         [-0.0311],\n",
      "         [ 0.0257],\n",
      "         [ 0.0441],\n",
      "         [-0.1163],\n",
      "         [ 0.0351],\n",
      "         [ 0.1161],\n",
      "         [-0.0110]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv1.bias | Size: torch.Size([16]) | Values : tensor([-0.0694, -0.0632], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[-0.1063,  0.0870, -0.0678],\n",
      "         [ 0.0082,  0.0376,  0.1082],\n",
      "         [-0.1260, -0.1423,  0.1047],\n",
      "         [ 0.1307,  0.0847, -0.1182],\n",
      "         [-0.0226, -0.0328,  0.0946],\n",
      "         [ 0.0435,  0.0771,  0.0807],\n",
      "         [-0.0676, -0.0708, -0.0692],\n",
      "         [-0.1146, -0.0229,  0.0275],\n",
      "         [-0.0018,  0.1259, -0.0671],\n",
      "         [-0.0064,  0.0448,  0.1351],\n",
      "         [-0.0274,  0.0818, -0.0807],\n",
      "         [ 0.1227, -0.0882,  0.0650],\n",
      "         [-0.1281, -0.1356,  0.0967],\n",
      "         [ 0.0416, -0.1272, -0.1232],\n",
      "         [ 0.0370,  0.1086,  0.0377],\n",
      "         [ 0.0564,  0.0731, -0.0262]],\n",
      "\n",
      "        [[ 0.1168,  0.0043, -0.1007],\n",
      "         [ 0.1101, -0.0620, -0.1025],\n",
      "         [-0.0561,  0.0926, -0.0436],\n",
      "         [-0.1297,  0.1374, -0.0139],\n",
      "         [ 0.1031,  0.1091,  0.1127],\n",
      "         [ 0.1169, -0.0987,  0.0644],\n",
      "         [ 0.0909, -0.1408,  0.0797],\n",
      "         [ 0.0309,  0.0861,  0.1179],\n",
      "         [ 0.0928,  0.1359, -0.0081],\n",
      "         [-0.0813,  0.0269,  0.1098],\n",
      "         [ 0.0156,  0.0766,  0.0760],\n",
      "         [ 0.0732, -0.1165,  0.1352],\n",
      "         [ 0.0461,  0.0981,  0.1041],\n",
      "         [ 0.1113,  0.1422, -0.1019],\n",
      "         [-0.1128,  0.0817, -0.1113],\n",
      "         [ 0.0207,  0.0675,  0.0491]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv2.bias | Size: torch.Size([16]) | Values : tensor([-0.0416, -0.0811], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[-1.3676e-01],\n",
      "         [ 1.1342e-01],\n",
      "         [ 7.3135e-02],\n",
      "         [ 1.6341e-02],\n",
      "         [ 6.1820e-02],\n",
      "         [ 1.5359e-01],\n",
      "         [ 1.2252e-01],\n",
      "         [ 2.4145e-01],\n",
      "         [-2.4552e-01],\n",
      "         [ 8.5934e-02],\n",
      "         [-1.3138e-01],\n",
      "         [ 6.4896e-02],\n",
      "         [-1.4583e-01],\n",
      "         [ 2.4378e-01],\n",
      "         [ 2.4596e-01],\n",
      "         [-1.2194e-01]],\n",
      "\n",
      "        [[ 8.1208e-02],\n",
      "         [ 5.0362e-03],\n",
      "         [-1.1808e-04],\n",
      "         [ 1.6814e-01],\n",
      "         [-1.8196e-01],\n",
      "         [ 7.7788e-02],\n",
      "         [-1.4488e-01],\n",
      "         [ 8.3482e-02],\n",
      "         [-1.2270e-01],\n",
      "         [-2.0680e-01],\n",
      "         [ 4.0602e-02],\n",
      "         [-3.8769e-02],\n",
      "         [-1.1346e-01],\n",
      "         [ 1.6355e-01],\n",
      "         [ 1.7580e-01],\n",
      "         [-1.4614e-01]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv3.bias | Size: torch.Size([64]) | Values : tensor([-0.0029, -0.0424], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[ 6.6188e-02],\n",
      "         [ 7.3208e-02],\n",
      "         [-4.0702e-02],\n",
      "         [ 6.4861e-02],\n",
      "         [ 6.9858e-02],\n",
      "         [ 9.0430e-02],\n",
      "         [-9.7911e-02],\n",
      "         [-7.5820e-02],\n",
      "         [ 3.7754e-02],\n",
      "         [ 1.0364e-01],\n",
      "         [-5.5051e-02],\n",
      "         [ 7.2051e-02],\n",
      "         [-7.0338e-02],\n",
      "         [-9.5578e-02],\n",
      "         [ 1.0270e-02],\n",
      "         [ 1.7643e-02],\n",
      "         [ 1.8711e-02],\n",
      "         [ 5.6382e-02],\n",
      "         [-1.0078e-01],\n",
      "         [ 1.2237e-01],\n",
      "         [ 1.1321e-01],\n",
      "         [ 4.8388e-02],\n",
      "         [ 2.0185e-02],\n",
      "         [ 1.2197e-01],\n",
      "         [-2.6392e-02],\n",
      "         [-6.4458e-03],\n",
      "         [-1.1874e-02],\n",
      "         [-1.2261e-01],\n",
      "         [-7.8884e-02],\n",
      "         [ 1.1733e-01],\n",
      "         [ 6.2198e-02],\n",
      "         [ 2.4201e-02],\n",
      "         [-8.3532e-02],\n",
      "         [ 6.1777e-02],\n",
      "         [-1.0650e-01],\n",
      "         [ 5.5806e-02],\n",
      "         [-5.1077e-02],\n",
      "         [ 1.2458e-01],\n",
      "         [-1.0259e-01],\n",
      "         [-4.9322e-02],\n",
      "         [ 8.4692e-02],\n",
      "         [-1.0915e-01],\n",
      "         [ 5.2573e-02],\n",
      "         [-1.3885e-03],\n",
      "         [ 5.1060e-02],\n",
      "         [ 1.0332e-01],\n",
      "         [-1.1972e-01],\n",
      "         [ 3.6244e-02],\n",
      "         [ 4.5039e-02],\n",
      "         [-2.5951e-02],\n",
      "         [ 9.3630e-02],\n",
      "         [-1.3644e-02],\n",
      "         [ 6.8340e-02],\n",
      "         [-3.0541e-03],\n",
      "         [ 6.8822e-03],\n",
      "         [ 8.7055e-02],\n",
      "         [ 7.8853e-02],\n",
      "         [-3.7758e-02],\n",
      "         [-4.6837e-02],\n",
      "         [-1.4075e-02],\n",
      "         [ 7.0242e-02],\n",
      "         [ 7.1250e-02],\n",
      "         [-1.2131e-02],\n",
      "         [-8.7227e-02]],\n",
      "\n",
      "        [[ 6.0480e-02],\n",
      "         [ 1.0528e-01],\n",
      "         [ 2.2203e-02],\n",
      "         [ 6.1817e-02],\n",
      "         [ 6.5541e-02],\n",
      "         [ 9.2383e-02],\n",
      "         [ 3.7285e-02],\n",
      "         [-3.9749e-02],\n",
      "         [-6.0553e-02],\n",
      "         [-5.2778e-03],\n",
      "         [ 8.8154e-03],\n",
      "         [-6.4621e-02],\n",
      "         [-9.9639e-02],\n",
      "         [ 1.0733e-02],\n",
      "         [ 9.2312e-02],\n",
      "         [-2.6467e-03],\n",
      "         [-7.3985e-02],\n",
      "         [-3.7839e-02],\n",
      "         [ 4.0030e-03],\n",
      "         [ 9.0429e-02],\n",
      "         [-1.1932e-01],\n",
      "         [ 6.4126e-02],\n",
      "         [-9.6019e-02],\n",
      "         [-5.8029e-02],\n",
      "         [-1.2000e-01],\n",
      "         [-4.7600e-02],\n",
      "         [ 7.1482e-02],\n",
      "         [-2.3899e-02],\n",
      "         [-8.8152e-02],\n",
      "         [ 9.6350e-02],\n",
      "         [-1.2172e-01],\n",
      "         [-1.0248e-04],\n",
      "         [ 4.8577e-02],\n",
      "         [ 1.1320e-01],\n",
      "         [ 2.5797e-03],\n",
      "         [-3.6455e-02],\n",
      "         [-1.1264e-01],\n",
      "         [ 8.5169e-02],\n",
      "         [-7.0550e-02],\n",
      "         [-4.8804e-02],\n",
      "         [ 7.8643e-02],\n",
      "         [-1.4487e-02],\n",
      "         [-8.6485e-02],\n",
      "         [-1.2027e-01],\n",
      "         [ 9.7658e-02],\n",
      "         [-1.2054e-02],\n",
      "         [ 2.9416e-02],\n",
      "         [-7.7414e-02],\n",
      "         [-4.3324e-02],\n",
      "         [ 7.8527e-02],\n",
      "         [-8.5859e-02],\n",
      "         [ 1.0780e-01],\n",
      "         [-5.9244e-02],\n",
      "         [ 7.3386e-02],\n",
      "         [ 2.1825e-02],\n",
      "         [-8.2052e-02],\n",
      "         [ 1.2641e-02],\n",
      "         [-3.3467e-03],\n",
      "         [ 2.3940e-02],\n",
      "         [ 8.1170e-02],\n",
      "         [ 1.2174e-01],\n",
      "         [-9.9848e-02],\n",
      "         [ 5.9825e-02],\n",
      "         [-1.1539e-01]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.convr.bias | Size: torch.Size([64]) | Values : tensor([-0.1100, -0.0644], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[ 0.0514],\n",
      "         [-0.0773],\n",
      "         [ 0.1137],\n",
      "         [ 0.0408],\n",
      "         [-0.0464],\n",
      "         [-0.0946],\n",
      "         [-0.0666],\n",
      "         [-0.0667],\n",
      "         [-0.0383],\n",
      "         [-0.0387],\n",
      "         [-0.0190],\n",
      "         [-0.0446],\n",
      "         [-0.1239],\n",
      "         [-0.0798],\n",
      "         [ 0.1228],\n",
      "         [-0.0499],\n",
      "         [-0.0421],\n",
      "         [-0.0835],\n",
      "         [ 0.0646],\n",
      "         [-0.0422],\n",
      "         [ 0.0512],\n",
      "         [ 0.0786],\n",
      "         [-0.0603],\n",
      "         [-0.0968],\n",
      "         [-0.0797],\n",
      "         [ 0.0304],\n",
      "         [-0.0643],\n",
      "         [-0.0847],\n",
      "         [-0.0446],\n",
      "         [-0.0429],\n",
      "         [-0.0780],\n",
      "         [ 0.0573],\n",
      "         [ 0.0920],\n",
      "         [ 0.0741],\n",
      "         [-0.1194],\n",
      "         [-0.1236],\n",
      "         [ 0.0435],\n",
      "         [ 0.0834],\n",
      "         [-0.0597],\n",
      "         [-0.0585],\n",
      "         [-0.0442],\n",
      "         [ 0.0634],\n",
      "         [ 0.0587],\n",
      "         [ 0.0401],\n",
      "         [-0.0606],\n",
      "         [ 0.0111],\n",
      "         [ 0.0091],\n",
      "         [-0.0360],\n",
      "         [-0.0559],\n",
      "         [ 0.0719],\n",
      "         [-0.1218],\n",
      "         [ 0.0169],\n",
      "         [-0.1107],\n",
      "         [-0.1115],\n",
      "         [ 0.0433],\n",
      "         [ 0.0517],\n",
      "         [-0.1204],\n",
      "         [ 0.0864],\n",
      "         [ 0.0339],\n",
      "         [-0.0694],\n",
      "         [-0.0411],\n",
      "         [-0.1100],\n",
      "         [-0.0636],\n",
      "         [-0.1133]],\n",
      "\n",
      "        [[-0.0047],\n",
      "         [ 0.0948],\n",
      "         [-0.1238],\n",
      "         [ 0.0109],\n",
      "         [ 0.0068],\n",
      "         [ 0.0870],\n",
      "         [ 0.0459],\n",
      "         [ 0.0142],\n",
      "         [ 0.0312],\n",
      "         [ 0.0413],\n",
      "         [-0.0898],\n",
      "         [ 0.0126],\n",
      "         [ 0.0805],\n",
      "         [-0.0624],\n",
      "         [ 0.1164],\n",
      "         [ 0.0021],\n",
      "         [-0.0086],\n",
      "         [ 0.0232],\n",
      "         [ 0.0977],\n",
      "         [-0.1026],\n",
      "         [ 0.0034],\n",
      "         [ 0.0580],\n",
      "         [-0.0922],\n",
      "         [ 0.0661],\n",
      "         [ 0.0010],\n",
      "         [-0.0171],\n",
      "         [-0.0711],\n",
      "         [-0.0316],\n",
      "         [ 0.0363],\n",
      "         [ 0.0500],\n",
      "         [ 0.1072],\n",
      "         [ 0.0763],\n",
      "         [ 0.1172],\n",
      "         [-0.1125],\n",
      "         [ 0.0763],\n",
      "         [ 0.0612],\n",
      "         [-0.1224],\n",
      "         [-0.0685],\n",
      "         [ 0.1052],\n",
      "         [ 0.1242],\n",
      "         [-0.0069],\n",
      "         [-0.1214],\n",
      "         [-0.0242],\n",
      "         [ 0.0980],\n",
      "         [-0.0221],\n",
      "         [ 0.0634],\n",
      "         [ 0.0906],\n",
      "         [-0.0960],\n",
      "         [ 0.0759],\n",
      "         [-0.0172],\n",
      "         [ 0.0061],\n",
      "         [ 0.0074],\n",
      "         [ 0.1215],\n",
      "         [-0.0666],\n",
      "         [-0.0415],\n",
      "         [-0.0339],\n",
      "         [-0.0354],\n",
      "         [ 0.0846],\n",
      "         [ 0.0193],\n",
      "         [ 0.0674],\n",
      "         [ 0.0776],\n",
      "         [-0.0794],\n",
      "         [-0.0473],\n",
      "         [-0.0726]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv1.bias | Size: torch.Size([16]) | Values : tensor([0.0993, 0.0374], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[-0.1155,  0.0779, -0.1245],\n",
      "         [-0.1391,  0.1160, -0.0948],\n",
      "         [ 0.0157,  0.1240,  0.0015],\n",
      "         [-0.0009,  0.1196, -0.0992],\n",
      "         [-0.0286,  0.1293, -0.1150],\n",
      "         [ 0.1009, -0.0349,  0.0008],\n",
      "         [ 0.0439,  0.0852, -0.1366],\n",
      "         [ 0.0969,  0.1308, -0.1007],\n",
      "         [-0.1300,  0.0145, -0.0035],\n",
      "         [-0.0110, -0.0203, -0.0772],\n",
      "         [-0.0177,  0.0523, -0.0609],\n",
      "         [-0.0832, -0.0362, -0.0235],\n",
      "         [ 0.0279, -0.1029,  0.0247],\n",
      "         [ 0.0601,  0.1339,  0.1176],\n",
      "         [-0.0483, -0.0251,  0.1399],\n",
      "         [ 0.0179,  0.0185, -0.0044]],\n",
      "\n",
      "        [[-0.0619, -0.1062,  0.1190],\n",
      "         [ 0.1229, -0.0734, -0.0801],\n",
      "         [-0.1180,  0.0165, -0.1132],\n",
      "         [-0.1211, -0.0205,  0.1316],\n",
      "         [ 0.1356, -0.0808,  0.1207],\n",
      "         [ 0.1422, -0.1073,  0.0724],\n",
      "         [ 0.0598,  0.0052,  0.0739],\n",
      "         [-0.0106,  0.0314, -0.1348],\n",
      "         [-0.1187, -0.0869, -0.0169],\n",
      "         [ 0.1383,  0.0956, -0.0316],\n",
      "         [ 0.0551, -0.0880,  0.0589],\n",
      "         [-0.1072, -0.0583,  0.1109],\n",
      "         [ 0.0077, -0.0686,  0.0163],\n",
      "         [ 0.0695,  0.0569,  0.0780],\n",
      "         [ 0.1418, -0.0472,  0.0049],\n",
      "         [-0.1237, -0.1153,  0.0972]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv2.bias | Size: torch.Size([16]) | Values : tensor([-0.0671, -0.1381], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[ 0.0889],\n",
      "         [-0.1470],\n",
      "         [ 0.1465],\n",
      "         [-0.1570],\n",
      "         [ 0.2106],\n",
      "         [-0.1920],\n",
      "         [-0.0934],\n",
      "         [ 0.1802],\n",
      "         [ 0.0255],\n",
      "         [-0.0646],\n",
      "         [-0.1733],\n",
      "         [ 0.0510],\n",
      "         [ 0.1019],\n",
      "         [-0.0056],\n",
      "         [-0.0102],\n",
      "         [-0.0145]],\n",
      "\n",
      "        [[-0.0359],\n",
      "         [-0.0720],\n",
      "         [ 0.1937],\n",
      "         [ 0.1402],\n",
      "         [-0.1702],\n",
      "         [-0.0352],\n",
      "         [-0.2185],\n",
      "         [-0.0498],\n",
      "         [-0.0699],\n",
      "         [-0.1795],\n",
      "         [-0.1296],\n",
      "         [-0.0929],\n",
      "         [ 0.0303],\n",
      "         [-0.2449],\n",
      "         [ 0.1326],\n",
      "         [ 0.2168]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv3.bias | Size: torch.Size([64]) | Values : tensor([0.1596, 0.2220], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[ 0.0061],\n",
      "         [-0.0259],\n",
      "         [-0.1228],\n",
      "         [-0.0122],\n",
      "         [-0.0488],\n",
      "         [-0.0617],\n",
      "         [-0.1199],\n",
      "         [-0.0659],\n",
      "         [ 0.0617],\n",
      "         [-0.0614],\n",
      "         [-0.1163],\n",
      "         [ 0.0940],\n",
      "         [-0.0911],\n",
      "         [-0.0491],\n",
      "         [ 0.1156],\n",
      "         [-0.0910],\n",
      "         [-0.0182],\n",
      "         [-0.0422],\n",
      "         [-0.1103],\n",
      "         [-0.0949],\n",
      "         [-0.0075],\n",
      "         [ 0.0252],\n",
      "         [-0.0096],\n",
      "         [ 0.0754],\n",
      "         [-0.1189],\n",
      "         [ 0.0982],\n",
      "         [-0.0852],\n",
      "         [-0.0308],\n",
      "         [-0.0294],\n",
      "         [-0.0245],\n",
      "         [ 0.1087],\n",
      "         [ 0.0313],\n",
      "         [ 0.1186],\n",
      "         [ 0.1097],\n",
      "         [-0.0386],\n",
      "         [ 0.0383],\n",
      "         [-0.1246],\n",
      "         [-0.0403],\n",
      "         [-0.0811],\n",
      "         [-0.0168],\n",
      "         [-0.0935],\n",
      "         [ 0.0588],\n",
      "         [ 0.0520],\n",
      "         [-0.0463],\n",
      "         [ 0.0809],\n",
      "         [ 0.0382],\n",
      "         [-0.0501],\n",
      "         [-0.0780],\n",
      "         [-0.0862],\n",
      "         [-0.1207],\n",
      "         [-0.0465],\n",
      "         [ 0.1248],\n",
      "         [ 0.0336],\n",
      "         [ 0.0934],\n",
      "         [-0.0624],\n",
      "         [ 0.0863],\n",
      "         [ 0.0439],\n",
      "         [ 0.0669],\n",
      "         [-0.0017],\n",
      "         [-0.0986],\n",
      "         [ 0.0637],\n",
      "         [ 0.0482],\n",
      "         [ 0.0265],\n",
      "         [ 0.0911]],\n",
      "\n",
      "        [[-0.0635],\n",
      "         [-0.0734],\n",
      "         [-0.0194],\n",
      "         [ 0.0863],\n",
      "         [ 0.0906],\n",
      "         [-0.0859],\n",
      "         [ 0.1223],\n",
      "         [-0.0225],\n",
      "         [ 0.0003],\n",
      "         [ 0.0756],\n",
      "         [-0.0409],\n",
      "         [ 0.0964],\n",
      "         [ 0.0019],\n",
      "         [-0.0758],\n",
      "         [ 0.1139],\n",
      "         [-0.0096],\n",
      "         [ 0.0033],\n",
      "         [-0.0296],\n",
      "         [-0.0673],\n",
      "         [-0.0257],\n",
      "         [ 0.0330],\n",
      "         [-0.1221],\n",
      "         [-0.0216],\n",
      "         [ 0.0786],\n",
      "         [-0.0935],\n",
      "         [ 0.0284],\n",
      "         [-0.0204],\n",
      "         [-0.0541],\n",
      "         [ 0.0245],\n",
      "         [ 0.1163],\n",
      "         [ 0.0382],\n",
      "         [-0.0768],\n",
      "         [-0.0072],\n",
      "         [-0.0214],\n",
      "         [-0.0205],\n",
      "         [ 0.0706],\n",
      "         [ 0.0634],\n",
      "         [-0.0709],\n",
      "         [-0.0241],\n",
      "         [-0.0482],\n",
      "         [-0.0750],\n",
      "         [-0.0337],\n",
      "         [ 0.0202],\n",
      "         [-0.0559],\n",
      "         [-0.0590],\n",
      "         [-0.0424],\n",
      "         [-0.0076],\n",
      "         [ 0.0598],\n",
      "         [ 0.0762],\n",
      "         [-0.0128],\n",
      "         [ 0.0623],\n",
      "         [-0.0733],\n",
      "         [ 0.0799],\n",
      "         [-0.0332],\n",
      "         [-0.0201],\n",
      "         [-0.1123],\n",
      "         [ 0.0593],\n",
      "         [-0.0974],\n",
      "         [-0.0236],\n",
      "         [ 0.0163],\n",
      "         [-0.0885],\n",
      "         [-0.1017],\n",
      "         [-0.1176],\n",
      "         [ 0.0534]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.convr.bias | Size: torch.Size([64]) | Values : tensor([0.0315, 0.0690], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[ 0.0340],\n",
      "         [-0.1104],\n",
      "         [-0.0109],\n",
      "         [ 0.0548],\n",
      "         [-0.1194],\n",
      "         [ 0.0396],\n",
      "         [ 0.1237],\n",
      "         [ 0.0281],\n",
      "         [-0.0451],\n",
      "         [-0.0658],\n",
      "         [ 0.0791],\n",
      "         [-0.0871],\n",
      "         [ 0.0275],\n",
      "         [-0.0252],\n",
      "         [-0.0420],\n",
      "         [ 0.1118],\n",
      "         [-0.0457],\n",
      "         [-0.0763],\n",
      "         [-0.0377],\n",
      "         [ 0.0537],\n",
      "         [-0.0033],\n",
      "         [ 0.0948],\n",
      "         [-0.0049],\n",
      "         [ 0.1085],\n",
      "         [-0.0681],\n",
      "         [ 0.0383],\n",
      "         [ 0.0757],\n",
      "         [ 0.0551],\n",
      "         [-0.0914],\n",
      "         [-0.1241],\n",
      "         [ 0.0827],\n",
      "         [-0.0668],\n",
      "         [ 0.0321],\n",
      "         [ 0.1223],\n",
      "         [ 0.0722],\n",
      "         [ 0.0679],\n",
      "         [ 0.0480],\n",
      "         [ 0.0592],\n",
      "         [ 0.1010],\n",
      "         [-0.0382],\n",
      "         [ 0.1016],\n",
      "         [ 0.0758],\n",
      "         [ 0.0364],\n",
      "         [-0.0468],\n",
      "         [ 0.0912],\n",
      "         [-0.0901],\n",
      "         [ 0.0846],\n",
      "         [-0.0759],\n",
      "         [ 0.0960],\n",
      "         [-0.0169],\n",
      "         [-0.0186],\n",
      "         [ 0.0137],\n",
      "         [-0.1168],\n",
      "         [-0.0402],\n",
      "         [-0.0263],\n",
      "         [ 0.0722],\n",
      "         [ 0.0367],\n",
      "         [ 0.0492],\n",
      "         [-0.0116],\n",
      "         [-0.0179],\n",
      "         [-0.0268],\n",
      "         [ 0.0590],\n",
      "         [ 0.0040],\n",
      "         [ 0.0030]],\n",
      "\n",
      "        [[-0.0075],\n",
      "         [ 0.0819],\n",
      "         [ 0.0160],\n",
      "         [ 0.0513],\n",
      "         [-0.0584],\n",
      "         [-0.0517],\n",
      "         [-0.0079],\n",
      "         [ 0.1019],\n",
      "         [ 0.0590],\n",
      "         [-0.0783],\n",
      "         [ 0.0537],\n",
      "         [-0.1096],\n",
      "         [-0.0501],\n",
      "         [ 0.0447],\n",
      "         [ 0.1009],\n",
      "         [ 0.0107],\n",
      "         [-0.0047],\n",
      "         [-0.0173],\n",
      "         [ 0.0701],\n",
      "         [-0.0096],\n",
      "         [-0.0029],\n",
      "         [-0.1037],\n",
      "         [ 0.0134],\n",
      "         [-0.0884],\n",
      "         [-0.0012],\n",
      "         [ 0.0111],\n",
      "         [ 0.0209],\n",
      "         [ 0.1163],\n",
      "         [ 0.0540],\n",
      "         [ 0.1139],\n",
      "         [-0.1080],\n",
      "         [ 0.0298],\n",
      "         [ 0.0823],\n",
      "         [-0.0980],\n",
      "         [-0.0843],\n",
      "         [-0.0874],\n",
      "         [-0.1235],\n",
      "         [ 0.0188],\n",
      "         [-0.0300],\n",
      "         [ 0.0867],\n",
      "         [-0.0548],\n",
      "         [-0.1222],\n",
      "         [-0.0775],\n",
      "         [ 0.0659],\n",
      "         [-0.0877],\n",
      "         [ 0.0032],\n",
      "         [ 0.0105],\n",
      "         [ 0.0065],\n",
      "         [ 0.0870],\n",
      "         [ 0.0390],\n",
      "         [-0.1070],\n",
      "         [-0.0802],\n",
      "         [-0.0984],\n",
      "         [-0.0398],\n",
      "         [ 0.0608],\n",
      "         [-0.0643],\n",
      "         [ 0.0357],\n",
      "         [ 0.1249],\n",
      "         [ 0.0019],\n",
      "         [ 0.0517],\n",
      "         [ 0.0787],\n",
      "         [ 0.0709],\n",
      "         [ 0.0795],\n",
      "         [ 0.0986]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.conv1.bias | Size: torch.Size([16]) | Values : tensor([-0.0946,  0.0850], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[ 0.1100,  0.1314,  0.1322],\n",
      "         [ 0.1155,  0.0689, -0.1022],\n",
      "         [ 0.0734,  0.1323, -0.1356],\n",
      "         [ 0.0244, -0.1215, -0.1343],\n",
      "         [ 0.0950, -0.0279, -0.0020],\n",
      "         [-0.0597, -0.0800, -0.1331],\n",
      "         [-0.1144, -0.0651, -0.0112],\n",
      "         [-0.0704, -0.0401,  0.0066],\n",
      "         [-0.0693,  0.1230, -0.0902],\n",
      "         [ 0.1116,  0.1123, -0.0437],\n",
      "         [ 0.0542,  0.0190, -0.0308],\n",
      "         [-0.0055,  0.1092, -0.0870],\n",
      "         [-0.1328,  0.0947,  0.0926],\n",
      "         [ 0.0163,  0.0437, -0.0788],\n",
      "         [-0.0512,  0.0048,  0.0524],\n",
      "         [ 0.0754, -0.0189, -0.0281]],\n",
      "\n",
      "        [[ 0.0630,  0.1148,  0.1325],\n",
      "         [ 0.0100,  0.1109,  0.1346],\n",
      "         [-0.0611,  0.0962, -0.0326],\n",
      "         [ 0.0435,  0.0418,  0.0992],\n",
      "         [-0.0899,  0.1147, -0.0943],\n",
      "         [-0.0783,  0.0183,  0.0078],\n",
      "         [-0.0161, -0.0101,  0.0140],\n",
      "         [ 0.0600, -0.1367, -0.1101],\n",
      "         [-0.0619, -0.0338, -0.1340],\n",
      "         [ 0.0130, -0.0355, -0.1247],\n",
      "         [ 0.0584,  0.0085, -0.0685],\n",
      "         [ 0.0532, -0.0337,  0.1077],\n",
      "         [-0.0707,  0.0976, -0.0646],\n",
      "         [ 0.1132,  0.0486, -0.0898],\n",
      "         [-0.0982,  0.0185,  0.0129],\n",
      "         [ 0.0005,  0.0785,  0.0147]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.conv2.bias | Size: torch.Size([16]) | Values : tensor([-0.0360,  0.0480], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[ 0.2080],\n",
      "         [-0.0148],\n",
      "         [ 0.0815],\n",
      "         [ 0.0656],\n",
      "         [-0.2460],\n",
      "         [-0.1574],\n",
      "         [ 0.2479],\n",
      "         [ 0.1533],\n",
      "         [ 0.1011],\n",
      "         [-0.1960],\n",
      "         [ 0.0471],\n",
      "         [ 0.0999],\n",
      "         [ 0.0615],\n",
      "         [ 0.2387],\n",
      "         [-0.0290],\n",
      "         [ 0.1726]],\n",
      "\n",
      "        [[-0.0648],\n",
      "         [ 0.0152],\n",
      "         [-0.1630],\n",
      "         [-0.1280],\n",
      "         [ 0.0240],\n",
      "         [-0.1999],\n",
      "         [ 0.1655],\n",
      "         [ 0.0021],\n",
      "         [ 0.0160],\n",
      "         [ 0.1310],\n",
      "         [-0.1538],\n",
      "         [ 0.0991],\n",
      "         [-0.2137],\n",
      "         [-0.0801],\n",
      "         [-0.2218],\n",
      "         [-0.1289]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.conv3.bias | Size: torch.Size([64]) | Values : tensor([ 0.0805, -0.2076], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk1.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[ 5.7490e-02],\n",
      "         [ 4.5725e-02],\n",
      "         [ 8.9044e-02],\n",
      "         [-2.2304e-02],\n",
      "         [ 7.1080e-02],\n",
      "         [ 6.2421e-05],\n",
      "         [ 1.0267e-01],\n",
      "         [ 5.2566e-03],\n",
      "         [ 2.3735e-03],\n",
      "         [-1.0907e-01],\n",
      "         [ 3.4977e-02],\n",
      "         [ 4.5454e-02],\n",
      "         [ 9.8807e-02],\n",
      "         [ 1.1824e-01],\n",
      "         [ 5.2266e-02],\n",
      "         [-9.6794e-02],\n",
      "         [-7.8222e-02],\n",
      "         [ 3.5552e-02],\n",
      "         [-5.2551e-02],\n",
      "         [-6.6191e-02],\n",
      "         [ 7.4561e-02],\n",
      "         [-7.7175e-02],\n",
      "         [-1.1764e-02],\n",
      "         [ 3.3740e-02],\n",
      "         [ 1.1936e-01],\n",
      "         [ 2.1165e-02],\n",
      "         [ 2.3770e-02],\n",
      "         [ 6.7648e-02],\n",
      "         [-4.6723e-02],\n",
      "         [-1.7155e-02],\n",
      "         [-2.1681e-03],\n",
      "         [-6.4052e-02],\n",
      "         [ 9.9239e-04],\n",
      "         [-7.7739e-02],\n",
      "         [ 4.1484e-02],\n",
      "         [ 6.7154e-02],\n",
      "         [-1.0669e-01],\n",
      "         [ 8.7602e-03],\n",
      "         [-3.8291e-02],\n",
      "         [-7.1363e-02],\n",
      "         [ 3.0075e-02],\n",
      "         [-7.8232e-02],\n",
      "         [ 7.9983e-02],\n",
      "         [-1.2237e-01],\n",
      "         [-5.9257e-02],\n",
      "         [ 7.2758e-02],\n",
      "         [ 5.2546e-03],\n",
      "         [ 1.1118e-01],\n",
      "         [ 9.2125e-02],\n",
      "         [ 8.8528e-03],\n",
      "         [-1.4136e-02],\n",
      "         [ 3.5640e-02],\n",
      "         [ 3.7459e-02],\n",
      "         [-3.0279e-03],\n",
      "         [-2.4721e-02],\n",
      "         [ 3.4449e-02],\n",
      "         [ 3.5575e-02],\n",
      "         [-8.8266e-02],\n",
      "         [ 6.4329e-03],\n",
      "         [-2.9834e-02],\n",
      "         [-3.7457e-02],\n",
      "         [-3.9036e-02],\n",
      "         [-8.2176e-02],\n",
      "         [-6.8532e-02]],\n",
      "\n",
      "        [[ 1.1223e-02],\n",
      "         [ 1.1216e-01],\n",
      "         [ 1.1126e-01],\n",
      "         [ 1.0637e-01],\n",
      "         [ 1.6344e-02],\n",
      "         [ 2.8046e-02],\n",
      "         [-4.8489e-02],\n",
      "         [ 1.0338e-01],\n",
      "         [ 7.5566e-02],\n",
      "         [-8.8211e-02],\n",
      "         [-9.2701e-02],\n",
      "         [-1.1463e-01],\n",
      "         [-1.1122e-01],\n",
      "         [ 1.0790e-01],\n",
      "         [-1.1406e-01],\n",
      "         [-1.1591e-01],\n",
      "         [ 5.2622e-02],\n",
      "         [ 1.2309e-01],\n",
      "         [-4.6457e-02],\n",
      "         [-1.9528e-02],\n",
      "         [-3.9631e-02],\n",
      "         [ 2.9351e-02],\n",
      "         [ 1.0370e-01],\n",
      "         [ 1.0014e-01],\n",
      "         [ 1.1785e-01],\n",
      "         [ 6.5902e-02],\n",
      "         [ 1.0825e-01],\n",
      "         [ 2.5493e-02],\n",
      "         [-8.3735e-03],\n",
      "         [-9.3028e-05],\n",
      "         [-1.1645e-02],\n",
      "         [ 9.0882e-02],\n",
      "         [-4.5095e-02],\n",
      "         [-7.4015e-02],\n",
      "         [ 2.4217e-02],\n",
      "         [-6.8371e-03],\n",
      "         [-1.0183e-01],\n",
      "         [-2.1394e-03],\n",
      "         [ 1.0953e-01],\n",
      "         [ 3.7146e-02],\n",
      "         [-6.8453e-02],\n",
      "         [-8.3123e-02],\n",
      "         [-1.0821e-01],\n",
      "         [-5.6214e-02],\n",
      "         [-8.1363e-03],\n",
      "         [ 1.1141e-01],\n",
      "         [-1.6822e-02],\n",
      "         [ 7.0253e-02],\n",
      "         [ 1.7896e-02],\n",
      "         [ 5.5787e-03],\n",
      "         [-8.2073e-02],\n",
      "         [ 1.4857e-03],\n",
      "         [-9.9318e-02],\n",
      "         [ 1.2093e-01],\n",
      "         [ 9.2529e-02],\n",
      "         [ 1.0163e-01],\n",
      "         [-1.1765e-01],\n",
      "         [-3.6300e-02],\n",
      "         [-8.5934e-03],\n",
      "         [ 4.7311e-02],\n",
      "         [ 5.4584e-02],\n",
      "         [ 5.8499e-03],\n",
      "         [-1.1334e-01],\n",
      "         [ 5.8318e-02]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv1.bias | Size: torch.Size([16]) | Values : tensor([-0.1163,  0.0829], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[ 9.3813e-02,  8.9580e-02, -7.3055e-02],\n",
      "         [ 1.2159e-01,  4.2289e-02, -4.0009e-03],\n",
      "         [ 9.7384e-02, -6.0457e-02,  5.0244e-02],\n",
      "         [-3.6567e-05, -8.5684e-02,  1.1703e-01],\n",
      "         [-1.2887e-01, -5.9432e-02, -6.4262e-02],\n",
      "         [ 1.0977e-02,  1.1082e-01, -9.0387e-02],\n",
      "         [ 2.6429e-02,  6.9941e-02, -4.2446e-02],\n",
      "         [-6.5022e-02,  1.3451e-01, -1.1822e-01],\n",
      "         [ 4.8103e-02, -5.9335e-03, -8.8691e-02],\n",
      "         [-9.5922e-02,  1.1521e-01,  4.2901e-02],\n",
      "         [ 5.7162e-02, -1.0502e-01, -8.4778e-03],\n",
      "         [ 9.6786e-02,  2.7784e-02, -6.3389e-02],\n",
      "         [-4.1052e-02, -1.9728e-03,  7.2606e-02],\n",
      "         [ 1.0525e-01, -4.6195e-02, -1.4141e-01],\n",
      "         [-3.7617e-02, -1.3874e-01,  1.1985e-01],\n",
      "         [ 3.9579e-02, -5.2660e-02, -6.1620e-03]],\n",
      "\n",
      "        [[ 9.1711e-02, -9.7449e-02,  1.3140e-01],\n",
      "         [ 1.3765e-01,  1.2276e-01,  8.9492e-02],\n",
      "         [ 3.3251e-02, -5.6596e-02,  3.7059e-02],\n",
      "         [ 7.5837e-02, -1.1907e-01,  1.3612e-01],\n",
      "         [ 1.1450e-01,  6.5984e-02,  1.1383e-01],\n",
      "         [-8.3828e-02,  1.2073e-01, -5.1965e-03],\n",
      "         [-4.3784e-02, -7.2680e-02, -9.7064e-02],\n",
      "         [-4.6552e-02,  4.9078e-02, -1.2295e-01],\n",
      "         [-1.0892e-01, -2.3104e-02, -7.3943e-02],\n",
      "         [ 7.4073e-02,  7.5633e-02, -4.1755e-02],\n",
      "         [ 7.6584e-02,  3.9208e-02, -1.0773e-01],\n",
      "         [-1.0249e-01, -1.0294e-01, -6.8625e-02],\n",
      "         [-1.3733e-01, -4.1266e-03,  8.2028e-02],\n",
      "         [-6.2440e-02,  3.8130e-02, -2.8188e-02],\n",
      "         [-2.4165e-02, -9.0293e-02, -1.3015e-01],\n",
      "         [ 1.4192e-01, -2.7539e-03, -1.7272e-02]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv2.bias | Size: torch.Size([16]) | Values : tensor([-0.0569, -0.0357], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[ 0.1885],\n",
      "         [-0.0714],\n",
      "         [-0.0475],\n",
      "         [-0.1409],\n",
      "         [ 0.0554],\n",
      "         [ 0.1681],\n",
      "         [ 0.1681],\n",
      "         [ 0.1088],\n",
      "         [ 0.1798],\n",
      "         [ 0.2419],\n",
      "         [ 0.2298],\n",
      "         [-0.1397],\n",
      "         [ 0.2132],\n",
      "         [-0.1601],\n",
      "         [-0.0655],\n",
      "         [-0.0980]],\n",
      "\n",
      "        [[-0.1652],\n",
      "         [-0.1635],\n",
      "         [ 0.0521],\n",
      "         [-0.1603],\n",
      "         [-0.1890],\n",
      "         [-0.1376],\n",
      "         [-0.0439],\n",
      "         [-0.2322],\n",
      "         [ 0.2240],\n",
      "         [ 0.0640],\n",
      "         [ 0.1647],\n",
      "         [-0.1055],\n",
      "         [-0.0337],\n",
      "         [-0.1177],\n",
      "         [ 0.0382],\n",
      "         [ 0.0070]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv3.bias | Size: torch.Size([64]) | Values : tensor([ 0.1102, -0.1214], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[ 0.0789],\n",
      "         [-0.0458],\n",
      "         [-0.0051],\n",
      "         [ 0.0673],\n",
      "         [ 0.1238],\n",
      "         [ 0.1070],\n",
      "         [-0.1114],\n",
      "         [-0.0824],\n",
      "         [-0.0695],\n",
      "         [-0.1244],\n",
      "         [-0.1019],\n",
      "         [ 0.0232],\n",
      "         [-0.0011],\n",
      "         [-0.0234],\n",
      "         [-0.1188],\n",
      "         [-0.0890],\n",
      "         [ 0.1044],\n",
      "         [ 0.0888],\n",
      "         [ 0.0794],\n",
      "         [ 0.0074],\n",
      "         [-0.0595],\n",
      "         [ 0.0832],\n",
      "         [-0.0007],\n",
      "         [-0.0359],\n",
      "         [-0.0633],\n",
      "         [-0.0939],\n",
      "         [ 0.0132],\n",
      "         [-0.0085],\n",
      "         [ 0.0003],\n",
      "         [-0.1237],\n",
      "         [ 0.0116],\n",
      "         [ 0.0070],\n",
      "         [ 0.1083],\n",
      "         [-0.0139],\n",
      "         [ 0.1121],\n",
      "         [-0.1153],\n",
      "         [ 0.0234],\n",
      "         [ 0.0022],\n",
      "         [-0.0512],\n",
      "         [ 0.0088],\n",
      "         [ 0.1062],\n",
      "         [-0.0144],\n",
      "         [ 0.0124],\n",
      "         [ 0.0622],\n",
      "         [ 0.0815],\n",
      "         [ 0.0428],\n",
      "         [ 0.1003],\n",
      "         [ 0.0726],\n",
      "         [ 0.0816],\n",
      "         [-0.0918],\n",
      "         [-0.1159],\n",
      "         [ 0.0588],\n",
      "         [ 0.0360],\n",
      "         [ 0.1099],\n",
      "         [-0.1025],\n",
      "         [ 0.0673],\n",
      "         [ 0.0833],\n",
      "         [-0.0072],\n",
      "         [-0.0769],\n",
      "         [ 0.1101],\n",
      "         [ 0.0326],\n",
      "         [ 0.1102],\n",
      "         [-0.0530],\n",
      "         [-0.0972]],\n",
      "\n",
      "        [[-0.0474],\n",
      "         [-0.1033],\n",
      "         [-0.1142],\n",
      "         [-0.1065],\n",
      "         [ 0.0103],\n",
      "         [-0.0256],\n",
      "         [-0.1056],\n",
      "         [ 0.1205],\n",
      "         [ 0.0650],\n",
      "         [ 0.0188],\n",
      "         [-0.0550],\n",
      "         [-0.0503],\n",
      "         [-0.1186],\n",
      "         [ 0.0152],\n",
      "         [ 0.0524],\n",
      "         [ 0.0653],\n",
      "         [ 0.0349],\n",
      "         [ 0.0008],\n",
      "         [-0.0105],\n",
      "         [-0.0701],\n",
      "         [-0.0083],\n",
      "         [ 0.1058],\n",
      "         [-0.0112],\n",
      "         [ 0.0508],\n",
      "         [-0.0937],\n",
      "         [-0.0478],\n",
      "         [ 0.0008],\n",
      "         [-0.0525],\n",
      "         [ 0.0137],\n",
      "         [ 0.0609],\n",
      "         [ 0.0789],\n",
      "         [-0.0595],\n",
      "         [-0.0284],\n",
      "         [-0.1236],\n",
      "         [ 0.0524],\n",
      "         [-0.0965],\n",
      "         [-0.0531],\n",
      "         [-0.0126],\n",
      "         [ 0.1140],\n",
      "         [-0.0016],\n",
      "         [ 0.0411],\n",
      "         [ 0.1094],\n",
      "         [-0.1163],\n",
      "         [ 0.0288],\n",
      "         [-0.0244],\n",
      "         [-0.1203],\n",
      "         [ 0.0058],\n",
      "         [-0.0541],\n",
      "         [-0.0151],\n",
      "         [ 0.0419],\n",
      "         [ 0.1015],\n",
      "         [-0.0372],\n",
      "         [-0.0133],\n",
      "         [ 0.0705],\n",
      "         [-0.0357],\n",
      "         [ 0.0126],\n",
      "         [ 0.1143],\n",
      "         [-0.0519],\n",
      "         [-0.1103],\n",
      "         [-0.0455],\n",
      "         [-0.0118],\n",
      "         [-0.0143],\n",
      "         [-0.1173],\n",
      "         [-0.0290]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.convr.bias | Size: torch.Size([64]) | Values : tensor([0.1243, 0.0269], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[-0.0867],\n",
      "         [-0.0500],\n",
      "         [-0.1169],\n",
      "         [-0.0439],\n",
      "         [-0.0999],\n",
      "         [ 0.0190],\n",
      "         [ 0.0752],\n",
      "         [-0.1106],\n",
      "         [-0.0378],\n",
      "         [-0.0142],\n",
      "         [ 0.0461],\n",
      "         [ 0.1242],\n",
      "         [ 0.1214],\n",
      "         [-0.1006],\n",
      "         [-0.0951],\n",
      "         [ 0.0528],\n",
      "         [-0.0364],\n",
      "         [-0.0876],\n",
      "         [-0.0017],\n",
      "         [ 0.0057],\n",
      "         [-0.0817],\n",
      "         [ 0.1023],\n",
      "         [ 0.0873],\n",
      "         [ 0.0651],\n",
      "         [ 0.0865],\n",
      "         [ 0.1152],\n",
      "         [ 0.0856],\n",
      "         [-0.0462],\n",
      "         [-0.0778],\n",
      "         [-0.0688],\n",
      "         [-0.0798],\n",
      "         [ 0.0785],\n",
      "         [ 0.0025],\n",
      "         [ 0.0824],\n",
      "         [-0.1183],\n",
      "         [ 0.0521],\n",
      "         [-0.1246],\n",
      "         [-0.0563],\n",
      "         [-0.0237],\n",
      "         [-0.0060],\n",
      "         [-0.0712],\n",
      "         [-0.0801],\n",
      "         [ 0.0172],\n",
      "         [-0.0198],\n",
      "         [ 0.0688],\n",
      "         [ 0.0044],\n",
      "         [ 0.0278],\n",
      "         [ 0.0798],\n",
      "         [ 0.0112],\n",
      "         [ 0.1114],\n",
      "         [-0.0151],\n",
      "         [ 0.0750],\n",
      "         [-0.0932],\n",
      "         [ 0.1095],\n",
      "         [ 0.0695],\n",
      "         [-0.0600],\n",
      "         [-0.0925],\n",
      "         [ 0.0914],\n",
      "         [ 0.0475],\n",
      "         [ 0.0928],\n",
      "         [ 0.0593],\n",
      "         [-0.0721],\n",
      "         [-0.1114],\n",
      "         [-0.1111]],\n",
      "\n",
      "        [[-0.0611],\n",
      "         [-0.0855],\n",
      "         [ 0.0603],\n",
      "         [ 0.0384],\n",
      "         [ 0.0714],\n",
      "         [-0.0999],\n",
      "         [ 0.0205],\n",
      "         [ 0.0615],\n",
      "         [ 0.1019],\n",
      "         [-0.0113],\n",
      "         [ 0.0806],\n",
      "         [ 0.1004],\n",
      "         [ 0.0178],\n",
      "         [-0.0422],\n",
      "         [ 0.0861],\n",
      "         [-0.0163],\n",
      "         [ 0.0155],\n",
      "         [-0.0178],\n",
      "         [ 0.0742],\n",
      "         [ 0.0833],\n",
      "         [-0.0404],\n",
      "         [-0.0719],\n",
      "         [ 0.0177],\n",
      "         [-0.0111],\n",
      "         [ 0.1149],\n",
      "         [-0.0983],\n",
      "         [-0.0229],\n",
      "         [-0.0716],\n",
      "         [-0.0748],\n",
      "         [ 0.0244],\n",
      "         [-0.1142],\n",
      "         [-0.0913],\n",
      "         [ 0.0684],\n",
      "         [-0.0297],\n",
      "         [-0.0717],\n",
      "         [-0.0411],\n",
      "         [-0.0225],\n",
      "         [ 0.1241],\n",
      "         [-0.0405],\n",
      "         [ 0.0493],\n",
      "         [-0.1067],\n",
      "         [ 0.0050],\n",
      "         [-0.0046],\n",
      "         [-0.0587],\n",
      "         [-0.0637],\n",
      "         [-0.0519],\n",
      "         [ 0.0826],\n",
      "         [-0.0970],\n",
      "         [-0.0193],\n",
      "         [ 0.1131],\n",
      "         [ 0.0225],\n",
      "         [-0.0144],\n",
      "         [ 0.0452],\n",
      "         [-0.0713],\n",
      "         [ 0.0549],\n",
      "         [ 0.0284],\n",
      "         [-0.1155],\n",
      "         [ 0.1073],\n",
      "         [-0.0629],\n",
      "         [-0.0541],\n",
      "         [-0.0816],\n",
      "         [ 0.0860],\n",
      "         [-0.0488],\n",
      "         [-0.0721]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.conv1.bias | Size: torch.Size([16]) | Values : tensor([ 0.0448, -0.1058], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[-0.0578, -0.0040, -0.1080],\n",
      "         [ 0.0491,  0.1092,  0.1217],\n",
      "         [ 0.1027, -0.0624,  0.1172],\n",
      "         [ 0.0737, -0.0930, -0.0572],\n",
      "         [ 0.1234, -0.0285,  0.0733],\n",
      "         [-0.1236,  0.1161,  0.0338],\n",
      "         [-0.1332,  0.0222,  0.0395],\n",
      "         [-0.0234,  0.0339,  0.1086],\n",
      "         [-0.0076,  0.1046,  0.0986],\n",
      "         [ 0.0561, -0.0068, -0.0804],\n",
      "         [-0.0623, -0.1299, -0.0513],\n",
      "         [-0.0618, -0.1292, -0.0077],\n",
      "         [-0.0693,  0.0355, -0.1405],\n",
      "         [-0.0496, -0.0753,  0.0511],\n",
      "         [ 0.0634,  0.1437,  0.0830],\n",
      "         [-0.0715,  0.0540, -0.0486]],\n",
      "\n",
      "        [[-0.0762, -0.1411,  0.0669],\n",
      "         [-0.0182,  0.0844, -0.0719],\n",
      "         [ 0.0483,  0.0923,  0.0210],\n",
      "         [-0.0279,  0.1251, -0.1314],\n",
      "         [ 0.0458, -0.1176, -0.0953],\n",
      "         [ 0.0598, -0.1318,  0.0764],\n",
      "         [ 0.0074, -0.0084,  0.1105],\n",
      "         [-0.0725, -0.0655, -0.0244],\n",
      "         [-0.0425, -0.0974,  0.0060],\n",
      "         [-0.1340,  0.0669, -0.1220],\n",
      "         [-0.0958, -0.1118,  0.0121],\n",
      "         [-0.0740,  0.1315, -0.0056],\n",
      "         [-0.0899,  0.1438,  0.0969],\n",
      "         [ 0.1422,  0.0241, -0.0367],\n",
      "         [-0.0492,  0.0512, -0.0853],\n",
      "         [-0.1338,  0.1239, -0.1436]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.conv2.bias | Size: torch.Size([16]) | Values : tensor([-0.0908,  0.1038], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[ 0.2341],\n",
      "         [ 0.1859],\n",
      "         [ 0.1217],\n",
      "         [-0.0661],\n",
      "         [-0.1318],\n",
      "         [-0.1820],\n",
      "         [-0.1787],\n",
      "         [-0.1551],\n",
      "         [-0.2406],\n",
      "         [ 0.1428],\n",
      "         [-0.1132],\n",
      "         [-0.0064],\n",
      "         [ 0.0686],\n",
      "         [-0.2078],\n",
      "         [ 0.1368],\n",
      "         [ 0.1404]],\n",
      "\n",
      "        [[ 0.2219],\n",
      "         [ 0.0395],\n",
      "         [-0.2366],\n",
      "         [-0.0282],\n",
      "         [ 0.0196],\n",
      "         [ 0.1491],\n",
      "         [ 0.0340],\n",
      "         [ 0.1561],\n",
      "         [ 0.2042],\n",
      "         [ 0.1419],\n",
      "         [-0.1277],\n",
      "         [ 0.0959],\n",
      "         [-0.0155],\n",
      "         [-0.1176],\n",
      "         [-0.0546],\n",
      "         [-0.1126]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.conv3.bias | Size: torch.Size([64]) | Values : tensor([-0.2345,  0.0629], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk2.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[ 0.0989],\n",
      "         [-0.1201],\n",
      "         [-0.0061],\n",
      "         [-0.0931],\n",
      "         [ 0.0314],\n",
      "         [ 0.0305],\n",
      "         [ 0.0729],\n",
      "         [ 0.0047],\n",
      "         [-0.0693],\n",
      "         [ 0.0526],\n",
      "         [-0.0537],\n",
      "         [-0.0315],\n",
      "         [-0.0148],\n",
      "         [-0.0356],\n",
      "         [-0.0748],\n",
      "         [ 0.0125],\n",
      "         [-0.0024],\n",
      "         [ 0.0629],\n",
      "         [-0.1037],\n",
      "         [ 0.0668],\n",
      "         [ 0.0722],\n",
      "         [-0.0021],\n",
      "         [ 0.1009],\n",
      "         [-0.0843],\n",
      "         [-0.0867],\n",
      "         [-0.0229],\n",
      "         [-0.0669],\n",
      "         [-0.0008],\n",
      "         [ 0.0786],\n",
      "         [ 0.1081],\n",
      "         [-0.0834],\n",
      "         [ 0.0731],\n",
      "         [-0.0499],\n",
      "         [ 0.0527],\n",
      "         [ 0.0519],\n",
      "         [-0.0778],\n",
      "         [-0.0278],\n",
      "         [-0.0071],\n",
      "         [ 0.0274],\n",
      "         [ 0.0841],\n",
      "         [ 0.1243],\n",
      "         [ 0.0967],\n",
      "         [-0.0863],\n",
      "         [-0.0231],\n",
      "         [ 0.0630],\n",
      "         [ 0.1017],\n",
      "         [-0.0303],\n",
      "         [-0.0291],\n",
      "         [-0.0884],\n",
      "         [ 0.0574],\n",
      "         [-0.0132],\n",
      "         [-0.1143],\n",
      "         [-0.0572],\n",
      "         [-0.0799],\n",
      "         [ 0.0206],\n",
      "         [-0.1098],\n",
      "         [-0.0024],\n",
      "         [ 0.0804],\n",
      "         [-0.0650],\n",
      "         [ 0.0751],\n",
      "         [-0.0498],\n",
      "         [-0.0520],\n",
      "         [-0.0466],\n",
      "         [-0.0366]],\n",
      "\n",
      "        [[ 0.0028],\n",
      "         [ 0.1047],\n",
      "         [ 0.0502],\n",
      "         [-0.0562],\n",
      "         [ 0.0297],\n",
      "         [ 0.0497],\n",
      "         [-0.0475],\n",
      "         [-0.0168],\n",
      "         [ 0.0598],\n",
      "         [-0.0203],\n",
      "         [ 0.0263],\n",
      "         [ 0.0680],\n",
      "         [ 0.0963],\n",
      "         [ 0.0895],\n",
      "         [ 0.0400],\n",
      "         [-0.0217],\n",
      "         [ 0.0140],\n",
      "         [-0.0591],\n",
      "         [ 0.0738],\n",
      "         [ 0.0293],\n",
      "         [ 0.0260],\n",
      "         [-0.0778],\n",
      "         [ 0.0145],\n",
      "         [ 0.0848],\n",
      "         [ 0.0996],\n",
      "         [-0.0496],\n",
      "         [-0.0373],\n",
      "         [ 0.0830],\n",
      "         [-0.0602],\n",
      "         [ 0.0685],\n",
      "         [ 0.1097],\n",
      "         [ 0.1036],\n",
      "         [-0.0330],\n",
      "         [-0.0500],\n",
      "         [-0.0769],\n",
      "         [-0.0412],\n",
      "         [-0.1015],\n",
      "         [-0.0422],\n",
      "         [-0.0512],\n",
      "         [ 0.0362],\n",
      "         [-0.0766],\n",
      "         [-0.0352],\n",
      "         [ 0.1077],\n",
      "         [-0.1240],\n",
      "         [ 0.0742],\n",
      "         [-0.1032],\n",
      "         [-0.0122],\n",
      "         [ 0.0878],\n",
      "         [ 0.0601],\n",
      "         [ 0.0173],\n",
      "         [-0.0859],\n",
      "         [-0.0956],\n",
      "         [ 0.1096],\n",
      "         [-0.1103],\n",
      "         [-0.0362],\n",
      "         [-0.0927],\n",
      "         [-0.1152],\n",
      "         [-0.0067],\n",
      "         [-0.0900],\n",
      "         [ 0.0514],\n",
      "         [ 0.0110],\n",
      "         [ 0.0058],\n",
      "         [ 0.1136],\n",
      "         [-0.0469]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv1.bias | Size: torch.Size([16]) | Values : tensor([-0.0684,  0.0652], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[ 0.0558, -0.0715,  0.1215],\n",
      "         [-0.0393, -0.1330, -0.0766],\n",
      "         [-0.1429,  0.0006, -0.0342],\n",
      "         [-0.0590, -0.1367, -0.0038],\n",
      "         [ 0.1297, -0.0778,  0.0941],\n",
      "         [ 0.0593,  0.0925,  0.0856],\n",
      "         [ 0.0909, -0.0332, -0.1390],\n",
      "         [ 0.1239, -0.1427, -0.0036],\n",
      "         [ 0.0346,  0.0023, -0.0910],\n",
      "         [-0.1087,  0.0298, -0.0655],\n",
      "         [-0.1356, -0.0963,  0.0135],\n",
      "         [-0.0142, -0.0967,  0.1204],\n",
      "         [ 0.1178,  0.0976,  0.0912],\n",
      "         [ 0.0981, -0.0695, -0.1403],\n",
      "         [-0.0842,  0.0090,  0.1237],\n",
      "         [-0.0910, -0.0440,  0.0812]],\n",
      "\n",
      "        [[-0.1078, -0.0134,  0.0775],\n",
      "         [ 0.0956, -0.0616,  0.1310],\n",
      "         [ 0.1156,  0.0254, -0.0474],\n",
      "         [ 0.1157,  0.0666, -0.0774],\n",
      "         [-0.0615, -0.1318, -0.1045],\n",
      "         [-0.0803,  0.0652,  0.0859],\n",
      "         [ 0.1159,  0.1102, -0.1442],\n",
      "         [ 0.0396, -0.0999,  0.1385],\n",
      "         [ 0.0306,  0.1001, -0.0673],\n",
      "         [ 0.0274,  0.1400,  0.0048],\n",
      "         [-0.0454, -0.0827, -0.0018],\n",
      "         [ 0.1373,  0.0843,  0.1203],\n",
      "         [-0.0646,  0.0267,  0.1208],\n",
      "         [ 0.1399,  0.0363,  0.0129],\n",
      "         [ 0.0119,  0.1438,  0.1150],\n",
      "         [-0.1298, -0.1318, -0.0908]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv2.bias | Size: torch.Size([16]) | Values : tensor([0.0560, 0.0416], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[ 0.2143],\n",
      "         [-0.1158],\n",
      "         [ 0.1477],\n",
      "         [-0.0050],\n",
      "         [ 0.2268],\n",
      "         [-0.0144],\n",
      "         [-0.1962],\n",
      "         [ 0.0451],\n",
      "         [ 0.0567],\n",
      "         [ 0.0479],\n",
      "         [ 0.2241],\n",
      "         [-0.0515],\n",
      "         [ 0.0009],\n",
      "         [-0.0376],\n",
      "         [-0.0221],\n",
      "         [ 0.1836]],\n",
      "\n",
      "        [[ 0.0548],\n",
      "         [ 0.0186],\n",
      "         [-0.0317],\n",
      "         [ 0.2371],\n",
      "         [ 0.1140],\n",
      "         [ 0.1896],\n",
      "         [-0.0150],\n",
      "         [ 0.1722],\n",
      "         [ 0.1706],\n",
      "         [ 0.1702],\n",
      "         [ 0.0254],\n",
      "         [ 0.0439],\n",
      "         [-0.1671],\n",
      "         [-0.0349],\n",
      "         [-0.1555],\n",
      "         [ 0.2109]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv3.bias | Size: torch.Size([64]) | Values : tensor([ 0.1464, -0.1850], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[-0.1216],\n",
      "         [-0.0131],\n",
      "         [-0.0393],\n",
      "         [ 0.1156],\n",
      "         [ 0.0689],\n",
      "         [-0.0699],\n",
      "         [-0.0824],\n",
      "         [ 0.0805],\n",
      "         [-0.0429],\n",
      "         [-0.1221],\n",
      "         [-0.0249],\n",
      "         [-0.1212],\n",
      "         [ 0.0006],\n",
      "         [ 0.0155],\n",
      "         [-0.0134],\n",
      "         [-0.0445],\n",
      "         [ 0.0353],\n",
      "         [-0.1189],\n",
      "         [ 0.1177],\n",
      "         [ 0.0288],\n",
      "         [ 0.0570],\n",
      "         [-0.0223],\n",
      "         [ 0.0569],\n",
      "         [-0.0136],\n",
      "         [-0.1156],\n",
      "         [-0.0554],\n",
      "         [ 0.0003],\n",
      "         [-0.1147],\n",
      "         [ 0.0462],\n",
      "         [ 0.0896],\n",
      "         [-0.0140],\n",
      "         [ 0.0166],\n",
      "         [ 0.0972],\n",
      "         [-0.1005],\n",
      "         [ 0.0846],\n",
      "         [ 0.1098],\n",
      "         [-0.0838],\n",
      "         [-0.0032],\n",
      "         [ 0.0091],\n",
      "         [-0.0900],\n",
      "         [ 0.0670],\n",
      "         [ 0.1108],\n",
      "         [ 0.0201],\n",
      "         [-0.0514],\n",
      "         [-0.1119],\n",
      "         [ 0.0181],\n",
      "         [-0.0409],\n",
      "         [ 0.0148],\n",
      "         [-0.0071],\n",
      "         [-0.0466],\n",
      "         [-0.0682],\n",
      "         [-0.0560],\n",
      "         [-0.1181],\n",
      "         [ 0.0421],\n",
      "         [-0.0965],\n",
      "         [-0.0151],\n",
      "         [-0.0206],\n",
      "         [-0.0502],\n",
      "         [ 0.1040],\n",
      "         [-0.0855],\n",
      "         [ 0.0989],\n",
      "         [-0.1226],\n",
      "         [-0.0427],\n",
      "         [-0.0852]],\n",
      "\n",
      "        [[-0.0691],\n",
      "         [-0.0812],\n",
      "         [-0.1111],\n",
      "         [ 0.0513],\n",
      "         [-0.0313],\n",
      "         [-0.0198],\n",
      "         [ 0.1235],\n",
      "         [ 0.0822],\n",
      "         [ 0.0594],\n",
      "         [ 0.0453],\n",
      "         [ 0.1174],\n",
      "         [ 0.0432],\n",
      "         [ 0.0979],\n",
      "         [-0.0005],\n",
      "         [-0.0493],\n",
      "         [ 0.0031],\n",
      "         [ 0.0098],\n",
      "         [ 0.0031],\n",
      "         [-0.0493],\n",
      "         [-0.1068],\n",
      "         [ 0.1014],\n",
      "         [ 0.0517],\n",
      "         [ 0.0667],\n",
      "         [-0.1091],\n",
      "         [-0.0388],\n",
      "         [-0.0805],\n",
      "         [-0.0507],\n",
      "         [ 0.1024],\n",
      "         [ 0.0421],\n",
      "         [-0.1041],\n",
      "         [ 0.0446],\n",
      "         [ 0.0559],\n",
      "         [ 0.0883],\n",
      "         [-0.0558],\n",
      "         [ 0.0187],\n",
      "         [ 0.0924],\n",
      "         [ 0.0455],\n",
      "         [-0.1238],\n",
      "         [ 0.0279],\n",
      "         [-0.0503],\n",
      "         [ 0.0300],\n",
      "         [ 0.0795],\n",
      "         [-0.0711],\n",
      "         [ 0.0410],\n",
      "         [-0.0959],\n",
      "         [-0.1113],\n",
      "         [-0.1038],\n",
      "         [-0.0174],\n",
      "         [-0.1142],\n",
      "         [-0.0008],\n",
      "         [ 0.0216],\n",
      "         [-0.0755],\n",
      "         [-0.1019],\n",
      "         [ 0.0361],\n",
      "         [-0.0226],\n",
      "         [ 0.0923],\n",
      "         [ 0.0182],\n",
      "         [-0.0655],\n",
      "         [ 0.1243],\n",
      "         [ 0.0402],\n",
      "         [-0.0123],\n",
      "         [-0.1172],\n",
      "         [-0.0897],\n",
      "         [-0.0627]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.convr.bias | Size: torch.Size([64]) | Values : tensor([ 0.0575, -0.0443], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[ 1.1432e-01],\n",
      "         [ 5.7445e-02],\n",
      "         [-1.2023e-01],\n",
      "         [ 1.2232e-01],\n",
      "         [-3.1396e-02],\n",
      "         [ 4.2975e-02],\n",
      "         [-7.0154e-02],\n",
      "         [ 2.4226e-02],\n",
      "         [-3.3004e-02],\n",
      "         [ 9.3676e-03],\n",
      "         [-1.2314e-01],\n",
      "         [-9.3380e-02],\n",
      "         [ 5.7688e-02],\n",
      "         [ 6.5950e-03],\n",
      "         [ 7.7409e-02],\n",
      "         [ 1.0674e-01],\n",
      "         [ 1.0813e-01],\n",
      "         [ 9.3050e-02],\n",
      "         [ 4.2548e-02],\n",
      "         [-6.7623e-02],\n",
      "         [ 3.1989e-02],\n",
      "         [ 4.8558e-02],\n",
      "         [ 7.0647e-03],\n",
      "         [ 1.1033e-02],\n",
      "         [-9.0519e-03],\n",
      "         [ 7.4564e-02],\n",
      "         [-6.6829e-02],\n",
      "         [ 6.8079e-02],\n",
      "         [-1.2725e-02],\n",
      "         [ 1.1854e-01],\n",
      "         [-6.8481e-02],\n",
      "         [-2.8867e-02],\n",
      "         [-9.1154e-02],\n",
      "         [-3.4388e-02],\n",
      "         [-5.2085e-03],\n",
      "         [ 6.9105e-02],\n",
      "         [-1.0507e-01],\n",
      "         [ 2.2972e-02],\n",
      "         [-3.8786e-02],\n",
      "         [-7.6094e-02],\n",
      "         [-2.2652e-02],\n",
      "         [ 1.0749e-01],\n",
      "         [ 4.0796e-02],\n",
      "         [-1.0785e-01],\n",
      "         [ 1.0093e-01],\n",
      "         [ 8.2669e-02],\n",
      "         [-9.8298e-02],\n",
      "         [ 1.2118e-01],\n",
      "         [ 1.0629e-01],\n",
      "         [ 1.3685e-02],\n",
      "         [ 8.2514e-02],\n",
      "         [-5.2782e-02],\n",
      "         [ 5.8924e-03],\n",
      "         [ 3.5499e-02],\n",
      "         [-2.1192e-02],\n",
      "         [-9.9543e-02],\n",
      "         [ 3.3741e-02],\n",
      "         [-3.2783e-07],\n",
      "         [ 1.0449e-01],\n",
      "         [ 9.6932e-02],\n",
      "         [ 9.9509e-02],\n",
      "         [-3.4478e-02],\n",
      "         [-1.6271e-02],\n",
      "         [-3.3977e-02]],\n",
      "\n",
      "        [[ 9.5945e-02],\n",
      "         [-7.7328e-02],\n",
      "         [ 1.1732e-01],\n",
      "         [ 1.2030e-02],\n",
      "         [ 4.6053e-02],\n",
      "         [ 9.2392e-02],\n",
      "         [ 3.6458e-02],\n",
      "         [-5.5138e-02],\n",
      "         [ 6.2460e-02],\n",
      "         [-2.4253e-03],\n",
      "         [-8.7448e-02],\n",
      "         [-6.1772e-02],\n",
      "         [-4.2087e-02],\n",
      "         [ 2.9029e-02],\n",
      "         [-1.2375e-01],\n",
      "         [-2.4394e-02],\n",
      "         [-5.7019e-02],\n",
      "         [-9.3586e-02],\n",
      "         [-5.6814e-02],\n",
      "         [-4.2898e-02],\n",
      "         [ 6.0620e-02],\n",
      "         [ 1.1532e-01],\n",
      "         [ 4.5902e-02],\n",
      "         [ 1.1387e-01],\n",
      "         [-1.1673e-01],\n",
      "         [ 9.1183e-02],\n",
      "         [-7.6889e-02],\n",
      "         [-2.4486e-03],\n",
      "         [-2.5652e-02],\n",
      "         [-6.9740e-03],\n",
      "         [ 2.5328e-02],\n",
      "         [-1.3351e-02],\n",
      "         [ 1.6089e-02],\n",
      "         [ 1.0120e-01],\n",
      "         [ 7.4078e-02],\n",
      "         [ 6.3848e-02],\n",
      "         [-1.6948e-02],\n",
      "         [ 8.5750e-02],\n",
      "         [-6.0355e-02],\n",
      "         [ 1.0232e-01],\n",
      "         [ 7.2337e-02],\n",
      "         [ 9.9842e-02],\n",
      "         [-2.1373e-02],\n",
      "         [ 1.1083e-01],\n",
      "         [ 1.0033e-01],\n",
      "         [-5.1072e-02],\n",
      "         [ 8.1037e-02],\n",
      "         [-7.9792e-02],\n",
      "         [-1.0265e-02],\n",
      "         [-5.3530e-02],\n",
      "         [ 2.6815e-02],\n",
      "         [-2.5195e-03],\n",
      "         [ 7.2440e-03],\n",
      "         [-8.1595e-02],\n",
      "         [-6.9721e-02],\n",
      "         [ 1.0702e-01],\n",
      "         [-1.1844e-02],\n",
      "         [ 1.2036e-01],\n",
      "         [-1.1992e-01],\n",
      "         [-7.4344e-02],\n",
      "         [-8.9253e-03],\n",
      "         [-9.1975e-02],\n",
      "         [-9.1519e-02],\n",
      "         [ 1.2183e-01]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.conv1.bias | Size: torch.Size([16]) | Values : tensor([ 0.0810, -0.1013], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[-0.0437, -0.0119,  0.1300],\n",
      "         [-0.1139,  0.0582, -0.1346],\n",
      "         [-0.0534, -0.0095, -0.0795],\n",
      "         [-0.1394,  0.0884,  0.0316],\n",
      "         [-0.0256, -0.0303,  0.0760],\n",
      "         [ 0.1166, -0.0293, -0.0903],\n",
      "         [-0.0296,  0.0921,  0.0151],\n",
      "         [-0.1365,  0.0756, -0.0474],\n",
      "         [ 0.0716,  0.1357,  0.0505],\n",
      "         [-0.0490,  0.0573,  0.0795],\n",
      "         [ 0.1039,  0.0859,  0.1368],\n",
      "         [ 0.1331,  0.0991, -0.0507],\n",
      "         [-0.1204,  0.0465,  0.0682],\n",
      "         [-0.0927, -0.0903,  0.1174],\n",
      "         [ 0.0676,  0.0988,  0.0257],\n",
      "         [ 0.0639, -0.0792,  0.0930]],\n",
      "\n",
      "        [[-0.0614,  0.0610,  0.0556],\n",
      "         [-0.0676, -0.0944, -0.0115],\n",
      "         [ 0.0002, -0.0950, -0.0076],\n",
      "         [-0.0047, -0.1334,  0.1121],\n",
      "         [-0.0473,  0.0707,  0.1431],\n",
      "         [-0.0156, -0.0353, -0.0635],\n",
      "         [-0.1124,  0.0008,  0.0439],\n",
      "         [ 0.0957,  0.0101,  0.0150],\n",
      "         [-0.0272, -0.0675,  0.0514],\n",
      "         [-0.0390,  0.0966,  0.0650],\n",
      "         [-0.0361,  0.1248,  0.0456],\n",
      "         [-0.0566, -0.0448, -0.0299],\n",
      "         [ 0.0706,  0.1354, -0.1330],\n",
      "         [ 0.0921, -0.0349,  0.0389],\n",
      "         [ 0.0071, -0.0430,  0.0104],\n",
      "         [-0.0599, -0.0542, -0.0777]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.conv2.bias | Size: torch.Size([16]) | Values : tensor([ 0.1262, -0.0787], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[-0.1209],\n",
      "         [-0.1099],\n",
      "         [-0.2118],\n",
      "         [-0.1917],\n",
      "         [-0.2465],\n",
      "         [-0.0327],\n",
      "         [-0.2170],\n",
      "         [-0.2500],\n",
      "         [-0.0642],\n",
      "         [ 0.2337],\n",
      "         [ 0.1544],\n",
      "         [-0.1293],\n",
      "         [-0.2237],\n",
      "         [ 0.0823],\n",
      "         [-0.1872],\n",
      "         [-0.0181]],\n",
      "\n",
      "        [[-0.0441],\n",
      "         [-0.1767],\n",
      "         [ 0.0688],\n",
      "         [ 0.1611],\n",
      "         [ 0.0838],\n",
      "         [-0.2225],\n",
      "         [-0.0968],\n",
      "         [-0.1370],\n",
      "         [ 0.1887],\n",
      "         [-0.2188],\n",
      "         [-0.1577],\n",
      "         [-0.0797],\n",
      "         [ 0.0228],\n",
      "         [ 0.1809],\n",
      "         [ 0.1976],\n",
      "         [-0.0941]]], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.conv3.bias | Size: torch.Size([64]) | Values : tensor([0.2097, 0.0565], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: identityblk3.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc.1.weight | Size: torch.Size([2, 704]) | Values : tensor([[-0.0310, -0.0220, -0.0127,  ...,  0.0309, -0.0204, -0.0322],\n",
      "        [-0.0114, -0.0344, -0.0245,  ...,  0.0102, -0.0006,  0.0088]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc.1.bias | Size: torch.Size([2]) | Values : tensor([0.0083, 0.0172], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from models.ResNet24 import ResNet24\n",
    "\n",
    "# Create an instance of the model\n",
    "model_resnet = ResNet24().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_resnet.parameters(), lr=learning_rate)\n",
    "# Initialize the scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=patience, verbose=True)\n",
    "print(f\"Model structure: {model_resnet}\\n\\n\")\n",
    "for name, param in model_resnet.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "loss: 1.489265  [   64/23296]\n",
      "loss: 0.290545  [ 6464/23296]\n",
      "loss: 0.286031  [12864/23296]\n",
      "loss: 0.025492  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 96.4%, Avg loss: 0.102006 \n",
      "\n",
      "Epoch 1:\n",
      "loss: 0.207128  [   64/23296]\n",
      "loss: 0.138656  [ 6464/23296]\n",
      "loss: 0.042633  [12864/23296]\n",
      "loss: 0.257121  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.090810 \n",
      "\n",
      "Epoch 2:\n",
      "loss: 0.288569  [   64/23296]\n",
      "loss: 0.029002  [ 6464/23296]\n",
      "loss: 0.551850  [12864/23296]\n",
      "loss: 0.101267  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.089915 \n",
      "\n",
      "Epoch 3:\n",
      "loss: 0.375462  [   64/23296]\n",
      "loss: 0.236927  [ 6464/23296]\n",
      "loss: 0.266980  [12864/23296]\n",
      "loss: 0.084374  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 96.6%, Avg loss: 0.098709 \n",
      "\n",
      "Epoch 4:\n",
      "loss: 0.088557  [   64/23296]\n",
      "loss: 0.077737  [ 6464/23296]\n",
      "loss: 0.082905  [12864/23296]\n",
      "loss: 0.053934  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.073724 \n",
      "\n",
      "Epoch 5:\n",
      "loss: 0.080863  [   64/23296]\n",
      "loss: 0.268738  [ 6464/23296]\n",
      "loss: 0.183223  [12864/23296]\n",
      "loss: 0.059877  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 97.3%, Avg loss: 0.071194 \n",
      "\n",
      "Epoch 6:\n",
      "loss: 0.554571  [   64/23296]\n",
      "loss: 0.084354  [ 6464/23296]\n",
      "loss: 0.285500  [12864/23296]\n",
      "loss: 0.043246  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.073416 \n",
      "\n",
      "Epoch 7:\n",
      "loss: 0.038254  [   64/23296]\n",
      "loss: 0.006655  [ 6464/23296]\n",
      "loss: 0.149557  [12864/23296]\n",
      "loss: 0.062737  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.069285 \n",
      "\n",
      "Epoch 8:\n",
      "loss: 0.250871  [   64/23296]\n",
      "loss: 0.036408  [ 6464/23296]\n",
      "loss: 0.027391  [12864/23296]\n",
      "loss: 0.042896  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.075594 \n",
      "\n",
      "Epoch 9:\n",
      "loss: 0.086217  [   64/23296]\n",
      "loss: 0.381882  [ 6464/23296]\n",
      "loss: 0.119678  [12864/23296]\n",
      "loss: 0.053994  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.068013 \n",
      "\n",
      "Epoch 10:\n",
      "loss: 0.433423  [   64/23296]\n",
      "loss: 0.175890  [ 6464/23296]\n",
      "loss: 0.099279  [12864/23296]\n",
      "loss: 0.030190  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 97.5%, Avg loss: 0.082518 \n",
      "\n",
      "Epoch 11:\n",
      "loss: 0.009853  [   64/23296]\n",
      "loss: 0.276534  [ 6464/23296]\n",
      "loss: 0.060251  [12864/23296]\n",
      "loss: 0.027339  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 98.0%, Avg loss: 0.067995 \n",
      "\n",
      "Epoch 12:\n",
      "loss: 0.067582  [   64/23296]\n",
      "loss: 0.018868  [ 6464/23296]\n",
      "loss: 0.023541  [12864/23296]\n",
      "loss: 0.010232  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.069651 \n",
      "\n",
      "Epoch 13:\n",
      "loss: 0.068597  [   64/23296]\n",
      "loss: 0.095910  [ 6464/23296]\n",
      "loss: 0.192503  [12864/23296]\n",
      "loss: 0.011312  [19264/23296]\n",
      "Validation Error: \n",
      " Accuracy: 97.8%, Avg loss: 0.067077 \n",
      "\n",
      "Epoch 14:\n",
      "loss: 0.012542  [   64/23296]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/liuxinqing/Documents/Fall_Detection/train_Kfall.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/liuxinqing/Documents/Fall_Detection/train_Kfall.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train(train_dataloader, model_resnet, loss_fn, optimizer,val_dataloader, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/liuxinqing/Documents/Fall_Detection/train_Kfall.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m         patience\u001b[39m=\u001b[39;49mpatience, scheduler\u001b[39m=\u001b[39;49mscheduler, device\u001b[39m=\u001b[39;49mdevice, epochs\u001b[39m=\u001b[39;49mepochs, B_size\u001b[39m=\u001b[39;49mB_size, A_size\u001b[39m=\u001b[39;49mA_size)\n",
      "File \u001b[0;32m~/Documents/Fall_Detection/utils.py:57\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer, val_dataloader, patience, scheduler, device, epochs, B_size, A_size)\u001b[0m\n\u001b[1;32m     54\u001b[0m pred \u001b[39m=\u001b[39m model(X\u001b[39m.\u001b[39mfloat())\n\u001b[1;32m     55\u001b[0m loss \u001b[39m=\u001b[39m (loss_fn(pred, y) \u001b[39m*\u001b[39m multipliers)\u001b[39m.\u001b[39mmean()\n\u001b[0;32m---> 57\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     58\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     59\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fall_detection/lib/python3.9/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fall_detection/lib/python3.9/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(train_dataloader, model_resnet, loss_fn, optimizer,val_dataloader, \n",
    "        patience=patience, scheduler=scheduler, device=device, epochs=epochs, B_size=B_size, A_size=A_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.835674 \n",
      "\n",
      " Label 0\n",
      "    accuracy\t0.839\n",
      " specificity\t0.677\n",
      " sensitivity\t1.000\n",
      " Label 1\n",
      "    accuracy\t0.839\n",
      " specificity\t1.000\n",
      " sensitivity\t0.677\n",
      "[[31  0]\n",
      " [10 21]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# final test\n",
    "test(test_dataloader, model_resnet, loss_fn, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TinyFallNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, out_channels=16, kernel_size=1)\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=16, kernel_size=3, padding='same')\n",
    "        self.bn2 = nn.BatchNorm1d(16)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=64, kernel_size=1)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.convr = nn.Conv1d(in_channels=in_channels, out_channels=64, kernel_size=1)\n",
    "    def forward(self, input):\n",
    "        residual = self.convr(input)\n",
    "        x = self.conv1(input)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x += residual\n",
    "        x = self.relu3(x)\n",
    "        return x\n",
    "\n",
    "class TinyFallNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TinyFallNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=9, out_channels=64, kernel_size=3)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.convblk1 = ConvBlock(64)\n",
    "        self.convblk2 = ConvBlock(64)\n",
    "        self.convblk3 = ConvBlock(64)\n",
    "        self.convblk4 = ConvBlock(64)\n",
    "        \n",
    "        self.pool2 = nn.AvgPool1d(2)\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.Flatten(),\n",
    "                                nn.Linear(in_features=768, out_features=2),\n",
    "                                nn.Softmax())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.convblk1(x)\n",
    "        x = self.convblk2(x)\n",
    "        x = self.convblk3(x)\n",
    "        x = self.convblk4(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: TinyFallNet(\n",
      "  (conv1): Conv1d(9, 64, kernel_size=(3,), stride=(1,))\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (convblk1): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (convblk2): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (convblk3): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (convblk4): ConvBlock(\n",
      "    (conv1): Conv1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "    (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv2): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=same)\n",
      "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv3): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "    (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (convr): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      "  (pool2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
      "  (fc): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=768, out_features=2, bias=True)\n",
      "    (2): Softmax(dim=None)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: conv1.weight | Size: torch.Size([64, 9, 3]) | Values : tensor([[[-0.0750,  0.1589, -0.1657],\n",
      "         [-0.0295,  0.0671,  0.1055],\n",
      "         [-0.1272,  0.1911,  0.0734],\n",
      "         [ 0.0240, -0.1226,  0.1451],\n",
      "         [ 0.0156, -0.0270, -0.1890],\n",
      "         [-0.0245,  0.0154, -0.0644],\n",
      "         [ 0.0743,  0.0181,  0.0670],\n",
      "         [-0.1418, -0.0791,  0.0301],\n",
      "         [-0.0880, -0.0973, -0.0092]],\n",
      "\n",
      "        [[ 0.0684,  0.0912, -0.1415],\n",
      "         [ 0.1526, -0.1618,  0.1475],\n",
      "         [-0.0571,  0.1131, -0.0075],\n",
      "         [-0.1629, -0.1026,  0.0392],\n",
      "         [-0.0639,  0.1318, -0.0841],\n",
      "         [-0.0191, -0.1093,  0.0695],\n",
      "         [-0.0236,  0.0931,  0.1423],\n",
      "         [ 0.0421,  0.0686,  0.1450],\n",
      "         [ 0.1166,  0.0265, -0.1520]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: conv1.bias | Size: torch.Size([64]) | Values : tensor([ 0.1026, -0.1774], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[ 0.0039],\n",
      "         [-0.1104],\n",
      "         [-0.0967],\n",
      "         [ 0.0389],\n",
      "         [-0.0151],\n",
      "         [ 0.0295],\n",
      "         [-0.1245],\n",
      "         [ 0.0426],\n",
      "         [ 0.0445],\n",
      "         [ 0.0771],\n",
      "         [ 0.0044],\n",
      "         [ 0.1013],\n",
      "         [-0.1077],\n",
      "         [-0.0331],\n",
      "         [-0.0589],\n",
      "         [-0.0843],\n",
      "         [-0.1171],\n",
      "         [ 0.1011],\n",
      "         [-0.0852],\n",
      "         [ 0.1201],\n",
      "         [ 0.0136],\n",
      "         [-0.0401],\n",
      "         [-0.0932],\n",
      "         [-0.0323],\n",
      "         [ 0.0447],\n",
      "         [ 0.0429],\n",
      "         [-0.0038],\n",
      "         [ 0.0444],\n",
      "         [-0.0315],\n",
      "         [-0.0733],\n",
      "         [ 0.1072],\n",
      "         [-0.0162],\n",
      "         [ 0.0798],\n",
      "         [ 0.0009],\n",
      "         [ 0.0681],\n",
      "         [-0.0853],\n",
      "         [-0.0248],\n",
      "         [ 0.0725],\n",
      "         [-0.1032],\n",
      "         [ 0.0189],\n",
      "         [ 0.0679],\n",
      "         [-0.0430],\n",
      "         [ 0.0310],\n",
      "         [ 0.0910],\n",
      "         [ 0.0101],\n",
      "         [ 0.1007],\n",
      "         [ 0.1225],\n",
      "         [ 0.0419],\n",
      "         [-0.0392],\n",
      "         [-0.0034],\n",
      "         [-0.0014],\n",
      "         [ 0.0574],\n",
      "         [ 0.0386],\n",
      "         [-0.0020],\n",
      "         [ 0.0818],\n",
      "         [ 0.0219],\n",
      "         [-0.0014],\n",
      "         [-0.0457],\n",
      "         [ 0.0567],\n",
      "         [-0.0748],\n",
      "         [-0.1239],\n",
      "         [ 0.0085],\n",
      "         [-0.0028],\n",
      "         [-0.0783]],\n",
      "\n",
      "        [[-0.0046],\n",
      "         [ 0.0794],\n",
      "         [-0.0083],\n",
      "         [ 0.0922],\n",
      "         [ 0.0421],\n",
      "         [ 0.0875],\n",
      "         [ 0.0639],\n",
      "         [-0.1205],\n",
      "         [-0.0013],\n",
      "         [ 0.1122],\n",
      "         [ 0.0659],\n",
      "         [ 0.0588],\n",
      "         [-0.1092],\n",
      "         [-0.0614],\n",
      "         [-0.0556],\n",
      "         [ 0.0673],\n",
      "         [ 0.0956],\n",
      "         [ 0.0980],\n",
      "         [ 0.0149],\n",
      "         [-0.0397],\n",
      "         [ 0.0236],\n",
      "         [ 0.0396],\n",
      "         [-0.0575],\n",
      "         [-0.0028],\n",
      "         [-0.0324],\n",
      "         [-0.0635],\n",
      "         [-0.0477],\n",
      "         [-0.0929],\n",
      "         [ 0.0083],\n",
      "         [ 0.1023],\n",
      "         [ 0.1146],\n",
      "         [-0.0686],\n",
      "         [ 0.0939],\n",
      "         [ 0.1203],\n",
      "         [ 0.0352],\n",
      "         [ 0.0098],\n",
      "         [ 0.0794],\n",
      "         [ 0.1234],\n",
      "         [-0.1235],\n",
      "         [-0.0045],\n",
      "         [-0.0762],\n",
      "         [-0.0753],\n",
      "         [ 0.0840],\n",
      "         [ 0.0653],\n",
      "         [-0.0064],\n",
      "         [ 0.0715],\n",
      "         [ 0.1099],\n",
      "         [ 0.1130],\n",
      "         [ 0.0610],\n",
      "         [-0.0207],\n",
      "         [ 0.0409],\n",
      "         [-0.0227],\n",
      "         [ 0.1230],\n",
      "         [ 0.0248],\n",
      "         [ 0.1056],\n",
      "         [-0.0388],\n",
      "         [ 0.0408],\n",
      "         [-0.0599],\n",
      "         [-0.0597],\n",
      "         [ 0.0089],\n",
      "         [-0.0280],\n",
      "         [ 0.0548],\n",
      "         [ 0.0765],\n",
      "         [-0.0661]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv1.bias | Size: torch.Size([16]) | Values : tensor([ 0.0676, -0.0914], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[ 0.1352,  0.0212, -0.0852],\n",
      "         [-0.0352,  0.0744, -0.1183],\n",
      "         [ 0.0293, -0.1053, -0.0072],\n",
      "         [ 0.0444, -0.1416,  0.1256],\n",
      "         [-0.0144,  0.0643,  0.0649],\n",
      "         [-0.0836, -0.1065,  0.0891],\n",
      "         [-0.1011,  0.1020,  0.1063],\n",
      "         [-0.1137, -0.0204, -0.0498],\n",
      "         [ 0.0838, -0.0306,  0.0838],\n",
      "         [ 0.0229, -0.0247,  0.0099],\n",
      "         [-0.1015,  0.1370, -0.1382],\n",
      "         [-0.1328,  0.1135,  0.0095],\n",
      "         [ 0.1143,  0.1425, -0.0839],\n",
      "         [-0.0157, -0.0060, -0.0390],\n",
      "         [ 0.0960, -0.0185,  0.0669],\n",
      "         [ 0.1259,  0.0446,  0.0156]],\n",
      "\n",
      "        [[ 0.0154, -0.0665,  0.0737],\n",
      "         [ 0.0128, -0.0251,  0.0218],\n",
      "         [ 0.0630,  0.0221,  0.0987],\n",
      "         [ 0.0675, -0.1007,  0.0567],\n",
      "         [-0.0835, -0.1164,  0.0384],\n",
      "         [-0.0711, -0.0806,  0.1405],\n",
      "         [-0.1165, -0.0075,  0.0697],\n",
      "         [ 0.0306, -0.0995,  0.0264],\n",
      "         [ 0.0021,  0.0242,  0.0010],\n",
      "         [-0.0281, -0.0460,  0.0399],\n",
      "         [-0.1379, -0.0269, -0.0934],\n",
      "         [-0.1110, -0.0919,  0.1100],\n",
      "         [-0.1441,  0.0551, -0.1367],\n",
      "         [ 0.0590, -0.0688,  0.0089],\n",
      "         [ 0.0642, -0.1210,  0.1146],\n",
      "         [ 0.0518, -0.1028,  0.0329]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv2.bias | Size: torch.Size([16]) | Values : tensor([ 0.0220, -0.0669], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[-0.1189],\n",
      "         [ 0.2466],\n",
      "         [-0.0692],\n",
      "         [-0.2327],\n",
      "         [-0.0512],\n",
      "         [ 0.2396],\n",
      "         [ 0.2423],\n",
      "         [ 0.1255],\n",
      "         [ 0.0145],\n",
      "         [ 0.0750],\n",
      "         [-0.2201],\n",
      "         [-0.0594],\n",
      "         [ 0.0288],\n",
      "         [-0.2246],\n",
      "         [-0.1262],\n",
      "         [ 0.2163]],\n",
      "\n",
      "        [[ 0.0188],\n",
      "         [ 0.1010],\n",
      "         [-0.0121],\n",
      "         [ 0.1653],\n",
      "         [-0.2427],\n",
      "         [-0.1243],\n",
      "         [ 0.1657],\n",
      "         [-0.1953],\n",
      "         [ 0.0856],\n",
      "         [ 0.1430],\n",
      "         [-0.0319],\n",
      "         [ 0.1290],\n",
      "         [ 0.0604],\n",
      "         [-0.1089],\n",
      "         [ 0.1861],\n",
      "         [ 0.1993]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.conv3.bias | Size: torch.Size([64]) | Values : tensor([0.1329, 0.1901], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[ 0.0680],\n",
      "         [-0.0137],\n",
      "         [-0.0138],\n",
      "         [-0.0996],\n",
      "         [-0.0638],\n",
      "         [ 0.0889],\n",
      "         [-0.1013],\n",
      "         [ 0.0741],\n",
      "         [ 0.1194],\n",
      "         [ 0.0459],\n",
      "         [ 0.0504],\n",
      "         [-0.0449],\n",
      "         [-0.0847],\n",
      "         [ 0.0142],\n",
      "         [ 0.0288],\n",
      "         [ 0.1190],\n",
      "         [-0.0075],\n",
      "         [ 0.0053],\n",
      "         [ 0.0208],\n",
      "         [ 0.0553],\n",
      "         [ 0.1130],\n",
      "         [ 0.0295],\n",
      "         [-0.0441],\n",
      "         [ 0.0238],\n",
      "         [ 0.0370],\n",
      "         [-0.0159],\n",
      "         [-0.0011],\n",
      "         [ 0.0753],\n",
      "         [-0.0492],\n",
      "         [-0.0912],\n",
      "         [-0.0099],\n",
      "         [ 0.1091],\n",
      "         [-0.0980],\n",
      "         [ 0.0452],\n",
      "         [ 0.0193],\n",
      "         [-0.0360],\n",
      "         [-0.0800],\n",
      "         [-0.1059],\n",
      "         [ 0.0989],\n",
      "         [-0.0291],\n",
      "         [ 0.0849],\n",
      "         [ 0.0661],\n",
      "         [ 0.0247],\n",
      "         [-0.1179],\n",
      "         [ 0.0518],\n",
      "         [ 0.0645],\n",
      "         [-0.0623],\n",
      "         [-0.0562],\n",
      "         [ 0.0245],\n",
      "         [ 0.1074],\n",
      "         [ 0.1124],\n",
      "         [ 0.0175],\n",
      "         [-0.0181],\n",
      "         [ 0.0463],\n",
      "         [ 0.1054],\n",
      "         [ 0.1178],\n",
      "         [ 0.0222],\n",
      "         [-0.0757],\n",
      "         [ 0.0856],\n",
      "         [ 0.0467],\n",
      "         [ 0.0085],\n",
      "         [ 0.1175],\n",
      "         [ 0.0418],\n",
      "         [-0.0953]],\n",
      "\n",
      "        [[ 0.0776],\n",
      "         [-0.1082],\n",
      "         [ 0.0372],\n",
      "         [-0.0462],\n",
      "         [ 0.1073],\n",
      "         [-0.0792],\n",
      "         [ 0.0909],\n",
      "         [ 0.1106],\n",
      "         [ 0.0910],\n",
      "         [-0.0304],\n",
      "         [-0.1229],\n",
      "         [-0.0050],\n",
      "         [-0.0884],\n",
      "         [-0.0681],\n",
      "         [-0.1060],\n",
      "         [ 0.0376],\n",
      "         [-0.0828],\n",
      "         [-0.0211],\n",
      "         [-0.0494],\n",
      "         [ 0.0878],\n",
      "         [-0.0528],\n",
      "         [-0.1126],\n",
      "         [-0.0340],\n",
      "         [-0.0072],\n",
      "         [-0.0788],\n",
      "         [-0.0308],\n",
      "         [-0.1230],\n",
      "         [-0.0926],\n",
      "         [ 0.0898],\n",
      "         [-0.0181],\n",
      "         [ 0.0199],\n",
      "         [-0.0108],\n",
      "         [-0.0318],\n",
      "         [-0.0138],\n",
      "         [-0.0615],\n",
      "         [ 0.0750],\n",
      "         [-0.0376],\n",
      "         [ 0.0312],\n",
      "         [ 0.1032],\n",
      "         [-0.0138],\n",
      "         [-0.0978],\n",
      "         [ 0.0757],\n",
      "         [-0.1158],\n",
      "         [-0.0655],\n",
      "         [-0.1111],\n",
      "         [ 0.0953],\n",
      "         [ 0.0342],\n",
      "         [-0.1010],\n",
      "         [ 0.0579],\n",
      "         [-0.1179],\n",
      "         [-0.0844],\n",
      "         [-0.0446],\n",
      "         [ 0.0177],\n",
      "         [-0.1241],\n",
      "         [ 0.0557],\n",
      "         [ 0.0982],\n",
      "         [-0.0530],\n",
      "         [ 0.0729],\n",
      "         [ 0.0074],\n",
      "         [ 0.1058],\n",
      "         [-0.0547],\n",
      "         [-0.0393],\n",
      "         [-0.0484],\n",
      "         [ 0.1079]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk1.convr.bias | Size: torch.Size([64]) | Values : tensor([-0.0965,  0.1052], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[-0.0664],\n",
      "         [ 0.1162],\n",
      "         [ 0.0191],\n",
      "         [-0.0752],\n",
      "         [ 0.0432],\n",
      "         [-0.0988],\n",
      "         [-0.0717],\n",
      "         [-0.0429],\n",
      "         [-0.0148],\n",
      "         [ 0.0738],\n",
      "         [ 0.0634],\n",
      "         [-0.0938],\n",
      "         [ 0.0191],\n",
      "         [-0.0586],\n",
      "         [-0.0648],\n",
      "         [ 0.1144],\n",
      "         [-0.0104],\n",
      "         [ 0.0951],\n",
      "         [-0.1009],\n",
      "         [-0.0869],\n",
      "         [ 0.0160],\n",
      "         [ 0.0898],\n",
      "         [ 0.0914],\n",
      "         [-0.0595],\n",
      "         [ 0.1121],\n",
      "         [ 0.0045],\n",
      "         [ 0.0151],\n",
      "         [-0.1206],\n",
      "         [ 0.0713],\n",
      "         [ 0.1232],\n",
      "         [ 0.0444],\n",
      "         [ 0.0708],\n",
      "         [-0.0224],\n",
      "         [ 0.0965],\n",
      "         [-0.1198],\n",
      "         [-0.0625],\n",
      "         [-0.1189],\n",
      "         [ 0.0564],\n",
      "         [ 0.0413],\n",
      "         [-0.0364],\n",
      "         [ 0.0337],\n",
      "         [-0.0959],\n",
      "         [-0.0038],\n",
      "         [ 0.0005],\n",
      "         [ 0.0716],\n",
      "         [ 0.0565],\n",
      "         [-0.0127],\n",
      "         [ 0.1141],\n",
      "         [ 0.1206],\n",
      "         [-0.0597],\n",
      "         [ 0.1223],\n",
      "         [ 0.0316],\n",
      "         [ 0.0610],\n",
      "         [ 0.0911],\n",
      "         [ 0.1229],\n",
      "         [-0.0448],\n",
      "         [-0.0398],\n",
      "         [ 0.0169],\n",
      "         [-0.0892],\n",
      "         [-0.0684],\n",
      "         [ 0.0966],\n",
      "         [-0.0348],\n",
      "         [-0.0232],\n",
      "         [-0.0277]],\n",
      "\n",
      "        [[-0.0655],\n",
      "         [-0.0136],\n",
      "         [ 0.0578],\n",
      "         [ 0.1242],\n",
      "         [ 0.0167],\n",
      "         [-0.0735],\n",
      "         [-0.1181],\n",
      "         [ 0.0874],\n",
      "         [ 0.0382],\n",
      "         [ 0.0501],\n",
      "         [ 0.0107],\n",
      "         [-0.1062],\n",
      "         [ 0.0660],\n",
      "         [-0.0495],\n",
      "         [-0.0383],\n",
      "         [-0.0258],\n",
      "         [ 0.0523],\n",
      "         [ 0.0100],\n",
      "         [ 0.0722],\n",
      "         [-0.0552],\n",
      "         [-0.0650],\n",
      "         [-0.0747],\n",
      "         [-0.0609],\n",
      "         [-0.1015],\n",
      "         [ 0.0753],\n",
      "         [ 0.0960],\n",
      "         [ 0.1066],\n",
      "         [ 0.0829],\n",
      "         [ 0.0571],\n",
      "         [-0.1063],\n",
      "         [ 0.0908],\n",
      "         [ 0.0949],\n",
      "         [-0.0538],\n",
      "         [ 0.0472],\n",
      "         [ 0.0627],\n",
      "         [ 0.0606],\n",
      "         [ 0.1226],\n",
      "         [ 0.0298],\n",
      "         [-0.1249],\n",
      "         [-0.0090],\n",
      "         [-0.0120],\n",
      "         [-0.0790],\n",
      "         [ 0.0990],\n",
      "         [ 0.0816],\n",
      "         [ 0.0544],\n",
      "         [-0.0299],\n",
      "         [ 0.0722],\n",
      "         [-0.0951],\n",
      "         [ 0.0958],\n",
      "         [ 0.0239],\n",
      "         [ 0.0418],\n",
      "         [ 0.0696],\n",
      "         [ 0.0931],\n",
      "         [-0.0442],\n",
      "         [-0.1193],\n",
      "         [ 0.1210],\n",
      "         [-0.0502],\n",
      "         [ 0.0916],\n",
      "         [-0.0273],\n",
      "         [ 0.0451],\n",
      "         [-0.0205],\n",
      "         [-0.0130],\n",
      "         [-0.0228],\n",
      "         [-0.0654]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv1.bias | Size: torch.Size([16]) | Values : tensor([0.0763, 0.0384], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[-0.0879, -0.0650, -0.0354],\n",
      "         [-0.0214, -0.0415,  0.0230],\n",
      "         [-0.1407,  0.0985, -0.0039],\n",
      "         [ 0.0356,  0.0100,  0.1314],\n",
      "         [-0.0049, -0.1215, -0.1180],\n",
      "         [ 0.1215, -0.0903, -0.0242],\n",
      "         [-0.0889,  0.0148, -0.0072],\n",
      "         [ 0.0725,  0.0657, -0.1123],\n",
      "         [-0.0663,  0.0632,  0.1017],\n",
      "         [-0.0440, -0.1078, -0.1219],\n",
      "         [ 0.0894, -0.0117,  0.0597],\n",
      "         [ 0.1258,  0.1088, -0.0291],\n",
      "         [ 0.0980,  0.0702,  0.0241],\n",
      "         [ 0.0035,  0.0429, -0.0832],\n",
      "         [-0.0293, -0.0874, -0.1176],\n",
      "         [-0.1296, -0.0120,  0.0690]],\n",
      "\n",
      "        [[-0.1018,  0.0277,  0.1179],\n",
      "         [-0.0929, -0.1365,  0.0658],\n",
      "         [ 0.0643, -0.1087, -0.0339],\n",
      "         [ 0.0963, -0.0053, -0.0905],\n",
      "         [-0.0075,  0.0658,  0.1100],\n",
      "         [ 0.0161, -0.0770, -0.0590],\n",
      "         [-0.1191, -0.1040, -0.0486],\n",
      "         [-0.0879, -0.1329,  0.1203],\n",
      "         [ 0.0069, -0.0068, -0.0537],\n",
      "         [-0.0104, -0.0965, -0.1076],\n",
      "         [ 0.0428, -0.0244,  0.0598],\n",
      "         [-0.0914,  0.0508, -0.1029],\n",
      "         [-0.0255, -0.0365, -0.1271],\n",
      "         [ 0.1434,  0.0878,  0.1122],\n",
      "         [-0.0087, -0.0927, -0.0067],\n",
      "         [-0.0556,  0.0432, -0.1405]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv2.bias | Size: torch.Size([16]) | Values : tensor([-0.1046,  0.1255], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[-0.1589],\n",
      "         [ 0.1523],\n",
      "         [ 0.0593],\n",
      "         [ 0.0832],\n",
      "         [ 0.1178],\n",
      "         [ 0.1771],\n",
      "         [-0.1761],\n",
      "         [-0.1047],\n",
      "         [-0.0636],\n",
      "         [ 0.0297],\n",
      "         [-0.2056],\n",
      "         [ 0.1071],\n",
      "         [ 0.1245],\n",
      "         [ 0.1786],\n",
      "         [ 0.2079],\n",
      "         [-0.1335]],\n",
      "\n",
      "        [[-0.0010],\n",
      "         [ 0.0606],\n",
      "         [ 0.0538],\n",
      "         [ 0.0085],\n",
      "         [-0.1711],\n",
      "         [ 0.0481],\n",
      "         [-0.1588],\n",
      "         [-0.1155],\n",
      "         [ 0.2098],\n",
      "         [ 0.2144],\n",
      "         [ 0.0016],\n",
      "         [ 0.0690],\n",
      "         [ 0.1554],\n",
      "         [-0.2132],\n",
      "         [ 0.0670],\n",
      "         [-0.2025]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.conv3.bias | Size: torch.Size([64]) | Values : tensor([0.0537, 0.1150], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[ 0.0213],\n",
      "         [ 0.0937],\n",
      "         [-0.0296],\n",
      "         [ 0.1168],\n",
      "         [-0.1056],\n",
      "         [ 0.0809],\n",
      "         [-0.0555],\n",
      "         [-0.0314],\n",
      "         [-0.1104],\n",
      "         [ 0.0397],\n",
      "         [-0.0090],\n",
      "         [-0.1036],\n",
      "         [ 0.1228],\n",
      "         [-0.0851],\n",
      "         [ 0.0861],\n",
      "         [-0.0661],\n",
      "         [ 0.1248],\n",
      "         [ 0.0004],\n",
      "         [ 0.0943],\n",
      "         [ 0.1095],\n",
      "         [ 0.0910],\n",
      "         [-0.1045],\n",
      "         [ 0.0418],\n",
      "         [ 0.0581],\n",
      "         [-0.0586],\n",
      "         [-0.0652],\n",
      "         [-0.1100],\n",
      "         [ 0.0441],\n",
      "         [-0.0189],\n",
      "         [-0.0630],\n",
      "         [ 0.1230],\n",
      "         [ 0.0318],\n",
      "         [-0.0965],\n",
      "         [ 0.0993],\n",
      "         [-0.1071],\n",
      "         [ 0.0249],\n",
      "         [ 0.0229],\n",
      "         [-0.0032],\n",
      "         [-0.0375],\n",
      "         [ 0.0400],\n",
      "         [-0.0732],\n",
      "         [-0.0056],\n",
      "         [ 0.0007],\n",
      "         [-0.0363],\n",
      "         [-0.1074],\n",
      "         [-0.0978],\n",
      "         [ 0.0359],\n",
      "         [ 0.0665],\n",
      "         [ 0.0205],\n",
      "         [-0.0243],\n",
      "         [ 0.1025],\n",
      "         [-0.1232],\n",
      "         [-0.1163],\n",
      "         [-0.0452],\n",
      "         [-0.0090],\n",
      "         [-0.0649],\n",
      "         [ 0.1217],\n",
      "         [-0.0214],\n",
      "         [ 0.1039],\n",
      "         [-0.0438],\n",
      "         [-0.0598],\n",
      "         [ 0.1092],\n",
      "         [ 0.0961],\n",
      "         [ 0.0213]],\n",
      "\n",
      "        [[ 0.0184],\n",
      "         [ 0.0701],\n",
      "         [-0.0597],\n",
      "         [-0.0033],\n",
      "         [-0.1096],\n",
      "         [ 0.0196],\n",
      "         [-0.0756],\n",
      "         [-0.0759],\n",
      "         [-0.1142],\n",
      "         [-0.0039],\n",
      "         [ 0.0681],\n",
      "         [ 0.0016],\n",
      "         [-0.1087],\n",
      "         [-0.0301],\n",
      "         [-0.0921],\n",
      "         [ 0.1108],\n",
      "         [ 0.1019],\n",
      "         [-0.0075],\n",
      "         [-0.0985],\n",
      "         [ 0.0509],\n",
      "         [ 0.0863],\n",
      "         [ 0.1044],\n",
      "         [-0.0539],\n",
      "         [-0.0338],\n",
      "         [ 0.0197],\n",
      "         [ 0.0664],\n",
      "         [-0.0773],\n",
      "         [-0.1064],\n",
      "         [ 0.0575],\n",
      "         [ 0.0002],\n",
      "         [-0.0274],\n",
      "         [ 0.0479],\n",
      "         [ 0.0965],\n",
      "         [ 0.0305],\n",
      "         [ 0.0728],\n",
      "         [ 0.0611],\n",
      "         [ 0.0689],\n",
      "         [ 0.1123],\n",
      "         [-0.0108],\n",
      "         [-0.0658],\n",
      "         [-0.0489],\n",
      "         [-0.1016],\n",
      "         [ 0.1244],\n",
      "         [ 0.1023],\n",
      "         [-0.0858],\n",
      "         [-0.0259],\n",
      "         [-0.0021],\n",
      "         [-0.0935],\n",
      "         [-0.0512],\n",
      "         [ 0.0012],\n",
      "         [ 0.1165],\n",
      "         [ 0.0978],\n",
      "         [ 0.0135],\n",
      "         [ 0.1070],\n",
      "         [ 0.0983],\n",
      "         [ 0.0895],\n",
      "         [ 0.1123],\n",
      "         [ 0.0045],\n",
      "         [ 0.1230],\n",
      "         [ 0.0539],\n",
      "         [-0.0256],\n",
      "         [-0.0219],\n",
      "         [ 0.1157],\n",
      "         [-0.1008]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk2.convr.bias | Size: torch.Size([64]) | Values : tensor([-0.0849,  0.0840], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[-0.0268],\n",
      "         [ 0.0942],\n",
      "         [ 0.0738],\n",
      "         [ 0.0023],\n",
      "         [-0.1217],\n",
      "         [-0.0468],\n",
      "         [ 0.0756],\n",
      "         [ 0.0988],\n",
      "         [ 0.0189],\n",
      "         [-0.0659],\n",
      "         [ 0.1045],\n",
      "         [-0.0268],\n",
      "         [ 0.0769],\n",
      "         [-0.0226],\n",
      "         [-0.0751],\n",
      "         [-0.0181],\n",
      "         [ 0.0338],\n",
      "         [-0.0264],\n",
      "         [-0.0376],\n",
      "         [-0.0273],\n",
      "         [ 0.0929],\n",
      "         [-0.0722],\n",
      "         [ 0.0697],\n",
      "         [ 0.0761],\n",
      "         [-0.0472],\n",
      "         [-0.0329],\n",
      "         [-0.0858],\n",
      "         [ 0.0917],\n",
      "         [ 0.0114],\n",
      "         [ 0.0375],\n",
      "         [ 0.0636],\n",
      "         [ 0.1041],\n",
      "         [ 0.0830],\n",
      "         [ 0.1119],\n",
      "         [ 0.0567],\n",
      "         [-0.1248],\n",
      "         [ 0.0546],\n",
      "         [-0.1096],\n",
      "         [ 0.0592],\n",
      "         [-0.0169],\n",
      "         [ 0.0332],\n",
      "         [ 0.0666],\n",
      "         [-0.1016],\n",
      "         [ 0.1086],\n",
      "         [ 0.0678],\n",
      "         [-0.0836],\n",
      "         [-0.0488],\n",
      "         [ 0.0517],\n",
      "         [ 0.0456],\n",
      "         [ 0.1020],\n",
      "         [-0.0169],\n",
      "         [-0.0590],\n",
      "         [ 0.0283],\n",
      "         [ 0.0069],\n",
      "         [ 0.0339],\n",
      "         [-0.0728],\n",
      "         [ 0.0715],\n",
      "         [-0.1139],\n",
      "         [-0.0436],\n",
      "         [ 0.0952],\n",
      "         [-0.0802],\n",
      "         [-0.0676],\n",
      "         [-0.0274],\n",
      "         [-0.0722]],\n",
      "\n",
      "        [[-0.1081],\n",
      "         [ 0.0044],\n",
      "         [ 0.0173],\n",
      "         [-0.1033],\n",
      "         [ 0.0053],\n",
      "         [-0.1041],\n",
      "         [ 0.0674],\n",
      "         [ 0.1131],\n",
      "         [-0.1235],\n",
      "         [-0.0960],\n",
      "         [-0.0633],\n",
      "         [ 0.1082],\n",
      "         [-0.0703],\n",
      "         [-0.0545],\n",
      "         [-0.0230],\n",
      "         [-0.0052],\n",
      "         [-0.0255],\n",
      "         [-0.0117],\n",
      "         [ 0.0097],\n",
      "         [ 0.0655],\n",
      "         [ 0.0028],\n",
      "         [ 0.0782],\n",
      "         [ 0.0911],\n",
      "         [-0.0006],\n",
      "         [-0.0958],\n",
      "         [-0.0355],\n",
      "         [ 0.1140],\n",
      "         [-0.1007],\n",
      "         [-0.0316],\n",
      "         [ 0.0275],\n",
      "         [ 0.1089],\n",
      "         [-0.1188],\n",
      "         [-0.0593],\n",
      "         [-0.0599],\n",
      "         [-0.0210],\n",
      "         [ 0.0603],\n",
      "         [-0.0611],\n",
      "         [-0.0318],\n",
      "         [ 0.0291],\n",
      "         [-0.1099],\n",
      "         [-0.0550],\n",
      "         [-0.0992],\n",
      "         [ 0.0548],\n",
      "         [ 0.0771],\n",
      "         [ 0.0230],\n",
      "         [-0.1141],\n",
      "         [-0.0631],\n",
      "         [ 0.0549],\n",
      "         [ 0.0609],\n",
      "         [ 0.0754],\n",
      "         [ 0.0133],\n",
      "         [-0.0723],\n",
      "         [ 0.1029],\n",
      "         [ 0.0488],\n",
      "         [ 0.1010],\n",
      "         [-0.1048],\n",
      "         [ 0.0271],\n",
      "         [ 0.1018],\n",
      "         [ 0.1026],\n",
      "         [-0.0252],\n",
      "         [-0.1196],\n",
      "         [-0.1048],\n",
      "         [ 0.0363],\n",
      "         [ 0.0674]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv1.bias | Size: torch.Size([16]) | Values : tensor([-0.0226,  0.0574], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[ 0.0354, -0.0034,  0.0429],\n",
      "         [ 0.0827, -0.0186, -0.1294],\n",
      "         [ 0.0763,  0.0318, -0.0187],\n",
      "         [-0.0440, -0.0574, -0.0347],\n",
      "         [ 0.0664,  0.1297, -0.0498],\n",
      "         [-0.0842,  0.0759, -0.0017],\n",
      "         [ 0.1362,  0.0717, -0.1427],\n",
      "         [ 0.1008,  0.0333,  0.1047],\n",
      "         [ 0.0857,  0.0578, -0.1213],\n",
      "         [-0.0064, -0.0793, -0.0761],\n",
      "         [-0.0530,  0.1371,  0.0749],\n",
      "         [-0.0759,  0.0431, -0.1101],\n",
      "         [ 0.1082,  0.0521, -0.1285],\n",
      "         [-0.1178,  0.0418,  0.0448],\n",
      "         [-0.0003,  0.0764,  0.0335],\n",
      "         [ 0.1157, -0.0673,  0.0864]],\n",
      "\n",
      "        [[ 0.0220,  0.0485, -0.0509],\n",
      "         [ 0.0991, -0.1353,  0.0755],\n",
      "         [-0.0255, -0.0822,  0.0787],\n",
      "         [ 0.1081,  0.0608,  0.1371],\n",
      "         [ 0.0483, -0.0362,  0.1131],\n",
      "         [ 0.0421, -0.1089,  0.0540],\n",
      "         [-0.1322, -0.0344, -0.1418],\n",
      "         [-0.1292,  0.0693,  0.0675],\n",
      "         [ 0.1350,  0.0446,  0.0853],\n",
      "         [ 0.1212,  0.1297, -0.0923],\n",
      "         [-0.1423, -0.0279, -0.1384],\n",
      "         [ 0.1107, -0.0263,  0.0976],\n",
      "         [-0.0983,  0.0859,  0.0997],\n",
      "         [ 0.1215,  0.1244,  0.0628],\n",
      "         [ 0.0510, -0.0618,  0.0564],\n",
      "         [-0.0133,  0.1194, -0.0835]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv2.bias | Size: torch.Size([16]) | Values : tensor([ 0.0699, -0.0112], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[-0.2391],\n",
      "         [ 0.1636],\n",
      "         [ 0.0230],\n",
      "         [ 0.1281],\n",
      "         [-0.0859],\n",
      "         [ 0.0031],\n",
      "         [ 0.0816],\n",
      "         [ 0.1796],\n",
      "         [ 0.1518],\n",
      "         [ 0.0104],\n",
      "         [ 0.0678],\n",
      "         [ 0.0930],\n",
      "         [-0.2181],\n",
      "         [ 0.1368],\n",
      "         [-0.2477],\n",
      "         [ 0.1228]],\n",
      "\n",
      "        [[ 0.1659],\n",
      "         [ 0.2241],\n",
      "         [ 0.0693],\n",
      "         [-0.1397],\n",
      "         [ 0.0158],\n",
      "         [ 0.0934],\n",
      "         [-0.0601],\n",
      "         [-0.0242],\n",
      "         [ 0.0923],\n",
      "         [ 0.2233],\n",
      "         [-0.2177],\n",
      "         [-0.0019],\n",
      "         [-0.0417],\n",
      "         [ 0.0344],\n",
      "         [-0.0887],\n",
      "         [-0.1301]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.conv3.bias | Size: torch.Size([64]) | Values : tensor([-0.0126,  0.1923], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[ 0.1133],\n",
      "         [-0.0775],\n",
      "         [ 0.0354],\n",
      "         [ 0.0828],\n",
      "         [-0.0018],\n",
      "         [ 0.0528],\n",
      "         [-0.1090],\n",
      "         [-0.0273],\n",
      "         [ 0.0680],\n",
      "         [-0.0451],\n",
      "         [ 0.0464],\n",
      "         [-0.0279],\n",
      "         [-0.0052],\n",
      "         [-0.1227],\n",
      "         [ 0.0612],\n",
      "         [ 0.0025],\n",
      "         [ 0.0632],\n",
      "         [-0.0694],\n",
      "         [ 0.0619],\n",
      "         [ 0.0723],\n",
      "         [ 0.0650],\n",
      "         [-0.0383],\n",
      "         [ 0.0404],\n",
      "         [ 0.0923],\n",
      "         [-0.1025],\n",
      "         [ 0.0178],\n",
      "         [ 0.0407],\n",
      "         [ 0.1165],\n",
      "         [-0.1143],\n",
      "         [-0.0722],\n",
      "         [-0.0002],\n",
      "         [-0.1154],\n",
      "         [ 0.0078],\n",
      "         [-0.0029],\n",
      "         [-0.1047],\n",
      "         [-0.0607],\n",
      "         [-0.0474],\n",
      "         [-0.0205],\n",
      "         [-0.0171],\n",
      "         [ 0.0438],\n",
      "         [-0.0645],\n",
      "         [-0.0716],\n",
      "         [ 0.0413],\n",
      "         [ 0.1075],\n",
      "         [ 0.0665],\n",
      "         [ 0.0518],\n",
      "         [-0.1174],\n",
      "         [ 0.0860],\n",
      "         [-0.0412],\n",
      "         [-0.1204],\n",
      "         [ 0.1241],\n",
      "         [-0.0123],\n",
      "         [ 0.0336],\n",
      "         [-0.0776],\n",
      "         [ 0.0901],\n",
      "         [ 0.1142],\n",
      "         [ 0.0873],\n",
      "         [-0.0109],\n",
      "         [ 0.0002],\n",
      "         [ 0.0092],\n",
      "         [ 0.0714],\n",
      "         [ 0.0203],\n",
      "         [-0.1242],\n",
      "         [-0.0072]],\n",
      "\n",
      "        [[-0.0632],\n",
      "         [-0.0497],\n",
      "         [-0.0601],\n",
      "         [-0.0765],\n",
      "         [-0.1142],\n",
      "         [ 0.0598],\n",
      "         [-0.0431],\n",
      "         [ 0.1021],\n",
      "         [-0.0688],\n",
      "         [ 0.0932],\n",
      "         [-0.0850],\n",
      "         [-0.0369],\n",
      "         [ 0.0057],\n",
      "         [ 0.0400],\n",
      "         [-0.1149],\n",
      "         [ 0.0734],\n",
      "         [ 0.0581],\n",
      "         [-0.0685],\n",
      "         [-0.0518],\n",
      "         [ 0.0848],\n",
      "         [-0.0649],\n",
      "         [-0.0474],\n",
      "         [ 0.0290],\n",
      "         [-0.0639],\n",
      "         [-0.1144],\n",
      "         [ 0.0834],\n",
      "         [ 0.0051],\n",
      "         [ 0.0064],\n",
      "         [-0.1156],\n",
      "         [-0.0282],\n",
      "         [ 0.0912],\n",
      "         [ 0.1055],\n",
      "         [ 0.0948],\n",
      "         [-0.0179],\n",
      "         [-0.0725],\n",
      "         [-0.0226],\n",
      "         [ 0.0670],\n",
      "         [ 0.0226],\n",
      "         [-0.0800],\n",
      "         [ 0.0002],\n",
      "         [-0.0058],\n",
      "         [ 0.0815],\n",
      "         [ 0.0465],\n",
      "         [-0.1053],\n",
      "         [-0.0968],\n",
      "         [ 0.0724],\n",
      "         [-0.1182],\n",
      "         [ 0.0319],\n",
      "         [ 0.0221],\n",
      "         [ 0.1195],\n",
      "         [-0.0930],\n",
      "         [ 0.0189],\n",
      "         [ 0.0101],\n",
      "         [ 0.0868],\n",
      "         [ 0.0828],\n",
      "         [-0.0353],\n",
      "         [ 0.0675],\n",
      "         [-0.0342],\n",
      "         [ 0.0481],\n",
      "         [-0.1110],\n",
      "         [-0.0808],\n",
      "         [-0.0293],\n",
      "         [-0.0951],\n",
      "         [ 0.0969]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk3.convr.bias | Size: torch.Size([64]) | Values : tensor([-0.0846, -0.0643], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv1.weight | Size: torch.Size([16, 64, 1]) | Values : tensor([[[ 0.0493],\n",
      "         [ 0.0039],\n",
      "         [ 0.0549],\n",
      "         [-0.0752],\n",
      "         [ 0.0871],\n",
      "         [-0.0892],\n",
      "         [-0.0980],\n",
      "         [ 0.0222],\n",
      "         [-0.0092],\n",
      "         [-0.0527],\n",
      "         [-0.0600],\n",
      "         [-0.0322],\n",
      "         [ 0.0760],\n",
      "         [ 0.0160],\n",
      "         [ 0.0225],\n",
      "         [-0.1043],\n",
      "         [-0.0975],\n",
      "         [-0.0574],\n",
      "         [-0.0755],\n",
      "         [-0.0311],\n",
      "         [ 0.0212],\n",
      "         [-0.0944],\n",
      "         [-0.0065],\n",
      "         [ 0.0820],\n",
      "         [-0.0862],\n",
      "         [-0.0875],\n",
      "         [-0.1018],\n",
      "         [ 0.0797],\n",
      "         [-0.0989],\n",
      "         [ 0.0185],\n",
      "         [-0.0125],\n",
      "         [-0.0832],\n",
      "         [ 0.0975],\n",
      "         [ 0.0242],\n",
      "         [ 0.0901],\n",
      "         [-0.0633],\n",
      "         [ 0.0809],\n",
      "         [ 0.0013],\n",
      "         [-0.0911],\n",
      "         [ 0.1034],\n",
      "         [-0.1000],\n",
      "         [ 0.0218],\n",
      "         [ 0.0238],\n",
      "         [ 0.0296],\n",
      "         [ 0.0059],\n",
      "         [-0.0379],\n",
      "         [-0.0888],\n",
      "         [ 0.0610],\n",
      "         [ 0.1081],\n",
      "         [ 0.0305],\n",
      "         [ 0.0892],\n",
      "         [-0.1069],\n",
      "         [ 0.1128],\n",
      "         [-0.0879],\n",
      "         [ 0.0555],\n",
      "         [ 0.0183],\n",
      "         [ 0.0447],\n",
      "         [ 0.0734],\n",
      "         [ 0.1114],\n",
      "         [-0.1045],\n",
      "         [ 0.0540],\n",
      "         [ 0.0087],\n",
      "         [ 0.1245],\n",
      "         [-0.0698]],\n",
      "\n",
      "        [[-0.0170],\n",
      "         [ 0.1134],\n",
      "         [-0.0043],\n",
      "         [ 0.0540],\n",
      "         [ 0.0797],\n",
      "         [ 0.1041],\n",
      "         [-0.0819],\n",
      "         [ 0.1140],\n",
      "         [-0.0969],\n",
      "         [ 0.1035],\n",
      "         [-0.0271],\n",
      "         [ 0.1199],\n",
      "         [-0.1140],\n",
      "         [-0.0034],\n",
      "         [-0.0130],\n",
      "         [-0.0474],\n",
      "         [-0.0251],\n",
      "         [-0.1018],\n",
      "         [ 0.1161],\n",
      "         [-0.0195],\n",
      "         [-0.0071],\n",
      "         [-0.0042],\n",
      "         [-0.0874],\n",
      "         [-0.1134],\n",
      "         [-0.0607],\n",
      "         [-0.1044],\n",
      "         [-0.0211],\n",
      "         [ 0.1148],\n",
      "         [ 0.0926],\n",
      "         [-0.0434],\n",
      "         [ 0.0341],\n",
      "         [-0.1138],\n",
      "         [ 0.0978],\n",
      "         [ 0.0472],\n",
      "         [-0.1103],\n",
      "         [ 0.0307],\n",
      "         [-0.0117],\n",
      "         [ 0.0195],\n",
      "         [-0.1044],\n",
      "         [ 0.0579],\n",
      "         [-0.0464],\n",
      "         [ 0.1047],\n",
      "         [-0.1027],\n",
      "         [ 0.0610],\n",
      "         [ 0.1063],\n",
      "         [ 0.1095],\n",
      "         [ 0.0539],\n",
      "         [ 0.1126],\n",
      "         [-0.0390],\n",
      "         [ 0.0355],\n",
      "         [-0.0427],\n",
      "         [-0.0032],\n",
      "         [-0.0785],\n",
      "         [-0.0665],\n",
      "         [-0.0945],\n",
      "         [ 0.0036],\n",
      "         [ 0.0665],\n",
      "         [-0.0022],\n",
      "         [-0.1131],\n",
      "         [-0.0409],\n",
      "         [-0.0828],\n",
      "         [-0.0357],\n",
      "         [-0.0430],\n",
      "         [ 0.0651]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv1.bias | Size: torch.Size([16]) | Values : tensor([-0.0098,  0.1073], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn1.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn1.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv2.weight | Size: torch.Size([16, 16, 3]) | Values : tensor([[[-0.0511, -0.1001, -0.0349],\n",
      "         [ 0.0702,  0.0858,  0.0606],\n",
      "         [ 0.0903,  0.1236,  0.0434],\n",
      "         [-0.0247, -0.0130,  0.0797],\n",
      "         [ 0.0347,  0.0967,  0.1423],\n",
      "         [ 0.0300,  0.1402,  0.1154],\n",
      "         [ 0.0294,  0.0168,  0.0257],\n",
      "         [ 0.0627,  0.1429,  0.0554],\n",
      "         [-0.0237,  0.0036, -0.0187],\n",
      "         [ 0.1333, -0.0834,  0.0356],\n",
      "         [-0.1167,  0.1288,  0.0500],\n",
      "         [-0.1103, -0.0080,  0.1359],\n",
      "         [ 0.0219,  0.0616,  0.1135],\n",
      "         [-0.0138, -0.0579, -0.0504],\n",
      "         [-0.1307, -0.0916, -0.0580],\n",
      "         [ 0.0271,  0.0440, -0.0658]],\n",
      "\n",
      "        [[ 0.0383, -0.0948, -0.0473],\n",
      "         [-0.0884,  0.0215,  0.1170],\n",
      "         [-0.0548, -0.1312,  0.1137],\n",
      "         [ 0.1001, -0.1384, -0.0075],\n",
      "         [ 0.1186, -0.0251,  0.0701],\n",
      "         [ 0.0892, -0.0055,  0.1075],\n",
      "         [-0.0522,  0.0225,  0.1035],\n",
      "         [-0.0712, -0.0748, -0.0605],\n",
      "         [ 0.1386,  0.0709, -0.0315],\n",
      "         [-0.1392,  0.1257, -0.1320],\n",
      "         [-0.1151, -0.0576, -0.0011],\n",
      "         [ 0.1427, -0.0295, -0.1388],\n",
      "         [-0.0058, -0.0512,  0.0987],\n",
      "         [-0.0999, -0.1150, -0.1241],\n",
      "         [-0.0427,  0.0448, -0.1138],\n",
      "         [-0.0491,  0.0196, -0.0047]]], device='cuda:0',\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv2.bias | Size: torch.Size([16]) | Values : tensor([-0.1223, -0.0693], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn2.weight | Size: torch.Size([16]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn2.bias | Size: torch.Size([16]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv3.weight | Size: torch.Size([64, 16, 1]) | Values : tensor([[[ 0.1358],\n",
      "         [ 0.2470],\n",
      "         [ 0.0363],\n",
      "         [ 0.1227],\n",
      "         [-0.0496],\n",
      "         [ 0.2379],\n",
      "         [ 0.1994],\n",
      "         [-0.2160],\n",
      "         [ 0.0121],\n",
      "         [ 0.2416],\n",
      "         [-0.0967],\n",
      "         [ 0.1562],\n",
      "         [-0.2020],\n",
      "         [-0.2049],\n",
      "         [-0.2361],\n",
      "         [ 0.0050]],\n",
      "\n",
      "        [[ 0.0351],\n",
      "         [-0.0263],\n",
      "         [-0.2013],\n",
      "         [ 0.2245],\n",
      "         [-0.0738],\n",
      "         [ 0.0206],\n",
      "         [ 0.0629],\n",
      "         [ 0.0038],\n",
      "         [ 0.0051],\n",
      "         [-0.1878],\n",
      "         [ 0.1629],\n",
      "         [ 0.1279],\n",
      "         [-0.2449],\n",
      "         [ 0.1661],\n",
      "         [ 0.2184],\n",
      "         [-0.1073]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.conv3.bias | Size: torch.Size([64]) | Values : tensor([-0.2161, -0.1765], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn3.weight | Size: torch.Size([64]) | Values : tensor([1., 1.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.bn3.bias | Size: torch.Size([64]) | Values : tensor([0., 0.], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.convr.weight | Size: torch.Size([64, 64, 1]) | Values : tensor([[[-0.0860],\n",
      "         [-0.0288],\n",
      "         [-0.1117],\n",
      "         [ 0.0699],\n",
      "         [-0.0235],\n",
      "         [-0.0085],\n",
      "         [ 0.1073],\n",
      "         [ 0.0635],\n",
      "         [-0.0719],\n",
      "         [-0.1220],\n",
      "         [ 0.1203],\n",
      "         [-0.0598],\n",
      "         [-0.0160],\n",
      "         [ 0.0297],\n",
      "         [ 0.1061],\n",
      "         [ 0.0940],\n",
      "         [ 0.0788],\n",
      "         [-0.0646],\n",
      "         [-0.1189],\n",
      "         [ 0.0072],\n",
      "         [ 0.0384],\n",
      "         [-0.1089],\n",
      "         [-0.0013],\n",
      "         [ 0.0478],\n",
      "         [-0.0058],\n",
      "         [-0.0954],\n",
      "         [-0.0203],\n",
      "         [-0.0500],\n",
      "         [-0.0299],\n",
      "         [-0.0425],\n",
      "         [-0.0893],\n",
      "         [ 0.1080],\n",
      "         [ 0.0163],\n",
      "         [ 0.0719],\n",
      "         [ 0.0635],\n",
      "         [ 0.0669],\n",
      "         [-0.0569],\n",
      "         [-0.0833],\n",
      "         [ 0.1133],\n",
      "         [ 0.0077],\n",
      "         [ 0.1196],\n",
      "         [ 0.0520],\n",
      "         [ 0.0086],\n",
      "         [-0.0496],\n",
      "         [-0.0509],\n",
      "         [ 0.0565],\n",
      "         [ 0.1061],\n",
      "         [-0.0032],\n",
      "         [-0.0077],\n",
      "         [ 0.0149],\n",
      "         [ 0.0225],\n",
      "         [-0.1040],\n",
      "         [ 0.0499],\n",
      "         [ 0.1165],\n",
      "         [-0.1227],\n",
      "         [-0.1172],\n",
      "         [-0.0440],\n",
      "         [-0.0605],\n",
      "         [-0.0290],\n",
      "         [-0.0982],\n",
      "         [-0.0580],\n",
      "         [ 0.0589],\n",
      "         [ 0.0997],\n",
      "         [-0.0094]],\n",
      "\n",
      "        [[ 0.0410],\n",
      "         [-0.1079],\n",
      "         [-0.0794],\n",
      "         [ 0.0391],\n",
      "         [-0.1119],\n",
      "         [ 0.0024],\n",
      "         [-0.0875],\n",
      "         [ 0.0901],\n",
      "         [-0.0742],\n",
      "         [-0.1207],\n",
      "         [-0.0246],\n",
      "         [ 0.1168],\n",
      "         [ 0.0445],\n",
      "         [-0.0845],\n",
      "         [ 0.1085],\n",
      "         [-0.0416],\n",
      "         [ 0.1140],\n",
      "         [-0.0648],\n",
      "         [ 0.1072],\n",
      "         [-0.0741],\n",
      "         [-0.0421],\n",
      "         [ 0.1149],\n",
      "         [-0.0258],\n",
      "         [-0.0183],\n",
      "         [-0.0249],\n",
      "         [-0.0054],\n",
      "         [-0.0422],\n",
      "         [ 0.0997],\n",
      "         [-0.0278],\n",
      "         [-0.0542],\n",
      "         [ 0.1128],\n",
      "         [ 0.0234],\n",
      "         [ 0.0504],\n",
      "         [ 0.0472],\n",
      "         [ 0.0613],\n",
      "         [ 0.0482],\n",
      "         [ 0.0206],\n",
      "         [-0.0707],\n",
      "         [ 0.0731],\n",
      "         [ 0.0373],\n",
      "         [ 0.0373],\n",
      "         [-0.0965],\n",
      "         [ 0.1150],\n",
      "         [-0.0200],\n",
      "         [-0.0753],\n",
      "         [ 0.0500],\n",
      "         [ 0.0624],\n",
      "         [-0.0042],\n",
      "         [ 0.1120],\n",
      "         [ 0.0157],\n",
      "         [-0.0104],\n",
      "         [-0.0849],\n",
      "         [-0.1031],\n",
      "         [-0.0890],\n",
      "         [-0.0257],\n",
      "         [-0.0922],\n",
      "         [ 0.0682],\n",
      "         [-0.1112],\n",
      "         [-0.0697],\n",
      "         [-0.1154],\n",
      "         [-0.0144],\n",
      "         [ 0.0078],\n",
      "         [-0.0382],\n",
      "         [-0.0373]]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: convblk4.convr.bias | Size: torch.Size([64]) | Values : tensor([-0.0045,  0.0451], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc.1.weight | Size: torch.Size([2, 768]) | Values : tensor([[-0.0352,  0.0061, -0.0174,  ...,  0.0160,  0.0232,  0.0081],\n",
      "        [-0.0326,  0.0080,  0.0165,  ...,  0.0019,  0.0271, -0.0247]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc.1.bias | Size: torch.Size([2]) | Values : tensor([0.0196, 0.0293], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from models.TinyFallNet import TinyFallNet\n",
    "\n",
    "# Create an instance of the model\n",
    "model_tinyFallNet = TinyFallNet().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_tinyFallNet.parameters(), lr=learning_rate)\n",
    "# Initialize the scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=patience, verbose=True)\n",
    "\n",
    "print(f\"Model structure: {model_tinyFallNet}\\n\\n\")\n",
    "for name, param in model_tinyFallNet.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.403193  [   64/23290]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\python\\lib\\site-packages\\torch\\nn\\modules\\container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.332907  [ 6464/23290]\n",
      "loss: 0.313266  [12864/23290]\n",
      "loss: 0.676014  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338264 \n",
      "\n",
      "Epoch 1:\n",
      "loss: 1.098921  [   64/23290]\n",
      "loss: 0.676019  [ 6464/23290]\n",
      "loss: 0.487121  [12864/23290]\n",
      "loss: 0.313264  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 2:\n",
      "loss: 0.313262  [   64/23290]\n",
      "loss: 0.676017  [ 6464/23290]\n",
      "loss: 0.676019  [12864/23290]\n",
      "loss: 0.879943  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 3:\n",
      "loss: 0.487121  [   64/23290]\n",
      "loss: 0.313262  [ 6464/23290]\n",
      "loss: 1.098907  [12864/23290]\n",
      "loss: 0.676015  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 4:\n",
      "loss: 0.487121  [   64/23290]\n",
      "loss: 1.332905  [ 6464/23290]\n",
      "loss: 0.676014  [12864/23290]\n",
      "loss: 1.098907  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 5:\n",
      "loss: 0.676014  [   64/23290]\n",
      "loss: 1.332905  [ 6464/23290]\n",
      "loss: 0.487121  [12864/23290]\n",
      "loss: 0.676015  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 6:\n",
      "loss: 0.676014  [   64/23290]\n",
      "loss: 0.487121  [ 6464/23290]\n",
      "loss: 0.879943  [12864/23290]\n",
      "loss: 0.487121  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 00007: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Epoch 7:\n",
      "loss: 0.879943  [   64/23290]\n",
      "loss: 0.487121  [ 6464/23290]\n",
      "loss: 0.487121  [12864/23290]\n",
      "loss: 0.676014  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 8:\n",
      "loss: 0.879943  [   64/23290]\n",
      "loss: 0.676014  [ 6464/23290]\n",
      "loss: 0.487121  [12864/23290]\n",
      "loss: 0.879943  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 9:\n",
      "loss: 0.879943  [   64/23290]\n",
      "loss: 1.098907  [ 6464/23290]\n",
      "loss: 0.676014  [12864/23290]\n",
      "loss: 0.676014  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 10:\n",
      "loss: 0.676014  [   64/23290]\n",
      "loss: 0.487120  [ 6464/23290]\n",
      "loss: 1.332905  [12864/23290]\n",
      "loss: 0.676014  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 11:\n",
      "loss: 0.676014  [   64/23290]\n",
      "loss: 0.676014  [ 6464/23290]\n",
      "loss: 0.676014  [12864/23290]\n",
      "loss: 1.332905  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 12:\n",
      "loss: 0.676014  [   64/23290]\n",
      "loss: 1.098907  [ 6464/23290]\n",
      "loss: 0.676014  [12864/23290]\n",
      "loss: 0.487121  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 00013: reducing learning rate of group 0 to 5.0000e-06.\n",
      "Epoch 13:\n",
      "loss: 0.487121  [   64/23290]\n",
      "loss: 0.487121  [ 6464/23290]\n",
      "loss: 0.313262  [12864/23290]\n",
      "loss: 1.098907  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 14:\n",
      "loss: 0.879943  [   64/23290]\n",
      "loss: 0.879944  [ 6464/23290]\n",
      "loss: 0.879943  [12864/23290]\n",
      "loss: 1.098907  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 15:\n",
      "loss: 0.676014  [   64/23290]\n",
      "loss: 0.487121  [ 6464/23290]\n",
      "loss: 0.676014  [12864/23290]\n",
      "loss: 0.313262  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 16:\n",
      "loss: 0.879943  [   64/23290]\n",
      "loss: 0.676014  [ 6464/23290]\n",
      "loss: 1.581939  [12864/23290]\n",
      "loss: 1.098907  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 17:\n",
      "loss: 0.487121  [   64/23290]\n",
      "loss: 0.879943  [ 6464/23290]\n",
      "loss: 0.676014  [12864/23290]\n",
      "loss: 1.332905  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 18:\n",
      "loss: 0.313262  [   64/23290]\n",
      "loss: 1.581939  [ 6464/23290]\n",
      "loss: 0.879943  [12864/23290]\n",
      "loss: 0.879943  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Epoch 00019: reducing learning rate of group 0 to 5.0000e-07.\n",
      "Epoch 19:\n",
      "loss: 0.676014  [   64/23290]\n",
      "loss: 0.879943  [ 6464/23290]\n",
      "loss: 0.487121  [12864/23290]\n",
      "loss: 1.332906  [19264/23290]\n",
      "Validation Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.338262 \n",
      "\n",
      "Early stopping due to no improvement in validation loss.\n"
     ]
    }
   ],
   "source": [
    "train(train_dataloader, model_tinyFallNet, loss_fn, optimizer,val_dataloader, \n",
    "        patience=patience, scheduler=scheduler, device=device, epochs=epochs, B_size=B_size, A_size=A_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.813262 \n",
      "\n",
      " Label 0\n",
      "    accuracy\t0.500\n",
      " specificity\t0.000\n",
      " sensitivity\t1.000\n",
      " Label 1\n",
      "    accuracy\t0.500\n",
      " specificity\t1.000\n",
      " sensitivity\t0.000\n",
      "[[31  0]\n",
      " [31  0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# final test\n",
    "test(test_dataloader, model_tinyFallNet, loss_fn, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvLSTM\n",
      "Test Error: \n",
      " Accuracy: 90.3%, Avg loss: 0.322582 \n",
      "\n",
      " Label 0\n",
      "    accuracy\t0.903\n",
      " specificity\t0.806\n",
      " sensitivity\t1.000\n",
      " Label 1\n",
      "    accuracy\t0.903\n",
      " specificity\t1.000\n",
      " sensitivity\t0.806\n",
      "[[31  0]\n",
      " [ 6 25]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ConvLSTM\n",
    "print('ConvLSTM')\n",
    "test(test_dataloader, model_ConvLSTM, loss_fn, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet24\n",
      "Test Error: \n",
      " Accuracy: 83.9%, Avg loss: 0.835674 \n",
      "\n",
      " Label 0\n",
      "    accuracy\t0.839\n",
      " specificity\t0.677\n",
      " sensitivity\t1.000\n",
      " Label 1\n",
      "    accuracy\t0.839\n",
      " specificity\t1.000\n",
      " sensitivity\t0.677\n",
      "[[31  0]\n",
      " [10 21]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ResNet24\n",
    "print('ResNet24')\n",
    "test(test_dataloader, model_resnet, loss_fn, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinyFallNet\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.813262 \n",
      "\n",
      " Label 0\n",
      "    accuracy\t0.500\n",
      " specificity\t0.000\n",
      " sensitivity\t1.000\n",
      " Label 1\n",
      "    accuracy\t0.500\n",
      " specificity\t1.000\n",
      " sensitivity\t0.000\n",
      "[[31  0]\n",
      " [31  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\python\\lib\\site-packages\\torch\\nn\\modules\\container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TinyFallNet\n",
    "print('TinyFallNet')\n",
    "test(test_dataloader, model_tinyFallNet, loss_fn, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fall_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
