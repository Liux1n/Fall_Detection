{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From g:\\python\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "from scipy.signal import resample\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from utils import train, test, plot_confusion_matrix, get_gzipped_model_size\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras import models, layers\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_size 16005\n",
      "A_size 339\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "X_train = np.load('data/X_train.npy')\n",
    "y_train = np.load('data/y_train.npy')\n",
    "X_test = np.load('data/X_test.npy')\n",
    "y_test = np.load('data/y_test.npy')\n",
    "X_val = np.load('data/X_val.npy')\n",
    "y_val = np.load('data/y_val.npy')\n",
    "\n",
    "# B_size = (label == 0).sum()\n",
    "#A_size = (label == 1).sum()\n",
    "B_size = y_train[y_train == 0].shape[0]\n",
    "A_size = y_train[y_train == 1].shape[0]\n",
    "print(\"B_size\", B_size)\n",
    "print(\"A_size\", A_size)\n",
    "\n",
    "device = (\n",
    "     \"cuda\"\n",
    "     if torch.cuda.is_available()\n",
    "     else \"cpu\"\n",
    " )\n",
    "#device = \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 5e-4\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "patience = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(50, 9))\n",
    "x = layers.Reshape((1, 50, 9))(inputs)\n",
    "x = layers.Conv2D(filters=64, kernel_size=(1, 3))(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=(1, 3))(x)\n",
    "x = layers.MaxPooling2D(pool_size=(1, 2))(x)\n",
    "\n",
    "# ConvBlock\n",
    "residual = layers.Conv2D(filters=64, kernel_size=(1, 1))(x)\n",
    "x = layers.Conv2D(filters=16, kernel_size=(1, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(filters=16, kernel_size=(1, 3), padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=(1, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Add()([x, residual])\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "# ConvBlock\n",
    "residual = layers.Conv2D(filters=64, kernel_size=(1, 1))(x)\n",
    "x = layers.Conv2D(filters=16, kernel_size=(1, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(filters=16, kernel_size=(1, 3), padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=(1, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Add()([x, residual])\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "# IdentityBlock\n",
    "residual = x\n",
    "x = layers.Conv2D(filters=16, kernel_size=(1, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(filters=16, kernel_size=(1, 3), padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=(1, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Add()([x, residual])\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "# ConvBlock\n",
    "residual = layers.Conv2D(filters=64, kernel_size=(1, 1))(x)\n",
    "x = layers.Conv2D(filters=16, kernel_size=(1, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(filters=16, kernel_size=(1, 3), padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=(1, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Add()([x, residual])\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "# IdentityBlock\n",
    "residual = x\n",
    "x = layers.Conv2D(filters=16, kernel_size=(1, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(filters=16, kernel_size=(1, 3), padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=(1, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Add()([x, residual])\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "# ConvBlock\n",
    "residual = layers.Conv2D(filters=64, kernel_size=(1, 1))(x)\n",
    "x = layers.Conv2D(filters=16, kernel_size=(1, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(filters=16, kernel_size=(1, 3), padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=(1, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Add()([x, residual])\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "# IdentityBlock\n",
    "residual = x\n",
    "x = layers.Conv2D(filters=16, kernel_size=(1, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(filters=16, kernel_size=(1, 3), padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=(1, 1))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Add()([x, residual])\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "x = layers.AveragePooling2D(pool_size=(1, 2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "ResNet24 = keras.Model(inputs=inputs, outputs=outputs, name=\"ResNet24\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: \n",
      "\n",
      "Model: \"ResNet24\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 50, 9)]              0         []                            \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)         (None, 1, 50, 9)             0         ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)          (None, 1, 48, 64)            1792      ['reshape_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)          (None, 1, 46, 64)            12352     ['conv2d_27[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 1, 23, 64)            0         ['conv2d_28[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)          (None, 1, 23, 16)            1040      ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_21 (Ba  (None, 1, 23, 16)            64        ['conv2d_30[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_21 (ReLU)             (None, 1, 23, 16)            0         ['batch_normalization_21[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)          (None, 1, 23, 16)            784       ['re_lu_21[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_22 (Ba  (None, 1, 23, 16)            64        ['conv2d_31[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_22 (ReLU)             (None, 1, 23, 16)            0         ['batch_normalization_22[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)          (None, 1, 23, 64)            1088      ['re_lu_22[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_23 (Ba  (None, 1, 23, 64)            256       ['conv2d_32[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)          (None, 1, 23, 64)            4160      ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " add_7 (Add)                 (None, 1, 23, 64)            0         ['batch_normalization_23[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'conv2d_29[0][0]']           \n",
      "                                                                                                  \n",
      " re_lu_23 (ReLU)             (None, 1, 23, 64)            0         ['add_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)          (None, 1, 23, 16)            1040      ['re_lu_23[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_24 (Ba  (None, 1, 23, 16)            64        ['conv2d_34[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_24 (ReLU)             (None, 1, 23, 16)            0         ['batch_normalization_24[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)          (None, 1, 23, 16)            784       ['re_lu_24[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_25 (Ba  (None, 1, 23, 16)            64        ['conv2d_35[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_25 (ReLU)             (None, 1, 23, 16)            0         ['batch_normalization_25[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)          (None, 1, 23, 64)            1088      ['re_lu_25[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_26 (Ba  (None, 1, 23, 64)            256       ['conv2d_36[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)          (None, 1, 23, 64)            4160      ['re_lu_23[0][0]']            \n",
      "                                                                                                  \n",
      " add_8 (Add)                 (None, 1, 23, 64)            0         ['batch_normalization_26[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'conv2d_33[0][0]']           \n",
      "                                                                                                  \n",
      " re_lu_26 (ReLU)             (None, 1, 23, 64)            0         ['add_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)          (None, 1, 23, 16)            1040      ['re_lu_26[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_27 (Ba  (None, 1, 23, 16)            64        ['conv2d_37[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_27 (ReLU)             (None, 1, 23, 16)            0         ['batch_normalization_27[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)          (None, 1, 23, 16)            784       ['re_lu_27[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_28 (Ba  (None, 1, 23, 16)            64        ['conv2d_38[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_28 (ReLU)             (None, 1, 23, 16)            0         ['batch_normalization_28[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)          (None, 1, 23, 64)            1088      ['re_lu_28[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_29 (Ba  (None, 1, 23, 64)            256       ['conv2d_39[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_9 (Add)                 (None, 1, 23, 64)            0         ['batch_normalization_29[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     're_lu_26[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_29 (ReLU)             (None, 1, 23, 64)            0         ['add_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)          (None, 1, 23, 16)            1040      ['re_lu_29[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_30 (Ba  (None, 1, 23, 16)            64        ['conv2d_41[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_30 (ReLU)             (None, 1, 23, 16)            0         ['batch_normalization_30[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)          (None, 1, 23, 16)            784       ['re_lu_30[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_31 (Ba  (None, 1, 23, 16)            64        ['conv2d_42[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_31 (ReLU)             (None, 1, 23, 16)            0         ['batch_normalization_31[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)          (None, 1, 23, 64)            1088      ['re_lu_31[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_32 (Ba  (None, 1, 23, 64)            256       ['conv2d_43[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)          (None, 1, 23, 64)            4160      ['re_lu_29[0][0]']            \n",
      "                                                                                                  \n",
      " add_10 (Add)                (None, 1, 23, 64)            0         ['batch_normalization_32[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'conv2d_40[0][0]']           \n",
      "                                                                                                  \n",
      " re_lu_32 (ReLU)             (None, 1, 23, 64)            0         ['add_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)          (None, 1, 23, 16)            1040      ['re_lu_32[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_33 (Ba  (None, 1, 23, 16)            64        ['conv2d_44[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_33 (ReLU)             (None, 1, 23, 16)            0         ['batch_normalization_33[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)          (None, 1, 23, 16)            784       ['re_lu_33[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_34 (Ba  (None, 1, 23, 16)            64        ['conv2d_45[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_34 (ReLU)             (None, 1, 23, 16)            0         ['batch_normalization_34[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)          (None, 1, 23, 64)            1088      ['re_lu_34[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_35 (Ba  (None, 1, 23, 64)            256       ['conv2d_46[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_11 (Add)                (None, 1, 23, 64)            0         ['batch_normalization_35[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     're_lu_32[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_35 (ReLU)             (None, 1, 23, 64)            0         ['add_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)          (None, 1, 23, 16)            1040      ['re_lu_35[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_36 (Ba  (None, 1, 23, 16)            64        ['conv2d_48[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_36 (ReLU)             (None, 1, 23, 16)            0         ['batch_normalization_36[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)          (None, 1, 23, 16)            784       ['re_lu_36[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_37 (Ba  (None, 1, 23, 16)            64        ['conv2d_49[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_37 (ReLU)             (None, 1, 23, 16)            0         ['batch_normalization_37[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)          (None, 1, 23, 64)            1088      ['re_lu_37[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_38 (Ba  (None, 1, 23, 64)            256       ['conv2d_50[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)          (None, 1, 23, 64)            4160      ['re_lu_35[0][0]']            \n",
      "                                                                                                  \n",
      " add_12 (Add)                (None, 1, 23, 64)            0         ['batch_normalization_38[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'conv2d_47[0][0]']           \n",
      "                                                                                                  \n",
      " re_lu_38 (ReLU)             (None, 1, 23, 64)            0         ['add_12[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)          (None, 1, 23, 16)            1040      ['re_lu_38[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_39 (Ba  (None, 1, 23, 16)            64        ['conv2d_51[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_39 (ReLU)             (None, 1, 23, 16)            0         ['batch_normalization_39[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)          (None, 1, 23, 16)            784       ['re_lu_39[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_40 (Ba  (None, 1, 23, 16)            64        ['conv2d_52[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_40 (ReLU)             (None, 1, 23, 16)            0         ['batch_normalization_40[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)          (None, 1, 23, 64)            1088      ['re_lu_40[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_41 (Ba  (None, 1, 23, 64)            256       ['conv2d_53[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " add_13 (Add)                (None, 1, 23, 64)            0         ['batch_normalization_41[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     're_lu_38[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_41 (ReLU)             (None, 1, 23, 64)            0         ['add_13[0][0]']              \n",
      "                                                                                                  \n",
      " average_pooling2d_1 (Avera  (None, 1, 11, 64)            0         ['re_lu_41[0][0]']            \n",
      " gePooling2D)                                                                                     \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 704)                  0         ['average_pooling2d_1[0][0]'] \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 2)                    1410      ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 55266 (215.88 KB)\n",
      "Trainable params: 53922 (210.63 KB)\n",
      "Non-trainable params: 1344 (5.25 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: \\n\")\n",
    "ResNet24.build(input_shape=(None, 50, 9))\n",
    "ResNet24.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train.shape:  (16344, 2)\n",
      "y_val.shape:  (4087, 2)\n",
      "X_train.shape:  (16344, 50, 9)\n",
      "y_train.shape:  (16344, 2)\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From g:\\python\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From g:\\python\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "256/256 [==============================] - 14s 27ms/step - loss: 1.1230 - accuracy: 0.8316 - val_loss: 0.2254 - val_accuracy: 0.9469 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 0.8811 - accuracy: 0.8594 - val_loss: 0.5552 - val_accuracy: 0.7492 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "256/256 [==============================] - 6s 23ms/step - loss: 0.6570 - accuracy: 0.8754 - val_loss: 0.3371 - val_accuracy: 0.9090 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "256/256 [==============================] - 4s 17ms/step - loss: 0.5733 - accuracy: 0.8922 - val_loss: 0.2397 - val_accuracy: 0.9288 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "256/256 [==============================] - 5s 18ms/step - loss: 0.5586 - accuracy: 0.8886 - val_loss: 0.2494 - val_accuracy: 0.9219 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "254/256 [============================>.] - ETA: 0s - loss: 0.4705 - accuracy: 0.9032\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "256/256 [==============================] - 5s 18ms/step - loss: 0.4698 - accuracy: 0.9032 - val_loss: 0.3733 - val_accuracy: 0.8630 - lr: 5.0000e-04\n",
      "Epoch 6: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Ensure y_train and y_val are one-hot encoded only once\n",
    "if y_train.ndim == 1:\n",
    "    y_train = to_categorical(y_train)\n",
    "if y_val.ndim == 1:\n",
    "    y_val = to_categorical(y_val)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('y_val.shape: ', y_val.shape)\n",
    "\n",
    "# Calculate class weights\n",
    "B_multiplier = 1\n",
    "A_multiplier = B_size / A_size\n",
    "class_weight = {0: B_multiplier, 1: A_multiplier}\n",
    "\n",
    "\n",
    "ResNet24.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "                loss='categorical_crossentropy',\n",
    "                #loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "# Ensure y_train and y_val are one-hot encoded only once\n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=patience)\n",
    "lrs = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=patience, verbose=1)\n",
    "print('X_train.shape: ', X_train.shape) # (23291, 50, 9)\n",
    "print('y_train.shape: ', y_train.shape) # (23291,)\n",
    "\n",
    "history = ResNet24.fit(X_train, y_train, \n",
    "          validation_data=(X_val, y_val), \n",
    "          epochs=epochs, \n",
    "          batch_size=batch_size,\n",
    "          callbacks=[es, lrs],\n",
    "          class_weight=class_weight) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test.shape:  (182, 50, 9)\n",
      "6/6 - 0s - loss: 0.4297 - accuracy: 0.8681 - 64ms/epoch - 11ms/step\n",
      "Test loss: [0.42969799041748047, 0.8681318759918213]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "if y_test.ndim == 1:\n",
    "    y_test = to_categorical(y_test)\n",
    "test_loss = ResNet24.evaluate(X_test, y_test, verbose=2)\n",
    "print('Test loss:', test_loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1988953a4d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training history\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 8ms/step\n",
      "[[73 16]\n",
      " [ 8 85]]\n",
      "Confusion matrix, without normalization\n",
      "[[73 16]\n",
      " [ 8 85]]\n",
      "accuracy:  0.8681318681318682\n",
      "f1_score:  0.8762886597938144\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert y_test back to its original form\n",
    "y_test_original = np.argmax(y_test, axis=-1)\n",
    "\n",
    "# Get the model's predictions\n",
    "predictions = np.argmax(ResNet24.predict(X_test), axis=-1)\n",
    "\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test_original, predictions)\n",
    "\n",
    "print(cm)\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(cm, classes=['Not Fall', 'Fall'], normalize=False, title='Confusion Matrix')\n",
    "\n",
    "# get accuracy\n",
    "accuracy_fp = (cm[0][0] + cm[1][1]) / np.sum(cm)\n",
    "print('accuracy: ', accuracy_fp)\n",
    "\n",
    "f1_score = 2 * cm[1][1] / (2 * cm[1][1] + cm[0][1] + cm[1][0])\n",
    "print('f1_score: ', f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\10744\\AppData\\Local\\Temp\\tmpt4_gqpdu\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\10744\\AppData\\Local\\Temp\\tmpt4_gqpdu\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "231880"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResNet24.save('saved_models/ResNet24.keras')  # The file needs to end with the .keras extension\n",
    "# convert the model to tflite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(ResNet24)\n",
    "ResNet24_tflite = converter.convert()\n",
    "# save the model\n",
    "open(\"saved_models/ResNet24.tflite\", \"wb\").write(ResNet24_tflite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet24\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 50, 9)]              0         []                            \n",
      "                                                                                                  \n",
      " quantize_layer (QuantizeLa  (None, 50, 9)                3         ['input_2[0][0]']             \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " quant_reshape_1 (QuantizeW  (None, 1, 50, 9)             1         ['quantize_layer[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_conv2d_27 (QuantizeW  (None, 1, 48, 64)            1923      ['quant_reshape_1[0][0]']     \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_conv2d_28 (QuantizeW  (None, 1, 46, 64)            12483     ['quant_conv2d_27[0][0]']     \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_max_pooling2d_1 (Qua  (None, 1, 23, 64)            1         ['quant_conv2d_28[0][0]']     \n",
      " ntizeWrapperV2)                                                                                  \n",
      "                                                                                                  \n",
      " quant_conv2d_30 (QuantizeW  (None, 1, 23, 16)            1073      ['quant_max_pooling2d_1[0][0]'\n",
      " rapperV2)                                                          ]                             \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 16)            65        ['quant_conv2d_30[0][0]']     \n",
      " 21 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_21 (QuantizeWr  (None, 1, 23, 16)            3         ['quant_batch_normalization_21\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_31 (QuantizeW  (None, 1, 23, 16)            817       ['quant_re_lu_21[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 16)            65        ['quant_conv2d_31[0][0]']     \n",
      " 22 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_22 (QuantizeWr  (None, 1, 23, 16)            3         ['quant_batch_normalization_22\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_32 (QuantizeW  (None, 1, 23, 64)            1217      ['quant_re_lu_22[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 64)            259       ['quant_conv2d_32[0][0]']     \n",
      " 23 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_conv2d_29 (QuantizeW  (None, 1, 23, 64)            4291      ['quant_max_pooling2d_1[0][0]'\n",
      " rapperV2)                                                          ]                             \n",
      "                                                                                                  \n",
      " quant_add_7 (QuantizeWrapp  (None, 1, 23, 64)            1         ['quant_batch_normalization_23\n",
      " erV2)                                                              [0][0]',                      \n",
      "                                                                     'quant_conv2d_29[0][0]']     \n",
      "                                                                                                  \n",
      " quant_re_lu_23 (QuantizeWr  (None, 1, 23, 64)            3         ['quant_add_7[0][0]']         \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_conv2d_34 (QuantizeW  (None, 1, 23, 16)            1073      ['quant_re_lu_23[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 16)            65        ['quant_conv2d_34[0][0]']     \n",
      " 24 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_24 (QuantizeWr  (None, 1, 23, 16)            3         ['quant_batch_normalization_24\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_35 (QuantizeW  (None, 1, 23, 16)            817       ['quant_re_lu_24[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 16)            65        ['quant_conv2d_35[0][0]']     \n",
      " 25 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_25 (QuantizeWr  (None, 1, 23, 16)            3         ['quant_batch_normalization_25\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_36 (QuantizeW  (None, 1, 23, 64)            1217      ['quant_re_lu_25[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 64)            259       ['quant_conv2d_36[0][0]']     \n",
      " 26 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_conv2d_33 (QuantizeW  (None, 1, 23, 64)            4291      ['quant_re_lu_23[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_add_8 (QuantizeWrapp  (None, 1, 23, 64)            1         ['quant_batch_normalization_26\n",
      " erV2)                                                              [0][0]',                      \n",
      "                                                                     'quant_conv2d_33[0][0]']     \n",
      "                                                                                                  \n",
      " quant_re_lu_26 (QuantizeWr  (None, 1, 23, 64)            3         ['quant_add_8[0][0]']         \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_conv2d_37 (QuantizeW  (None, 1, 23, 16)            1073      ['quant_re_lu_26[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 16)            65        ['quant_conv2d_37[0][0]']     \n",
      " 27 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_27 (QuantizeWr  (None, 1, 23, 16)            3         ['quant_batch_normalization_27\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_38 (QuantizeW  (None, 1, 23, 16)            817       ['quant_re_lu_27[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 16)            65        ['quant_conv2d_38[0][0]']     \n",
      " 28 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_28 (QuantizeWr  (None, 1, 23, 16)            3         ['quant_batch_normalization_28\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_39 (QuantizeW  (None, 1, 23, 64)            1217      ['quant_re_lu_28[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 64)            259       ['quant_conv2d_39[0][0]']     \n",
      " 29 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_add_9 (QuantizeWrapp  (None, 1, 23, 64)            1         ['quant_batch_normalization_29\n",
      " erV2)                                                              [0][0]',                      \n",
      "                                                                     'quant_re_lu_26[0][0]']      \n",
      "                                                                                                  \n",
      " quant_re_lu_29 (QuantizeWr  (None, 1, 23, 64)            3         ['quant_add_9[0][0]']         \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_conv2d_41 (QuantizeW  (None, 1, 23, 16)            1073      ['quant_re_lu_29[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 16)            65        ['quant_conv2d_41[0][0]']     \n",
      " 30 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_30 (QuantizeWr  (None, 1, 23, 16)            3         ['quant_batch_normalization_30\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_42 (QuantizeW  (None, 1, 23, 16)            817       ['quant_re_lu_30[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 16)            65        ['quant_conv2d_42[0][0]']     \n",
      " 31 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_31 (QuantizeWr  (None, 1, 23, 16)            3         ['quant_batch_normalization_31\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_43 (QuantizeW  (None, 1, 23, 64)            1217      ['quant_re_lu_31[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 64)            259       ['quant_conv2d_43[0][0]']     \n",
      " 32 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_conv2d_40 (QuantizeW  (None, 1, 23, 64)            4291      ['quant_re_lu_29[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_add_10 (QuantizeWrap  (None, 1, 23, 64)            1         ['quant_batch_normalization_32\n",
      " perV2)                                                             [0][0]',                      \n",
      "                                                                     'quant_conv2d_40[0][0]']     \n",
      "                                                                                                  \n",
      " quant_re_lu_32 (QuantizeWr  (None, 1, 23, 64)            3         ['quant_add_10[0][0]']        \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_conv2d_44 (QuantizeW  (None, 1, 23, 16)            1073      ['quant_re_lu_32[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 16)            65        ['quant_conv2d_44[0][0]']     \n",
      " 33 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_33 (QuantizeWr  (None, 1, 23, 16)            3         ['quant_batch_normalization_33\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_45 (QuantizeW  (None, 1, 23, 16)            817       ['quant_re_lu_33[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 16)            65        ['quant_conv2d_45[0][0]']     \n",
      " 34 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_34 (QuantizeWr  (None, 1, 23, 16)            3         ['quant_batch_normalization_34\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_46 (QuantizeW  (None, 1, 23, 64)            1217      ['quant_re_lu_34[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 64)            259       ['quant_conv2d_46[0][0]']     \n",
      " 35 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_add_11 (QuantizeWrap  (None, 1, 23, 64)            1         ['quant_batch_normalization_35\n",
      " perV2)                                                             [0][0]',                      \n",
      "                                                                     'quant_re_lu_32[0][0]']      \n",
      "                                                                                                  \n",
      " quant_re_lu_35 (QuantizeWr  (None, 1, 23, 64)            3         ['quant_add_11[0][0]']        \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_conv2d_48 (QuantizeW  (None, 1, 23, 16)            1073      ['quant_re_lu_35[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 16)            65        ['quant_conv2d_48[0][0]']     \n",
      " 36 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_36 (QuantizeWr  (None, 1, 23, 16)            3         ['quant_batch_normalization_36\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_49 (QuantizeW  (None, 1, 23, 16)            817       ['quant_re_lu_36[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 16)            65        ['quant_conv2d_49[0][0]']     \n",
      " 37 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_37 (QuantizeWr  (None, 1, 23, 16)            3         ['quant_batch_normalization_37\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_50 (QuantizeW  (None, 1, 23, 64)            1217      ['quant_re_lu_37[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 64)            259       ['quant_conv2d_50[0][0]']     \n",
      " 38 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_conv2d_47 (QuantizeW  (None, 1, 23, 64)            4291      ['quant_re_lu_35[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_add_12 (QuantizeWrap  (None, 1, 23, 64)            1         ['quant_batch_normalization_38\n",
      " perV2)                                                             [0][0]',                      \n",
      "                                                                     'quant_conv2d_47[0][0]']     \n",
      "                                                                                                  \n",
      " quant_re_lu_38 (QuantizeWr  (None, 1, 23, 64)            3         ['quant_add_12[0][0]']        \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_conv2d_51 (QuantizeW  (None, 1, 23, 16)            1073      ['quant_re_lu_38[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 16)            65        ['quant_conv2d_51[0][0]']     \n",
      " 39 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_39 (QuantizeWr  (None, 1, 23, 16)            3         ['quant_batch_normalization_39\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_52 (QuantizeW  (None, 1, 23, 16)            817       ['quant_re_lu_39[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 16)            65        ['quant_conv2d_52[0][0]']     \n",
      " 40 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_40 (QuantizeWr  (None, 1, 23, 16)            3         ['quant_batch_normalization_40\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_53 (QuantizeW  (None, 1, 23, 64)            1217      ['quant_re_lu_40[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 64)            259       ['quant_conv2d_53[0][0]']     \n",
      " 41 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_add_13 (QuantizeWrap  (None, 1, 23, 64)            1         ['quant_batch_normalization_41\n",
      " perV2)                                                             [0][0]',                      \n",
      "                                                                     'quant_re_lu_38[0][0]']      \n",
      "                                                                                                  \n",
      " quant_re_lu_41 (QuantizeWr  (None, 1, 23, 64)            3         ['quant_add_13[0][0]']        \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_average_pooling2d_1   (None, 1, 11, 64)            3         ['quant_re_lu_41[0][0]']      \n",
      " (QuantizeWrapperV2)                                                                              \n",
      "                                                                                                  \n",
      " quant_flatten_1 (QuantizeW  (None, 704)                  1         ['quant_average_pooling2d_1[0]\n",
      " rapperV2)                                                          [0]']                         \n",
      "                                                                                                  \n",
      " quant_dense_1 (QuantizeWra  (None, 2)                    1415      ['quant_flatten_1[0][0]']     \n",
      " pperV2)                                                                                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 57536 (224.75 KB)\n",
      "Trainable params: 53922 (210.63 KB)\n",
      "Non-trainable params: 3614 (14.12 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "q_ResNet24 = tfmot.quantization.keras.quantize_model(ResNet24)\n",
    "q_ResNet24.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "                loss='categorical_crossentropy',\n",
    "                #loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "q_ResNet24.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "256/256 [==============================] - 17s 32ms/step - loss: 0.9207 - accuracy: 0.7891 - val_loss: 0.1845 - val_accuracy: 0.9359 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 0.7372 - accuracy: 0.8618 - val_loss: 0.4831 - val_accuracy: 0.8099 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 0.6076 - accuracy: 0.8773 - val_loss: 0.3245 - val_accuracy: 0.8931 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 0.5561 - accuracy: 0.8947 - val_loss: 1.1855 - val_accuracy: 0.6244 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "256/256 [==============================] - 7s 27ms/step - loss: 0.5015 - accuracy: 0.8950 - val_loss: 0.3207 - val_accuracy: 0.9036 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "256/256 [==============================] - ETA: 0s - loss: 0.4439 - accuracy: 0.9085\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "256/256 [==============================] - 7s 25ms/step - loss: 0.4439 - accuracy: 0.9085 - val_loss: 0.4208 - val_accuracy: 0.8471 - lr: 5.0000e-04\n",
      "Epoch 6: early stopping\n"
     ]
    }
   ],
   "source": [
    "q_history = q_ResNet24.fit(X_train, y_train, \n",
    "            validation_data=(X_val, y_val), \n",
    "            epochs=epochs, \n",
    "            batch_size=batch_size,\n",
    "            callbacks=[es, lrs],\n",
    "            class_weight=class_weight) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_ResNet24.save('saved_models/q_ResNet24.keras')  # The file needs to end with the .keras extension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\10744\\AppData\\Local\\Temp\\tmp0mzmc9ib\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\10744\\AppData\\Local\\Temp\\tmp0mzmc9ib\\assets\n",
      "g:\\python\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# convert the QAT model to a fully quantized model using TFLite\n",
    "\n",
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(X_train.astype('float32')).batch(1).take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "# Set up the converter for quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(ResNet24)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "\n",
    "\n",
    "# This is required for full integer quantization (including input and output)\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.float32  # Keep input as float32\n",
    "converter.inference_output_type = tf.int8  # Keep output as float32\n",
    "\n",
    "# Convert the model\n",
    "tflite_model_quant_int8_qat = converter.convert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  <class 'numpy.float32'>\n",
      "output:  <class 'numpy.int8'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "105488"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant_int8_qat)\n",
    "input_type = interpreter.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)\n",
    "# Save the quantized model to disk\n",
    "open(\"saved_models/ResNet24_quant_int8_qat.tflite\", \"wb\").write(tflite_model_quant_int8_qat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  {'name': 'serving_default_input_2:0', 'index': 0, 'shape': array([ 1, 50,  9]), 'shape_signature': array([-1, 50,  9]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "output:  {'name': 'StatefulPartitionedCall:0', 'index': 106, 'shape': array([1, 2]), 'shape_signature': array([-1,  2]), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00390625, -128), 'quantization_parameters': {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128]), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "Evaluated on  0 .\n",
      "Evaluated on  100 .\n"
     ]
    }
   ],
   "source": [
    "# test the quantized model\n",
    "X_test_int8 = X_test.astype('float32')\n",
    "y_test_int8 = y_test.astype('int8')\n",
    "# Load the model into an interpreter\n",
    "interpreter = tf.lite.Interpreter(model_content= tflite_model_quant_int8_qat)\n",
    "# Allocate memory for the model's input Tensor(s)\n",
    "interpreter.allocate_tensors()\n",
    "# Get the model input and output details\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "print(\"input: \", input_details)\n",
    "print(\"output: \", output_details)\n",
    "predictions = np.zeros(X_test.shape[0])\n",
    "for i, test_data in enumerate(X_test_int8):\n",
    "    test_data = np.expand_dims(test_data, axis=0)\n",
    "    #print(test_data.shape)\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_data)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "    if i%100 == 0:\n",
    "        # print(\"Evaluated on %d images.\" % test_image_index)\n",
    "        print('Evaluated on ', i, '.')\n",
    "    predictions[i] = output.argmax()\n",
    "\n",
    "gt = np.argmax(y_test_int8, axis=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 - 1s - loss: 0.4297 - accuracy: 0.8681 - 530ms/epoch - 88ms/step\n",
      "Test loss: [0.42969799041748047, 0.8681318759918213]\n"
     ]
    }
   ],
   "source": [
    "test_loss = ResNet24.evaluate(X_test_int8, y_test_int8, verbose=2)\n",
    "print('Test loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite Model size with 8-bit quantization: 103 KB\n",
      "TFLite Model size without quantization: 226 KB\n",
      "\n",
      "Reduction in model size by a factor of 2.197065\n",
      "accuracy:  0.8516483516483516\n",
      "Confusion matrix, without normalization\n",
      "[[72 17]\n",
      " [10 83]]\n",
      "f1_score:  0.8601036269430051\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the model size for the 8-bit quantized TFLite model\n",
    "tflite_in_kb = os.path.getsize('saved_models/ResNet24.tflite') / 1024\n",
    "# ResNet24_tflite tflite_quant_in_kb\n",
    "tflite_quant_in_kb = os.path.getsize('saved_models/ResNet24_quant_int8_qat.tflite') / 1024\n",
    "print(\"TFLite Model size with 8-bit quantization: %d KB\" % tflite_quant_in_kb)\n",
    "\n",
    "print(\"TFLite Model size without quantization: %d KB\" % tflite_in_kb)\n",
    "\n",
    "# Determine the reduction in model size\n",
    "print(\"\\nReduction in model size by a factor of %f\" % (tflite_in_kb / tflite_quant_in_kb))\n",
    "\n",
    "accuracy = (predictions == gt).mean()\n",
    "print('accuracy: ', accuracy)\n",
    "# compute the confusion matrix\n",
    "cm = confusion_matrix(gt, predictions)\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(cm, classes=['Not Fall', 'Fall'], normalize=False, title='Confusion Matrix')\n",
    "f1_score = 2 * cm[1][1] / (2 * cm[1][1] + cm[0][1] + cm[1][0])\n",
    "print('f1_score: ', f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of full precision model:  0.8681318681318682\n",
      "accuracy of quantized model:  0.8516483516483516\n"
     ]
    }
   ],
   "source": [
    "print('accuracy of full precision model: ', accuracy_fp)\n",
    "print('accuracy of quantized model: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning + QAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet24\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 50, 9)]              0         []                            \n",
      "                                                                                                  \n",
      " prune_low_magnitude_reshap  (None, 1, 50, 9)             1         ['input_2[0][0]']             \n",
      " e_1 (PruneLowMagnitude)                                                                          \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 48, 64)            3522      ['prune_low_magnitude_reshape_\n",
      " _27 (PruneLowMagnitude)                                            1[0][0]']                     \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 46, 64)            24642     ['prune_low_magnitude_conv2d_2\n",
      " _28 (PruneLowMagnitude)                                            7[0][0]']                     \n",
      "                                                                                                  \n",
      " prune_low_magnitude_max_po  (None, 1, 23, 64)            1         ['prune_low_magnitude_conv2d_2\n",
      " oling2d_1 (PruneLowMagnitu                                         8[0][0]']                     \n",
      " de)                                                                                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 23, 16)            2066      ['prune_low_magnitude_max_pool\n",
      " _30 (PruneLowMagnitude)                                            ing2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 23, 16)            65        ['prune_low_magnitude_conv2d_3\n",
      " normalization_21 (PruneLow                                         0[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 23, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 21 (PruneLowMagnitude)                                             rmalization_21[0][0]']        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 23, 16)            1554      ['prune_low_magnitude_re_lu_21\n",
      " _31 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 23, 16)            65        ['prune_low_magnitude_conv2d_3\n",
      " normalization_22 (PruneLow                                         1[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 23, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 22 (PruneLowMagnitude)                                             rmalization_22[0][0]']        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 23, 64)            2114      ['prune_low_magnitude_re_lu_22\n",
      " _32 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 23, 64)            257       ['prune_low_magnitude_conv2d_3\n",
      " normalization_23 (PruneLow                                         2[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 23, 64)            8258      ['prune_low_magnitude_max_pool\n",
      " _29 (PruneLowMagnitude)                                            ing2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_7   (None, 1, 23, 64)            1         ['prune_low_magnitude_batch_no\n",
      " (PruneLowMagnitude)                                                rmalization_23[0][0]',        \n",
      "                                                                     'prune_low_magnitude_conv2d_2\n",
      "                                                                    9[0][0]']                     \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 23, 64)            1         ['prune_low_magnitude_add_7[0]\n",
      " 23 (PruneLowMagnitude)                                             [0]']                         \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 23, 16)            2066      ['prune_low_magnitude_re_lu_23\n",
      " _34 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 23, 16)            65        ['prune_low_magnitude_conv2d_3\n",
      " normalization_24 (PruneLow                                         4[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 23, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 24 (PruneLowMagnitude)                                             rmalization_24[0][0]']        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 23, 16)            1554      ['prune_low_magnitude_re_lu_24\n",
      " _35 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 23, 16)            65        ['prune_low_magnitude_conv2d_3\n",
      " normalization_25 (PruneLow                                         5[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 23, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 25 (PruneLowMagnitude)                                             rmalization_25[0][0]']        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 23, 64)            2114      ['prune_low_magnitude_re_lu_25\n",
      " _36 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 23, 64)            257       ['prune_low_magnitude_conv2d_3\n",
      " normalization_26 (PruneLow                                         6[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 23, 64)            8258      ['prune_low_magnitude_re_lu_23\n",
      " _33 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_8   (None, 1, 23, 64)            1         ['prune_low_magnitude_batch_no\n",
      " (PruneLowMagnitude)                                                rmalization_26[0][0]',        \n",
      "                                                                     'prune_low_magnitude_conv2d_3\n",
      "                                                                    3[0][0]']                     \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 23, 64)            1         ['prune_low_magnitude_add_8[0]\n",
      " 26 (PruneLowMagnitude)                                             [0]']                         \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 23, 16)            2066      ['prune_low_magnitude_re_lu_26\n",
      " _37 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 23, 16)            65        ['prune_low_magnitude_conv2d_3\n",
      " normalization_27 (PruneLow                                         7[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 23, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 27 (PruneLowMagnitude)                                             rmalization_27[0][0]']        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 23, 16)            1554      ['prune_low_magnitude_re_lu_27\n",
      " _38 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 23, 16)            65        ['prune_low_magnitude_conv2d_3\n",
      " normalization_28 (PruneLow                                         8[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 23, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 28 (PruneLowMagnitude)                                             rmalization_28[0][0]']        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 23, 64)            2114      ['prune_low_magnitude_re_lu_28\n",
      " _39 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 23, 64)            257       ['prune_low_magnitude_conv2d_3\n",
      " normalization_29 (PruneLow                                         9[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_9   (None, 1, 23, 64)            1         ['prune_low_magnitude_batch_no\n",
      " (PruneLowMagnitude)                                                rmalization_29[0][0]',        \n",
      "                                                                     'prune_low_magnitude_re_lu_26\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 23, 64)            1         ['prune_low_magnitude_add_9[0]\n",
      " 29 (PruneLowMagnitude)                                             [0]']                         \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 23, 16)            2066      ['prune_low_magnitude_re_lu_29\n",
      " _41 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 23, 16)            65        ['prune_low_magnitude_conv2d_4\n",
      " normalization_30 (PruneLow                                         1[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 23, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 30 (PruneLowMagnitude)                                             rmalization_30[0][0]']        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 23, 16)            1554      ['prune_low_magnitude_re_lu_30\n",
      " _42 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 23, 16)            65        ['prune_low_magnitude_conv2d_4\n",
      " normalization_31 (PruneLow                                         2[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 23, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 31 (PruneLowMagnitude)                                             rmalization_31[0][0]']        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 23, 64)            2114      ['prune_low_magnitude_re_lu_31\n",
      " _43 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 23, 64)            257       ['prune_low_magnitude_conv2d_4\n",
      " normalization_32 (PruneLow                                         3[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 23, 64)            8258      ['prune_low_magnitude_re_lu_29\n",
      " _40 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_10  (None, 1, 23, 64)            1         ['prune_low_magnitude_batch_no\n",
      "  (PruneLowMagnitude)                                               rmalization_32[0][0]',        \n",
      "                                                                     'prune_low_magnitude_conv2d_4\n",
      "                                                                    0[0][0]']                     \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 23, 64)            1         ['prune_low_magnitude_add_10[0\n",
      " 32 (PruneLowMagnitude)                                             ][0]']                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 23, 16)            2066      ['prune_low_magnitude_re_lu_32\n",
      " _44 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 23, 16)            65        ['prune_low_magnitude_conv2d_4\n",
      " normalization_33 (PruneLow                                         4[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 23, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 33 (PruneLowMagnitude)                                             rmalization_33[0][0]']        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 23, 16)            1554      ['prune_low_magnitude_re_lu_33\n",
      " _45 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 23, 16)            65        ['prune_low_magnitude_conv2d_4\n",
      " normalization_34 (PruneLow                                         5[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 23, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 34 (PruneLowMagnitude)                                             rmalization_34[0][0]']        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 23, 64)            2114      ['prune_low_magnitude_re_lu_34\n",
      " _46 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 23, 64)            257       ['prune_low_magnitude_conv2d_4\n",
      " normalization_35 (PruneLow                                         6[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_11  (None, 1, 23, 64)            1         ['prune_low_magnitude_batch_no\n",
      "  (PruneLowMagnitude)                                               rmalization_35[0][0]',        \n",
      "                                                                     'prune_low_magnitude_re_lu_32\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 23, 64)            1         ['prune_low_magnitude_add_11[0\n",
      " 35 (PruneLowMagnitude)                                             ][0]']                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 23, 16)            2066      ['prune_low_magnitude_re_lu_35\n",
      " _48 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 23, 16)            65        ['prune_low_magnitude_conv2d_4\n",
      " normalization_36 (PruneLow                                         8[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 23, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 36 (PruneLowMagnitude)                                             rmalization_36[0][0]']        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 23, 16)            1554      ['prune_low_magnitude_re_lu_36\n",
      " _49 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 23, 16)            65        ['prune_low_magnitude_conv2d_4\n",
      " normalization_37 (PruneLow                                         9[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 23, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 37 (PruneLowMagnitude)                                             rmalization_37[0][0]']        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 23, 64)            2114      ['prune_low_magnitude_re_lu_37\n",
      " _50 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 23, 64)            257       ['prune_low_magnitude_conv2d_5\n",
      " normalization_38 (PruneLow                                         0[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 23, 64)            8258      ['prune_low_magnitude_re_lu_35\n",
      " _47 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_12  (None, 1, 23, 64)            1         ['prune_low_magnitude_batch_no\n",
      "  (PruneLowMagnitude)                                               rmalization_38[0][0]',        \n",
      "                                                                     'prune_low_magnitude_conv2d_4\n",
      "                                                                    7[0][0]']                     \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 23, 64)            1         ['prune_low_magnitude_add_12[0\n",
      " 38 (PruneLowMagnitude)                                             ][0]']                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 23, 16)            2066      ['prune_low_magnitude_re_lu_38\n",
      " _51 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 23, 16)            65        ['prune_low_magnitude_conv2d_5\n",
      " normalization_39 (PruneLow                                         1[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 23, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 39 (PruneLowMagnitude)                                             rmalization_39[0][0]']        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 23, 16)            1554      ['prune_low_magnitude_re_lu_39\n",
      " _52 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 23, 16)            65        ['prune_low_magnitude_conv2d_5\n",
      " normalization_40 (PruneLow                                         2[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 23, 16)            1         ['prune_low_magnitude_batch_no\n",
      " 40 (PruneLowMagnitude)                                             rmalization_40[0][0]']        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d  (None, 1, 23, 64)            2114      ['prune_low_magnitude_re_lu_40\n",
      " _53 (PruneLowMagnitude)                                            [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_  (None, 1, 23, 64)            257       ['prune_low_magnitude_conv2d_5\n",
      " normalization_41 (PruneLow                                         3[0][0]']                     \n",
      " Magnitude)                                                                                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_13  (None, 1, 23, 64)            1         ['prune_low_magnitude_batch_no\n",
      "  (PruneLowMagnitude)                                               rmalization_41[0][0]',        \n",
      "                                                                     'prune_low_magnitude_re_lu_38\n",
      "                                                                    [0][0]']                      \n",
      "                                                                                                  \n",
      " prune_low_magnitude_re_lu_  (None, 1, 23, 64)            1         ['prune_low_magnitude_add_13[0\n",
      " 41 (PruneLowMagnitude)                                             ][0]']                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_averag  (None, 1, 11, 64)            1         ['prune_low_magnitude_re_lu_41\n",
      " e_pooling2d_1 (PruneLowMag                                         [0][0]']                      \n",
      " nitude)                                                                                          \n",
      "                                                                                                  \n",
      " prune_low_magnitude_flatte  (None, 704)                  1         ['prune_low_magnitude_average_\n",
      " n_1 (PruneLowMagnitude)                                            pooling2d_1[0][0]']           \n",
      "                                                                                                  \n",
      " prune_low_magnitude_dense_  (None, 2)                    2820      ['prune_low_magnitude_flatten_\n",
      " 1 (PruneLowMagnitude)                                              1[0][0]']                     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 106895 (417.88 KB)\n",
      "Trainable params: 53922 (210.63 KB)\n",
      "Non-trainable params: 52973 (207.24 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Unstrucutred pruning with constant sparsity\n",
    "pruning_params = {\n",
    "        'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(0.5, begin_step=2000, frequency=100),\n",
    "}\n",
    "\n",
    "# Create a pruning model\n",
    "pruned_model_unstructured = tfmot.sparsity.keras.prune_low_magnitude(ResNet24, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "pruned_model_unstructured.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "                loss='categorical_crossentropy',\n",
    "                #loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "pruned_model_unstructured.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "256/256 [==============================] - 26s 28ms/step - loss: 0.6170 - accuracy: 0.8831 - val_loss: 0.4677 - val_accuracy: 0.8713 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 0.5442 - accuracy: 0.8943 - val_loss: 0.3971 - val_accuracy: 0.8679 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 0.5121 - accuracy: 0.8956 - val_loss: 0.5966 - val_accuracy: 0.8510 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "256/256 [==============================] - 6s 22ms/step - loss: 0.4373 - accuracy: 0.9136 - val_loss: 0.2640 - val_accuracy: 0.9180 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "256/256 [==============================] - 6s 22ms/step - loss: 0.3529 - accuracy: 0.9230 - val_loss: 0.4645 - val_accuracy: 0.8544 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 0.4503 - accuracy: 0.9112 - val_loss: 0.5140 - val_accuracy: 0.8674 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "256/256 [==============================] - 6s 22ms/step - loss: 0.4441 - accuracy: 0.9083 - val_loss: 0.3564 - val_accuracy: 0.9024 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "256/256 [==============================] - 6s 23ms/step - loss: 0.4227 - accuracy: 0.9149 - val_loss: 0.4136 - val_accuracy: 0.7947 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "256/256 [==============================] - 6s 24ms/step - loss: 0.4010 - accuracy: 0.9068 - val_loss: 0.1417 - val_accuracy: 0.9464 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 0.2842 - accuracy: 0.9310 - val_loss: 0.2153 - val_accuracy: 0.9200 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "256/256 [==============================] - 6s 22ms/step - loss: 0.2689 - accuracy: 0.9369 - val_loss: 0.1228 - val_accuracy: 0.9523 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 0.2472 - accuracy: 0.9422 - val_loss: 0.1369 - val_accuracy: 0.9533 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "256/256 [==============================] - 6s 22ms/step - loss: 0.2561 - accuracy: 0.9393 - val_loss: 0.2439 - val_accuracy: 0.9131 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "256/256 [==============================] - 6s 22ms/step - loss: 0.2228 - accuracy: 0.9448 - val_loss: 0.1418 - val_accuracy: 0.9437 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "256/256 [==============================] - 5s 21ms/step - loss: 0.2194 - accuracy: 0.9492 - val_loss: 0.1483 - val_accuracy: 0.9469 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.1936 - accuracy: 0.9548\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "256/256 [==============================] - 6s 23ms/step - loss: 0.1935 - accuracy: 0.9547 - val_loss: 0.1746 - val_accuracy: 0.9398 - lr: 5.0000e-04\n",
      "Epoch 16: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x198c2de21d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_model_unstructured.fit(X_train, y_train, \n",
    "            validation_data=(X_val, y_val), \n",
    "            epochs=epochs, \n",
    "            batch_size=batch_size,\n",
    "            callbacks=[es, lrs, pruning_callbacks.UpdatePruningStep()],\n",
    "            class_weight=class_weight) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned model loss:  0.39252224564552307\n",
      "Pruned model accuracy:  0.901098906993866\n",
      "Full-precision model accuracy:  0.8681318681318682\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the test set\n",
    "pruned_loss_unstructured, pruned_acc_unstructured = pruned_model_unstructured.evaluate(X_test, y_test, verbose=0)\n",
    "print('Pruned model loss: ', pruned_loss_unstructured)\n",
    "print('Pruned model accuracy: ', pruned_acc_unstructured)\n",
    "print('Full-precision model accuracy: ', accuracy_fp)\n",
    "\n",
    "# f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion to TF Lite\n",
    "pruned_model_unstructured_for_export = tfmot.sparsity.keras.strip_pruning(pruned_model_unstructured)\n",
    "\n",
    "# save the model\n",
    "pruned_model_unstructured.save('saved_models/ResNet24_pruned_unstructured.keras')  # The file needs to end with the .keras extension\n",
    "#print('Saved pruned Keras model to:', os.path.abspath(pruned_keras_file_unstructured))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\10744\\AppData\\Local\\Temp\\tmp29amt8lw\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\10744\\AppData\\Local\\Temp\\tmp29amt8lw\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned TFLite model to: g:\\MLonMCU\\Fall_Detection\\saved_models\\ResNet24_pruned_unstructured.tflite\n"
     ]
    }
   ],
   "source": [
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model_unstructured_for_export)\n",
    "pruned_tflite_model_unstructured = converter.convert()\n",
    "\n",
    "# Save the model\n",
    "pruned_tflite_file_unstructured = 'saved_models/ResNet24_pruned_unstructured.tflite'\n",
    "\n",
    "with open(pruned_tflite_file_unstructured, 'wb') as f:\n",
    "    f.write(pruned_tflite_model_unstructured)\n",
    "\n",
    "print('Saved pruned TFLite model to:', os.path.abspath(pruned_tflite_file_unstructured))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the unstructured pruned model:  77794\n",
      "Size of the full-precision model:  127396\n",
      "The achieved compression ratio is 1.00x\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# compare the size of the pruned model and the full-precision model\n",
    "print('Size of the unstructured pruned model: ', get_gzipped_model_size(pruned_tflite_file_unstructured))\n",
    "print('Size of the full-precision model: ', get_gzipped_model_size('saved_models/ResNet24.tflite'))\n",
    "print(\"The achieved compression ratio is %.2fx\" % (get_gzipped_model_size('saved_models/ResNet24_pruned_unstructured.tflite') / get_gzipped_model_size(pruned_tflite_file_unstructured)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet24\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 50, 9)]              0         []                            \n",
      "                                                                                                  \n",
      " quantize_layer_1 (Quantize  (None, 50, 9)                3         ['input_2[0][0]']             \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " quant_reshape_1 (QuantizeW  (None, 1, 50, 9)             1         ['quantize_layer_1[0][0]']    \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_conv2d_27 (QuantizeW  (None, 1, 48, 64)            1923      ['quant_reshape_1[0][0]']     \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_conv2d_28 (QuantizeW  (None, 1, 46, 64)            12483     ['quant_conv2d_27[0][0]']     \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_max_pooling2d_1 (Qua  (None, 1, 23, 64)            1         ['quant_conv2d_28[0][0]']     \n",
      " ntizeWrapperV2)                                                                                  \n",
      "                                                                                                  \n",
      " quant_conv2d_30 (QuantizeW  (None, 1, 23, 16)            1073      ['quant_max_pooling2d_1[0][0]'\n",
      " rapperV2)                                                          ]                             \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 16)            65        ['quant_conv2d_30[0][0]']     \n",
      " 21 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_21 (QuantizeWr  (None, 1, 23, 16)            3         ['quant_batch_normalization_21\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_31 (QuantizeW  (None, 1, 23, 16)            817       ['quant_re_lu_21[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 16)            65        ['quant_conv2d_31[0][0]']     \n",
      " 22 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_22 (QuantizeWr  (None, 1, 23, 16)            3         ['quant_batch_normalization_22\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_32 (QuantizeW  (None, 1, 23, 64)            1217      ['quant_re_lu_22[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 64)            259       ['quant_conv2d_32[0][0]']     \n",
      " 23 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_conv2d_29 (QuantizeW  (None, 1, 23, 64)            4291      ['quant_max_pooling2d_1[0][0]'\n",
      " rapperV2)                                                          ]                             \n",
      "                                                                                                  \n",
      " quant_add_7 (QuantizeWrapp  (None, 1, 23, 64)            1         ['quant_batch_normalization_23\n",
      " erV2)                                                              [0][0]',                      \n",
      "                                                                     'quant_conv2d_29[0][0]']     \n",
      "                                                                                                  \n",
      " quant_re_lu_23 (QuantizeWr  (None, 1, 23, 64)            3         ['quant_add_7[0][0]']         \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_conv2d_34 (QuantizeW  (None, 1, 23, 16)            1073      ['quant_re_lu_23[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 16)            65        ['quant_conv2d_34[0][0]']     \n",
      " 24 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_24 (QuantizeWr  (None, 1, 23, 16)            3         ['quant_batch_normalization_24\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_35 (QuantizeW  (None, 1, 23, 16)            817       ['quant_re_lu_24[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 16)            65        ['quant_conv2d_35[0][0]']     \n",
      " 25 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_25 (QuantizeWr  (None, 1, 23, 16)            3         ['quant_batch_normalization_25\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_36 (QuantizeW  (None, 1, 23, 64)            1217      ['quant_re_lu_25[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 64)            259       ['quant_conv2d_36[0][0]']     \n",
      " 26 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_conv2d_33 (QuantizeW  (None, 1, 23, 64)            4291      ['quant_re_lu_23[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_add_8 (QuantizeWrapp  (None, 1, 23, 64)            1         ['quant_batch_normalization_26\n",
      " erV2)                                                              [0][0]',                      \n",
      "                                                                     'quant_conv2d_33[0][0]']     \n",
      "                                                                                                  \n",
      " quant_re_lu_26 (QuantizeWr  (None, 1, 23, 64)            3         ['quant_add_8[0][0]']         \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_conv2d_37 (QuantizeW  (None, 1, 23, 16)            1073      ['quant_re_lu_26[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 16)            65        ['quant_conv2d_37[0][0]']     \n",
      " 27 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_27 (QuantizeWr  (None, 1, 23, 16)            3         ['quant_batch_normalization_27\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_38 (QuantizeW  (None, 1, 23, 16)            817       ['quant_re_lu_27[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 16)            65        ['quant_conv2d_38[0][0]']     \n",
      " 28 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_28 (QuantizeWr  (None, 1, 23, 16)            3         ['quant_batch_normalization_28\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_39 (QuantizeW  (None, 1, 23, 64)            1217      ['quant_re_lu_28[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 64)            259       ['quant_conv2d_39[0][0]']     \n",
      " 29 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_add_9 (QuantizeWrapp  (None, 1, 23, 64)            1         ['quant_batch_normalization_29\n",
      " erV2)                                                              [0][0]',                      \n",
      "                                                                     'quant_re_lu_26[0][0]']      \n",
      "                                                                                                  \n",
      " quant_re_lu_29 (QuantizeWr  (None, 1, 23, 64)            3         ['quant_add_9[0][0]']         \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_conv2d_41 (QuantizeW  (None, 1, 23, 16)            1073      ['quant_re_lu_29[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 16)            65        ['quant_conv2d_41[0][0]']     \n",
      " 30 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_30 (QuantizeWr  (None, 1, 23, 16)            3         ['quant_batch_normalization_30\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_42 (QuantizeW  (None, 1, 23, 16)            817       ['quant_re_lu_30[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 16)            65        ['quant_conv2d_42[0][0]']     \n",
      " 31 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_31 (QuantizeWr  (None, 1, 23, 16)            3         ['quant_batch_normalization_31\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_43 (QuantizeW  (None, 1, 23, 64)            1217      ['quant_re_lu_31[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 64)            259       ['quant_conv2d_43[0][0]']     \n",
      " 32 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_conv2d_40 (QuantizeW  (None, 1, 23, 64)            4291      ['quant_re_lu_29[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_add_10 (QuantizeWrap  (None, 1, 23, 64)            1         ['quant_batch_normalization_32\n",
      " perV2)                                                             [0][0]',                      \n",
      "                                                                     'quant_conv2d_40[0][0]']     \n",
      "                                                                                                  \n",
      " quant_re_lu_32 (QuantizeWr  (None, 1, 23, 64)            3         ['quant_add_10[0][0]']        \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_conv2d_44 (QuantizeW  (None, 1, 23, 16)            1073      ['quant_re_lu_32[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 16)            65        ['quant_conv2d_44[0][0]']     \n",
      " 33 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_33 (QuantizeWr  (None, 1, 23, 16)            3         ['quant_batch_normalization_33\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_45 (QuantizeW  (None, 1, 23, 16)            817       ['quant_re_lu_33[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 16)            65        ['quant_conv2d_45[0][0]']     \n",
      " 34 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_34 (QuantizeWr  (None, 1, 23, 16)            3         ['quant_batch_normalization_34\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_46 (QuantizeW  (None, 1, 23, 64)            1217      ['quant_re_lu_34[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 64)            259       ['quant_conv2d_46[0][0]']     \n",
      " 35 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_add_11 (QuantizeWrap  (None, 1, 23, 64)            1         ['quant_batch_normalization_35\n",
      " perV2)                                                             [0][0]',                      \n",
      "                                                                     'quant_re_lu_32[0][0]']      \n",
      "                                                                                                  \n",
      " quant_re_lu_35 (QuantizeWr  (None, 1, 23, 64)            3         ['quant_add_11[0][0]']        \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_conv2d_48 (QuantizeW  (None, 1, 23, 16)            1073      ['quant_re_lu_35[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 16)            65        ['quant_conv2d_48[0][0]']     \n",
      " 36 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_36 (QuantizeWr  (None, 1, 23, 16)            3         ['quant_batch_normalization_36\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_49 (QuantizeW  (None, 1, 23, 16)            817       ['quant_re_lu_36[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 16)            65        ['quant_conv2d_49[0][0]']     \n",
      " 37 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_37 (QuantizeWr  (None, 1, 23, 16)            3         ['quant_batch_normalization_37\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_50 (QuantizeW  (None, 1, 23, 64)            1217      ['quant_re_lu_37[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 64)            259       ['quant_conv2d_50[0][0]']     \n",
      " 38 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_conv2d_47 (QuantizeW  (None, 1, 23, 64)            4291      ['quant_re_lu_35[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_add_12 (QuantizeWrap  (None, 1, 23, 64)            1         ['quant_batch_normalization_38\n",
      " perV2)                                                             [0][0]',                      \n",
      "                                                                     'quant_conv2d_47[0][0]']     \n",
      "                                                                                                  \n",
      " quant_re_lu_38 (QuantizeWr  (None, 1, 23, 64)            3         ['quant_add_12[0][0]']        \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_conv2d_51 (QuantizeW  (None, 1, 23, 16)            1073      ['quant_re_lu_38[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 16)            65        ['quant_conv2d_51[0][0]']     \n",
      " 39 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_39 (QuantizeWr  (None, 1, 23, 16)            3         ['quant_batch_normalization_39\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_52 (QuantizeW  (None, 1, 23, 16)            817       ['quant_re_lu_39[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 16)            65        ['quant_conv2d_52[0][0]']     \n",
      " 40 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_re_lu_40 (QuantizeWr  (None, 1, 23, 16)            3         ['quant_batch_normalization_40\n",
      " apperV2)                                                           [0][0]']                      \n",
      "                                                                                                  \n",
      " quant_conv2d_53 (QuantizeW  (None, 1, 23, 64)            1217      ['quant_re_lu_40[0][0]']      \n",
      " rapperV2)                                                                                        \n",
      "                                                                                                  \n",
      " quant_batch_normalization_  (None, 1, 23, 64)            259       ['quant_conv2d_53[0][0]']     \n",
      " 41 (QuantizeWrapperV2)                                                                           \n",
      "                                                                                                  \n",
      " quant_add_13 (QuantizeWrap  (None, 1, 23, 64)            1         ['quant_batch_normalization_41\n",
      " perV2)                                                             [0][0]',                      \n",
      "                                                                     'quant_re_lu_38[0][0]']      \n",
      "                                                                                                  \n",
      " quant_re_lu_41 (QuantizeWr  (None, 1, 23, 64)            3         ['quant_add_13[0][0]']        \n",
      " apperV2)                                                                                         \n",
      "                                                                                                  \n",
      " quant_average_pooling2d_1   (None, 1, 11, 64)            3         ['quant_re_lu_41[0][0]']      \n",
      " (QuantizeWrapperV2)                                                                              \n",
      "                                                                                                  \n",
      " quant_flatten_1 (QuantizeW  (None, 704)                  1         ['quant_average_pooling2d_1[0]\n",
      " rapperV2)                                                          [0]']                         \n",
      "                                                                                                  \n",
      " quant_dense_1 (QuantizeWra  (None, 2)                    1415      ['quant_flatten_1[0][0]']     \n",
      " pperV2)                                                                                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 57536 (224.75 KB)\n",
      "Trainable params: 53922 (210.63 KB)\n",
      "Non-trainable params: 3614 (14.12 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# PQAT\n",
    "quant_aware_annotate_model = tfmot.quantization.keras.quantize_annotate_model(\n",
    "              pruned_model_unstructured_for_export)\n",
    "\n",
    "pruned_qat_model = tfmot.quantization.keras.quantize_apply(quant_aware_annotate_model,\n",
    "                   tfmot.experimental.combine.Default8BitPrunePreserveQuantizeScheme())\n",
    "\n",
    "pruned_qat_model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), \n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "pruned_qat_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (16344, 50, 9)\n",
      "y_train.shape:  (16344, 2)\n",
      "64\n",
      "Epoch 1/50\n",
      "256/256 [==============================] - 18s 36ms/step - loss: 0.8626 - accuracy: 0.8085 - val_loss: 0.2044 - val_accuracy: 0.9259 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 0.5317 - accuracy: 0.8858 - val_loss: 0.1963 - val_accuracy: 0.9254 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "256/256 [==============================] - 9s 33ms/step - loss: 0.3881 - accuracy: 0.9139 - val_loss: 0.2291 - val_accuracy: 0.9163 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 0.3343 - accuracy: 0.9206 - val_loss: 0.2809 - val_accuracy: 0.8955 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 0.2796 - accuracy: 0.9334 - val_loss: 0.1177 - val_accuracy: 0.9584 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 0.2337 - accuracy: 0.9496 - val_loss: 0.1673 - val_accuracy: 0.9418 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 0.1972 - accuracy: 0.9513 - val_loss: 0.1450 - val_accuracy: 0.9506 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "256/256 [==============================] - 7s 29ms/step - loss: 0.1906 - accuracy: 0.9560 - val_loss: 0.1600 - val_accuracy: 0.9496 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 0.2102 - accuracy: 0.9524 - val_loss: 0.2133 - val_accuracy: 0.9391 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "255/256 [============================>.] - ETA: 0s - loss: 0.1982 - accuracy: 0.9568\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
      "256/256 [==============================] - 8s 30ms/step - loss: 0.1990 - accuracy: 0.9569 - val_loss: 0.2425 - val_accuracy: 0.9347 - lr: 5.0000e-04\n",
      "Epoch 10: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x199086b7760>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\n",
    "print('X_train.shape: ', X_train.shape) # (16362, 50, 9)\n",
    "print('y_train.shape: ', y_train.shape) # (16362, 2)\n",
    "print(batch_size)\n",
    "pruned_qat_model.fit(X_train, y_train, \n",
    "            validation_data=(X_val, y_val), \n",
    "            epochs=epochs, \n",
    "            batch_size=batch_size,\n",
    "            callbacks=[es, lrs, pruning_callbacks.UpdatePruningStep()],\n",
    "            class_weight=class_weight) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned QAT model loss:  0.34742674231529236\n",
      "Pruned QAT model accuracy:  0.8846153616905212\n",
      "Full-precision model accuracy:  0.8681318681318682\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the test set\n",
    "pruned_qat_loss, pruned_qat_acc = pruned_qat_model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Pruned QAT model loss: ', pruned_qat_loss)\n",
    "print('Pruned QAT model accuracy: ', pruned_qat_acc)\n",
    "print('Full-precision model accuracy: ', accuracy_fp)\n",
    "# f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\10744\\AppData\\Local\\Temp\\tmp497uwn6n\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\10744\\AppData\\Local\\Temp\\tmp497uwn6n\\assets\n",
      "g:\\python\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "109368"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(pruned_qat_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "pruned_qat_tflite_model = converter.convert()\n",
    "\n",
    "# Save the model\n",
    "open(\"saved_models/ResNet24_pruned_qat.tflite\", \"wb\").write(pruned_qat_tflite_model)\n",
    "\n",
    "# write TFLite model to a C source (or header) file\n",
    "#c_model_name = 'pruned_qat_fmnist'\n",
    "\n",
    "#with open('cfiles/' + c_model_name + '.h', 'w') as file:\n",
    "#    file.write(hex_to_c_array(pruned_qat_tflite_model, c_model_name))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:  {'name': 'serving_default_input_2:0', 'index': 0, 'shape': array([ 1, 50,  9]), 'shape_signature': array([-1, 50,  9]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "output:  {'name': 'StatefulPartitionedCall:0', 'index': 108, 'shape': array([1, 2]), 'shape_signature': array([-1,  2]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "Evaluated on  0 .\n",
      "Evaluated on  100 .\n"
     ]
    }
   ],
   "source": [
    "# test the quantized model\n",
    "X_test_int8 = X_test.astype('float32')\n",
    "y_test_int8 = y_test.astype('int8')\n",
    "# Load the model into an interpreter\n",
    "interpreter = tf.lite.Interpreter(model_content= pruned_qat_tflite_model)\n",
    "# Allocate memory for the model's input Tensor(s)\n",
    "interpreter.allocate_tensors()\n",
    "# Get the model input and output details\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "print(\"input: \", input_details)\n",
    "print(\"output: \", output_details)\n",
    "predictions = np.zeros(X_test.shape[0])\n",
    "for i, test_data in enumerate(X_test_int8):\n",
    "    test_data = np.expand_dims(test_data, axis=0)\n",
    "    #print(test_data.shape)\n",
    "    interpreter.set_tensor(input_details[\"index\"], test_data)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "    if i%100 == 0:\n",
    "        # print(\"Evaluated on %d images.\" % test_image_index)\n",
    "        print('Evaluated on ', i, '.')\n",
    "    predictions[i] = output.argmax()\n",
    "\n",
    "gt = np.argmax(y_test_int8, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite Model size with 8-bit quantization: 106 KB\n",
      "TFLite Model size without quantization: 226 KB\n",
      "\n",
      "Reduction in model size by a factor of 2.119121\n",
      "accuracy:  0.9010989010989011\n",
      "Confusion matrix, without normalization\n",
      "[[81  8]\n",
      " [10 83]]\n",
      "f1_score:  0.9021739130434783\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the model size for the 8-bit quantized TFLite model\n",
    "tflite_in_kb = os.path.getsize('saved_models/ResNet24.tflite') / 1024\n",
    "# ResNet24_tflite tflite_quant_in_kb\n",
    "tflite_quant_in_kb = os.path.getsize('saved_models/ResNet24_pruned_qat.tflite') / 1024\n",
    "print(\"TFLite Model size with 8-bit quantization: %d KB\" % tflite_quant_in_kb)\n",
    "\n",
    "print(\"TFLite Model size without quantization: %d KB\" % tflite_in_kb)\n",
    "\n",
    "# Determine the reduction in model size\n",
    "print(\"\\nReduction in model size by a factor of %f\" % (tflite_in_kb / tflite_quant_in_kb))\n",
    "\n",
    "accuracy = (predictions == gt).mean()\n",
    "print('accuracy: ', accuracy)\n",
    "# compute the confusion matrix\n",
    "cm = confusion_matrix(gt, predictions)\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(cm, classes=['Not Fall', 'Fall'], normalize=False, title='Confusion Matrix')\n",
    "f1_score = 2 * cm[1][1] / (2 * cm[1][1] + cm[0][1] + cm[1][0])\n",
    "print('f1_score: ', f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the pruned QAT model:  53304\n",
      "Size of th QAT model:  69159\n",
      "Size of the full-precision model:  201914\n",
      "The achieved compression ratio is 3.79x\n"
     ]
    }
   ],
   "source": [
    "# compare the size of the pruned model and the full-precision model\n",
    "print('Size of the pruned QAT model: ', get_gzipped_model_size('saved_models/ResNet24_pruned_qat.tflite'))\n",
    "print('Size of th QAT model: ', get_gzipped_model_size( 'saved_models/ResNet24_quant_int8_qat.tflite'))\n",
    "print('Size of the full-precision model: ', get_gzipped_model_size('saved_models/ResNet24.tflite'))\n",
    "print(\"The achieved compression ratio is %.2fx\" % (get_gzipped_model_size('saved_models/ResNet24.tflite') / get_gzipped_model_size('saved_models/ResNet24_pruned_qat.tflite')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fall_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
